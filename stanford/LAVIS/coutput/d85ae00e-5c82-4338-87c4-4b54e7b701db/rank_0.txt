WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 00:31:02.777900] Starting job[2023-11-13 00:31:02.777902] Starting job[2023-11-13 00:31:02.777904] Starting job


[2023-11-13 00:31:02.777907] Starting job[2023-11-13 00:31:02.777910] Starting job

[2023-11-13 00:31:02.777910] Starting job
| distributed init (rank 0, world 12): env://
| distributed init (rank 5, world 12): env://
| distributed init (rank 2, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 4, world 12): env://
| distributed init (rank 1, world 12): env://
2023-11-13 00:31:11,382 [INFO] 
=====  Running Parameters    =====
2023-11-13 00:31:11,383 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 00:31:11,383 [INFO] 
======  Dataset Attributes  ======
2023-11-13 00:31:11,383 [INFO] 
======== coco_caption =======
2023-11-13 00:31:11,383 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 00:31:11,383 [INFO] 
======  Model Attributes  ======
2023-11-13 00:31:11,383 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 00:31:11,385 [INFO] Building datasets...
2023-11-13 00:31:27,192 [INFO] number of trainable parameters: 446290492
2023-11-13 00:31:27,490 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 00:31:27,490 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 00:31:27,490 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 00:31:27,490 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 00:31:27,491 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 00:31:27,494 [INFO] Start training
2023-11-13 00:31:27,504 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 166/4722]  eta: 5:23:03  lr: 0.000010  loss: 6.6746  loss_lm: 6.6746 (6.6746)  time: 4.2545  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 166/4722]  eta: 5:23:19  lr: 0.000010  loss: 6.9342  loss_lm: 6.9342 (6.9342)  time: 4.2581  data: 0.0000  max mem: 18863Train: data epoch: [0]  [ 166/4722]  eta: 5:23:06  lr: 0.000010  loss: 7.0136  loss_lm: 7.0136 (7.0136)  time: 4.2552  data: 0.0000  max mem: 18863Train: data epoch: [0]  [ 166/4722]  eta: 5:23:06  lr: 0.000010  loss: 7.0886  loss_lm: 7.0886 (7.0886)  time: 4.2552  data: 0.0000  max mem: 18863Train: data epoch: [0]  [ 166/4722]  eta: 5:23:09  lr: 0.000010  loss: 7.2415  loss_lm: 7.2415 (7.2415)  time: 4.2558  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 166/4722]  eta: 5:23:29  lr: 0.000010  loss: 6.8821  loss_lm: 6.8821 (6.8821)  time: 4.2602  data: 0.0000  max mem: 18863


2023-11-13 00:31:31,773 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 167/4722]  eta: 3:38:48  lr: 0.000010  loss: 6.9779  loss_lm: 6.9342 (6.9560)  time: 2.8822  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 167/4722]  eta: 3:38:40  lr: 0.000010  loss: 6.5527  loss_lm: 6.5527 (6.6137)  time: 2.8804  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 167/4722]  eta: 3:38:41  lr: 0.000010  loss: 6.8363  loss_lm: 6.8363 (6.9624)  time: 2.8807  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 167/4722]  eta: 3:38:53  lr: 0.000010  loss: 6.8002  loss_lm: 6.8002 (6.8411)  time: 2.8832  data: 0.0000  max mem: 18863

Train: data epoch: [0]  [ 167/4722]  eta: 3:38:43  lr: 0.000010  loss: 6.5113  loss_lm: 6.5113 (6.8764)  time: 2.8810  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 167/4722]  eta: 3:38:41  lr: 0.000010  loss: 7.2211  loss_lm: 7.0136 (7.1173)  time: 2.8807  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 168/4722]  eta: 3:03:09  lr: 0.000010  loss: 7.1303  loss_lm: 6.9779 (7.0141)  time: 2.4132  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 168/4722]  eta: 3:03:04  lr: 0.000010  loss: 6.4533  loss_lm: 6.5527 (6.5602)  time: 2.4120  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 168/4722]  eta: 3:03:05  lr: 0.000010  loss: 6.7776  loss_lm: 6.8363 (6.9008)  time: 2.4122  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 168/4722]  eta: 3:03:12  lr: 0.000010  loss: 6.8322  loss_lm: 6.8322 (6.8382)  time: 2.4139  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 168/4722]  eta: 3:03:06  lr: 0.000010  loss: 6.7618  loss_lm: 6.7618 (6.8382)  time: 2.4124  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 168/4722]  eta: 3:03:05  lr: 0.000010  loss: 6.8684  loss_lm: 7.0136 (7.0344)  time: 2.4122  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 169/4722]  eta: 2:45:10  lr: 0.000010  loss: 6.6401  loss_lm: 6.5527 (6.5802)  time: 2.1766  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 169/4722]  eta: 2:45:14  lr: 0.000010  loss: 6.6980  loss_lm: 6.9342 (6.9351)  time: 2.1775  data: 0.0000  max mem: 18977

Train: data epoch: [0]  [ 169/4722]  eta: 2:45:10  lr: 0.000010  loss: 7.0319  loss_lm: 7.0136 (7.0337)  time: 2.1768  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 169/4722]  eta: 2:45:16  lr: 0.000010  loss: 6.8214  loss_lm: 6.8214 (6.8340)  time: 2.1780  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 169/4722]  eta: 2:45:10  lr: 0.000010  loss: 7.0562  loss_lm: 6.8363 (6.9397)  time: 2.1768  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 169/4722]  eta: 2:45:11  lr: 0.000010  loss: 6.7579  loss_lm: 6.7579 (6.8181)  time: 2.1769  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:31:37,687 [INFO] Saving checkpoint at iters: 170 and epoch: 0
2023-11-13 00:31:37,692 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:31:42,954 [INFO] Saved successfully
2023-11-13 00:31:42,955 [INFO] Averaged stats: lr: 0.0000  loss: 6.8292  loss_lm: 6.8292
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:24  lr: 0.000010  loss: 6.8103  loss_lm: 6.8214 (6.8292)  time: 3.0896  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:20  lr: 0.000010  loss: 6.5659  loss_lm: 6.7579 (6.7677)  time: 3.0888  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:19  lr: 0.000010  loss: 6.5450  loss_lm: 6.8363 (6.8607)  time: 3.0886  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:19  lr: 0.000010  loss: 6.8734  loss_lm: 7.0136 (7.0017)  time: 3.0886  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:22  lr: 0.000010  loss: 7.0646  loss_lm: 6.9779 (6.9610)  time: 3.0893  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 170/4722]  eta: 3:54:19  lr: 0.000010  loss: 6.7695  loss_lm: 6.6401 (6.6180)  time: 3.0886  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 171/4722]  eta: 3:33:54  lr: 0.000010  loss: 6.9750  loss_lm: 6.9750 (6.9972)  time: 2.8201  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 171/4722]  eta: 3:33:53  lr: 0.000010  loss: 7.1555  loss_lm: 6.6401 (6.7076)  time: 2.8200  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 171/4722]  eta: 3:33:58  lr: 0.000010  loss: 6.6462  loss_lm: 6.8103 (6.7987)  time: 2.8210  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 171/4722]  eta: 3:33:54  lr: 0.000010  loss: 7.0107  loss_lm: 6.7579 (6.8082)  time: 2.8202  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 171/4722]  eta: 3:33:56  lr: 0.000010  loss: 6.9614  loss_lm: 6.9614 (6.9611)  time: 2.8206  data: 0.0000  max mem: 18977

Train: data epoch: [0]  [ 171/4722]  eta: 3:33:54  lr: 0.000010  loss: 6.6265  loss_lm: 6.7776 (6.8217)  time: 2.8201  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 172/4722]  eta: 3:19:39  lr: 0.000010  loss: 6.3534  loss_lm: 6.6401 (6.6570)  time: 2.6328  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 172/4722]  eta: 3:19:39  lr: 0.000010  loss: 6.8289  loss_lm: 6.9750 (6.9732)  time: 2.6329  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 172/4722]  eta: 3:19:40  lr: 0.000010  loss: 6.4201  loss_lm: 6.7579 (6.7527)  time: 2.6330  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 172/4722]  eta: 3:19:43  lr: 0.000010  loss: 6.7080  loss_lm: 6.8103 (6.7858)  time: 2.6338  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 172/4722]  eta: 3:19:39  lr: 0.000010  loss: 6.8047  loss_lm: 6.8047 (6.8193)  time: 2.6329  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 172/4722]  eta: 3:19:41  lr: 0.000010  loss: 6.6063  loss_lm: 6.9614 (6.9104)  time: 2.6333  data: 0.0000  max mem: 18977

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 173/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.7812  loss_lm: 6.6401 (6.6725)  time: 2.4884  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 173/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.4691  loss_lm: 6.7776 (6.7755)  time: 2.4884  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 173/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.8047  loss_lm: 6.8734 (6.9521)  time: 2.4884  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 173/4722]  eta: 3:08:41  lr: 0.000010  loss: 6.7468  loss_lm: 6.9342 (6.8899)  time: 2.4888  data: 0.0000  max mem: 18977Train: data epoch: [0]  [ 173/4722]  eta: 3:08:43  lr: 0.000010  loss: 6.7184  loss_lm: 6.8002 (6.7774)  time: 2.4892  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 173/4722]  eta: 3:08:40  lr: 0.000010  loss: 7.0047  loss_lm: 6.7579 (6.7842)  time: 2.4885  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 174/4722]  eta: 3:00:02  lr: 0.000010  loss: 7.1193  loss_lm: 6.6746 (6.7222)  time: 2.3752  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 174/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.8151  loss_lm: 6.8734 (6.9369)  time: 2.3752  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 174/4722]  eta: 3:00:05  lr: 0.000010  loss: 6.6899  loss_lm: 6.8002 (6.7676)  time: 2.3759  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 174/4722]  eta: 3:00:04  lr: 0.000010  loss: 6.8720  loss_lm: 6.9342 (6.8879)  time: 2.3756  data: 0.0000  max mem: 18977

Train: data epoch: [0]  [ 174/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.5374  loss_lm: 6.7776 (6.7490)  time: 2.3752  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 174/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.7892  loss_lm: 6.7618 (6.7848)  time: 2.3753  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:31:50,361 [INFO] Saving checkpoint at iters: 175 and epoch: 0
2023-11-13 00:31:50,365 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:31:55,862 [INFO] Saved successfully
2023-11-13 00:31:55,863 [INFO] Averaged stats: lr: 0.0000  loss: 6.7714  loss_lm: 6.7714
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:52  lr: 0.000010  loss: 6.8056  loss_lm: 6.8002 (6.7714)  time: 2.8354  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:51  lr: 0.000010  loss: 6.9122  loss_lm: 6.9122 (6.8904)  time: 2.8351  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:49  lr: 0.000010  loss: 6.3814  loss_lm: 6.6401 (6.6881)  time: 2.8348  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:50  lr: 0.000010  loss: 6.8705  loss_lm: 6.7618 (6.7934)  time: 2.8349  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:49  lr: 0.000010  loss: 6.2660  loss_lm: 6.6265 (6.7007)  time: 2.8348  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 175/4722]  eta: 3:34:49  lr: 0.000010  loss: 6.9783  loss_lm: 6.8734 (6.9410)  time: 2.8348  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 176/4722]  eta: 3:25:26  lr: 0.000010  loss: 6.7650  loss_lm: 6.8734 (6.9250)  time: 2.7115  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 176/4722]  eta: 3:25:26  lr: 0.000010  loss: 6.6006  loss_lm: 6.7618 (6.7758)  time: 2.7115  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 176/4722]  eta: 3:25:29  lr: 0.000010  loss: 6.2898  loss_lm: 6.8002 (6.7277)  time: 2.7121  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 176/4722]  eta: 3:25:27  lr: 0.000010  loss: 6.5110  loss_lm: 6.9122 (6.8559)  time: 2.7117  data: 0.0000  max mem: 18977

Train: data epoch: [0]  [ 176/4722]  eta: 3:25:26  lr: 0.000010  loss: 6.4834  loss_lm: 6.6265 (6.6810)  time: 2.7115  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 176/4722]  eta: 3:25:26  lr: 0.000010  loss: 6.6946  loss_lm: 6.6746 (6.6887)  time: 2.7114  data: 0.0000  max mem: 19014
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 177/4722]  eta: 3:17:34  lr: 0.000010  loss: 6.3345  loss_lm: 6.5450 (6.6521)  time: 2.6083  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 177/4722]  eta: 3:17:34  lr: 0.000010  loss: 6.7360  loss_lm: 6.8684 (6.9093)  time: 2.6083  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 177/4722]  eta: 3:17:34  lr: 0.000010  loss: 6.7034  loss_lm: 6.7579 (6.7698)  time: 2.6083  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 177/4722]  eta: 3:17:37  lr: 0.000010  loss: 7.0416  loss_lm: 6.8002 (6.7538)  time: 2.6089  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 177/4722]  eta: 3:17:35  lr: 0.000010  loss: 6.6815  loss_lm: 6.8720 (6.8414)  time: 2.6086  data: 0.0000  max mem: 18977Train: data epoch: [0]  [ 177/4722]  eta: 3:17:34  lr: 0.000010  loss: 6.5813  loss_lm: 6.6401 (6.6797)  time: 2.6083  data: 0.0000  max mem: 19014

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 178/4722]  eta: 3:10:56  lr: 0.000010  loss: 6.6589  loss_lm: 6.8684 (6.8900)  time: 2.5212  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 178/4722]  eta: 3:10:56  lr: 0.000010  loss: 7.2131  loss_lm: 6.6265 (6.6953)  time: 2.5212  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 178/4722]  eta: 3:10:57  lr: 0.000010  loss: 7.0117  loss_lm: 6.9122 (6.8545)  time: 2.5215  data: 0.0000  max mem: 18977Train: data epoch: [0]  [ 178/4722]  eta: 3:10:58  lr: 0.000010  loss: 6.4305  loss_lm: 6.8002 (6.7289)  time: 2.5217  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 178/4722]  eta: 3:10:56  lr: 0.000010  loss: 6.5927  loss_lm: 6.6401 (6.6730)  time: 2.5212  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 178/4722]  eta: 3:10:56  lr: 0.000010  loss: 7.1458  loss_lm: 6.7618 (6.7987)  time: 2.5213  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 179/4722]  eta: 3:05:19  lr: 0.000010  loss: 7.1221  loss_lm: 6.8002 (6.7570)  time: 2.4475  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 179/4722]  eta: 3:05:16  lr: 0.000010  loss: 6.7763  loss_lm: 6.6265 (6.7011)  time: 2.4470  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 179/4722]  eta: 3:05:16  lr: 0.000010  loss: 6.8785  loss_lm: 6.8684 (6.8892)  time: 2.4471  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 179/4722]  eta: 3:05:17  lr: 0.000010  loss: 7.0316  loss_lm: 6.7618 (6.8154)  time: 2.4471  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 179/4722]  eta: 3:05:16  lr: 0.000010  loss: 6.8355  loss_lm: 6.6401 (6.6846)  time: 2.4470  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 179/4722]  eta: 3:05:17  lr: 0.000010  loss: 6.4717  loss_lm: 6.8720 (6.8271)  time: 2.4473  data: 0.0000  max mem: 18977
2023-11-13 00:32:03,256 [INFO] Saving checkpoint at iters: 180 and epoch: 0
2023-11-13 00:32:03,261 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:32:09,057 [INFO] Saved successfully
2023-11-13 00:32:09,060 [INFO] Averaged stats: lr: 0.0000  loss: 6.7396  loss_lm: 6.7396
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:41  lr: 0.000010  loss: 6.4952  loss_lm: 6.8002 (6.7396)  time: 2.7700  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:39  lr: 0.000010  loss: 6.7663  loss_lm: 6.8684 (6.8810)  time: 2.7695  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:39  lr: 0.000010  loss: 6.4979  loss_lm: 6.7618 (6.7942)  time: 2.7695  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:39  lr: 0.000010  loss: 6.5837  loss_lm: 6.8720 (6.8109)  time: 2.7697  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:38  lr: 0.000010  loss: 6.5800  loss_lm: 6.6401 (6.6777)  time: 2.7695  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 180/4722]  eta: 3:29:39  lr: 0.000010  loss: 6.9596  loss_lm: 6.7763 (6.7183)  time: 2.7695  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 181/4722]  eta: 3:23:29  lr: 0.000010  loss: 6.6433  loss_lm: 6.8289 (6.8661)  time: 2.6888  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 181/4722]  eta: 3:23:29  lr: 0.000010  loss: 6.8090  loss_lm: 6.6401 (6.6859)  time: 2.6888  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 181/4722]  eta: 3:23:29  lr: 0.000010  loss: 6.6601  loss_lm: 6.7579 (6.7858)  time: 2.6888  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 181/4722]  eta: 3:23:30  lr: 0.000010  loss: 7.1047  loss_lm: 6.8720 (6.8293)  time: 2.6890  data: 0.0000  max mem: 18977Train: data epoch: [0]  [ 181/4722]  eta: 3:23:31  lr: 0.000010  loss: 7.0326  loss_lm: 6.8002 (6.7579)  time: 2.6893  data: 0.0000  max mem: 18995

Train: data epoch: [0]  [ 181/4722]  eta: 3:23:29  lr: 0.000010  loss: 6.4752  loss_lm: 6.6265 (6.7031)  time: 2.6888  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 182/4722]  eta: 3:18:03  lr: 0.000010  loss: 6.3272  loss_lm: 6.6401 (6.6648)  time: 2.6175  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 182/4722]  eta: 3:18:03  lr: 0.000010  loss: 6.9223  loss_lm: 6.8684 (6.8694)  time: 2.6176  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 182/4722]  eta: 3:18:03  lr: 0.000010  loss: 6.8521  loss_lm: 6.7763 (6.7119)  time: 2.6175  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 182/4722]  eta: 3:18:03  lr: 0.000010  loss: 6.7168  loss_lm: 6.7579 (6.7817)  time: 2.6176  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 182/4722]  eta: 3:18:04  lr: 0.000010  loss: 6.3855  loss_lm: 6.8720 (6.8032)  time: 2.6177  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 182/4722]  eta: 3:18:05  lr: 0.000010  loss: 6.7068  loss_lm: 6.8002 (6.7549)  time: 2.6180  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 183/4722]  eta: 3:13:11  lr: 0.000010  loss: 6.8250  loss_lm: 6.6401 (6.6737)  time: 2.5538  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 183/4722]  eta: 3:13:12  lr: 0.000010  loss: 6.7122  loss_lm: 6.8289 (6.8607)  time: 2.5539  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 183/4722]  eta: 3:13:11  lr: 0.000010  loss: 6.9628  loss_lm: 6.7763 (6.7258)  time: 2.5539  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 183/4722]  eta: 3:13:12  lr: 0.000010  loss: 6.8291  loss_lm: 6.7579 (6.7844)  time: 2.5539  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 183/4722]  eta: 3:13:13  lr: 0.000010  loss: 6.6667  loss_lm: 6.7184 (6.7500)  time: 2.5543  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 183/4722]  eta: 3:13:12  lr: 0.000010  loss: 6.7623  loss_lm: 6.7623 (6.8009)  time: 2.5540  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 184/4722]  eta: 3:08:50  lr: 0.000010  loss: 6.5767  loss_lm: 6.6401 (6.6686)  time: 2.4967  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 184/4722]  eta: 3:08:50  lr: 0.000010  loss: 7.2214  loss_lm: 6.7618 (6.8074)  time: 2.4968  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 184/4722]  eta: 3:08:50  lr: 0.000010  loss: 6.6871  loss_lm: 6.8289 (6.8516)  time: 2.4968  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 184/4722]  eta: 3:08:50  lr: 0.000010  loss: 6.2032  loss_lm: 6.7763 (6.6983)  time: 2.4967  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 184/4722]  eta: 3:08:50  lr: 0.000010  loss: 6.4728  loss_lm: 6.7623 (6.7836)  time: 2.4969  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 184/4722]  eta: 3:08:51  lr: 0.000010  loss: 6.7468  loss_lm: 6.7468 (6.7498)  time: 2.4971  data: 0.0000  max mem: 18995
2023-11-13 00:32:16,433 [INFO] Saving checkpoint at iters: 185 and epoch: 0
2023-11-13 00:32:16,438 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:32:21,651 [INFO] Saved successfully
2023-11-13 00:32:21,653 [INFO] Averaged stats: lr: 0.0000  loss: 6.7295  loss_lm: 6.7295
Train: data epoch: [0]  [ 185/4722]  eta: 3:24:40  lr: 0.000010  loss: 6.3438  loss_lm: 6.7184 (6.7295)  time: 2.7068  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 185/4722]  eta: 3:24:39  lr: 0.000010  loss: 6.2999  loss_lm: 6.7468 (6.7594)  time: 2.7065  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 185/4722]  eta: 3:24:38  lr: 0.000010  loss: 6.4668  loss_lm: 6.5927 (6.6585)  time: 2.7064  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 185/4722]  eta: 3:24:38  lr: 0.000010  loss: 6.4715  loss_lm: 6.6265 (6.6870)  time: 2.7064  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 185/4722]  eta: 3:24:39  lr: 0.000010  loss: 6.5309  loss_lm: 6.7579 (6.7936)  time: 2.7064  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 185/4722]  eta: 3:24:39  lr: 0.000010  loss: 6.4561  loss_lm: 6.8151 (6.8318)  time: 2.7064  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 186/4722]  eta: 3:20:09  lr: 0.000010  loss: 6.4436  loss_lm: 6.5813 (6.6483)  time: 2.5672  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 186/4722]  eta: 3:20:09  lr: 0.000010  loss: 6.4842  loss_lm: 6.5450 (6.6773)  time: 2.5672  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 186/4722]  eta: 3:20:10  lr: 0.000010  loss: 6.9007  loss_lm: 6.7468 (6.7662)  time: 2.5672  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 186/4722]  eta: 3:20:09  lr: 0.000010  loss: 6.9674  loss_lm: 6.8151 (6.8383)  time: 2.5672  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 186/4722]  eta: 3:20:09  lr: 0.000010  loss: 6.5892  loss_lm: 6.7168 (6.7838)  time: 2.5672  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 186/4722]  eta: 3:20:11  lr: 0.000010  loss: 6.5101  loss_lm: 6.7080 (6.7191)  time: 2.5674  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 187/4722]  eta: 3:16:07  lr: 0.000010  loss: 6.8306  loss_lm: 6.7468 (6.7691)  time: 2.5661  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 187/4722]  eta: 3:16:07  lr: 0.000010  loss: 6.6294  loss_lm: 6.7168 (6.7768)  time: 2.5661  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 187/4722]  eta: 3:16:06  lr: 0.000010  loss: 6.8735  loss_lm: 6.5450 (6.6862)  time: 2.5661  data: 0.0000  max mem: 18876Train: data epoch: [0]  [ 187/4722]  eta: 3:16:07  lr: 0.000010  loss: 6.7369  loss_lm: 6.8047 (6.8336)  time: 2.5661  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 187/4722]  eta: 3:16:06  lr: 0.000010  loss: 6.2959  loss_lm: 6.5813 (6.6322)  time: 2.5661  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 187/4722]  eta: 3:16:08  lr: 0.000010  loss: 6.4616  loss_lm: 6.7068 (6.7074)  time: 2.5662  data: 0.0000  max mem: 18995

Train: data epoch: [0]  [ 188/4722]  eta: 3:12:23  lr: 0.000010  loss: 6.7191  loss_lm: 6.5927 (6.6360)  time: 2.5662  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 188/4722]  eta: 3:12:23  lr: 0.000010  loss: 6.1814  loss_lm: 6.5374 (6.6643)  time: 2.5662  data: 0.0000  max mem: 18876Train: data epoch: [0]  [ 188/4722]  eta: 3:12:24  lr: 0.000010  loss: 6.8257  loss_lm: 6.8047 (6.8333)  time: 2.5662  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 188/4722]  eta: 3:12:24  lr: 0.000010  loss: 7.0200  loss_lm: 6.7468 (6.7800)  time: 2.5662  data: 0.0000  max mem: 18977
Train: data epoch: [0]  [ 188/4722]  eta: 3:12:25  lr: 0.000010  loss: 6.3629  loss_lm: 6.6899 (6.6924)  time: 2.5663  data: 0.0000  max mem: 18995
Train: data epoch: [0]  [ 188/4722]  eta: 3:12:24  lr: 0.000010  loss: 7.0671  loss_lm: 6.7168 (6.7894)  time: 2.5662  data: 0.0000  max mem: 18865
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 00:38:51.415071] Starting job[2023-11-13 00:38:51.415072] Starting job

[2023-11-13 00:38:51.415077] Starting job[2023-11-13 00:38:51.415079] Starting job[2023-11-13 00:38:51.415077] Starting job


[2023-11-13 00:38:51.415087] Starting job
| distributed init (rank 2, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 4, world 12): env://
| distributed init (rank 0, world 12): env://
| distributed init (rank 1, world 12): env://
| distributed init (rank 5, world 12): env://
2023-11-13 00:38:59,613 [INFO] 
=====  Running Parameters    =====
2023-11-13 00:38:59,613 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 00:38:59,613 [INFO] 
======  Dataset Attributes  ======
2023-11-13 00:38:59,613 [INFO] 
======== coco_caption =======
2023-11-13 00:38:59,614 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 00:38:59,614 [INFO] 
======  Model Attributes  ======
2023-11-13 00:38:59,614 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 00:38:59,615 [INFO] Building datasets...
2023-11-13 00:39:14,679 [INFO] number of trainable parameters: 446290492
2023-11-13 00:39:14,979 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 00:39:14,979 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 00:39:14,979 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 00:39:14,979 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 00:39:14,980 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 00:39:14,983 [INFO] Start training
2023-11-13 00:39:14,994 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 186/4722]  eta: 5:15:54  lr: 0.000010  loss: 6.4897  loss_lm: 6.4897 (6.4897)  time: 4.1786  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 186/4722]  eta: 5:15:51  lr: 0.000010  loss: 6.4472  loss_lm: 6.4472 (6.4472)  time: 4.1779  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 186/4722]  eta: 5:16:04  lr: 0.000010  loss: 6.8837  loss_lm: 6.8837 (6.8837)  time: 4.1810  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 186/4722]  eta: 5:16:06  lr: 0.000010  loss: 6.9387  loss_lm: 6.9387 (6.9387)  time: 4.1814  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 186/4722]  eta: 5:15:55  lr: 0.000010  loss: 6.5982  loss_lm: 6.5982 (6.5982)  time: 4.1789  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 186/4722]  eta: 5:16:17  lr: 0.000010  loss: 6.5266  loss_lm: 6.5266 (6.5266)  time: 4.1837  data: 0.0000  max mem: 18866



2023-11-13 00:39:19,187 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 187/4722]  eta: 3:34:00  lr: 0.000010  loss: 6.3282  loss_lm: 6.3282 (6.3877)  time: 2.8313  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 187/4722]  eta: 3:34:01  lr: 0.000010  loss: 6.9367  loss_lm: 6.4897 (6.7132)  time: 2.8317  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 187/4722]  eta: 3:34:06  lr: 0.000010  loss: 6.8750  loss_lm: 6.8750 (6.8793)  time: 2.8328  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 187/4722]  eta: 3:34:02  lr: 0.000010  loss: 6.6426  loss_lm: 6.5982 (6.6204)  time: 2.8318  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 187/4722]  eta: 3:34:07  lr: 0.000010  loss: 6.7626  loss_lm: 6.7626 (6.8507)  time: 2.8330  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 187/4722]  eta: 3:34:13  lr: 0.000010  loss: 6.4751  loss_lm: 6.4751 (6.5009)  time: 2.8342  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:41  lr: 0.000010  loss: 6.7265  loss_lm: 6.4472 (6.5006)  time: 2.3778  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:42  lr: 0.000010  loss: 6.1715  loss_lm: 6.4897 (6.5326)  time: 2.3781  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:49  lr: 0.000010  loss: 6.3893  loss_lm: 6.4751 (6.4637)  time: 2.3797  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:45  lr: 0.000010  loss: 7.0521  loss_lm: 6.8837 (6.9369)  time: 2.3788  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:46  lr: 0.000010  loss: 6.8125  loss_lm: 6.8125 (6.8379)  time: 2.3790  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 188/4722]  eta: 2:59:42  lr: 0.000010  loss: 7.0980  loss_lm: 6.6426 (6.7796)  time: 2.3782  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:36  lr: 0.000010  loss: 6.7784  loss_lm: 6.4472 (6.5701)  time: 2.1523  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:36  lr: 0.000010  loss: 6.5917  loss_lm: 6.4897 (6.5474)  time: 2.1524  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:39  lr: 0.000010  loss: 6.6844  loss_lm: 6.7626 (6.7995)  time: 2.1531  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:39  lr: 0.000010  loss: 6.9602  loss_lm: 6.8837 (6.9427)  time: 2.1530  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:37  lr: 0.000010  loss: 6.2869  loss_lm: 6.5982 (6.6564)  time: 2.1525  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 189/4722]  eta: 2:42:42  lr: 0.000010  loss: 6.7594  loss_lm: 6.4751 (6.5376)  time: 2.1537  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:39:25,085 [INFO] Saving checkpoint at iters: 190 and epoch: 0
2023-11-13 00:39:25,090 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:39:30,536 [INFO] Saved successfully
2023-11-13 00:39:30,538 [INFO] Averaged stats: lr: 0.0000  loss: 6.4939  loss_lm: 6.4939
Train: data epoch: [0]  [ 190/4722]  eta: 3:54:45  lr: 0.000010  loss: 6.3190  loss_lm: 6.4751 (6.4939)  time: 3.1080  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 190/4722]  eta: 3:54:42  lr: 0.000010  loss: 6.5028  loss_lm: 6.8837 (6.8547)  time: 3.1074  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 190/4722]  eta: 3:54:43  lr: 0.000010  loss: 6.4299  loss_lm: 6.7626 (6.7256)  time: 3.1075  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 190/4722]  eta: 3:54:41  lr: 0.000010  loss: 6.7991  loss_lm: 6.6426 (6.6849)  time: 3.1070  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 190/4722]  eta: 3:54:40  lr: 0.000010  loss: 6.4035  loss_lm: 6.4472 (6.5368)  time: 3.1069  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 190/4722]  eta: 3:54:41  lr: 0.000010  loss: 6.3080  loss_lm: 6.4897 (6.4995)  time: 3.1070  data: 0.0000  max mem: 18876
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:08  lr: 0.000010  loss: 6.4361  loss_lm: 6.4361 (6.4889)  time: 2.8358  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:10  lr: 0.000010  loss: 6.8945  loss_lm: 6.7626 (6.7538)  time: 2.8362  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:09  lr: 0.000010  loss: 6.4257  loss_lm: 6.5982 (6.6417)  time: 2.8358  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:08  lr: 0.000010  loss: 7.1956  loss_lm: 6.4472 (6.6466)  time: 2.8357  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:10  lr: 0.000010  loss: 6.9632  loss_lm: 6.8837 (6.8728)  time: 2.8362  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 191/4722]  eta: 3:34:13  lr: 0.000010  loss: 6.4243  loss_lm: 6.4243 (6.4823)  time: 2.8367  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 192/4722]  eta: 3:19:26  lr: 0.000010  loss: 6.6106  loss_lm: 6.7626 (6.7333)  time: 2.6417  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 192/4722]  eta: 3:19:28  lr: 0.000010  loss: 6.4718  loss_lm: 6.4718 (6.4808)  time: 2.6421  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 192/4722]  eta: 3:19:25  lr: 0.000010  loss: 6.1316  loss_lm: 6.4361 (6.4379)  time: 2.6413  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 192/4722]  eta: 3:19:25  lr: 0.000010  loss: 6.4821  loss_lm: 6.5982 (6.6189)  time: 2.6413  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 192/4722]  eta: 3:19:24  lr: 0.000010  loss: 6.9630  loss_lm: 6.7265 (6.6918)  time: 2.6412  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 192/4722]  eta: 3:19:26  lr: 0.000010  loss: 6.5298  loss_lm: 6.8837 (6.8238)  time: 2.6416  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 193/4722]  eta: 3:08:25  lr: 0.000010  loss: 6.3353  loss_lm: 6.4243 (6.4626)  time: 2.4962  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 193/4722]  eta: 3:08:23  lr: 0.000010  loss: 6.8843  loss_lm: 6.7626 (6.7522)  time: 2.4959  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 193/4722]  eta: 3:08:21  lr: 0.000010  loss: 6.8860  loss_lm: 6.7265 (6.7161)  time: 2.4955  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 193/4722]  eta: 3:08:22  lr: 0.000010  loss: 6.7704  loss_lm: 6.5982 (6.6379)  time: 2.4956  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 193/4722]  eta: 3:08:22  lr: 0.000010  loss: 6.6935  loss_lm: 6.4361 (6.4698)  time: 2.4956  data: 0.0000  max mem: 18876

Train: data epoch: [0]  [ 193/4722]  eta: 3:08:23  lr: 0.000010  loss: 6.1404  loss_lm: 6.8750 (6.7384)  time: 2.4958  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 194/4722]  eta: 2:59:49  lr: 0.000010  loss: 6.2833  loss_lm: 6.7626 (6.7001)  time: 2.3829  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 194/4722]  eta: 2:59:49  lr: 0.000010  loss: 6.7421  loss_lm: 6.8750 (6.7388)  time: 2.3828  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 194/4722]  eta: 2:59:51  lr: 0.000010  loss: 6.6187  loss_lm: 6.4718 (6.4800)  time: 2.3832  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 194/4722]  eta: 2:59:47  lr: 0.000010  loss: 7.0192  loss_lm: 6.7784 (6.7497)  time: 2.3825  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 194/4722]  eta: 2:59:48  lr: 0.000010  loss: 6.7216  loss_lm: 6.6426 (6.6472)  time: 2.3826  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 194/4722]  eta: 2:59:48  lr: 0.000010  loss: 6.8607  loss_lm: 6.4897 (6.5133)  time: 2.3826  data: 0.0000  max mem: 18876
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:39:37,927 [INFO] Saving checkpoint at iters: 195 and epoch: 0
2023-11-13 00:39:37,932 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:39:43,189 [INFO] Saved successfully
2023-11-13 00:39:43,190 [INFO] Averaged stats: lr: 0.0000  loss: 6.5138  loss_lm: 6.5138
Train: data epoch: [0]  [ 195/4722]  eta: 3:32:41  lr: 0.000010  loss: 6.8184  loss_lm: 6.4718 (6.5138)  time: 2.8189  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 195/4722]  eta: 3:32:38  lr: 0.000010  loss: 6.6886  loss_lm: 6.4897 (6.5308)  time: 2.8184  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 195/4722]  eta: 3:32:40  lr: 0.000010  loss: 6.6411  loss_lm: 6.6844 (6.6942)  time: 2.8187  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 195/4722]  eta: 3:32:39  lr: 0.000010  loss: 6.3998  loss_lm: 6.7421 (6.7049)  time: 2.8186  data: 0.0000  max mem: 18892

Train: data epoch: [0]  [ 195/4722]  eta: 3:32:38  lr: 0.000010  loss: 6.9946  loss_lm: 6.6426 (6.6819)  time: 2.8184  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 195/4722]  eta: 3:32:38  lr: 0.000010  loss: 6.4865  loss_lm: 6.7265 (6.7234)  time: 2.8183  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 196/4722]  eta: 3:23:27  lr: 0.000010  loss: 6.8102  loss_lm: 6.7626 (6.7047)  time: 2.6971  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 196/4722]  eta: 3:23:28  lr: 0.000010  loss: 6.5779  loss_lm: 6.4751 (6.5196)  time: 2.6974  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 196/4722]  eta: 3:23:25  lr: 0.000010  loss: 6.6641  loss_lm: 6.5917 (6.5429)  time: 2.6969  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 196/4722]  eta: 3:23:25  lr: 0.000010  loss: 6.5303  loss_lm: 6.6426 (6.6681)  time: 2.6969  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 196/4722]  eta: 3:23:25  lr: 0.000010  loss: 6.2747  loss_lm: 6.7265 (6.6826)  time: 2.6968  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 196/4722]  eta: 3:23:26  lr: 0.000010  loss: 6.7301  loss_lm: 6.7421 (6.7072)  time: 2.6970  data: 0.0000  max mem: 18892
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.7613  loss_lm: 6.4751 (6.5398)  time: 2.5961  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:44  lr: 0.000010  loss: 6.7036  loss_lm: 6.5917 (6.5563)  time: 2.5956  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:45  lr: 0.000010  loss: 6.3910  loss_lm: 6.7301 (6.6808)  time: 2.5957  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:44  lr: 0.000010  loss: 6.6285  loss_lm: 6.6285 (6.6648)  time: 2.5956  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:44  lr: 0.000010  loss: 6.4127  loss_lm: 6.4865 (6.6601)  time: 2.5955  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 197/4722]  eta: 3:15:46  lr: 0.000010  loss: 6.1196  loss_lm: 6.6844 (6.6560)  time: 2.5958  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 198/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.2748  loss_lm: 6.5917 (6.5347)  time: 2.5093  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 198/4722]  eta: 3:09:12  lr: 0.000010  loss: 6.6825  loss_lm: 6.7301 (6.6810)  time: 2.5094  data: 0.0000  max mem: 18892Train: data epoch: [0]  [ 198/4722]  eta: 3:09:14  lr: 0.000010  loss: 6.1348  loss_lm: 6.4751 (6.5086)  time: 2.5097  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 198/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.9950  loss_lm: 6.7265 (6.6859)  time: 2.5092  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 198/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.8717  loss_lm: 6.6426 (6.6807)  time: 2.5092  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 198/4722]  eta: 3:09:12  lr: 0.000010  loss: 6.5842  loss_lm: 6.6844 (6.6505)  time: 2.5095  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:36  lr: 0.000010  loss: 7.2077  loss_lm: 6.4751 (6.5585)  time: 2.4356  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:35  lr: 0.000010  loss: 6.9281  loss_lm: 6.6844 (6.6703)  time: 2.4354  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:34  lr: 0.000010  loss: 6.6029  loss_lm: 6.6825 (6.6754)  time: 2.4353  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:34  lr: 0.000010  loss: 6.4616  loss_lm: 6.6285 (6.6651)  time: 2.4352  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:33  lr: 0.000010  loss: 6.8682  loss_lm: 6.7265 (6.6989)  time: 2.4351  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 199/4722]  eta: 3:03:34  lr: 0.000010  loss: 6.4791  loss_lm: 6.4897 (6.5307)  time: 2.4352  data: 0.0000  max mem: 18876
2023-11-13 00:39:50,575 [INFO] Saving checkpoint at iters: 200 and epoch: 0
2023-11-13 00:39:50,580 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:39:55,939 [INFO] Saved successfully
2023-11-13 00:39:55,940 [INFO] Averaged stats: lr: 0.0000  loss: 6.5385  loss_lm: 6.5385
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:41  lr: 0.000010  loss: 6.2572  loss_lm: 6.4751 (6.5385)  time: 2.7291  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:39  lr: 0.000010  loss: 6.2624  loss_lm: 6.6825 (6.6478)  time: 2.7289  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:40  lr: 0.000010  loss: 6.3888  loss_lm: 6.6844 (6.6515)  time: 2.7289  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:38  lr: 0.000010  loss: 6.5680  loss_lm: 6.7265 (6.6902)  time: 2.7286  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:39  lr: 0.000010  loss: 6.7536  loss_lm: 6.5917 (6.5455)  time: 2.7287  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 200/4722]  eta: 3:25:39  lr: 0.000010  loss: 6.6458  loss_lm: 6.6426 (6.6638)  time: 2.7287  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:03  lr: 0.000010  loss: 6.7909  loss_lm: 6.4751 (6.5542)  time: 2.6550  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:01  lr: 0.000010  loss: 6.6825  loss_lm: 6.6825 (6.6500)  time: 2.6547  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:01  lr: 0.000010  loss: 6.2959  loss_lm: 6.4897 (6.5299)  time: 2.6546  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:00  lr: 0.000010  loss: 6.5100  loss_lm: 6.5680 (6.6789)  time: 2.6545  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:02  lr: 0.000010  loss: 6.3285  loss_lm: 6.6411 (6.6313)  time: 2.6547  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 201/4722]  eta: 3:20:01  lr: 0.000010  loss: 6.2800  loss_lm: 6.6285 (6.6398)  time: 2.6545  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 202/4722]  eta: 3:14:50  lr: 0.000010  loss: 6.6527  loss_lm: 6.5266 (6.5600)  time: 2.5864  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 202/4722]  eta: 3:14:49  lr: 0.000010  loss: 6.3899  loss_lm: 6.6825 (6.6347)  time: 2.5861  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 202/4722]  eta: 3:14:48  lr: 0.000010  loss: 6.9066  loss_lm: 6.7265 (6.6923)  time: 2.5859  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 202/4722]  eta: 3:14:49  lr: 0.000010  loss: 6.7019  loss_lm: 6.6844 (6.6355)  time: 2.5862  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 202/4722]  eta: 3:14:48  lr: 0.000010  loss: 6.5570  loss_lm: 6.5570 (6.5315)  time: 2.5860  data: 0.0000  max mem: 18876Train: data epoch: [0]  [ 202/4722]  eta: 3:14:48  lr: 0.000010  loss: 6.9486  loss_lm: 6.6426 (6.6580)  time: 2.5860  data: 0.0000  max mem: 18865


Train: data epoch: [0]  [ 203/4722]  eta: 3:10:08  lr: 0.000010  loss: 6.7442  loss_lm: 6.5266 (6.5703)  time: 2.5245  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 203/4722]  eta: 3:10:06  lr: 0.000010  loss: 6.9144  loss_lm: 6.6825 (6.6503)  time: 2.5242  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 203/4722]  eta: 3:10:06  lr: 0.000010  loss: 6.2635  loss_lm: 6.6285 (6.6361)  time: 2.5240  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 203/4722]  eta: 3:10:06  lr: 0.000010  loss: 6.6301  loss_lm: 6.6301 (6.6889)  time: 2.5240  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 203/4722]  eta: 3:10:06  lr: 0.000010  loss: 6.8048  loss_lm: 6.5570 (6.5467)  time: 2.5241  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 203/4722]  eta: 3:10:06  lr: 0.000010  loss: 6.1868  loss_lm: 6.6411 (6.6106)  time: 2.5242  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:58  lr: 0.000010  loss: 6.5722  loss_lm: 6.5722 (6.5704)  time: 2.4697  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:57  lr: 0.000010  loss: 7.1246  loss_lm: 6.6825 (6.6752)  time: 2.4695  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:57  lr: 0.000010  loss: 6.8551  loss_lm: 6.6844 (6.6234)  time: 2.4695  data: 0.0000  max mem: 18888
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:56  lr: 0.000010  loss: 6.5863  loss_lm: 6.5863 (6.5488)  time: 2.4693  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:56  lr: 0.000010  loss: 6.5504  loss_lm: 6.6285 (6.6316)  time: 2.4693  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 204/4722]  eta: 3:05:56  lr: 0.000010  loss: 6.4550  loss_lm: 6.6301 (6.6766)  time: 2.4693  data: 0.0000  max mem: 19014
2023-11-13 00:40:03,402 [INFO] Saving checkpoint at iters: 205 and epoch: 0
2023-11-13 00:40:03,407 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:40:08,632 [INFO] Saved successfully
2023-11-13 00:40:08,633 [INFO] Averaged stats: lr: 0.0000  loss: 6.5793  loss_lm: 6.5793
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:51  lr: 0.000010  loss: 6.7489  loss_lm: 6.5722 (6.5793)  time: 2.6814  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:50  lr: 0.000010  loss: 7.1599  loss_lm: 6.6844 (6.6503)  time: 2.6812  data: 0.0000  max mem: 18888
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:50  lr: 0.000010  loss: 6.2144  loss_lm: 6.5570 (6.5321)  time: 2.6810  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:49  lr: 0.000010  loss: 6.5948  loss_lm: 6.5948 (6.6725)  time: 2.6810  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:50  lr: 0.000010  loss: 6.7659  loss_lm: 6.6285 (6.6383)  time: 2.6810  data: 0.0000  max mem: 18888
Train: data epoch: [0]  [ 205/4722]  eta: 3:21:50  lr: 0.000010  loss: 6.5594  loss_lm: 6.6825 (6.6694)  time: 2.6811  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 206/4722]  eta: 3:17:31  lr: 0.000010  loss: 6.6851  loss_lm: 6.5779 (6.5843)  time: 2.5464  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 206/4722]  eta: 3:17:30  lr: 0.000010  loss: 6.2293  loss_lm: 6.6029 (6.6485)  time: 2.5463  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 206/4722]  eta: 3:17:29  lr: 0.000010  loss: 6.8395  loss_lm: 6.6301 (6.6804)  time: 2.5462  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 206/4722]  eta: 3:17:29  lr: 0.000010  loss: 6.5667  loss_lm: 6.5667 (6.5337)  time: 2.5463  data: 0.0000  max mem: 18876Train: data epoch: [0]  [ 206/4722]  eta: 3:17:30  lr: 0.000010  loss: 6.5979  loss_lm: 6.6411 (6.6478)  time: 2.5463  data: 0.0000  max mem: 18888

Train: data epoch: [0]  [ 206/4722]  eta: 3:17:29  lr: 0.000010  loss: 6.7336  loss_lm: 6.6426 (6.6428)  time: 2.5462  data: 0.0000  max mem: 18888
Train: data epoch: [0]  [ 207/4722]  eta: 3:13:31  lr: 0.000010  loss: 6.2682  loss_lm: 6.5594 (6.6312)  time: 2.5457  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 207/4722]  eta: 3:13:31  lr: 0.000010  loss: 6.3877  loss_lm: 6.6106 (6.6359)  time: 2.5457  data: 0.0000  max mem: 18888Train: data epoch: [0]  [ 207/4722]  eta: 3:13:32  lr: 0.000010  loss: 6.6256  loss_lm: 6.6187 (6.5862)  time: 2.5459  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 207/4722]  eta: 3:13:31  lr: 0.000010  loss: 6.6336  loss_lm: 6.5667 (6.5383)  time: 2.5457  data: 0.0000  max mem: 18876


Train: data epoch: [0]  [ 207/4722]  eta: 3:13:31  lr: 0.000010  loss: 6.3017  loss_lm: 6.6285 (6.6273)  time: 2.5457  data: 0.0000  max mem: 18888
Train: data epoch: [0]  [ 207/4722]  eta: 3:13:31  lr: 0.000010  loss: 6.3465  loss_lm: 6.6301 (6.6652)  time: 2.5457  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 208/4722]  eta: 3:09:55  lr: 0.000010  loss: 6.6899  loss_lm: 6.6256 (6.5907)  time: 2.5461  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 208/4722]  eta: 3:09:53  lr: 0.000010  loss: 6.3993  loss_lm: 6.5298 (6.6211)  time: 2.5459  data: 0.0000  max mem: 18892
Train: data epoch: [0]  [ 208/4722]  eta: 3:09:54  lr: 0.000010  loss: 6.4268  loss_lm: 6.5979 (6.6268)  time: 2.5459  data: 0.0000  max mem: 18888Train: data epoch: [0]  [ 208/4722]  eta: 3:09:53  lr: 0.000010  loss: 6.8482  loss_lm: 6.5863 (6.5517)  time: 2.5459  data: 0.0000  max mem: 18876

Train: data epoch: [0]  [ 208/4722]  eta: 3:09:53  lr: 0.000010  loss: 6.5389  loss_lm: 6.5504 (6.6235)  time: 2.5459  data: 0.0000  max mem: 18888Train: data epoch: [0]  [ 208/4722]  eta: 3:09:53  lr: 0.000010  loss: 6.4889  loss_lm: 6.5948 (6.6576)  time: 2.5459  data: 0.0000  max mem: 19014

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 00:45:08.596107] Starting job[2023-11-13 00:45:08.596110] Starting job[2023-11-13 00:45:08.596109] Starting job
[2023-11-13 00:45:08.596113] Starting job[2023-11-13 00:45:08.596111] Starting job[2023-11-13 00:45:08.596113] Starting job




| distributed init (rank 0, world 12): env://
| distributed init (rank 4, world 12): env://
| distributed init (rank 2, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 5, world 12): env://
| distributed init (rank 1, world 12): env://
2023-11-13 00:45:11,544 [INFO] 
=====  Running Parameters    =====
2023-11-13 00:45:11,544 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 00:45:11,544 [INFO] 
======  Dataset Attributes  ======
2023-11-13 00:45:11,545 [INFO] 
======== coco_caption =======
2023-11-13 00:45:11,545 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 00:45:11,545 [INFO] 
======  Model Attributes  ======
2023-11-13 00:45:11,545 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 00:45:11,547 [INFO] Building datasets...
2023-11-13 00:45:26,729 [INFO] number of trainable parameters: 446290492
2023-11-13 00:45:27,028 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 00:45:27,028 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 00:45:27,028 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 00:45:27,028 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 00:45:27,029 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 00:45:27,031 [INFO] Start training
2023-11-13 00:45:27,042 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 206/4722]  eta: 5:20:02  lr: 0.000010  loss: 6.2736  loss_lm: 6.2736 (6.2736)  time: 4.2521  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 206/4722]  eta: 5:19:57  lr: 0.000010  loss: 6.5980  loss_lm: 6.5980 (6.5980)  time: 4.2509  data: 0.0000  max mem: 18863Train: data epoch: [0]  [ 206/4722]  eta: 5:20:26  lr: 0.000010  loss: 6.6813  loss_lm: 6.6813 (6.6813)  time: 4.2575  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 206/4722]  eta: 5:20:01  lr: 0.000010  loss: 6.8378  loss_lm: 6.8378 (6.8378)  time: 4.2519  data: 0.0000  max mem: 18863
Train: data epoch: [0]  [ 206/4722]  eta: 5:19:54  lr: 0.000010  loss: 6.5976  loss_lm: 6.5976 (6.5976)  time: 4.2503  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 206/4722]  eta: 5:20:06  lr: 0.000010  loss: 6.6764  loss_lm: 6.6764 (6.6764)  time: 4.2531  data: 0.0000  max mem: 18863
2023-11-13 00:45:31,308 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:24  lr: 0.000010  loss: 6.2961  loss_lm: 6.2961 (6.4862)  time: 2.9025  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:22  lr: 0.000010  loss: 6.2967  loss_lm: 6.2967 (6.5672)  time: 2.9019  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:20  lr: 0.000010  loss: 6.6286  loss_lm: 6.5980 (6.6133)  time: 2.9015  data: 0.0000  max mem: 18863
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:22  lr: 0.000010  loss: 6.2766  loss_lm: 6.2736 (6.2751)  time: 2.9020  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:34  lr: 0.000010  loss: 6.6307  loss_lm: 6.6307 (6.6560)  time: 2.9047  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 207/4722]  eta: 3:38:18  lr: 0.000010  loss: 6.3680  loss_lm: 6.3680 (6.4828)  time: 2.9012  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 208/4722]  eta: 3:04:17  lr: 0.000010  loss: 6.4004  loss_lm: 6.2766 (6.3169)  time: 2.4495  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 208/4722]  eta: 3:04:17  lr: 0.000010  loss: 6.5036  loss_lm: 6.5036 (6.5460)  time: 2.4495  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 208/4722]  eta: 3:04:18  lr: 0.000010  loss: 6.5362  loss_lm: 6.5362 (6.5029)  time: 2.4499  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 208/4722]  eta: 3:04:15  lr: 0.000010  loss: 6.8825  loss_lm: 6.6286 (6.7030)  time: 2.4492  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 208/4722]  eta: 3:04:14  lr: 0.000010  loss: 6.4213  loss_lm: 6.4213 (6.4623)  time: 2.4489  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 208/4722]  eta: 3:04:25  lr: 0.000010  loss: 6.6940  loss_lm: 6.6813 (6.6687)  time: 2.4513  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 209/4722]  eta: 2:47:15  lr: 0.000010  loss: 6.4556  loss_lm: 6.6307 (6.6154)  time: 2.2237  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 209/4722]  eta: 2:47:10  lr: 0.000010  loss: 6.2472  loss_lm: 6.2961 (6.4389)  time: 2.2227  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 209/4722]  eta: 2:47:09  lr: 0.000010  loss: 6.5051  loss_lm: 6.2766 (6.3639)  time: 2.2224  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 209/4722]  eta: 2:47:07  lr: 0.000010  loss: 6.4620  loss_lm: 6.4213 (6.4622)  time: 2.2219  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 209/4722]  eta: 2:47:09  lr: 0.000010  loss: 6.5557  loss_lm: 6.5036 (6.5484)  time: 2.2224  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 209/4722]  eta: 2:47:08  lr: 0.000010  loss: 6.9242  loss_lm: 6.6286 (6.7583)  time: 2.2221  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:45:37,490 [INFO] Saving checkpoint at iters: 210 and epoch: 0
2023-11-13 00:45:37,495 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:45:42,915 [INFO] Saved successfully
2023-11-13 00:45:42,916 [INFO] Averaged stats: lr: 0.0000  loss: 6.5909  loss_lm: 6.5909
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:41  lr: 0.000010  loss: 6.4926  loss_lm: 6.6307 (6.5909)  time: 3.1741  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:35  lr: 0.000010  loss: 6.4390  loss_lm: 6.6286 (6.6945)  time: 3.1728  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:37  lr: 0.000010  loss: 6.9950  loss_lm: 6.5362 (6.5502)  time: 3.1732  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:36  lr: 0.000010  loss: 6.5335  loss_lm: 6.4004 (6.3978)  time: 3.1730  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:36  lr: 0.000010  loss: 6.6684  loss_lm: 6.5557 (6.5724)  time: 3.1730  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 210/4722]  eta: 3:58:34  lr: 0.000010  loss: 6.7117  loss_lm: 6.4620 (6.5121)  time: 3.1726  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 211/4722]  eta: 3:37:15  lr: 0.000010  loss: 7.2457  loss_lm: 6.5557 (6.6846)  time: 2.8896  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 211/4722]  eta: 3:37:20  lr: 0.000010  loss: 6.6236  loss_lm: 6.6236 (6.5963)  time: 2.8907  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 211/4722]  eta: 3:37:14  lr: 0.000010  loss: 6.2816  loss_lm: 6.5980 (6.6256)  time: 2.8895  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 211/4722]  eta: 3:37:13  lr: 0.000010  loss: 6.7716  loss_lm: 6.4620 (6.5553)  time: 2.8894  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 211/4722]  eta: 3:37:15  lr: 0.000010  loss: 6.8993  loss_lm: 6.4004 (6.4814)  time: 2.8897  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 211/4722]  eta: 3:37:16  lr: 0.000010  loss: 6.4050  loss_lm: 6.4050 (6.5260)  time: 2.8899  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 212/4722]  eta: 3:22:00  lr: 0.000010  loss: 6.6376  loss_lm: 6.6376 (6.6779)  time: 2.6874  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 212/4722]  eta: 3:22:04  lr: 0.000010  loss: 6.8311  loss_lm: 6.6307 (6.6299)  time: 2.6883  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 212/4722]  eta: 3:21:58  lr: 0.000010  loss: 6.6486  loss_lm: 6.5976 (6.5687)  time: 2.6871  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 212/4722]  eta: 3:22:00  lr: 0.000010  loss: 6.8687  loss_lm: 6.5051 (6.5367)  time: 2.6874  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 212/4722]  eta: 3:22:00  lr: 0.000010  loss: 6.7745  loss_lm: 6.5362 (6.5615)  time: 2.6876  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 212/4722]  eta: 3:21:59  lr: 0.000010  loss: 6.5070  loss_lm: 6.5980 (6.6087)  time: 2.6872  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 213/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.5974  loss_lm: 6.6236 (6.6258)  time: 2.5368  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 213/4722]  eta: 3:10:35  lr: 0.000010  loss: 6.3475  loss_lm: 6.5557 (6.6366)  time: 2.5360  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 213/4722]  eta: 3:10:35  lr: 0.000010  loss: 6.7129  loss_lm: 6.5051 (6.5587)  time: 2.5361  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 213/4722]  eta: 3:10:33  lr: 0.000010  loss: 6.8317  loss_lm: 6.5976 (6.6016)  time: 2.5358  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 213/4722]  eta: 3:10:34  lr: 0.000010  loss: 6.0293  loss_lm: 6.5070 (6.5363)  time: 2.5359  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 213/4722]  eta: 3:10:35  lr: 0.000010  loss: 6.5148  loss_lm: 6.5148 (6.5556)  time: 2.5362  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 214/4722]  eta: 3:01:40  lr: 0.000010  loss: 6.3029  loss_lm: 6.5557 (6.5995)  time: 2.4180  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 214/4722]  eta: 3:01:43  lr: 0.000010  loss: 6.6541  loss_lm: 6.6307 (6.6290)  time: 2.4187  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 214/4722]  eta: 3:01:39  lr: 0.000010  loss: 6.6280  loss_lm: 6.6280 (6.6045)  time: 2.4178  data: 0.0000  max mem: 18866


Train: data epoch: [0]  [ 214/4722]  eta: 3:01:41  lr: 0.000010  loss: 6.9414  loss_lm: 6.5362 (6.5985)  time: 2.4182  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 214/4722]  eta: 3:01:40  lr: 0.000010  loss: 6.2970  loss_lm: 6.5051 (6.5297)  time: 2.4180  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 214/4722]  eta: 3:01:39  lr: 0.000010  loss: 6.3308  loss_lm: 6.5070 (6.5134)  time: 2.4179  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:45:50,291 [INFO] Saving checkpoint at iters: 215 and epoch: 0
2023-11-13 00:45:50,296 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:45:55,388 [INFO] Saved successfully
2023-11-13 00:45:55,389 [INFO] Averaged stats: lr: 0.0000  loss: 6.6407  loss_lm: 6.6407
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:53  lr: 0.000010  loss: 6.7467  loss_lm: 6.6307 (6.6407)  time: 2.8341  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:50  lr: 0.000010  loss: 5.9091  loss_lm: 6.5036 (6.5305)  time: 2.8334  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:50  lr: 0.000010  loss: 6.8133  loss_lm: 6.5362 (6.6200)  time: 2.8335  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:49  lr: 0.000010  loss: 6.2838  loss_lm: 6.5976 (6.5724)  time: 2.8332  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:49  lr: 0.000010  loss: 6.2891  loss_lm: 6.4390 (6.4910)  time: 2.8333  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 215/4722]  eta: 3:32:50  lr: 0.000010  loss: 6.4601  loss_lm: 6.4601 (6.5227)  time: 2.8334  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:34  lr: 0.000010  loss: 6.5361  loss_lm: 6.5361 (6.5310)  time: 2.7106  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:33  lr: 0.000010  loss: 6.3601  loss_lm: 6.4390 (6.4791)  time: 2.7105  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:33  lr: 0.000010  loss: 6.3869  loss_lm: 6.4601 (6.5104)  time: 2.7106  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:36  lr: 0.000010  loss: 6.5150  loss_lm: 6.6307 (6.6293)  time: 2.7112  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:33  lr: 0.000010  loss: 6.1188  loss_lm: 6.5976 (6.5312)  time: 2.7104  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 216/4722]  eta: 3:23:34  lr: 0.000010  loss: 6.0515  loss_lm: 6.5362 (6.5683)  time: 2.7107  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 217/4722]  eta: 3:15:45  lr: 0.000010  loss: 6.1920  loss_lm: 6.3601 (6.4552)  time: 2.6072  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 217/4722]  eta: 3:15:46  lr: 0.000010  loss: 6.2099  loss_lm: 6.5036 (6.5042)  time: 2.6074  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 217/4722]  eta: 3:15:45  lr: 0.000010  loss: 6.2419  loss_lm: 6.4620 (6.5071)  time: 2.6072  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 217/4722]  eta: 3:15:45  lr: 0.000010  loss: 6.6352  loss_lm: 6.4601 (6.5208)  time: 2.6073  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 217/4722]  eta: 3:15:48  lr: 0.000010  loss: 6.8443  loss_lm: 6.6307 (6.6472)  time: 2.6079  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 217/4722]  eta: 3:15:46  lr: 0.000010  loss: 6.5382  loss_lm: 6.5362 (6.5658)  time: 2.6074  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 218/4722]  eta: 3:09:12  lr: 0.000010  loss: 6.8980  loss_lm: 6.5361 (6.5345)  time: 2.5205  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 218/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.3205  loss_lm: 6.3601 (6.4448)  time: 2.5204  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 218/4722]  eta: 3:09:12  lr: 0.000010  loss: 6.7095  loss_lm: 6.5382 (6.5768)  time: 2.5205  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 218/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.6555  loss_lm: 6.5976 (6.5185)  time: 2.5203  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 218/4722]  eta: 3:09:14  lr: 0.000010  loss: 6.3440  loss_lm: 6.6307 (6.6239)  time: 2.5210  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 218/4722]  eta: 3:09:11  lr: 0.000010  loss: 6.2760  loss_lm: 6.4601 (6.5019)  time: 2.5204  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 219/4722]  eta: 3:03:36  lr: 0.000010  loss: 6.5024  loss_lm: 6.3601 (6.4489)  time: 2.4464  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 219/4722]  eta: 3:03:36  lr: 0.000010  loss: 6.3049  loss_lm: 6.5036 (6.5181)  time: 2.4465  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 219/4722]  eta: 3:03:36  lr: 0.000010  loss: 6.2690  loss_lm: 6.5362 (6.5549)  time: 2.4465  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 219/4722]  eta: 3:03:35  lr: 0.000010  loss: 6.5313  loss_lm: 6.5313 (6.5194)  time: 2.4463  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 219/4722]  eta: 3:03:36  lr: 0.000010  loss: 6.3469  loss_lm: 6.4004 (6.4908)  time: 2.4464  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 219/4722]  eta: 3:03:38  lr: 0.000010  loss: 6.1038  loss_lm: 6.6236 (6.5867)  time: 2.4470  data: 0.0000  max mem: 18866
2023-11-13 00:46:02,792 [INFO] Saving checkpoint at iters: 220 and epoch: 0
2023-11-13 00:46:02,796 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:46:07,915 [INFO] Saved successfully
2023-11-13 00:46:07,916 [INFO] Averaged stats: lr: 0.0000  loss: 6.5734  loss_lm: 6.5734
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:25  lr: 0.000010  loss: 6.3873  loss_lm: 6.6236 (6.5734)  time: 2.7244  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:22  lr: 0.000010  loss: 6.5967  loss_lm: 6.4390 (6.4588)  time: 2.7238  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:22  lr: 0.000010  loss: 6.1669  loss_lm: 6.5313 (6.4959)  time: 2.7238  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:23  lr: 0.000010  loss: 6.4957  loss_lm: 6.5036 (6.5166)  time: 2.7240  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:23  lr: 0.000010  loss: 6.6040  loss_lm: 6.5382 (6.5581)  time: 2.7240  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 220/4722]  eta: 3:24:22  lr: 0.000010  loss: 6.5756  loss_lm: 6.4601 (6.4965)  time: 2.7239  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 221/4722]  eta: 3:18:29  lr: 0.000010  loss: 6.3334  loss_lm: 6.4957 (6.5052)  time: 2.6461  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 221/4722]  eta: 3:18:31  lr: 0.000010  loss: 6.9141  loss_lm: 6.6236 (6.5947)  time: 2.6465  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 221/4722]  eta: 3:18:30  lr: 0.000010  loss: 6.7342  loss_lm: 6.5382 (6.5691)  time: 2.6461  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 221/4722]  eta: 3:18:29  lr: 0.000010  loss: 6.3867  loss_lm: 6.4004 (6.4896)  time: 2.6460  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 221/4722]  eta: 3:18:29  lr: 0.000010  loss: 6.6974  loss_lm: 6.5313 (6.5085)  time: 2.6459  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 221/4722]  eta: 3:18:29  lr: 0.000010  loss: 6.4557  loss_lm: 6.4390 (6.4586)  time: 2.6460  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:18  lr: 0.000010  loss: 6.6061  loss_lm: 6.5036 (6.5111)  time: 2.5775  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:18  lr: 0.000010  loss: 6.4861  loss_lm: 6.5382 (6.5643)  time: 2.5775  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:20  lr: 0.000010  loss: 6.6355  loss_lm: 6.6307 (6.5971)  time: 2.5779  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:17  lr: 0.000010  loss: 6.5650  loss_lm: 6.5650 (6.5118)  time: 2.5773  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:18  lr: 0.000010  loss: 6.7648  loss_lm: 6.4601 (6.5058)  time: 2.5774  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 222/4722]  eta: 3:13:18  lr: 0.000010  loss: 6.6461  loss_lm: 6.4557 (6.4696)  time: 2.5774  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:41  lr: 0.000010  loss: 6.2313  loss_lm: 6.6236 (6.5768)  time: 2.5164  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.5922  loss_lm: 6.5036 (6.5156)  time: 2.5160  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.6218  loss_lm: 6.4557 (6.4781)  time: 2.5159  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.1769  loss_lm: 6.5362 (6.5427)  time: 2.5160  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:39  lr: 0.000010  loss: 6.8917  loss_lm: 6.4601 (6.5273)  time: 2.5159  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 223/4722]  eta: 3:08:38  lr: 0.000010  loss: 6.3085  loss_lm: 6.5313 (6.5005)  time: 2.5159  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 224/4722]  eta: 3:04:29  lr: 0.000010  loss: 6.7870  loss_lm: 6.5361 (6.5299)  time: 2.4610  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 224/4722]  eta: 3:04:31  lr: 0.000010  loss: 6.5246  loss_lm: 6.6236 (6.5741)  time: 2.4613  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 224/4722]  eta: 3:04:29  lr: 0.000010  loss: 6.2752  loss_lm: 6.4557 (6.4674)  time: 2.4609  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 224/4722]  eta: 3:04:29  lr: 0.000010  loss: 6.2232  loss_lm: 6.4601 (6.5113)  time: 2.4609  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 224/4722]  eta: 3:04:28  lr: 0.000010  loss: 6.8430  loss_lm: 6.5650 (6.5186)  time: 2.4608  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 224/4722]  eta: 3:04:29  lr: 0.000010  loss: 6.7198  loss_lm: 6.5382 (6.5521)  time: 2.4610  data: 0.0000  max mem: 18864

2023-11-13 00:46:15,292 [INFO] Saving checkpoint at iters: 225 and epoch: 0
2023-11-13 00:46:15,297 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:46:21,374 [INFO] Saved successfully
2023-11-13 00:46:21,375 [INFO] Averaged stats: lr: 0.0000  loss: 6.5653  loss_lm: 6.5653
Train: data epoch: [0]  [ 225/4722]  eta: 3:23:34  lr: 0.000010  loss: 6.3982  loss_lm: 6.5974 (6.5653)  time: 2.7161  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 225/4722]  eta: 3:23:32  lr: 0.000010  loss: 5.9654  loss_lm: 6.5362 (6.5227)  time: 2.7157  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 225/4722]  eta: 3:23:32  lr: 0.000010  loss: 6.3728  loss_lm: 6.4390 (6.4627)  time: 2.7156  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 225/4722]  eta: 3:23:32  lr: 0.000010  loss: 6.3975  loss_lm: 6.4004 (6.5056)  time: 2.7156  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 225/4722]  eta: 3:23:31  lr: 0.000010  loss: 6.9212  loss_lm: 6.5650 (6.5387)  time: 2.7156  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 225/4722]  eta: 3:23:32  lr: 0.000010  loss: 6.1741  loss_lm: 6.5036 (6.5121)  time: 2.7157  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 226/4722]  eta: 3:19:03  lr: 0.000010  loss: 6.4182  loss_lm: 6.4182 (6.4606)  time: 2.5768  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 226/4722]  eta: 3:19:03  lr: 0.000010  loss: 6.3579  loss_lm: 6.4957 (6.5048)  time: 2.5768  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 226/4722]  eta: 3:19:03  lr: 0.000010  loss: 6.5088  loss_lm: 6.5148 (6.5221)  time: 2.5768  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 226/4722]  eta: 3:19:03  lr: 0.000010  loss: 6.3519  loss_lm: 6.5313 (6.5298)  time: 2.5767  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 226/4722]  eta: 3:19:05  lr: 0.000010  loss: 6.2352  loss_lm: 6.5246 (6.5496)  time: 2.5769  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 226/4722]  eta: 3:19:03  lr: 0.000010  loss: 6.7059  loss_lm: 6.4601 (6.5151)  time: 2.5767  data: 0.0000  max mem: 18865


Train: data epoch: [0]  [ 227/4722]  eta: 3:15:00  lr: 0.000010  loss: 6.4297  loss_lm: 6.4957 (6.5014)  time: 2.5731  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 227/4722]  eta: 3:14:59  lr: 0.000010  loss: 6.5298  loss_lm: 6.5313 (6.5298)  time: 2.5730  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 227/4722]  eta: 3:15:02  lr: 0.000010  loss: 6.5403  loss_lm: 6.5246 (6.5491)  time: 2.5732  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 227/4722]  eta: 3:15:00  lr: 0.000010  loss: 6.4590  loss_lm: 6.4182 (6.4605)  time: 2.5731  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 227/4722]  eta: 3:15:00  lr: 0.000010  loss: 6.0255  loss_lm: 6.4601 (6.4929)  time: 2.5730  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 227/4722]  eta: 3:15:00  lr: 0.000010  loss: 6.7731  loss_lm: 6.5362 (6.5335)  time: 2.5731  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 228/4722]  eta: 3:11:17  lr: 0.000010  loss: 6.4863  loss_lm: 6.4863 (6.5007)  time: 2.5695  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 228/4722]  eta: 3:11:16  lr: 0.000010  loss: 6.3521  loss_lm: 6.5313 (6.5221)  time: 2.5695  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 228/4722]  eta: 3:11:16  lr: 0.000010  loss: 6.7169  loss_lm: 6.4182 (6.4716)  time: 2.5695  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 228/4722]  eta: 3:11:18  lr: 0.000010  loss: 6.6560  loss_lm: 6.5246 (6.5538)  time: 2.5696  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 228/4722]  eta: 3:11:17  lr: 0.000010  loss: 6.1740  loss_lm: 6.5148 (6.5178)  time: 2.5695  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 228/4722]  eta: 3:11:16  lr: 0.000010  loss: 6.2351  loss_lm: 6.4601 (6.4817)  time: 2.5694  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 229/4722]  eta: 3:07:52  lr: 0.000010  loss: 6.6724  loss_lm: 6.4863 (6.5079)  time: 2.5662  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 229/4722]  eta: 3:07:52  lr: 0.000010  loss: 6.5216  loss_lm: 6.4182 (6.4737)  time: 2.5662  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 229/4722]  eta: 3:07:52  lr: 0.000010  loss: 6.5964  loss_lm: 6.4601 (6.4864)  time: 2.5661  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 229/4722]  eta: 3:07:53  lr: 0.000010  loss: 6.1344  loss_lm: 6.5246 (6.5363)  time: 2.5663  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 229/4722]  eta: 3:07:51  lr: 0.000010  loss: 6.6079  loss_lm: 6.5650 (6.5257)  time: 2.5661  data: 0.0000  max mem: 18866


Train: data epoch: [0]  [ 229/4722]  eta: 3:07:52  lr: 0.000010  loss: 6.2827  loss_lm: 6.5148 (6.5080)  time: 2.5662  data: 0.0000  max mem: 18864
2023-11-13 00:46:28,756 [INFO] Saving checkpoint at iters: 230 and epoch: 0
2023-11-13 00:46:28,761 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 00:51:24.892851] Starting job[2023-11-13 00:51:24.892850] Starting job[2023-11-13 00:51:24.892853] Starting job[2023-11-13 00:51:24.892854] Starting job



[2023-11-13 00:51:24.892853] Starting job
[2023-11-13 00:51:24.892865] Starting job
| distributed init (rank 3, world 12): env://
| distributed init (rank 0, world 12): env://
| distributed init (rank 4, world 12): env://
| distributed init (rank 1, world 12): env://
| distributed init (rank 2, world 12): env://
| distributed init (rank 5, world 12): env://
2023-11-13 00:51:33,043 [INFO] 
=====  Running Parameters    =====
2023-11-13 00:51:33,043 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 00:51:33,043 [INFO] 
======  Dataset Attributes  ======
2023-11-13 00:51:33,043 [INFO] 
======== coco_caption =======
2023-11-13 00:51:33,044 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 00:51:33,044 [INFO] 
======  Model Attributes  ======
2023-11-13 00:51:33,044 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 00:51:33,046 [INFO] Building datasets...
2023-11-13 00:51:48,779 [INFO] number of trainable parameters: 446290492
2023-11-13 00:51:49,078 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 00:51:49,078 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 00:51:49,078 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 00:51:49,078 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 00:51:49,079 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 00:51:49,082 [INFO] Start training
2023-11-13 00:51:49,093 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 226/4722]  eta: 5:15:59  lr: 0.000010  loss: 6.4975  loss_lm: 6.4975 (6.4975)  time: 4.2171  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 226/4722]  eta: 5:16:19  lr: 0.000010  loss: 6.2254  loss_lm: 6.2254 (6.2254)  time: 4.2213  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 226/4722]  eta: 5:16:00  lr: 0.000010  loss: 6.4048  loss_lm: 6.4048 (6.4048)  time: 4.2171  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 226/4722]  eta: 5:16:03  lr: 0.000010  loss: 6.3594  loss_lm: 6.3594 (6.3594)  time: 4.2179  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 226/4722]  eta: 5:16:00  lr: 0.000010  loss: 6.3982  loss_lm: 6.3982 (6.3982)  time: 4.2173  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 226/4722]  eta: 5:16:00  lr: 0.000010  loss: 6.7170  loss_lm: 6.7170 (6.7170)  time: 4.2173  data: 0.0000  max mem: 18863

2023-11-13 00:51:53,323 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 227/4722]  eta: 3:33:09  lr: 0.000010  loss: 6.5247  loss_lm: 6.3594 (6.4420)  time: 2.8453  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 227/4722]  eta: 3:33:17  lr: 0.000010  loss: 6.5265  loss_lm: 6.2254 (6.3759)  time: 2.8470  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 227/4722]  eta: 3:33:07  lr: 0.000010  loss: 6.7694  loss_lm: 6.4975 (6.6334)  time: 2.8449  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 227/4722]  eta: 3:33:07  lr: 0.000010  loss: 6.4658  loss_lm: 6.4048 (6.4353)  time: 2.8449  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 227/4722]  eta: 3:33:08  lr: 0.000010  loss: 6.0467  loss_lm: 6.0467 (6.3819)  time: 2.8450  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 227/4722]  eta: 3:33:08  lr: 0.000010  loss: 6.4362  loss_lm: 6.3982 (6.4172)  time: 2.8450  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:44  lr: 0.000010  loss: 6.3545  loss_lm: 6.3594 (6.4129)  time: 2.3864  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:49  lr: 0.000010  loss: 6.6846  loss_lm: 6.5265 (6.4788)  time: 2.3875  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:43  lr: 0.000010  loss: 6.5190  loss_lm: 6.4362 (6.4511)  time: 2.3861  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:43  lr: 0.000010  loss: 6.7357  loss_lm: 6.4658 (6.5354)  time: 2.3861  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:43  lr: 0.000010  loss: 6.2029  loss_lm: 6.4975 (6.4899)  time: 2.3861  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 228/4722]  eta: 2:58:43  lr: 0.000010  loss: 6.2506  loss_lm: 6.2506 (6.3381)  time: 2.3861  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 229/4722]  eta: 2:41:28  lr: 0.000010  loss: 6.6014  loss_lm: 6.3594 (6.4600)  time: 2.1563  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 229/4722]  eta: 2:41:32  lr: 0.000010  loss: 6.1593  loss_lm: 6.2254 (6.3989)  time: 2.1572  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 229/4722]  eta: 2:41:27  lr: 0.000010  loss: 6.6577  loss_lm: 6.4362 (6.5028)  time: 2.1561  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 229/4722]  eta: 2:41:27  lr: 0.000010  loss: 6.2866  loss_lm: 6.2866 (6.4391)  time: 2.1561  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 229/4722]  eta: 2:41:27  lr: 0.000010  loss: 6.5102  loss_lm: 6.4658 (6.5291)  time: 2.1561  data: 0.0000  max mem: 18878

Train: data epoch: [0]  [ 229/4722]  eta: 2:41:27  lr: 0.000010  loss: 6.5759  loss_lm: 6.2506 (6.3976)  time: 2.1561  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:51:59,187 [INFO] Saving checkpoint at iters: 230 and epoch: 0
2023-11-13 00:51:59,193 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:52:04,475 [INFO] Saved successfully
2023-11-13 00:52:04,477 [INFO] Averaged stats: lr: 0.0000  loss: 6.4286  loss_lm: 6.4286
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:19  lr: 0.000010  loss: 6.5473  loss_lm: 6.5265 (6.4286)  time: 3.0765  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:15  lr: 0.000010  loss: 6.5659  loss_lm: 6.4975 (6.4644)  time: 3.0757  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:16  lr: 0.000010  loss: 6.6750  loss_lm: 6.5190 (6.5372)  time: 3.0757  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:16  lr: 0.000010  loss: 6.4392  loss_lm: 6.4392 (6.4059)  time: 3.0757  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:16  lr: 0.000010  loss: 6.5664  loss_lm: 6.5247 (6.4813)  time: 3.0759  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 230/4722]  eta: 3:50:15  lr: 0.000010  loss: 6.8640  loss_lm: 6.5102 (6.5961)  time: 3.0757  data: 0.0000  max mem: 18878
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:11  lr: 0.000010  loss: 6.5231  loss_lm: 6.5190 (6.5349)  time: 2.8082  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:11  lr: 0.000010  loss: 6.3997  loss_lm: 6.3997 (6.4537)  time: 2.8081  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:11  lr: 0.000010  loss: 6.4617  loss_lm: 6.4658 (6.5737)  time: 2.8081  data: 0.0000  max mem: 18878
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:15  lr: 0.000010  loss: 6.5966  loss_lm: 6.5265 (6.4566)  time: 2.8090  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:11  lr: 0.000010  loss: 6.4370  loss_lm: 6.4370 (6.4111)  time: 2.8081  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 231/4722]  eta: 3:30:11  lr: 0.000010  loss: 6.4336  loss_lm: 6.4336 (6.4733)  time: 2.8083  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:50  lr: 0.000010  loss: 6.1637  loss_lm: 6.5265 (6.4148)  time: 2.6170  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.2990  loss_lm: 6.4658 (6.5345)  time: 2.6163  data: 0.0000  max mem: 18878
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.6175  loss_lm: 6.4975 (6.4771)  time: 2.6163  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.5896  loss_lm: 6.5247 (6.4899)  time: 2.6165  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.0395  loss_lm: 6.5190 (6.4641)  time: 2.6164  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 232/4722]  eta: 3:15:47  lr: 0.000010  loss: 6.7297  loss_lm: 6.4392 (6.4566)  time: 2.6163  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 233/4722]  eta: 3:04:57  lr: 0.000010  loss: 6.7040  loss_lm: 6.4658 (6.5556)  time: 2.4721  data: 0.0000  max mem: 18878Train: data epoch: [0]  [ 233/4722]  eta: 3:04:57  lr: 0.000010  loss: 6.6499  loss_lm: 6.4975 (6.4987)  time: 2.4721  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 233/4722]  eta: 3:04:57  lr: 0.000010  loss: 6.4050  loss_lm: 6.4336 (6.4793)  time: 2.4722  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 233/4722]  eta: 3:04:59  lr: 0.000010  loss: 6.1899  loss_lm: 6.2254 (6.3867)  time: 2.4727  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 233/4722]  eta: 3:04:57  lr: 0.000010  loss: 6.2758  loss_lm: 6.4362 (6.4406)  time: 2.4721  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 233/4722]  eta: 3:04:57  lr: 0.000010  loss: 6.1067  loss_lm: 6.4370 (6.4129)  time: 2.4721  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 234/4722]  eta: 2:56:34  lr: 0.000010  loss: 6.2464  loss_lm: 6.4658 (6.5213)  time: 2.3606  data: 0.0000  max mem: 18878
Train: data epoch: [0]  [ 234/4722]  eta: 2:56:36  lr: 0.000010  loss: 6.3161  loss_lm: 6.3161 (6.3788)  time: 2.3611  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 234/4722]  eta: 2:56:34  lr: 0.000010  loss: 6.2091  loss_lm: 6.4975 (6.4665)  time: 2.3606  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 234/4722]  eta: 2:56:34  lr: 0.000010  loss: 5.9649  loss_lm: 6.4362 (6.3877)  time: 2.3606  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 234/4722]  eta: 2:56:34  lr: 0.000010  loss: 5.9743  loss_lm: 6.4370 (6.3641)  time: 2.3606  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 234/4722]  eta: 2:56:34  lr: 0.000010  loss: 6.3981  loss_lm: 6.4336 (6.4703)  time: 2.3607  data: 0.0000  max mem: 18867

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:52:11,809 [INFO] Saving checkpoint at iters: 235 and epoch: 0
2023-11-13 00:52:11,814 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:52:17,024 [INFO] Saved successfully
2023-11-13 00:52:17,025 [INFO] Averaged stats: lr: 0.0000  loss: 6.4059  loss_lm: 6.4059
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:50  lr: 0.000010  loss: 6.6499  loss_lm: 6.3161 (6.4059)  time: 2.7926  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:48  lr: 0.000010  loss: 6.0224  loss_lm: 6.3997 (6.4221)  time: 2.7921  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:48  lr: 0.000010  loss: 6.5780  loss_lm: 6.4658 (6.5270)  time: 2.7921  data: 0.0000  max mem: 18878
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:48  lr: 0.000010  loss: 6.5786  loss_lm: 6.4362 (6.4068)  time: 2.7921  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:47  lr: 0.000010  loss: 6.1281  loss_lm: 6.2506 (6.3405)  time: 2.7920  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 235/4722]  eta: 3:28:48  lr: 0.000010  loss: 6.7131  loss_lm: 6.4336 (6.4946)  time: 2.7921  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 236/4722]  eta: 3:19:45  lr: 0.000010  loss: 6.6460  loss_lm: 6.5102 (6.5378)  time: 2.6717  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 236/4722]  eta: 3:19:47  lr: 0.000010  loss: 6.2725  loss_lm: 6.3161 (6.3938)  time: 2.6722  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 236/4722]  eta: 3:19:45  lr: 0.000010  loss: 6.4555  loss_lm: 6.4370 (6.3510)  time: 2.6716  data: 0.0000  max mem: 18864


Train: data epoch: [0]  [ 236/4722]  eta: 3:19:45  lr: 0.000010  loss: 6.5088  loss_lm: 6.5088 (6.4959)  time: 2.6717  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 236/4722]  eta: 3:19:45  lr: 0.000010  loss: 6.2933  loss_lm: 6.4362 (6.3965)  time: 2.6717  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 236/4722]  eta: 3:19:45  lr: 0.000010  loss: 6.2683  loss_lm: 6.3997 (6.4081)  time: 2.6717  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 237/4722]  eta: 3:12:10  lr: 0.000010  loss: 5.9211  loss_lm: 6.4658 (6.4864)  time: 2.5709  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 237/4722]  eta: 3:12:12  lr: 0.000010  loss: 6.5831  loss_lm: 6.3161 (6.4096)  time: 2.5714  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 237/4722]  eta: 3:12:10  lr: 0.000010  loss: 6.6614  loss_lm: 6.5088 (6.5097)  time: 2.5710  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 237/4722]  eta: 3:12:10  lr: 0.000010  loss: 6.5776  loss_lm: 6.4370 (6.3699)  time: 2.5709  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 237/4722]  eta: 3:12:10  lr: 0.000010  loss: 6.3745  loss_lm: 6.3745 (6.4053)  time: 2.5710  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 237/4722]  eta: 3:12:10  lr: 0.000010  loss: 6.8787  loss_lm: 6.4362 (6.4367)  time: 2.5710  data: 0.0000  max mem: 18951
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 238/4722]  eta: 3:05:46  lr: 0.000010  loss: 6.4770  loss_lm: 6.4392 (6.3781)  time: 2.4859  data: 0.0000  max mem: 19003Train: data epoch: [0]  [ 238/4722]  eta: 3:05:47  lr: 0.000010  loss: 6.3428  loss_lm: 6.4658 (6.4753)  time: 2.4860  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 238/4722]  eta: 3:05:47  lr: 0.000010  loss: 6.4808  loss_lm: 6.3997 (6.4111)  time: 2.4860  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 238/4722]  eta: 3:05:47  lr: 0.000010  loss: 6.2014  loss_lm: 6.4362 (6.4186)  time: 2.4860  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 238/4722]  eta: 3:05:49  lr: 0.000010  loss: 6.6473  loss_lm: 6.5265 (6.4279)  time: 2.4864  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 238/4722]  eta: 3:05:47  lr: 0.000010  loss: 6.2086  loss_lm: 6.5088 (6.4865)  time: 2.4860  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 239/4722]  eta: 3:00:20  lr: 0.000010  loss: 6.4275  loss_lm: 6.4275 (6.4278)  time: 2.4136  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 239/4722]  eta: 3:00:18  lr: 0.000010  loss: 6.4487  loss_lm: 6.3997 (6.4138)  time: 2.4132  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 239/4722]  eta: 3:00:18  lr: 0.000010  loss: 6.8799  loss_lm: 6.4658 (6.5042)  time: 2.4132  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 239/4722]  eta: 3:00:18  lr: 0.000010  loss: 6.4334  loss_lm: 6.4334 (6.4196)  time: 2.4132  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 239/4722]  eta: 3:00:18  lr: 0.000010  loss: 6.3728  loss_lm: 6.4370 (6.3777)  time: 2.4132  data: 0.0000  max mem: 19003Train: data epoch: [0]  [ 239/4722]  eta: 3:00:18  lr: 0.000010  loss: 6.4086  loss_lm: 6.4336 (6.4809)  time: 2.4132  data: 0.0000  max mem: 18867

2023-11-13 00:52:24,357 [INFO] Saving checkpoint at iters: 240 and epoch: 0
2023-11-13 00:52:24,362 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:52:29,854 [INFO] Saved successfully
2023-11-13 00:52:29,856 [INFO] Averaged stats: lr: 0.0000  loss: 6.4492  loss_lm: 6.4492
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:57  lr: 0.000010  loss: 6.7482  loss_lm: 6.5265 (6.4492)  time: 2.7169  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:55  lr: 0.000010  loss: 6.2855  loss_lm: 6.3997 (6.4052)  time: 2.7165  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:55  lr: 0.000010  loss: 6.3934  loss_lm: 6.4370 (6.3788)  time: 2.7165  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:55  lr: 0.000010  loss: 6.5560  loss_lm: 6.4362 (6.4287)  time: 2.7165  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:55  lr: 0.000010  loss: 6.3862  loss_lm: 6.4336 (6.4746)  time: 2.7165  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 240/4722]  eta: 3:22:55  lr: 0.000010  loss: 6.6108  loss_lm: 6.5102 (6.5113)  time: 2.7165  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 241/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.4883  loss_lm: 6.4362 (6.4324)  time: 2.6385  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 241/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.0441  loss_lm: 6.4658 (6.4821)  time: 2.6385  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 241/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.6383  loss_lm: 6.4370 (6.3950)  time: 2.6385  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 241/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.4175  loss_lm: 6.4175 (6.4711)  time: 2.6385  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 241/4722]  eta: 3:17:05  lr: 0.000010  loss: 5.8419  loss_lm: 6.4275 (6.4112)  time: 2.6389  data: 0.0000  max mem: 19004

Train: data epoch: [0]  [ 241/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.5934  loss_lm: 6.3997 (6.4170)  time: 2.6385  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 242/4722]  eta: 3:11:52  lr: 0.000010  loss: 6.1755  loss_lm: 6.4658 (6.4641)  time: 2.5697  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 242/4722]  eta: 3:11:52  lr: 0.000010  loss: 5.9161  loss_lm: 6.4362 (6.4021)  time: 2.5697  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 242/4722]  eta: 3:11:52  lr: 0.000010  loss: 6.3053  loss_lm: 6.4370 (6.3897)  time: 2.5697  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 242/4722]  eta: 3:11:52  lr: 0.000010  loss: 6.0552  loss_lm: 6.3997 (6.3957)  time: 2.5697  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 242/4722]  eta: 3:11:52  lr: 0.000010  loss: 6.4297  loss_lm: 6.4297 (6.4686)  time: 2.5697  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 242/4722]  eta: 3:11:53  lr: 0.000010  loss: 6.3231  loss_lm: 6.4275 (6.4060)  time: 2.5701  data: 0.0000  max mem: 19004

Train: data epoch: [0]  [ 243/4722]  eta: 3:07:24  lr: 0.000010  loss: 6.4486  loss_lm: 6.4362 (6.4047)  time: 2.5105  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 243/4722]  eta: 3:07:24  lr: 0.000010  loss: 6.2562  loss_lm: 6.4175 (6.4568)  time: 2.5105  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 243/4722]  eta: 3:07:24  lr: 0.000010  loss: 6.6881  loss_lm: 6.4658 (6.4765)  time: 2.5105  data: 0.0000  max mem: 19014

Train: data epoch: [0]  [ 243/4722]  eta: 3:07:24  lr: 0.000010  loss: 6.6932  loss_lm: 6.4370 (6.4066)  time: 2.5105  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 243/4722]  eta: 3:07:26  lr: 0.000010  loss: 6.0946  loss_lm: 6.3231 (6.3887)  time: 2.5109  data: 0.0000  max mem: 19004Train: data epoch: [0]  [ 243/4722]  eta: 3:07:24  lr: 0.000010  loss: 5.9676  loss_lm: 6.3745 (6.3719)  time: 2.5105  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 244/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.7644  loss_lm: 6.5102 (6.4917)  time: 2.4563  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 244/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.5170  loss_lm: 6.4486 (6.4106)  time: 2.4563  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 244/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.2665  loss_lm: 6.4370 (6.3992)  time: 2.4562  data: 0.0000  max mem: 19003Train: data epoch: [0]  [ 244/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.5939  loss_lm: 6.4297 (6.4640)  time: 2.4563  data: 0.0000  max mem: 18867

Train: data epoch: [0]  [ 244/4722]  eta: 3:03:20  lr: 0.000010  loss: 6.5928  loss_lm: 6.4275 (6.3995)  time: 2.4566  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 244/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.2442  loss_lm: 6.3745 (6.3652)  time: 2.4563  data: 0.0000  max mem: 18866
2023-11-13 00:52:37,244 [INFO] Saving checkpoint at iters: 245 and epoch: 0
2023-11-13 00:52:37,249 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:52:42,413 [INFO] Saved successfully
2023-11-13 00:52:42,414 [INFO] Averaged stats: lr: 0.0000  loss: 6.3802  loss_lm: 6.3802
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:53  lr: 0.000010  loss: 6.0148  loss_lm: 6.3231 (6.3802)  time: 2.6655  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:51  lr: 0.000010  loss: 6.5285  loss_lm: 6.4370 (6.4057)  time: 2.6651  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:51  lr: 0.000010  loss: 6.0212  loss_lm: 6.4658 (6.4682)  time: 2.6651  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:51  lr: 0.000010  loss: 6.8706  loss_lm: 6.3745 (6.3905)  time: 2.6651  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:51  lr: 0.000010  loss: 5.9469  loss_lm: 6.4362 (6.3874)  time: 2.6652  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 245/4722]  eta: 3:18:51  lr: 0.000010  loss: 6.5713  loss_lm: 6.4297 (6.4694)  time: 2.6652  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:32  lr: 0.000010  loss: 6.2000  loss_lm: 6.2866 (6.3814)  time: 2.5273  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:32  lr: 0.000010  loss: 6.2190  loss_lm: 6.4362 (6.3794)  time: 2.5273  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:33  lr: 0.000010  loss: 6.4376  loss_lm: 6.4275 (6.3830)  time: 2.5275  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:32  lr: 0.000010  loss: 6.5397  loss_lm: 6.5102 (6.4716)  time: 2.5273  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:32  lr: 0.000010  loss: 6.1152  loss_lm: 6.3934 (6.3918)  time: 2.5273  data: 0.0000  max mem: 19003
Train: data epoch: [0]  [ 246/4722]  eta: 3:14:32  lr: 0.000010  loss: 5.9499  loss_lm: 6.4297 (6.4447)  time: 2.5273  data: 0.0000  max mem: 18867
Train: data epoch: [0]  [ 247/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.5908  loss_lm: 6.2866 (6.3909)  time: 2.5272  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 247/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.2447  loss_lm: 6.4334 (6.3732)  time: 2.5272  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 247/4722]  eta: 3:10:39  lr: 0.000010  loss: 6.6063  loss_lm: 6.4275 (6.3931)  time: 2.5274  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 247/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.6818  loss_lm: 6.5397 (6.4811)  time: 2.5272  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 247/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.3472  loss_lm: 6.3934 (6.3898)  time: 2.5272  data: 0.0000  max mem: 19003Train: data epoch: [0]  [ 247/4722]  eta: 3:10:38  lr: 0.000010  loss: 6.5584  loss_lm: 6.4297 (6.4498)  time: 2.5272  data: 0.0000  max mem: 18867

Train: data epoch: [0]  [ 248/4722]  eta: 3:07:04  lr: 0.000010  loss: 6.2636  loss_lm: 6.2933 (6.3685)  time: 2.5273  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 248/4722]  eta: 3:07:04  lr: 0.000010  loss: 6.2158  loss_lm: 6.2866 (6.3833)  time: 2.5273  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 248/4722]  eta: 3:07:05  lr: 0.000010  loss: 6.1064  loss_lm: 6.3231 (6.3807)  time: 2.5274  data: 0.0000  max mem: 19004
Train: data epoch: [0]  [ 248/4722]  eta: 3:07:04  lr: 0.000010  loss: 6.4811  loss_lm: 6.4336 (6.4512)  time: 2.5272  data: 0.0000  max mem: 18867Train: data epoch: [0]  [ 248/4722]  eta: 3:07:04  lr: 0.000010  loss: 6.5179  loss_lm: 6.4370 (6.3954)  time: 2.5272  data: 0.0000  max mem: 19003Train: data epoch: [0]  [ 248/4722]  eta: 3:07:04  lr: 0.000010  loss: 6.1454  loss_lm: 6.5102 (6.4665)  time: 2.5273  data: 0.0000  max mem: 19014


WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 00:57:41.591561] Starting job[2023-11-13 00:57:41.591560] Starting job[2023-11-13 00:57:41.591564] Starting job[2023-11-13 00:57:41.591564] Starting job[2023-11-13 00:57:41.591564] Starting job[2023-11-13 00:57:41.591566] Starting job





| distributed init (rank 2, world 12): env://
| distributed init (rank 5, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 1, world 12): env://
| distributed init (rank 0, world 12): env://
| distributed init (rank 4, world 12): env://
2023-11-13 00:57:44,960 [INFO] 
=====  Running Parameters    =====
2023-11-13 00:57:44,960 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 00:57:44,961 [INFO] 
======  Dataset Attributes  ======
2023-11-13 00:57:44,961 [INFO] 
======== coco_caption =======
2023-11-13 00:57:44,961 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 00:57:44,961 [INFO] 
======  Model Attributes  ======
2023-11-13 00:57:44,961 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 00:57:44,962 [INFO] Building datasets...
2023-11-13 00:58:00,431 [INFO] number of trainable parameters: 446290492
2023-11-13 00:58:00,731 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 00:58:00,731 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 00:58:00,731 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 00:58:00,731 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 00:58:00,731 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 00:58:00,734 [INFO] Start training
2023-11-13 00:58:00,744 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 246/4722]  eta: 5:17:33  lr: 0.000010  loss: 6.2223  loss_lm: 6.2223 (6.2223)  time: 4.2569  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 246/4722]  eta: 5:17:29  lr: 0.000010  loss: 6.5144  loss_lm: 6.5144 (6.5144)  time: 4.2559  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 246/4722]  eta: 5:17:58  lr: 0.000010  loss: 6.4822  loss_lm: 6.4822 (6.4822)  time: 4.2624  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 246/4722]  eta: 5:17:29  lr: 0.000010  loss: 5.9198  loss_lm: 5.9198 (5.9198)  time: 4.2560  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 246/4722]  eta: 5:17:37  lr: 0.000010  loss: 6.2110  loss_lm: 6.2110 (6.2110)  time: 4.2577  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 246/4722]  eta: 5:17:44  lr: 0.000010  loss: 6.1260  loss_lm: 6.1260 (6.1260)  time: 4.2592  data: 0.0000  max mem: 18864
2023-11-13 00:58:05,016 [INFO] Reducer buckets have been rebuilt in this iteration.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 247/4722]  eta: 3:36:47  lr: 0.000010  loss: 6.5488  loss_lm: 5.9198 (6.2343)  time: 2.9067  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 247/4722]  eta: 3:37:01  lr: 0.000010  loss: 6.5985  loss_lm: 6.4822 (6.5404)  time: 2.9099  data: 0.0000  max mem: 18893Train: data epoch: [0]  [ 247/4722]  eta: 3:36:51  lr: 0.000010  loss: 6.6340  loss_lm: 6.2110 (6.4225)  time: 2.9076  data: 0.0000  max mem: 18864


Train: data epoch: [0]  [ 247/4722]  eta: 3:36:54  lr: 0.000010  loss: 6.3107  loss_lm: 6.1260 (6.2183)  time: 2.9083  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 247/4722]  eta: 3:36:47  lr: 0.000010  loss: 6.6755  loss_lm: 6.5144 (6.5950)  time: 2.9066  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 247/4722]  eta: 3:36:49  lr: 0.000010  loss: 6.2187  loss_lm: 6.2187 (6.2205)  time: 2.9071  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 248/4722]  eta: 3:01:04  lr: 0.000010  loss: 6.5344  loss_lm: 6.3107 (6.3237)  time: 2.4284  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 248/4722]  eta: 3:01:09  lr: 0.000010  loss: 6.1115  loss_lm: 6.4822 (6.3974)  time: 2.4295  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 248/4722]  eta: 3:01:02  lr: 0.000010  loss: 6.1636  loss_lm: 6.2110 (6.3362)  time: 2.4279  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 248/4722]  eta: 3:00:59  lr: 0.000010  loss: 6.5008  loss_lm: 6.5008 (6.3231)  time: 2.4273  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 248/4722]  eta: 3:00:59  lr: 0.000010  loss: 6.1679  loss_lm: 6.5144 (6.4526)  time: 2.4273  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 248/4722]  eta: 3:01:01  lr: 0.000010  loss: 6.2475  loss_lm: 6.2223 (6.2295)  time: 2.4276  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 249/4722]  eta: 2:43:14  lr: 0.000010  loss: 6.4972  loss_lm: 6.3107 (6.3671)  time: 2.1897  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 249/4722]  eta: 2:43:13  lr: 0.000010  loss: 6.2389  loss_lm: 6.2110 (6.3119)  time: 2.1894  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 249/4722]  eta: 2:43:10  lr: 0.000010  loss: 6.4751  loss_lm: 6.4751 (6.4582)  time: 2.1889  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 249/4722]  eta: 2:43:18  lr: 0.000010  loss: 6.4838  loss_lm: 6.4822 (6.4190)  time: 2.1906  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 249/4722]  eta: 2:43:12  lr: 0.000010  loss: 6.3887  loss_lm: 6.2223 (6.2693)  time: 2.1891  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 249/4722]  eta: 2:43:11  lr: 0.000010  loss: 5.9339  loss_lm: 5.9339 (6.2258)  time: 2.1889  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:58:10,987 [INFO] Saving checkpoint at iters: 250 and epoch: 0
2023-11-13 00:58:10,992 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:58:16,093 [INFO] Saved successfully
2023-11-13 00:58:16,096 [INFO] Averaged stats: lr: 0.0000  loss: 6.3696  loss_lm: 6.3696
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:48  lr: 0.000010  loss: 6.1718  loss_lm: 6.4822 (6.3696)  time: 3.0699  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:42  lr: 0.000010  loss: 6.5966  loss_lm: 6.5144 (6.4859)  time: 3.0686  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:42  lr: 0.000010  loss: 6.1676  loss_lm: 6.1676 (6.2142)  time: 3.0686  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:43  lr: 0.000010  loss: 6.1604  loss_lm: 6.2223 (6.2475)  time: 3.0688  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:44  lr: 0.000010  loss: 6.3383  loss_lm: 6.2389 (6.3172)  time: 3.0690  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 250/4722]  eta: 3:48:45  lr: 0.000010  loss: 6.0373  loss_lm: 6.3107 (6.3011)  time: 3.0693  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 251/4722]  eta: 3:28:53  lr: 0.000010  loss: 6.3228  loss_lm: 6.1676 (6.2323)  time: 2.8033  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 251/4722]  eta: 3:28:55  lr: 0.000010  loss: 6.1481  loss_lm: 6.1481 (6.2756)  time: 2.8038  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 251/4722]  eta: 3:28:54  lr: 0.000010  loss: 6.8810  loss_lm: 6.2389 (6.4111)  time: 2.8036  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 251/4722]  eta: 3:28:58  lr: 0.000010  loss: 6.5041  loss_lm: 6.4822 (6.3920)  time: 2.8044  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 251/4722]  eta: 3:28:54  lr: 0.000010  loss: 6.5571  loss_lm: 6.2223 (6.2991)  time: 2.8034  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 251/4722]  eta: 3:28:53  lr: 0.000010  loss: 6.0713  loss_lm: 6.4751 (6.4168)  time: 2.8033  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 252/4722]  eta: 3:15:07  lr: 0.000010  loss: 6.0285  loss_lm: 6.4822 (6.3401)  time: 2.6190  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 252/4722]  eta: 3:15:03  lr: 0.000010  loss: 6.3110  loss_lm: 6.3110 (6.2435)  time: 2.6181  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 252/4722]  eta: 3:15:04  lr: 0.000010  loss: 6.1347  loss_lm: 6.1481 (6.2555)  time: 2.6186  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 252/4722]  eta: 3:15:03  lr: 0.000010  loss: 6.4569  loss_lm: 6.2475 (6.3217)  time: 2.6182  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 252/4722]  eta: 3:15:02  lr: 0.000010  loss: 5.7927  loss_lm: 6.4751 (6.3276)  time: 2.6181  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 252/4722]  eta: 3:15:04  lr: 0.000010  loss: 6.2652  loss_lm: 6.2652 (6.3903)  time: 2.6184  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 253/4722]  eta: 3:04:28  lr: 0.000010  loss: 5.9614  loss_lm: 6.1718 (6.2927)  time: 2.4766  data: 0.0000  max mem: 18893Train: data epoch: [0]  [ 253/4722]  eta: 3:04:24  lr: 0.000010  loss: 6.4089  loss_lm: 6.2475 (6.3326)  time: 2.4759  data: 0.0000  max mem: 18876

Train: data epoch: [0]  [ 253/4722]  eta: 3:04:25  lr: 0.000010  loss: 6.2523  loss_lm: 6.2523 (6.3730)  time: 2.4760  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 253/4722]  eta: 3:04:26  lr: 0.000010  loss: 6.1622  loss_lm: 6.1481 (6.2438)  time: 2.4762  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 253/4722]  eta: 3:04:24  lr: 0.000010  loss: 6.1105  loss_lm: 6.1679 (6.3005)  time: 2.4758  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 253/4722]  eta: 3:04:24  lr: 0.000010  loss: 6.2133  loss_lm: 6.2133 (6.2397)  time: 2.4758  data: 0.0000  max mem: 18865

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 254/4722]  eta: 2:56:31  lr: 0.000010  loss: 6.1797  loss_lm: 6.1797 (6.2802)  time: 2.3705  data: 0.0000  max mem: 18893Train: data epoch: [0]  [ 254/4722]  eta: 2:56:28  lr: 0.000010  loss: 6.3575  loss_lm: 6.3575 (6.3353)  time: 2.3698  data: 0.0000  max mem: 18876

Train: data epoch: [0]  [ 254/4722]  eta: 2:56:28  lr: 0.000010  loss: 6.2825  loss_lm: 6.2825 (6.2445)  time: 2.3698  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 254/4722]  eta: 2:56:29  lr: 0.000010  loss: 6.5556  loss_lm: 6.1622 (6.2785)  time: 2.3701  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 254/4722]  eta: 2:56:28  lr: 0.000010  loss: 6.1552  loss_lm: 6.2523 (6.3488)  time: 2.3699  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 254/4722]  eta: 2:56:27  lr: 0.000010  loss: 5.9612  loss_lm: 6.1679 (6.2628)  time: 2.3697  data: 0.0000  max mem: 18866

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 00:58:23,561 [INFO] Saving checkpoint at iters: 255 and epoch: 0
2023-11-13 00:58:23,566 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:58:28,709 [INFO] Saved successfully
2023-11-13 00:58:28,710 [INFO] Averaged stats: lr: 0.0000  loss: 6.3069  loss_lm: 6.3069
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:09  lr: 0.000010  loss: 6.5473  loss_lm: 6.1797 (6.3069)  time: 2.7958  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:06  lr: 0.000010  loss: 6.2515  loss_lm: 6.2515 (6.2452)  time: 2.7952  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:07  lr: 0.000010  loss: 6.5756  loss_lm: 6.1622 (6.3082)  time: 2.7955  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:06  lr: 0.000010  loss: 6.2470  loss_lm: 6.2475 (6.3265)  time: 2.7953  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:06  lr: 0.000010  loss: 6.0916  loss_lm: 6.2389 (6.3231)  time: 2.7954  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 255/4722]  eta: 3:28:06  lr: 0.000010  loss: 6.0243  loss_lm: 6.1105 (6.2389)  time: 2.7952  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:11  lr: 0.000010  loss: 6.3976  loss_lm: 6.2523 (6.3299)  time: 2.6761  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:13  lr: 0.000010  loss: 6.1497  loss_lm: 6.1797 (6.2926)  time: 2.6766  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:10  lr: 0.000010  loss: 5.6925  loss_lm: 6.2515 (6.1950)  time: 2.6760  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:12  lr: 0.000010  loss: 5.7907  loss_lm: 6.1622 (6.2611)  time: 2.6763  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:11  lr: 0.000010  loss: 6.1482  loss_lm: 6.2475 (6.3103)  time: 2.6760  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 256/4722]  eta: 3:19:10  lr: 0.000010  loss: 5.9715  loss_lm: 6.1105 (6.2146)  time: 2.6760  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 257/4722]  eta: 3:11:40  lr: 0.000010  loss: 6.3488  loss_lm: 6.2523 (6.3315)  time: 2.5757  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 257/4722]  eta: 3:11:40  lr: 0.000010  loss: 6.5278  loss_lm: 6.2515 (6.2227)  time: 2.5756  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 257/4722]  eta: 3:11:42  lr: 0.000010  loss: 5.8270  loss_lm: 6.1718 (6.2538)  time: 2.5762  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 257/4722]  eta: 3:11:41  lr: 0.000010  loss: 5.9287  loss_lm: 6.1481 (6.2334)  time: 2.5758  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 257/4722]  eta: 3:11:40  lr: 0.000010  loss: 6.7214  loss_lm: 6.2475 (6.3446)  time: 2.5756  data: 0.0000  max mem: 18876

Train: data epoch: [0]  [ 257/4722]  eta: 3:11:39  lr: 0.000010  loss: 7.0989  loss_lm: 6.1105 (6.2883)  time: 2.5756  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:20  lr: 0.000010  loss: 6.4163  loss_lm: 6.2652 (6.3380)  time: 2.4912  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:20  lr: 0.000010  loss: 5.9704  loss_lm: 6.2515 (6.2033)  time: 2.4910  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:20  lr: 0.000010  loss: 6.3042  loss_lm: 6.3042 (6.3415)  time: 2.4911  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:20  lr: 0.000010  loss: 6.6241  loss_lm: 6.1622 (6.2635)  time: 2.4913  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:19  lr: 0.000010  loss: 6.5219  loss_lm: 6.1679 (6.3063)  time: 2.4910  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 258/4722]  eta: 3:05:22  lr: 0.000010  loss: 6.2330  loss_lm: 6.1797 (6.2522)  time: 2.4916  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 259/4722]  eta: 2:59:53  lr: 0.000010  loss: 6.3688  loss_lm: 6.2515 (6.2151)  time: 2.4184  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 259/4722]  eta: 2:59:53  lr: 0.000010  loss: 6.5679  loss_lm: 6.1622 (6.2852)  time: 2.4185  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 259/4722]  eta: 2:59:53  lr: 0.000010  loss: 6.0287  loss_lm: 6.2523 (6.3159)  time: 2.4185  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 259/4722]  eta: 2:59:55  lr: 0.000010  loss: 6.3199  loss_lm: 6.1797 (6.2570)  time: 2.4189  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 259/4722]  eta: 2:59:52  lr: 0.000010  loss: 5.9735  loss_lm: 6.1105 (6.2825)  time: 2.4183  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 259/4722]  eta: 2:59:53  lr: 0.000010  loss: 5.7870  loss_lm: 6.2475 (6.3019)  time: 2.4184  data: 0.0000  max mem: 18876

2023-11-13 00:58:36,094 [INFO] Saving checkpoint at iters: 260 and epoch: 0
2023-11-13 00:58:36,099 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:58:41,493 [INFO] Saved successfully
2023-11-13 00:58:41,494 [INFO] Averaged stats: lr: 0.0000  loss: 6.2396  loss_lm: 6.2396
Train: data epoch: [0]  [ 260/4722]  eta: 3:21:58  lr: 0.000010  loss: 5.9958  loss_lm: 6.1797 (6.2396)  time: 2.7159  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 260/4722]  eta: 3:21:56  lr: 0.000010  loss: 6.6880  loss_lm: 6.2825 (6.2466)  time: 2.7155  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 260/4722]  eta: 3:21:56  lr: 0.000010  loss: 6.2720  loss_lm: 6.1679 (6.2818)  time: 2.7154  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 260/4722]  eta: 3:21:57  lr: 0.000010  loss: 6.2461  loss_lm: 6.2461 (6.2826)  time: 2.7157  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 260/4722]  eta: 3:21:56  lr: 0.000010  loss: 5.9230  loss_lm: 6.2523 (6.2897)  time: 2.7156  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 260/4722]  eta: 3:21:56  lr: 0.000010  loss: 6.6163  loss_lm: 6.3042 (6.3228)  time: 2.7155  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 261/4722]  eta: 3:16:09  lr: 0.000010  loss: 6.4020  loss_lm: 6.3042 (6.3278)  time: 2.6382  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 261/4722]  eta: 3:16:09  lr: 0.000010  loss: 6.4984  loss_lm: 6.2461 (6.2961)  time: 2.6384  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 261/4722]  eta: 3:16:09  lr: 0.000010  loss: 6.0066  loss_lm: 6.2515 (6.2316)  time: 2.6382  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 261/4722]  eta: 3:16:11  lr: 0.000010  loss: 5.9355  loss_lm: 6.1718 (6.2206)  time: 2.6387  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 261/4722]  eta: 3:16:09  lr: 0.000010  loss: 6.3744  loss_lm: 6.2523 (6.2950)  time: 2.6383  data: 0.0000  max mem: 18951Train: data epoch: [0]  [ 261/4722]  eta: 3:16:08  lr: 0.000010  loss: 6.1092  loss_lm: 6.1105 (6.2710)  time: 2.6382  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 262/4722]  eta: 3:11:00  lr: 0.000010  loss: 6.7093  loss_lm: 6.2825 (6.2597)  time: 2.5697  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 262/4722]  eta: 3:11:01  lr: 0.000010  loss: 6.1223  loss_lm: 6.2461 (6.2859)  time: 2.5699  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 262/4722]  eta: 3:11:02  lr: 0.000010  loss: 5.9960  loss_lm: 6.1718 (6.2074)  time: 2.5702  data: 0.0000  max mem: 18893

Train: data epoch: [0]  [ 262/4722]  eta: 3:11:01  lr: 0.000010  loss: 6.1746  loss_lm: 6.2523 (6.2879)  time: 2.5698  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 262/4722]  eta: 3:11:00  lr: 0.000010  loss: 6.0794  loss_lm: 6.3042 (6.3132)  time: 2.5697  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 262/4722]  eta: 3:11:00  lr: 0.000010  loss: 6.3357  loss_lm: 6.1679 (6.2748)  time: 2.5697  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:26  lr: 0.000010  loss: 6.2198  loss_lm: 6.2389 (6.2841)  time: 2.5087  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:26  lr: 0.000010  loss: 6.5370  loss_lm: 6.2825 (6.2751)  time: 2.5087  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:26  lr: 0.000010  loss: 6.0408  loss_lm: 6.2475 (6.2980)  time: 2.5087  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:25  lr: 0.000010  loss: 6.3369  loss_lm: 6.1679 (6.2783)  time: 2.5086  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:26  lr: 0.000010  loss: 6.6754  loss_lm: 6.2461 (6.3075)  time: 2.5088  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 263/4722]  eta: 3:06:28  lr: 0.000010  loss: 6.5066  loss_lm: 6.1718 (6.2240)  time: 2.5091  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 264/4722]  eta: 3:02:30  lr: 0.000010  loss: 6.3481  loss_lm: 6.3042 (6.3007)  time: 2.4565  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 264/4722]  eta: 3:02:31  lr: 0.000010  loss: 6.5016  loss_lm: 6.2523 (6.2956)  time: 2.4565  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 264/4722]  eta: 3:02:31  lr: 0.000010  loss: 6.3613  loss_lm: 6.3107 (6.3104)  time: 2.4566  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 264/4722]  eta: 3:02:30  lr: 0.000010  loss: 5.9715  loss_lm: 6.1679 (6.2621)  time: 2.4564  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 264/4722]  eta: 3:02:32  lr: 0.000010  loss: 6.4309  loss_lm: 6.1797 (6.2349)  time: 2.4569  data: 0.0000  max mem: 18893Train: data epoch: [0]  [ 264/4722]  eta: 3:02:30  lr: 0.000010  loss: 6.6247  loss_lm: 6.3110 (6.2935)  time: 2.4565  data: 0.0000  max mem: 18865

2023-11-13 00:58:48,914 [INFO] Saving checkpoint at iters: 265 and epoch: 0
2023-11-13 00:58:48,919 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 00:58:54,308 [INFO] Saved successfully
2023-11-13 00:58:54,309 [INFO] Averaged stats: lr: 0.0000  loss: 6.2442  loss_lm: 6.2442
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:54  lr: 0.000010  loss: 6.4200  loss_lm: 6.1797 (6.2442)  time: 2.6776  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:52  lr: 0.000010  loss: 5.9087  loss_lm: 6.1105 (6.2445)  time: 2.6772  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:52  lr: 0.000010  loss: 6.2265  loss_lm: 6.2389 (6.2921)  time: 2.6773  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:52  lr: 0.000010  loss: 5.8956  loss_lm: 6.2461 (6.2896)  time: 2.6774  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:52  lr: 0.000010  loss: 6.1535  loss_lm: 6.2825 (6.2865)  time: 2.6772  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 265/4722]  eta: 3:18:52  lr: 0.000010  loss: 6.1043  loss_lm: 6.2475 (6.2908)  time: 2.6772  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 266/4722]  eta: 3:14:34  lr: 0.000010  loss: 6.3809  loss_lm: 6.1105 (6.2510)  time: 2.5381  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 266/4722]  eta: 3:14:36  lr: 0.000010  loss: 6.0717  loss_lm: 6.1718 (6.2360)  time: 2.5382  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 266/4722]  eta: 3:14:34  lr: 0.000010  loss: 6.2879  loss_lm: 6.2879 (6.2866)  time: 2.5382  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 266/4722]  eta: 3:14:34  lr: 0.000010  loss: 6.7679  loss_lm: 6.2523 (6.3148)  time: 2.5381  data: 0.0000  max mem: 18951Train: data epoch: [0]  [ 266/4722]  eta: 3:14:35  lr: 0.000010  loss: 6.3418  loss_lm: 6.3107 (6.2921)  time: 2.5381  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 266/4722]  eta: 3:14:34  lr: 0.000010  loss: 6.3556  loss_lm: 6.3042 (6.2939)  time: 2.5381  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:41  lr: 0.000010  loss: 6.3187  loss_lm: 6.2879 (6.2881)  time: 2.5344  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:42  lr: 0.000010  loss: 5.9599  loss_lm: 6.2461 (6.2770)  time: 2.5344  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:41  lr: 0.000010  loss: 6.1806  loss_lm: 6.2389 (6.3087)  time: 2.5344  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:43  lr: 0.000010  loss: 6.1071  loss_lm: 6.1497 (6.2301)  time: 2.5345  data: 0.0000  max mem: 18893
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:41  lr: 0.000010  loss: 6.1292  loss_lm: 6.1105 (6.2454)  time: 2.5344  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 267/4722]  eta: 3:10:41  lr: 0.000010  loss: 6.2091  loss_lm: 6.3042 (6.2901)  time: 2.5344  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 268/4722]  eta: 3:07:08  lr: 0.000010  loss: 6.4284  loss_lm: 6.1718 (6.2387)  time: 2.5348  data: 0.0000  max mem: 18893Train: data epoch: [0]  [ 268/4722]  eta: 3:07:07  lr: 0.000010  loss: 6.0219  loss_lm: 6.2825 (6.2765)  time: 2.5347  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 268/4722]  eta: 3:07:07  lr: 0.000010  loss: 5.6022  loss_lm: 6.1622 (6.2477)  time: 2.5347  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 268/4722]  eta: 3:07:07  lr: 0.000010  loss: 6.0056  loss_lm: 6.1092 (6.2350)  time: 2.5347  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 268/4722]  eta: 3:07:07  lr: 0.000010  loss: 6.4326  loss_lm: 6.2523 (6.3141)  time: 2.5347  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 268/4722]  eta: 3:07:07  lr: 0.000010  loss: 6.5000  loss_lm: 6.3481 (6.2992)  time: 2.5346  data: 0.0000  max mem: 18876
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 269/4722]  eta: 3:03:50  lr: 0.000010  loss: 6.4769  loss_lm: 6.1092 (6.2451)  time: 2.5347  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 269/4722]  eta: 3:03:50  lr: 0.000010  loss: 5.8552  loss_lm: 6.2825 (6.2589)  time: 2.5347  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 269/4722]  eta: 3:03:51  lr: 0.000010  loss: 6.5359  loss_lm: 6.1718 (6.2511)  time: 2.5348  data: 0.0000  max mem: 18893

Train: data epoch: [0]  [ 269/4722]  eta: 3:03:50  lr: 0.000010  loss: 6.5708  loss_lm: 6.1622 (6.2611)  time: 2.5347  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 269/4722]  eta: 3:03:50  lr: 0.000010  loss: 6.2170  loss_lm: 6.3042 (6.2958)  time: 2.5346  data: 0.0000  max mem: 18876
Train: data epoch: [0]  [ 269/4722]  eta: 3:03:50  lr: 0.000010  loss: 6.3865  loss_lm: 6.2652 (6.3171)  time: 2.5347  data: 0.0000  max mem: 18951
2023-11-13 00:59:01,705 [INFO] Saving checkpoint at iters: 270 and epoch: 0
2023-11-13 00:59:01,710 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 01:03:57.819075] Starting job[2023-11-13 01:03:57.819080] Starting job[2023-11-13 01:03:57.819080] Starting job[2023-11-13 01:03:57.819080] Starting job[2023-11-13 01:03:57.819082] Starting job
[2023-11-13 01:03:57.819080] Starting job




| distributed init (rank 5, world 12): env://
| distributed init (rank 2, world 12): env://
| distributed init (rank 4, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 0, world 12): env://
| distributed init (rank 1, world 12): env://
2023-11-13 01:04:05,391 [INFO] 
=====  Running Parameters    =====
2023-11-13 01:04:05,392 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 01:04:05,392 [INFO] 
======  Dataset Attributes  ======
2023-11-13 01:04:05,392 [INFO] 
======== coco_caption =======
2023-11-13 01:04:05,392 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 01:04:05,392 [INFO] 
======  Model Attributes  ======
2023-11-13 01:04:05,392 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 01:04:05,394 [INFO] Building datasets...
2023-11-13 01:04:20,505 [INFO] number of trainable parameters: 446290492
2023-11-13 01:04:20,807 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 01:04:20,807 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 01:04:20,807 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 01:04:20,807 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 01:04:20,808 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 01:04:20,810 [INFO] Start training
2023-11-13 01:04:20,821 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:42  lr: 0.000010  loss: 6.0904  loss_lm: 6.0904 (6.0904)  time: 4.4530  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:26  lr: 0.000010  loss: 6.3357  loss_lm: 6.3357 (6.3357)  time: 4.4494  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:21  lr: 0.000010  loss: 6.4150  loss_lm: 6.4150 (6.4150)  time: 4.4483  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:34  lr: 0.000010  loss: 6.3284  loss_lm: 6.3284 (6.3284)  time: 4.4512  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:29  lr: 0.000010  loss: 6.2776  loss_lm: 6.2776 (6.2776)  time: 4.4501  data: 0.0000  max mem: 18863
Train: data epoch: [0]  [ 266/4722]  eta: 5:30:30  lr: 0.000010  loss: 6.8011  loss_lm: 6.8011 (6.8011)  time: 4.4502  data: 0.0000  max mem: 18863
2023-11-13 01:04:25,283 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 267/4722]  eta: 3:40:31  lr: 0.000010  loss: 6.0117  loss_lm: 6.0117 (6.1701)  time: 2.9701  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 267/4722]  eta: 3:40:27  lr: 0.000010  loss: 6.2128  loss_lm: 6.2128 (6.2743)  time: 2.9692  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 267/4722]  eta: 3:40:25  lr: 0.000010  loss: 6.1472  loss_lm: 6.1472 (6.2811)  time: 2.9687  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 267/4722]  eta: 3:40:35  lr: 0.000010  loss: 6.0953  loss_lm: 6.0904 (6.0928)  time: 2.9710  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 267/4722]  eta: 3:40:29  lr: 0.000010  loss: 6.3036  loss_lm: 6.2776 (6.2906)  time: 2.9695  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 267/4722]  eta: 3:40:29  lr: 0.000010  loss: 6.1741  loss_lm: 6.1741 (6.4876)  time: 2.9696  data: 0.0000  max mem: 18863

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 268/4722]  eta: 3:03:27  lr: 0.000010  loss: 5.5918  loss_lm: 6.0117 (5.9773)  time: 2.4715  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 268/4722]  eta: 3:03:23  lr: 0.000010  loss: 6.0201  loss_lm: 6.1472 (6.1941)  time: 2.4705  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 268/4722]  eta: 3:03:26  lr: 0.000010  loss: 6.0319  loss_lm: 6.2776 (6.2044)  time: 2.4711  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 268/4722]  eta: 3:03:26  lr: 0.000010  loss: 6.4550  loss_lm: 6.4550 (6.4767)  time: 2.4711  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 268/4722]  eta: 3:03:30  lr: 0.000010  loss: 6.4091  loss_lm: 6.0953 (6.1983)  time: 2.4721  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 268/4722]  eta: 3:03:25  lr: 0.000010  loss: 6.5132  loss_lm: 6.3357 (6.3539)  time: 2.4709  data: 0.0000  max mem: 18866

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 269/4722]  eta: 2:44:55  lr: 0.000010  loss: 6.4363  loss_lm: 6.1472 (6.2546)  time: 2.2221  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 269/4722]  eta: 2:44:58  lr: 0.000010  loss: 6.5819  loss_lm: 6.0117 (6.1285)  time: 2.2228  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 269/4722]  eta: 2:45:00  lr: 0.000010  loss: 6.4886  loss_lm: 6.0953 (6.2709)  time: 2.2233  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 269/4722]  eta: 2:44:56  lr: 0.000010  loss: 6.2647  loss_lm: 6.2647 (6.3316)  time: 2.2224  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 269/4722]  eta: 2:44:56  lr: 0.000010  loss: 5.8728  loss_lm: 6.0319 (6.1215)  time: 2.2225  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 269/4722]  eta: 2:44:57  lr: 0.000010  loss: 6.3792  loss_lm: 6.3792 (6.4523)  time: 2.2226  data: 0.0000  max mem: 18864



/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 01:04:31,191 [INFO] Saving checkpoint at iters: 270 and epoch: 0
2023-11-13 01:04:31,196 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:04:36,468 [INFO] Saved successfully
2023-11-13 01:04:36,469 [INFO] Averaged stats: lr: 0.0000  loss: 6.2496  loss_lm: 6.2496
Train: data epoch: [0]  [ 270/4722]  eta: 3:52:09  lr: 0.000010  loss: 6.1645  loss_lm: 6.1645 (6.2496)  time: 3.1289  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 270/4722]  eta: 3:52:07  lr: 0.000010  loss: 5.9997  loss_lm: 6.3792 (6.3618)  time: 3.1283  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 270/4722]  eta: 3:52:05  lr: 0.000010  loss: 6.1080  loss_lm: 6.1472 (6.2253)  time: 3.1280  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 270/4722]  eta: 3:52:07  lr: 0.000010  loss: 6.2334  loss_lm: 6.2334 (6.1439)  time: 3.1283  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 270/4722]  eta: 3:52:08  lr: 0.000010  loss: 5.8610  loss_lm: 6.0117 (6.0750)  time: 3.1286  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 270/4722]  eta: 3:52:06  lr: 0.000010  loss: 6.5677  loss_lm: 6.3357 (6.3788)  time: 3.1282  data: 0.0000  max mem: 18866

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 271/4722]  eta: 3:31:38  lr: 0.000010  loss: 6.2483  loss_lm: 6.1472 (6.2291)  time: 2.8530  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 271/4722]  eta: 3:31:39  lr: 0.000010  loss: 6.1744  loss_lm: 6.1744 (6.1490)  time: 2.8533  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 271/4722]  eta: 3:31:40  lr: 0.000010  loss: 6.0410  loss_lm: 6.1741 (6.3083)  time: 2.8533  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 271/4722]  eta: 3:31:42  lr: 0.000010  loss: 5.8888  loss_lm: 6.0953 (6.1894)  time: 2.8539  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 271/4722]  eta: 3:31:39  lr: 0.000010  loss: 5.7234  loss_lm: 6.2647 (6.2696)  time: 2.8532  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 271/4722]  eta: 3:31:40  lr: 0.000010  loss: 6.3928  loss_lm: 6.0117 (6.1279)  time: 2.8535  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:01  lr: 0.000010  loss: 6.0582  loss_lm: 6.1741 (6.2726)  time: 2.6565  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:00  lr: 0.000010  loss: 6.1555  loss_lm: 6.1555 (6.2186)  time: 2.6562  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:00  lr: 0.000010  loss: 6.1831  loss_lm: 6.2647 (6.2572)  time: 2.6563  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:01  lr: 0.000010  loss: 6.5015  loss_lm: 6.2334 (6.1993)  time: 2.6564  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:03  lr: 0.000010  loss: 6.0666  loss_lm: 6.0953 (6.1719)  time: 2.6570  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 272/4722]  eta: 3:17:01  lr: 0.000010  loss: 6.6341  loss_lm: 6.3284 (6.2003)  time: 2.6566  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 273/4722]  eta: 3:06:01  lr: 0.000010  loss: 6.3398  loss_lm: 6.1741 (6.2810)  time: 2.5087  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 273/4722]  eta: 3:06:01  lr: 0.000010  loss: 6.3816  loss_lm: 6.2334 (6.2221)  time: 2.5087  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 273/4722]  eta: 3:06:00  lr: 0.000010  loss: 6.4295  loss_lm: 6.1555 (6.2450)  time: 2.5085  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 273/4722]  eta: 3:06:00  lr: 0.000010  loss: 6.2353  loss_lm: 6.2353 (6.2545)  time: 2.5086  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 273/4722]  eta: 3:06:01  lr: 0.000010  loss: 6.3101  loss_lm: 6.3101 (6.2140)  time: 2.5088  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 273/4722]  eta: 3:06:03  lr: 0.000010  loss: 5.8265  loss_lm: 6.0904 (6.1287)  time: 2.5091  data: 0.0000  max mem: 18864


Train: data epoch: [0]  [ 274/4722]  eta: 2:57:26  lr: 0.000010  loss: 5.9264  loss_lm: 6.1741 (6.2416)  time: 2.3935  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 274/4722]  eta: 2:57:25  lr: 0.000010  loss: 6.1975  loss_lm: 6.1975 (6.2397)  time: 2.3933  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 274/4722]  eta: 2:57:26  lr: 0.000010  loss: 6.1496  loss_lm: 6.3101 (6.2068)  time: 2.3936  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 274/4722]  eta: 2:57:26  lr: 0.000010  loss: 6.5599  loss_lm: 6.2776 (6.2596)  time: 2.3935  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 274/4722]  eta: 2:57:25  lr: 0.000010  loss: 6.3179  loss_lm: 6.2647 (6.2615)  time: 2.3934  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 274/4722]  eta: 2:57:27  lr: 0.000010  loss: 6.1718  loss_lm: 6.0953 (6.1335)  time: 2.3939  data: 0.0000  max mem: 18864

2023-11-13 01:04:43,847 [INFO] Saving checkpoint at iters: 275 and epoch: 0
2023-11-13 01:04:43,852 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:04:49,104 [INFO] Saved successfully
2023-11-13 01:04:49,105 [INFO] Averaged stats: lr: 0.0000  loss: 6.1678  loss_lm: 6.1678
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:35  lr: 0.000010  loss: 6.4760  loss_lm: 6.0953 (6.1678)  time: 2.8278  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:33  lr: 0.000010  loss: 6.5040  loss_lm: 6.2776 (6.2841)  time: 2.8275  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:33  lr: 0.000010  loss: 6.0105  loss_lm: 6.2353 (6.2364)  time: 2.8274  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:33  lr: 0.000010  loss: 5.9934  loss_lm: 6.1555 (6.2151)  time: 2.8273  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:33  lr: 0.000010  loss: 6.2993  loss_lm: 6.1741 (6.2474)  time: 2.8275  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 275/4722]  eta: 3:29:34  lr: 0.000010  loss: 6.0437  loss_lm: 6.1496 (6.1905)  time: 2.8275  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 276/4722]  eta: 3:20:24  lr: 0.000010  loss: 5.9551  loss_lm: 6.1496 (6.1691)  time: 2.7047  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 276/4722]  eta: 3:20:24  lr: 0.000010  loss: 6.0588  loss_lm: 6.2776 (6.2636)  time: 2.7046  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 276/4722]  eta: 3:20:23  lr: 0.000010  loss: 6.4989  loss_lm: 6.1975 (6.2409)  time: 2.7044  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 276/4722]  eta: 3:20:26  lr: 0.000010  loss: 6.1904  loss_lm: 6.1645 (6.1698)  time: 2.7050  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 276/4722]  eta: 3:20:24  lr: 0.000010  loss: 6.1776  loss_lm: 6.1776 (6.2410)  time: 2.7046  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 276/4722]  eta: 3:20:24  lr: 0.000010  loss: 6.6062  loss_lm: 6.2647 (6.2700)  time: 2.7045  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 277/4722]  eta: 3:12:48  lr: 0.000010  loss: 5.8091  loss_lm: 6.1555 (6.2049)  time: 2.6026  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 277/4722]  eta: 3:12:49  lr: 0.000010  loss: 6.2900  loss_lm: 6.1496 (6.1792)  time: 2.6028  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 277/4722]  eta: 3:12:48  lr: 0.000010  loss: 6.3166  loss_lm: 6.2776 (6.2680)  time: 2.6027  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 277/4722]  eta: 3:12:48  lr: 0.000010  loss: 6.1396  loss_lm: 6.2353 (6.2592)  time: 2.6026  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 277/4722]  eta: 3:12:49  lr: 0.000010  loss: 6.2431  loss_lm: 6.1776 (6.2412)  time: 2.6027  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 277/4722]  eta: 3:12:50  lr: 0.000010  loss: 6.6208  loss_lm: 6.1645 (6.2074)  time: 2.6030  data: 0.0000  max mem: 18864

/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:25  lr: 0.000010  loss: 6.5506  loss_lm: 6.2900 (6.2078)  time: 2.5170  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:24  lr: 0.000010  loss: 5.9005  loss_lm: 6.2353 (6.2316)  time: 2.5169  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:24  lr: 0.000010  loss: 6.1228  loss_lm: 6.1555 (6.1986)  time: 2.5168  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:25  lr: 0.000010  loss: 5.8529  loss_lm: 6.1776 (6.2113)  time: 2.5170  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:25  lr: 0.000010  loss: 6.3243  loss_lm: 6.3036 (6.2723)  time: 2.5169  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 278/4722]  eta: 3:06:26  lr: 0.000010  loss: 6.9335  loss_lm: 6.1718 (6.2633)  time: 2.5173  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:51  lr: 0.000010  loss: 6.1063  loss_lm: 6.2128 (6.2226)  time: 2.4423  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:50  lr: 0.000010  loss: 5.8920  loss_lm: 6.1472 (6.1767)  time: 2.4423  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:51  lr: 0.000010  loss: 5.9151  loss_lm: 6.1496 (6.1869)  time: 2.4424  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:51  lr: 0.000010  loss: 6.4904  loss_lm: 6.3036 (6.2879)  time: 2.4424  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:52  lr: 0.000010  loss: 6.2543  loss_lm: 6.1718 (6.2626)  time: 2.4426  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 279/4722]  eta: 3:00:51  lr: 0.000010  loss: 6.1873  loss_lm: 6.1776 (6.2096)  time: 2.4424  data: 0.0000  max mem: 18864
2023-11-13 01:04:56,510 [INFO] Saving checkpoint at iters: 280 and epoch: 0
2023-11-13 01:04:56,515 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:05:01,782 [INFO] Saved successfully
2023-11-13 01:05:01,784 [INFO] Averaged stats: lr: 0.0000  loss: 6.2620  loss_lm: 6.2620
Train: data epoch: [0]  [ 280/4722]  eta: 3:22:06  lr: 0.000010  loss: 6.2538  loss_lm: 6.1904 (6.2620)  time: 2.7299  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 280/4722]  eta: 3:22:04  lr: 0.000010  loss: 5.9247  loss_lm: 6.1472 (6.1599)  time: 2.7295  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 280/4722]  eta: 3:22:04  lr: 0.000010  loss: 6.2183  loss_lm: 6.3036 (6.2833)  time: 2.7296  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 280/4722]  eta: 3:22:04  lr: 0.000010  loss: 6.2482  loss_lm: 6.2353 (6.2243)  time: 2.7296  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 280/4722]  eta: 3:22:05  lr: 0.000010  loss: 5.9544  loss_lm: 6.1776 (6.1926)  time: 2.7296  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 280/4722]  eta: 3:22:05  lr: 0.000010  loss: 5.9598  loss_lm: 6.1496 (6.1717)  time: 2.7297  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 281/4722]  eta: 3:16:15  lr: 0.000010  loss: 6.2293  loss_lm: 6.2776 (6.2799)  time: 2.6515  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 281/4722]  eta: 3:16:14  lr: 0.000010  loss: 6.2922  loss_lm: 6.2353 (6.2286)  time: 2.6514  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 281/4722]  eta: 3:16:15  lr: 0.000010  loss: 5.9035  loss_lm: 6.0437 (6.1550)  time: 2.6515  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 281/4722]  eta: 3:16:14  lr: 0.000010  loss: 6.2963  loss_lm: 6.1472 (6.1684)  time: 2.6514  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 281/4722]  eta: 3:16:15  lr: 0.000010  loss: 5.9679  loss_lm: 6.1741 (6.1786)  time: 2.6515  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 281/4722]  eta: 3:16:16  lr: 0.000010  loss: 5.7794  loss_lm: 6.1718 (6.2319)  time: 2.6518  data: 0.0000  max mem: 18864


Train: data epoch: [0]  [ 282/4722]  eta: 3:11:06  lr: 0.000010  loss: 6.1839  loss_lm: 6.2776 (6.2743)  time: 2.5825  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 282/4722]  eta: 3:11:06  lr: 0.000010  loss: 6.1549  loss_lm: 6.2353 (6.2243)  time: 2.5825  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 282/4722]  eta: 3:11:06  lr: 0.000010  loss: 6.3945  loss_lm: 6.1776 (6.1913)  time: 2.5825  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 282/4722]  eta: 3:11:06  lr: 0.000010  loss: 5.9631  loss_lm: 6.1472 (6.1563)  time: 2.5824  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 282/4722]  eta: 3:11:06  lr: 0.000010  loss: 5.6030  loss_lm: 6.0437 (6.1225)  time: 2.5826  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 282/4722]  eta: 3:11:07  lr: 0.000010  loss: 6.3096  loss_lm: 6.1904 (6.2364)  time: 2.5828  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 283/4722]  eta: 3:06:29  lr: 0.000010  loss: 5.9562  loss_lm: 6.2128 (6.2094)  time: 2.5207  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 283/4722]  eta: 3:06:29  lr: 0.000010  loss: 6.1659  loss_lm: 6.1472 (6.1569)  time: 2.5207  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 283/4722]  eta: 3:06:29  lr: 0.000010  loss: 5.8611  loss_lm: 6.2334 (6.2513)  time: 2.5208  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 283/4722]  eta: 3:06:29  lr: 0.000010  loss: 5.7273  loss_lm: 6.1741 (6.1655)  time: 2.5208  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 283/4722]  eta: 3:06:30  lr: 0.000010  loss: 5.7738  loss_lm: 6.1718 (6.2107)  time: 2.5210  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 283/4722]  eta: 3:06:29  lr: 0.000010  loss: 5.9672  loss_lm: 6.0117 (6.1139)  time: 2.5208  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 284/4722]  eta: 3:02:23  lr: 0.000010  loss: 5.9462  loss_lm: 6.2128 (6.1955)  time: 2.4659  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 284/4722]  eta: 3:02:23  lr: 0.000010  loss: 6.3466  loss_lm: 6.2776 (6.2563)  time: 2.4659  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 284/4722]  eta: 3:02:23  lr: 0.000010  loss: 6.0552  loss_lm: 6.0437 (6.1108)  time: 2.4660  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 284/4722]  eta: 3:02:23  lr: 0.000010  loss: 6.1783  loss_lm: 6.1555 (6.1580)  time: 2.4658  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 284/4722]  eta: 3:02:23  lr: 0.000010  loss: 5.9687  loss_lm: 6.1741 (6.1551)  time: 2.4659  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 284/4722]  eta: 3:02:24  lr: 0.000010  loss: 5.8108  loss_lm: 6.1718 (6.1897)  time: 2.4662  data: 0.0000  max mem: 18864
2023-11-13 01:05:09,168 [INFO] Saving checkpoint at iters: 285 and epoch: 0
2023-11-13 01:05:09,173 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:05:14,346 [INFO] Saved successfully
2023-11-13 01:05:14,349 [INFO] Averaged stats: lr: 0.0000  loss: 6.1783  loss_lm: 6.1783
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:51  lr: 0.000010  loss: 5.9620  loss_lm: 6.1645 (6.1783)  time: 2.6755  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:50  lr: 0.000010  loss: 6.2533  loss_lm: 6.2533 (6.2562)  time: 2.6753  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:50  lr: 0.000010  loss: 5.8863  loss_lm: 6.0582 (6.1417)  time: 2.6752  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:49  lr: 0.000010  loss: 6.1695  loss_lm: 6.1831 (6.1942)  time: 2.6752  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:50  lr: 0.000010  loss: 6.3029  loss_lm: 6.0437 (6.1204)  time: 2.6753  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 285/4722]  eta: 3:17:49  lr: 0.000010  loss: 5.8812  loss_lm: 6.1472 (6.1441)  time: 2.6752  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 286/4722]  eta: 3:13:35  lr: 0.000010  loss: 6.5644  loss_lm: 6.1718 (6.1967)  time: 2.5267  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 286/4722]  eta: 3:13:34  lr: 0.000010  loss: 6.0311  loss_lm: 6.0410 (6.1364)  time: 2.5266  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 286/4722]  eta: 3:13:34  lr: 0.000010  loss: 5.9611  loss_lm: 6.2334 (6.2421)  time: 2.5266  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 286/4722]  eta: 3:13:34  lr: 0.000010  loss: 5.9330  loss_lm: 6.1695 (6.1818)  time: 2.5266  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 286/4722]  eta: 3:13:34  lr: 0.000010  loss: 6.2792  loss_lm: 6.0437 (6.1279)  time: 2.5266  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 286/4722]  eta: 3:13:34  lr: 0.000010  loss: 6.1992  loss_lm: 6.1472 (6.1468)  time: 2.5266  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 287/4722]  eta: 3:09:42  lr: 0.000010  loss: 5.9710  loss_lm: 6.1549 (6.1722)  time: 2.5263  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 287/4722]  eta: 3:09:43  lr: 0.000010  loss: 6.1077  loss_lm: 6.0552 (6.1270)  time: 2.5263  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 287/4722]  eta: 3:09:42  lr: 0.000010  loss: 6.1860  loss_lm: 6.1555 (6.1486)  time: 2.5263  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 287/4722]  eta: 3:09:42  lr: 0.000010  loss: 6.0113  loss_lm: 6.2293 (6.2316)  time: 2.5263  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 287/4722]  eta: 3:09:42  lr: 0.000010  loss: 6.3276  loss_lm: 6.0410 (6.1451)  time: 2.5263  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 287/4722]  eta: 3:09:43  lr: 0.000010  loss: 6.2875  loss_lm: 6.1904 (6.2008)  time: 2.5264  data: 0.0000  max mem: 18864


/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 288/4722]  eta: 3:06:10  lr: 0.000010  loss: 6.3565  loss_lm: 6.1659 (6.1576)  time: 2.5265  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 288/4722]  eta: 3:06:11  lr: 0.000010  loss: 5.9657  loss_lm: 6.1718 (6.1906)  time: 2.5266  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 288/4722]  eta: 3:06:10  lr: 0.000010  loss: 6.3997  loss_lm: 6.1077 (6.1389)  time: 2.5265  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 288/4722]  eta: 3:06:10  lr: 0.000010  loss: 6.5688  loss_lm: 6.1549 (6.1894)  time: 2.5265  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 288/4722]  eta: 3:06:10  lr: 0.000010  loss: 6.1203  loss_lm: 6.0410 (6.1440)  time: 2.5265  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 288/4722]  eta: 3:06:10  lr: 0.000010  loss: 6.2236  loss_lm: 6.2293 (6.2313)  time: 2.5266  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 289/4722]  eta: 3:02:54  lr: 0.000010  loss: 5.5852  loss_lm: 6.0552 (6.1158)  time: 2.5263  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 3:02:54  lr: 0.000010  loss: 6.7361  loss_lm: 6.0410 (6.1687)  time: 2.5263  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 3:02:55  lr: 0.000010  loss: 6.5653  loss_lm: 6.1718 (6.2062)  time: 2.5265  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 3:02:54  lr: 0.000010  loss: 5.9584  loss_lm: 6.1555 (6.1493)  time: 2.5264  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 3:02:54  lr: 0.000010  loss: 6.0749  loss_lm: 6.2293 (6.2248)  time: 2.5264  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 3:02:54  lr: 0.000010  loss: 6.0769  loss_lm: 6.1396 (6.1847)  time: 2.5263  data: 0.0000  max mem: 18866
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.
  deprecate(
[2023-11-13 01:10:13.954788] Starting job[2023-11-13 01:10:13.954790] Starting job[2023-11-13 01:10:13.954790] Starting job[2023-11-13 01:10:13.954789] Starting job[2023-11-13 01:10:13.954789] Starting job[2023-11-13 01:10:13.954791] Starting job





| distributed init (rank 5, world 12): env://
| distributed init (rank 0, world 12): env://
| distributed init (rank 2, world 12): env://
| distributed init (rank 1, world 12): env://
| distributed init (rank 3, world 12): env://
| distributed init (rank 4, world 12): env://
2023-11-13 01:10:16,834 [INFO] 
=====  Running Parameters    =====
2023-11-13 01:10:16,834 [INFO] {
    "amp": true,
    "batch_size_eval": 10,
    "batch_size_train": 10,
    "checkpoint_freq": 5,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "eval_freq": 2,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 1e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 5,
    "max_len": 20,
    "min_len": 5,
    "min_lr": 0,
    "num_beams": 3,
    "num_workers": 3,
    "output_dir": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint",
    "rank": 0,
    "resume_ckpt_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth",
    "runner": "runner_base",
    "seed": 42,
    "task": "captioning",
    "tensorboard_path": "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/logs",
    "test_splits": [
        "test"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "weight_decay": 0.05,
    "world_size": 12
}
2023-11-13 01:10:16,835 [INFO] 
======  Dataset Attributes  ======
2023-11-13 01:10:16,835 [INFO] 
======== coco_caption =======
2023-11-13 01:10:16,835 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "/mnt/.node1/Open-Datasets/coco"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a picture of "
        }
    },
    "vis_processor": {
        "eval": {
            "name": "blip_image_eval"
        },
        "train": {
            "name": "blip_image_train"
        }
    }
}
2023-11-13 01:10:16,835 [INFO] 
======  Model Attributes  ======
2023-11-13 01:10:16,835 [INFO] {
    "arch": "blip_caption",
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth",
    "image_size": 384,
    "load_finetuned": false,
    "load_pretrained": false,
    "med_config_path": "configs/models/med_large_config.json",
    "model_type": "large_coco",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth",
    "prompt": "a picture of ",
    "vit_ckpt_layer": 5,
    "vit_grad_ckpt": true,
    "vit_type": "large"
}
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_train.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_val.json
Using downloaded and verified file: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/stanford/LAVIS/.cache/lavis/coco/annotations/coco_karpathy_test.json
2023-11-13 01:10:16,836 [INFO] Building datasets...
2023-11-13 01:10:32,106 [INFO] number of trainable parameters: 446290492
2023-11-13 01:10:32,405 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-11-13 01:10:32,405 [INFO] Loaded 566747 records for train split from the dataset.
2023-11-13 01:10:32,405 [INFO] Loaded 5000 records for val split from the dataset.
2023-11-13 01:10:32,405 [INFO] Loaded 5000 records for test split from the dataset.
2023-11-13 01:10:32,406 [INFO] Resume checkpoint from /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth
2023-11-13 01:10:32,408 [INFO] Start training
2023-11-13 01:10:32,419 [INFO] Start training epoch 0, 4722 iters per inner epoch.
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 286/4722]  eta: 5:02:13  lr: 0.000010  loss: 6.1918  loss_lm: 6.1918 (6.1918)  time: 4.0879  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 286/4722]  eta: 5:02:35  lr: 0.000010  loss: 6.5751  loss_lm: 6.5751 (6.5751)  time: 4.0928  data: 0.0000  max mem: 18863Train: data epoch: [0]  [ 286/4722]  eta: 5:02:12  lr: 0.000010  loss: 6.0438  loss_lm: 6.0438 (6.0438)  time: 4.0875  data: 0.0000  max mem: 18866


Train: data epoch: [0]  [ 286/4722]  eta: 5:02:11  lr: 0.000010  loss: 5.9382  loss_lm: 5.9382 (5.9382)  time: 4.0875  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 286/4722]  eta: 5:02:25  lr: 0.000010  loss: 6.2916  loss_lm: 6.2916 (6.2916)  time: 4.0904  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 286/4722]  eta: 5:02:15  lr: 0.000010  loss: 6.0174  loss_lm: 6.0174 (6.0174)  time: 4.0883  data: 0.0000  max mem: 18865

2023-11-13 01:10:36,519 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [ 287/4722]  eta: 3:28:55  lr: 0.000010  loss: 6.1194  loss_lm: 6.1194 (6.2055)  time: 2.8264  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 287/4722]  eta: 3:28:48  lr: 0.000010  loss: 5.9711  loss_lm: 5.9382 (5.9547)  time: 2.8250  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 287/4722]  eta: 3:29:00  lr: 0.000010  loss: 6.2574  loss_lm: 6.2574 (6.4162)  time: 2.8276  data: 0.0000  max mem: 18864Train: data epoch: [0]  [ 287/4722]  eta: 3:28:49  lr: 0.000010  loss: 6.1567  loss_lm: 6.1567 (6.1743)  time: 2.8252  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 287/4722]  eta: 3:28:48  lr: 0.000010  loss: 5.9929  loss_lm: 5.9929 (6.0183)  time: 2.8250  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 287/4722]  eta: 3:28:50  lr: 0.000010  loss: 6.3297  loss_lm: 6.0174 (6.1736)  time: 2.8254  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 288/4722]  eta: 2:56:46  lr: 0.000010  loss: 6.5846  loss_lm: 5.9711 (6.1647)  time: 2.3920  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 288/4722]  eta: 2:56:50  lr: 0.000010  loss: 6.4088  loss_lm: 6.2916 (6.2733)  time: 2.3930  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 288/4722]  eta: 2:56:46  lr: 0.000010  loss: 6.3736  loss_lm: 6.1918 (6.2407)  time: 2.3921  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 288/4722]  eta: 2:56:47  lr: 0.000010  loss: 6.0950  loss_lm: 6.0950 (6.1474)  time: 2.3923  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 288/4722]  eta: 2:56:53  lr: 0.000010  loss: 5.9730  loss_lm: 6.2574 (6.2685)  time: 2.3938  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 288/4722]  eta: 2:56:46  lr: 0.000010  loss: 6.2156  loss_lm: 6.0438 (6.0841)  time: 2.3920  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:49  lr: 0.000010  loss: 5.9300  loss_lm: 6.1567 (6.1630)  time: 2.1632  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:49  lr: 0.000010  loss: 6.0499  loss_lm: 5.9711 (6.1360)  time: 2.1631  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:48  lr: 0.000010  loss: 6.0798  loss_lm: 6.0438 (6.0830)  time: 2.1631  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:52  lr: 0.000010  loss: 5.5768  loss_lm: 6.1194 (6.0992)  time: 2.1639  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:54  lr: 0.000010  loss: 6.5270  loss_lm: 6.2574 (6.3331)  time: 2.1644  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 289/4722]  eta: 2:39:49  lr: 0.000010  loss: 6.7375  loss_lm: 6.0950 (6.2949)  time: 2.1633  data: 0.0000  max mem: 18865
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 01:10:42,552 [INFO] Saving checkpoint at iters: 290 and epoch: 0
2023-11-13 01:10:42,557 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:10:47,863 [INFO] Saved successfully
2023-11-13 01:10:47,864 [INFO] Averaged stats: lr: 0.0000  loss: 6.2056  loss_lm: 6.2056
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:08  lr: 0.000010  loss: 5.6952  loss_lm: 6.2574 (6.2056)  time: 3.0886  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:06  lr: 0.000010  loss: 5.8480  loss_lm: 6.1194 (6.0489)  time: 3.0882  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:04  lr: 0.000010  loss: 6.3340  loss_lm: 6.0499 (6.1756)  time: 3.0876  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:04  lr: 0.000010  loss: 6.4790  loss_lm: 6.1918 (6.2262)  time: 3.0877  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:04  lr: 0.000010  loss: 6.3726  loss_lm: 6.3297 (6.3105)  time: 3.0877  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 290/4722]  eta: 3:48:04  lr: 0.000010  loss: 5.7108  loss_lm: 6.0438 (6.0086)  time: 3.0876  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:11  lr: 0.000010  loss: 5.6335  loss_lm: 5.9711 (6.0852)  time: 2.8192  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:12  lr: 0.000010  loss: 6.1425  loss_lm: 6.1567 (6.2123)  time: 2.8193  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:16  lr: 0.000010  loss: 5.8599  loss_lm: 5.9730 (6.1479)  time: 2.8202  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:12  lr: 0.000010  loss: 5.8869  loss_lm: 6.0950 (6.2399)  time: 2.8193  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:11  lr: 0.000010  loss: 5.9250  loss_lm: 5.9929 (5.9947)  time: 2.8192  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 291/4722]  eta: 3:28:14  lr: 0.000010  loss: 6.1862  loss_lm: 6.1194 (6.0718)  time: 2.8197  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 292/4722]  eta: 3:14:00  lr: 0.000010  loss: 6.4903  loss_lm: 6.1918 (6.2520)  time: 2.6276  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 292/4722]  eta: 3:14:00  lr: 0.000010  loss: 6.3419  loss_lm: 6.0499 (6.1219)  time: 2.6275  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 292/4722]  eta: 3:14:00  lr: 0.000010  loss: 6.1330  loss_lm: 6.1330 (6.2246)  time: 2.6276  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 292/4722]  eta: 3:13:59  lr: 0.000010  loss: 5.4878  loss_lm: 5.9929 (5.9223)  time: 2.6275  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 292/4722]  eta: 3:14:01  lr: 0.000010  loss: 6.5936  loss_lm: 6.1862 (6.1463)  time: 2.6279  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 292/4722]  eta: 3:14:03  lr: 0.000010  loss: 5.7184  loss_lm: 5.9730 (6.0866)  time: 2.6284  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 293/4722]  eta: 3:03:18  lr: 0.000010  loss: 5.8009  loss_lm: 6.1567 (6.1956)  time: 2.4833  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 293/4722]  eta: 3:03:18  lr: 0.000010  loss: 6.5965  loss_lm: 6.0499 (6.1812)  time: 2.4832  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 293/4722]  eta: 3:03:18  lr: 0.000010  loss: 5.7827  loss_lm: 6.0950 (6.1694)  time: 2.4833  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 293/4722]  eta: 3:03:18  lr: 0.000010  loss: 5.6686  loss_lm: 5.9250 (5.8906)  time: 2.4832  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 293/4722]  eta: 3:03:19  lr: 0.000010  loss: 6.1811  loss_lm: 6.1811 (6.1507)  time: 2.4836  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 293/4722]  eta: 3:03:21  lr: 0.000010  loss: 5.9665  loss_lm: 5.9665 (6.0716)  time: 2.4840  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 294/4722]  eta: 2:55:03  lr: 0.000010  loss: 5.6064  loss_lm: 6.1567 (6.1301)  time: 2.3720  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 294/4722]  eta: 2:55:03  lr: 0.000010  loss: 6.1638  loss_lm: 6.1638 (6.1793)  time: 2.3720  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 294/4722]  eta: 2:55:02  lr: 0.000010  loss: 6.4325  loss_lm: 5.9929 (5.9508)  time: 2.3719  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 294/4722]  eta: 2:55:03  lr: 0.000010  loss: 6.3068  loss_lm: 6.1330 (6.1846)  time: 2.3720  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 294/4722]  eta: 2:55:05  lr: 0.000010  loss: 5.6550  loss_lm: 5.9665 (6.0253)  time: 2.3726  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 294/4722]  eta: 2:55:04  lr: 0.000010  loss: 6.2893  loss_lm: 6.1862 (6.1661)  time: 2.3722  data: 0.0000  max mem: 18866
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
2023-11-13 01:10:55,254 [INFO] Saving checkpoint at iters: 295 and epoch: 0
2023-11-13 01:10:55,259 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:11:00,694 [INFO] Saved successfully
2023-11-13 01:11:00,695 [INFO] Averaged stats: lr: 0.0000  loss: 6.0512  loss_lm: 6.0512
Train: data epoch: [0]  [ 295/4722]  eta: 3:28:35  lr: 0.000010  loss: 6.2842  loss_lm: 5.9665 (6.0512)  time: 2.8271  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 295/4722]  eta: 3:28:33  lr: 0.000010  loss: 6.4531  loss_lm: 6.1567 (6.1624)  time: 2.8266  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 295/4722]  eta: 3:28:34  lr: 0.000010  loss: 5.8429  loss_lm: 6.1811 (6.1338)  time: 2.8268  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 295/4722]  eta: 3:28:33  lr: 0.000010  loss: 5.9859  loss_lm: 6.0499 (6.1600)  time: 2.8266  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 295/4722]  eta: 3:28:33  lr: 0.000010  loss: 6.5394  loss_lm: 5.9929 (6.0096)  time: 2.8265  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 295/4722]  eta: 3:28:33  lr: 0.000010  loss: 6.0571  loss_lm: 6.0950 (6.1719)  time: 2.8266  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 296/4722]  eta: 3:19:32  lr: 0.000010  loss: 6.3313  loss_lm: 6.1918 (6.1778)  time: 2.7050  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 296/4722]  eta: 3:19:32  lr: 0.000010  loss: 5.8613  loss_lm: 6.0499 (6.1328)  time: 2.7049  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 296/4722]  eta: 3:19:31  lr: 0.000010  loss: 6.1297  loss_lm: 6.0438 (6.0205)  time: 2.7049  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 296/4722]  eta: 3:19:32  lr: 0.000010  loss: 6.0825  loss_lm: 6.0950 (6.1638)  time: 2.7050  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 296/4722]  eta: 3:19:33  lr: 0.000010  loss: 6.2783  loss_lm: 6.1862 (6.1469)  time: 2.7052  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 296/4722]  eta: 3:19:34  lr: 0.000010  loss: 6.5320  loss_lm: 5.9730 (6.0949)  time: 2.7055  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 297/4722]  eta: 3:11:56  lr: 0.000010  loss: 6.3458  loss_lm: 6.1918 (6.1918)  time: 2.6026  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 297/4722]  eta: 3:11:56  lr: 0.000010  loss: 6.6254  loss_lm: 6.0438 (6.0710)  time: 2.6026  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 297/4722]  eta: 3:11:56  lr: 0.000010  loss: 6.3906  loss_lm: 6.0499 (6.1543)  time: 2.6026  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 297/4722]  eta: 3:11:57  lr: 0.000010  loss: 5.9692  loss_lm: 6.1811 (6.1321)  time: 2.6028  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 297/4722]  eta: 3:11:58  lr: 0.000010  loss: 5.9302  loss_lm: 5.9665 (6.0812)  time: 2.6031  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 297/4722]  eta: 3:11:56  lr: 0.000010  loss: 5.7617  loss_lm: 6.0825 (6.1303)  time: 2.6026  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:31  lr: 0.000010  loss: 5.9615  loss_lm: 6.1918 (6.1741)  time: 2.5162  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:31  lr: 0.000010  loss: 6.0345  loss_lm: 6.0438 (6.0682)  time: 2.5162  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:31  lr: 0.000010  loss: 5.6627  loss_lm: 6.0499 (6.1165)  time: 2.5162  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:33  lr: 0.000010  loss: 5.9347  loss_lm: 5.9665 (6.0699)  time: 2.5167  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:32  lr: 0.000010  loss: 5.7786  loss_lm: 6.1811 (6.1049)  time: 2.5164  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 298/4722]  eta: 3:05:31  lr: 0.000010  loss: 5.8794  loss_lm: 6.0825 (6.1110)  time: 2.5162  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 299/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.6394  loss_lm: 6.0499 (6.1538)  time: 2.4424  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 299/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.3687  loss_lm: 6.1918 (6.1880)  time: 2.4424  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 299/4722]  eta: 3:00:04  lr: 0.000010  loss: 5.7429  loss_lm: 5.9347 (6.0465)  time: 2.4428  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 299/4722]  eta: 3:00:02  lr: 0.000010  loss: 6.1756  loss_lm: 6.0438 (6.0758)  time: 2.4423  data: 0.0000  max mem: 18951Train: data epoch: [0]  [ 299/4722]  eta: 3:00:02  lr: 0.000010  loss: 5.7025  loss_lm: 6.0571 (6.0818)  time: 2.4424  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 299/4722]  eta: 3:00:03  lr: 0.000010  loss: 6.1889  loss_lm: 6.1811 (6.1109)  time: 2.4425  data: 0.0000  max mem: 18866
2023-11-13 01:11:08,104 [INFO] Saving checkpoint at iters: 300 and epoch: 0
2023-11-13 01:11:08,109 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
2023-11-13 01:11:13,581 [INFO] Saved successfully
2023-11-13 01:11:13,583 [INFO] Averaged stats: lr: 0.0000  loss: 6.0297  loss_lm: 6.0297
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:13  lr: 0.000010  loss: 5.7948  loss_lm: 5.9347 (6.0297)  time: 2.7439  data: 0.0000  max mem: 18864
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:11  lr: 0.000010  loss: 5.8359  loss_lm: 6.0499 (6.1326)  time: 2.7435  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:11  lr: 0.000010  loss: 6.0149  loss_lm: 6.0438 (6.0718)  time: 2.7434  data: 0.0000  max mem: 18951
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:11  lr: 0.000010  loss: 5.8210  loss_lm: 6.0571 (6.0644)  time: 2.7435  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:11  lr: 0.000010  loss: 6.2513  loss_lm: 6.2513 (6.1922)  time: 2.7435  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 300/4722]  eta: 3:22:12  lr: 0.000010  loss: 5.9442  loss_lm: 6.1811 (6.0998)  time: 2.7436  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 301/4722]  eta: 3:16:21  lr: 0.000010  loss: 6.8470  loss_lm: 6.0438 (6.1202)  time: 2.6650  data: 0.0000  max mem: 19014
Train: data epoch: [0]  [ 301/4722]  eta: 3:16:22  lr: 0.000010  loss: 6.4766  loss_lm: 6.2513 (6.2100)  time: 2.6650  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 301/4722]  eta: 3:16:22  lr: 0.000010  loss: 6.6026  loss_lm: 6.1811 (6.1312)  time: 2.6651  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 301/4722]  eta: 3:16:21  lr: 0.000010  loss: 5.6496  loss_lm: 6.0174 (6.0385)  time: 2.6650  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 301/4722]  eta: 3:16:21  lr: 0.000010  loss: 5.9097  loss_lm: 5.9859 (6.1187)  time: 2.6650  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 301/4722]  eta: 3:16:23  lr: 0.000010  loss: 5.8586  loss_lm: 5.9302 (6.0190)  time: 2.6654  data: 0.0000  max mem: 18864
/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/processors/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative
  offset = -low * scale
Train: data epoch: [0]  [ 302/4722]  eta: 3:11:10  lr: 0.000010  loss: 5.8593  loss_lm: 6.2513 (6.1893)  time: 2.5952  data: 0.0000  max mem: 18865Train: data epoch: [0]  [ 302/4722]  eta: 3:11:11  lr: 0.000010  loss: 5.9816  loss_lm: 6.1811 (6.1224)  time: 2.5953  data: 0.0000  max mem: 18866

Train: data epoch: [0]  [ 302/4722]  eta: 3:11:10  lr: 0.000010  loss: 6.3872  loss_lm: 6.0798 (6.1359)  time: 2.5951  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 302/4722]  eta: 3:11:10  lr: 0.000010  loss: 5.3850  loss_lm: 6.0174 (6.0000)  time: 2.5952  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 302/4722]  eta: 3:11:10  lr: 0.000010  loss: 6.1722  loss_lm: 6.0499 (6.1218)  time: 2.5952  data: 0.0000  max mem: 18866Train: data epoch: [0]  [ 302/4722]  eta: 3:11:12  lr: 0.000010  loss: 5.8508  loss_lm: 5.9302 (6.0092)  time: 2.5955  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 303/4722]  eta: 3:06:34  lr: 0.000010  loss: 6.0184  loss_lm: 6.1918 (6.1798)  time: 2.5333  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 303/4722]  eta: 3:06:34  lr: 0.000010  loss: 5.9639  loss_lm: 5.9859 (6.1131)  time: 2.5332  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 303/4722]  eta: 3:06:34  lr: 0.000010  loss: 5.8842  loss_lm: 6.0438 (6.1219)  time: 2.5332  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 303/4722]  eta: 3:06:34  lr: 0.000010  loss: 5.5722  loss_lm: 6.1194 (6.0919)  time: 2.5334  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 303/4722]  eta: 3:06:35  lr: 0.000010  loss: 5.4446  loss_lm: 5.8599 (5.9778)  time: 2.5336  data: 0.0000  max mem: 18864

Train: data epoch: [0]  [ 303/4722]  eta: 3:06:34  lr: 0.000010  loss: 6.1258  loss_lm: 6.0174 (6.0070)  time: 2.5332  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 304/4722]  eta: 3:02:25  lr: 0.000010  loss: 6.2810  loss_lm: 6.0798 (6.1303)  time: 2.4775  data: 0.0000  max mem: 19014Train: data epoch: [0]  [ 304/4722]  eta: 3:02:26  lr: 0.000010  loss: 5.9874  loss_lm: 6.1918 (6.1697)  time: 2.4776  data: 0.0000  max mem: 18865

Train: data epoch: [0]  [ 304/4722]  eta: 3:02:25  lr: 0.000010  loss: 5.9818  loss_lm: 5.9859 (6.1062)  time: 2.4776  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 304/4722]  eta: 3:02:26  lr: 0.000010  loss: 5.8455  loss_lm: 6.1194 (6.0789)  time: 2.4777  data: 0.0000  max mem: 18866
Train: data epoch: [0]  [ 304/4722]  eta: 3:02:25  lr: 0.000010  loss: 6.1435  loss_lm: 6.0571 (6.0142)  time: 2.4776  data: 0.0000  max mem: 18865
Train: data epoch: [0]  [ 304/4722]  eta: 3:02:27  lr: 0.000010  loss: 5.7692  loss_lm: 5.8599 (5.9668)  time: 2.4779  data: 0.0000  max mem: 18864
2023-11-13 01:11:20,994 [INFO] Saving checkpoint at iters: 305 and epoch: 0
2023-11-13 01:11:20,999 [INFO] Saving checkpoint at epoch 0 to /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint/caption_latest.pth.
Traceback (most recent call last):
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/train.py", line 106, in <module>
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/train.py", line 103, in main
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/runners/runner_base.py", line 387, in train
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/runners/runner_base.py", line 448, in train_epoch
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/tasks/base_task.py", line 122, in train_epoch
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/tasks/base_task.py", line 258, in _train_inner_loop
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/lavis/tasks/base_task.py", line 305, in save_checkpoint
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/cycling_utils/cycling_utils/saving.py", line 10, in atomic_torch_save
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/torch/serialization.py", line 440, in save
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/torch/serialization.py", line 315, in _open_zipfile_writer
  File "/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/lib/python3.10/site-packages/torch/serialization.py", line 288, in __init__
RuntimeError: Parent directory /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/checkpoint does not exist.
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3968277 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3968278 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3968279 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3968280 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3968281 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3968276) of binary: /mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/isc-demos/stanford/LAVIS/.venv/bin/python
