WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:11:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
2023-11-13,00:11:54 | INFO | Loaded RN50 model config.
Checkpoint file specified but not found, starting from scratch instead
Checkpoint file specified but not found, starting from scratch insteadCheckpoint file specified but not found, starting from scratch instead

Checkpoint file specified but not found, starting from scratch instead
Checkpoint file specified but not found, starting from scratch instead
Checkpoint file specified but not found, starting from scratch instead
2023-11-13,00:11:56 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:56 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:56 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:56 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:57 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:57 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:57 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:57 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:11:57 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:11:57 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:12:07 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:16:37 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:37 | INFO | Loaded RN50 model config.
2023-11-13,00:16:40 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:40 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:41 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:41 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:41 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:41 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 81)
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:42 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:16:42 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:16:52 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:21:20 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:20 | INFO | Loaded RN50 model config.
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:23 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 0) (iteration 161)
2023-11-13,00:21:24 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:24 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:24 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:24 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:24 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:24 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:24 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:25 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:25 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:25 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:25 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:21:25 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:21:35 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:22:39 | INFO | Beginning training with tb_writer = None and path is ./logs/
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:24:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:45 | INFO | Loaded RN50 model config.
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:49 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 1) (iteration 2)
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:50 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:51 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:24:51 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:25:07 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:27:54 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:54 | INFO | Loaded RN50 model config.
2023-11-13,00:27:57 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:57 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:58 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:58 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:58 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:58 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 61)
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:27:59 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:27:59 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:28:08 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:34:13 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:13 | INFO | Loaded RN50 model config.
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:16 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 141)
2023-11-13,00:34:17 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:17 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:17 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:17 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:17 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:17 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:18 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:18 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:18 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:18 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:34:18 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:34:28 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:40:25 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:25 | INFO | Loaded RN50 model config.
2023-11-13,00:40:28 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:28 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:29 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:29 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:29 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:29 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 2) (iteration 221)
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:30 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:40:30 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:40:40 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:41:00 | INFO | Beginning training with tb_writer = None and path is ./logs/
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:46:42 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:42 | INFO | Loaded RN50 model config.
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:45 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 41)
2023-11-13,00:46:46 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:46 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:46 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:46 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:46 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:46 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:47 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:47 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:47 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:47 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:46:47 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:46:57 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:52:59 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:52:59 | INFO | Loaded RN50 model config.
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:03 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 121)
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:04 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:53:04 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:53:14 | INFO | Reducer buckets have been rebuilt in this iteration.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,00:59:15 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:15 | INFO | Loaded RN50 model config.
2023-11-13,00:59:18 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:18 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:19 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:19 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:19 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:19 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 3) (iteration 201)
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:20 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,00:59:20 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,00:59:30 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:00:05 | INFO | Beginning training with tb_writer = None and path is ./logs/
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:4.Process (global: 10, local 4), total 12.
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:5.Process (global: 11, local 5), total 12.
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 7, local 1), total 12.
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 6, local 0), total 12.
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 8, local 2), total 12.
2023-11-13,01:05:32 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 9, local 3), total 12.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:32 | INFO | Loaded RN50 model config.
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:35 | INFO | => resuming checkpoint '/mnt/Client/Lachlahy4daeusijealkmjsh6qf6mchi/laclacoyiihruvjzhb3kmexw7qlks5yy/clip/open_clip/checkpoints/latest.pt' (epoch 4) (iteration 21)
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:36 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:36 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:36 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 599982 and num batches = 249
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:36 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:36 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:36 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:37 | INFO | Dataloader created with total num samples = 50000 and num batches = 21
2023-11-13,01:05:37 | INFO | Beginning training with tb_writer = None and path is ./logs/
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
2023-11-13,01:05:47 | INFO | Reducer buckets have been rebuilt in this iteration.
