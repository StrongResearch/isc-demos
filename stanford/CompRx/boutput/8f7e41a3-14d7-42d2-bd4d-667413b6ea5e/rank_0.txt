WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        


            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:47:23,298[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,299[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,379[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,575[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,595[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,601[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:47:25,435[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:25,446[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:25,524[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:25,718[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:25,818[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:25,856[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,063[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,070[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,187[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,296[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,425[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,441[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 02:47:27,038[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 02:47:27,041[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
[[36m2023-11-29 02:47:27,042[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
[[36m2023-11-29 02:47:27,043[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
=> Running in inference mode: False
[[36m2023-11-29 02:47:27,045[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
[[36m2023-11-29 02:47:27,045[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating train dataloader 
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
batch_size = 2, learning rate = 4.5e-06
Reached end on node 0
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 3
Reached 1.2 on node 3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth


            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:51:58,140[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,155[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,163[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,298[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,341[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,351[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:52:00,245[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:00,289[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:00,296[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:00,464[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:00,477[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:00,512[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:00,877[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:00,910[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:00,981[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,130[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,142[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,170[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 02:52:01,796[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 02:52:01,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:52:01,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:52:01,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 02:52:01,801[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 02:52:01,802[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 3 on node 0
Reached 5 on node 3
Reached 5 on node 0
Reached end on node 3
Reached end on node 0
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5Reached 1.3 on node 3

Reached 1.4 on node 3
Reached 5 on node 5Reached 2 on node 3

Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
=> Preparing opt_ae 
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1 on node 1Reached 1.2 on node 5

Reached 1.2 on node 1
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1Reached 1.3 on node 2

Reached 1.4 on node 2Reached 1.4 on node 1

Reached 2 on node 1Reached 2 on node 2

Reached 3 on node 2
Reached 3 on node 1
Reached 1.3 on node 5Reached 5 on node 2

Reached 5 on node 1
Reached 1.4 on node 5
Reached 1.3 on node 0
Reached end on node 1Reached 1.4 on node 0
Reached end on node 2

Reached 2 on node 5
Reached 2 on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached 3 on node 0
Reached end on node 5
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.3 on node 3
Reached 1.4 on node 3Reached end on node 4

Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4Reached 1 on node 2

Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2Reached 1.4 on node 4Reached end on node 1


Reached 1.4 on node 3Reached 2 on node 4

Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 3
Reached 1 on node 4Reached 1.4 on node 2

Reached 2 on node 2Reached 1.4 on node 3

Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2Reached 1 on node 4

Reached 1.4 on node 3Reached 2 on node 2

Reached 2 on node 3
Reached 3 on node 2
Reached 1.4 on node 4Reached 3 on node 2

Reached 2 on node 4Reached 3 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 1.4 on node 4Reached 3 on node 3

Reached 2 on node 4Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 0
Reached end on node 5
[[36m2023-11-29 02:52:03,698[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 02:52:05,062[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 02:52:05,510[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:52:05,510[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 02:52:05,510[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 02:52:05,526[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:52:05,529[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <021/2280>] - Data(s): 10.309 (5.497) - Batch(s): 11.572 
(11.363) - AE Loss: 3168134.000 (564913.250) - AE Rec Loss: 21.485 (3.831) - 
Disc Loss: 0.000 (0.000) - 20.32 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 3.688 (5.497) - Batch(s): 11.207 
(11.363) - AE Loss: 129243.273 (564913.250) - AE Rec Loss: 0.876 (3.831) - Disc 
Loss: 0.000 (0.000) - 19.67 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 2.898 (5.497) - Batch(s): 11.159 
(11.363) - AE Loss: 136514.078 (564913.250) - AE Rec Loss: 0.926 (3.831) - Disc 
Loss: 0.000 (0.000) - 19.59 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 5.038 (5.497) - Batch(s): 11.633 
(11.363) - AE Loss: 655097.875 (564913.250) - AE Rec Loss: 4.443 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.37 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 4.587 (5.497) - Batch(s): 10.970 
(11.363) - AE Loss: 430134.000 (564913.250) - AE Rec Loss: 2.917 (3.831) - Disc 
Loss: 0.000 (0.000) - 19.27 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 3.623 (5.497) - Batch(s): 10.986 
(11.363) - AE Loss: 335487.625 (564913.250) - AE Rec Loss: 2.275 (3.831) - Disc 
Loss: 0.000 (0.000) - 19.29 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.563 
(5.963) - AE Loss: 607085.750 (705908.938) - AE Rec Loss: 4.117 (4.787) - Disc 
Loss: 0.000 (0.000) - 19.61 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.567 
(5.963) - AE Loss: 641134.875 (705908.938) - AE Rec Loss: 4.348 (4.787) - Disc 
Loss: 0.000 (0.000) - 19.92 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.001 (2.749) - Batch(s): 0.563 
(5.963) - AE Loss: 457538.781 (705908.938) - AE Rec Loss: 3.103 (4.787) - Disc 
Loss: 0.000 (0.000) - 20.00 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.563 
(5.963) - AE Loss: 296844.938 (705908.938) - AE Rec Loss: 2.013 (4.787) - Disc 
Loss: 0.000 (0.000) - 19.64 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.001 (2.749) - Batch(s): 0.568 
(5.963) - AE Loss: 314544.625 (705908.938) - AE Rec Loss: 2.133 (4.787) - Disc 
Loss: 0.000 (0.000) - 20.62 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.568 
(5.963) - AE Loss: 1885186.250 (705908.938) - AE Rec Loss: 12.785 (4.787) - Disc
Loss: 0.000 (0.000) - 20.67 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.970 
(5.632) - AE Loss: 268854.906 (705409.875) - AE Rec Loss: 1.823 (4.784) - Disc 
Loss: 0.000 (0.000) - 26.82 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 4.292 (1.996) - Batch(s): 4.969 
(5.632) - AE Loss: 135042.016 (705409.875) - AE Rec Loss: 0.916 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.78 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.969 
(5.632) - AE Loss: 350160.062 (705409.875) - AE Rec Loss: 2.375 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.83 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.001 (1.996) - Batch(s): 4.970 
(5.632) - AE Loss: 351748.000 (705409.875) - AE Rec Loss: 2.385 (4.784) - Disc 
Loss: 0.000 (0.000) - 26.84 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 1.609 (1.996) - Batch(s): 4.970 
(5.632) - AE Loss: 493668.125 (705409.875) - AE Rec Loss: 3.348 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.19 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.970 
(5.632) - AE Loss: 1881880.375 (705409.875) - AE Rec Loss: 12.762 (4.784) - Disc
Loss: 0.000 (0.000) - 27.12 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.001 (1.497) - Batch(s): 0.569 
(4.366) - AE Loss: 1714374.125 (712598.250) - AE Rec Loss: 11.626 (4.833) - Disc
Loss: 0.000 (0.000) - 27.75 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.564 
(4.366) - AE Loss: 149359.547 (712598.250) - AE Rec Loss: 1.013 (4.833) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.001 (1.497) - Batch(s): 0.567 
(4.366) - AE Loss: 463969.938 (712598.250) - AE Rec Loss: 3.146 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.11 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.564 
(4.366) - AE Loss: 3596230.000 (712598.250) - AE Rec Loss: 24.388 (4.833) - Disc
Loss: 0.000 (0.000) - 27.18 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.564 
(4.366) - AE Loss: 292675.562 (712598.250) - AE Rec Loss: 1.985 (4.833) - Disc 
Loss: 0.000 (0.000) - 26.83 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.001 (1.497) - Batch(s): 0.569 
(4.366) - AE Loss: 320515.438 (712598.250) - AE Rec Loss: 2.174 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.80 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.568 
(3.605) - AE Loss: 2073601.750 (733957.312) - AE Rec Loss: 14.063 (4.977) - Disc
Loss: 0.000 (0.000) - 27.73 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.568 
(3.605) - AE Loss: 270182.812 (733957.312) - AE Rec Loss: 1.832 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.78 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.563 
(3.605) - AE Loss: 381150.656 (733957.312) - AE Rec Loss: 2.585 (4.977) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.564 
(3.605) - AE Loss: 144966.203 (733957.312) - AE Rec Loss: 0.983 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.19 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.568 
(3.605) - AE Loss: 330180.969 (733957.312) - AE Rec Loss: 2.239 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.12 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.565 
(3.605) - AE Loss: 165531.344 (733957.312) - AE Rec Loss: 1.123 (4.977) - Disc 
Loss: 0.000 (0.000) - 26.87 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.001 (1.001) - Batch(s): 0.818 
(3.141) - AE Loss: 3391041.750 (795993.688) - AE Rec Loss: 22.997 (5.398) - Disc
Loss: 0.000 (0.000) - 28.10 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.001 (1.001) - Batch(s): 0.820 
(3.141) - AE Loss: 613829.000 (795993.688) - AE Rec Loss: 4.163 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.47 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.001 (1.001) - Batch(s): 0.819 
(3.141) - AE Loss: 889843.125 (795993.688) - AE Rec Loss: 6.035 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.20 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.820 
(3.141) - AE Loss: 461564.906 (795993.688) - AE Rec Loss: 3.130 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.53 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.160 (1.001) - Batch(s): 0.820 
(3.141) - AE Loss: 140719.375 (795993.688) - AE Rec Loss: 0.954 (5.398) - Disc 
Loss: 0.000 (0.000) - 28.06 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.819 
(3.141) - AE Loss: 237530.656 (795993.688) - AE Rec Loss: 1.611 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.22 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.564 
(2.773) - AE Loss: 869943.000 (813414.375) - AE Rec Loss: 5.900 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.20 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.567 
(2.773) - AE Loss: 210218.281 (813414.375) - AE Rec Loss: 1.426 (5.516) - Disc 
Loss: 0.000 (0.000) - 28.02 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.568 
(2.773) - AE Loss: 3012073.500 (813414.375) - AE Rec Loss: 20.427 (5.516) - Disc
Loss: 0.000 (0.000) - 28.07 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.567 
(2.773) - AE Loss: 1869700.000 (813414.375) - AE Rec Loss: 12.680 (5.516) - Disc
Loss: 0.000 (0.000) - 27.45 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.564 
(2.773) - AE Loss: 329526.938 (813414.375) - AE Rec Loss: 2.235 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.52 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.564 
(2.773) - AE Loss: 136166.250 (813414.375) - AE Rec Loss: 0.923 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.22 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.389 (0.755) - Batch(s): 0.957 
(2.534) - AE Loss: 400710.000 (836026.812) - AE Rec Loss: 2.717 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.49 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.001 (0.755) - Batch(s): 0.598 
(2.534) - AE Loss: 519364.000 (836026.812) - AE Rec Loss: 3.522 (5.670) - Disc 
Loss: 0.000 (0.000) - 27.70 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.001 (0.755) - Batch(s): 0.598 
(2.534) - AE Loss: 361670.219 (836026.812) - AE Rec Loss: 2.453 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.53 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.598 
(2.534) - AE Loss: 172871.688 (836026.812) - AE Rec Loss: 1.172 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.00 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.953 
(2.534) - AE Loss: 1623004.250 (836026.812) - AE Rec Loss: 11.007 (5.670) - Disc
Loss: 0.000 (0.000) - 27.94 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.951 
(2.534) - AE Loss: 3335137.750 (836026.812) - AE Rec Loss: 22.618 (5.670) - Disc
Loss: 0.000 (0.000) - 27.71 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.001 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 399566.125 (821621.312) - AE Rec Loss: 2.710 (5.572) - Disc 
Loss: 0.000 (0.000) - 29.03 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.352 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 3324155.000 (821621.312) - AE Rec Loss: 22.543 (5.572) - Disc
Loss: 0.000 (0.000) - 28.99 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.010 
(2.365) - AE Loss: 135212.625 (821621.312) - AE Rec Loss: 0.917 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.46 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.001 (0.675) - Batch(s): 1.010 
(2.365) - AE Loss: 228888.656 (821621.312) - AE Rec Loss: 1.552 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.52 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.001 (0.675) - Batch(s): 1.010 
(2.365) - AE Loss: 197878.281 (821621.312) - AE Rec Loss: 1.342 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.23 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.012 
(2.365) - AE Loss: 361978.375 (821621.312) - AE Rec Loss: 2.455 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.24 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 8.547 (0.722) - Batch(s): 9.120 
(3.037) - AE Loss: 1577468.750 (810392.875) - AE Rec Loss: 10.698 (5.496) - Disc
Loss: 0.000 (0.000) - 38.53 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 8.763 
(3.037) - AE Loss: 360945.125 (810392.875) - AE Rec Loss: 2.448 (5.496) - Disc 
Loss: 0.000 (0.000) - 38.81 m remaining

bouta write to tb
[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.118 
(3.037) - AE Loss: 182900.719 (810392.875) - AE Rec Loss: 1.240 (5.496) - Disc 
Loss: 0.000 (0.000) - 38.75 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.120 
(3.037) - AE Loss: 264660.875 (810392.875) - AE Rec Loss: 1.795 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.27 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.001 (0.722) - Batch(s): 9.120 
(3.037) - AE Loss: 705600.000 (810392.875) - AE Rec Loss: 4.785 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.31 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.115 
(3.037) - AE Loss: 1888444.125 (810392.875) - AE Rec Loss: 12.807 (5.496) - Disc
Loss: 0.000 (0.000) - 38.55 m remaining

wrote to tb
[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.306 
(3.171) - AE Loss: 359331.812 (777911.062) - AE Rec Loss: 2.437 (5.276) - Disc 
Loss: 0.000 (0.000) - 42.95 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 3.516 
(3.171) - AE Loss: 205323.766 (777911.062) - AE Rec Loss: 1.392 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.23 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.001 (0.687) - Batch(s): 4.660 
(3.171) - AE Loss: 407419.562 (777911.062) - AE Rec Loss: 2.763 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.17 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.305 
(3.171) - AE Loss: 285742.625 (777911.062) - AE Rec Loss: 1.938 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.71 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.657 
(3.171) - AE Loss: 187304.219 (777911.062) - AE Rec Loss: 1.270 (5.276) - Disc 
Loss: 0.000 (0.000) - 42.97 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 4.090 (0.687) - Batch(s): 4.665 
(3.171) - AE Loss: 292605.000 (777911.062) - AE Rec Loss: 1.984 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.67 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.673 
(2.963) - AE Loss: 467601.062 (789665.562) - AE Rec Loss: 3.171 (5.355) - Disc 
Loss: 0.000 (0.000) - 43.31 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.673 
(2.963) - AE Loss: 1515038.250 (789665.562) - AE Rec Loss: 10.275 (5.355) - Disc
Loss: 0.000 (0.000) - 42.85 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.672 
(2.963) - AE Loss: 1622162.000 (789665.562) - AE Rec Loss: 11.001 (5.355) - Disc
Loss: 0.000 (0.000) - 43.27 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.673 
(2.963) - AE Loss: 271370.500 (789665.562) - AE Rec Loss: 1.840 (5.355) - Disc 
Loss: 0.000 (0.000) - 42.58 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.676 
(2.963) - AE Loss: 1924786.500 (789665.562) - AE Rec Loss: 13.053 (5.355) - Disc
Loss: 0.000 (0.000) - 42.60 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.673 
(2.963) - AE Loss: 1651737.875 (789665.562) - AE Rec Loss: 11.202 (5.355) - Disc
Loss: 0.000 (0.000) - 42.79 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.742 (0.586) - Batch(s): 1.304 
(2.833) - AE Loss: 1766340.750 (788930.750) - AE Rec Loss: 11.979 (5.350) - Disc
Loss: 0.000 (0.000) - 42.92 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.949 
(2.833) - AE Loss: 1897797.500 (788930.750) - AE Rec Loss: 12.870 (5.350) - Disc
Loss: 0.000 (0.000) - 43.18 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.304 
(2.833) - AE Loss: 135234.703 (788930.750) - AE Rec Loss: 0.917 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.13 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.305 
(2.833) - AE Loss: 1824622.500 (788930.750) - AE Rec Loss: 12.374 (5.350) - Disc
Loss: 0.000 (0.000) - 43.60 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.306 
(2.833) - AE Loss: 627557.250 (788930.750) - AE Rec Loss: 4.256 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.63 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.301 
(2.833) - AE Loss: 281073.688 (788930.750) - AE Rec Loss: 1.906 (5.350) - Disc 
Loss: 0.000 (0.000) - 42.94 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.001 (0.560) - Batch(s): 2.888 
(2.856) - AE Loss: 114003.188 (764211.062) - AE Rec Loss: 0.773 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.31 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.001 (0.560) - Batch(s): 2.887 
(2.856) - AE Loss: 515891.219 (764211.062) - AE Rec Loss: 3.499 (5.183) - Disc 
Loss: 0.000 (0.000) - 46.00 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.001 (0.560) - Batch(s): 2.888 
(2.856) - AE Loss: 252639.766 (764211.062) - AE Rec Loss: 1.713 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.57 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.242 
(2.856) - AE Loss: 201151.109 (764211.062) - AE Rec Loss: 1.364 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.52 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 2.671 (0.560) - Batch(s): 3.248 
(2.856) - AE Loss: 418693.875 (764211.062) - AE Rec Loss: 2.839 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.97 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.240 
(2.856) - AE Loss: 1782866.750 (764211.062) - AE Rec Loss: 12.091 (5.183) - Disc
Loss: 0.000 (0.000) - 45.33 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.001 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 386623.188 (756271.625) - AE Rec Loss: 2.622 (5.129) - Disc 
Loss: 0.000 (0.000) - 44.89 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.001 (0.523) - Batch(s): 0.666 
(2.710) - AE Loss: 291299.062 (756271.625) - AE Rec Loss: 1.975 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.14 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 242096.391 (756271.625) - AE Rec Loss: 1.642 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.56 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 1609006.000 (756271.625) - AE Rec Loss: 10.912 (5.129) - Disc
Loss: 0.000 (0.000) - 45.09 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 260498.391 (756271.625) - AE Rec Loss: 1.767 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.53 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.666 
(2.710) - AE Loss: 1557942.000 (756271.625) - AE Rec Loss: 10.565 (5.129) - Disc
Loss: 0.000 (0.000) - 44.91 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.503 
(2.695) - AE Loss: 409990.000 (767917.438) - AE Rec Loss: 2.780 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.54 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.503 
(2.695) - AE Loss: 377019.719 (767917.438) - AE Rec Loss: 2.557 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.97 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.500 
(2.695) - AE Loss: 1859457.000 (767917.438) - AE Rec Loss: 12.610 (5.208) - Disc
Loss: 0.000 (0.000) - 46.37 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.505 
(2.695) - AE Loss: 750327.750 (767917.438) - AE Rec Loss: 5.088 (5.208) - Disc 
Loss: 0.000 (0.000) - 47.01 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 1.932 (0.500) - Batch(s): 2.505 
(2.695) - AE Loss: 412575.938 (767917.438) - AE Rec Loss: 2.798 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.35 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.001 (0.500) - Batch(s): 2.147 
(2.695) - AE Loss: 475799.875 (767917.438) - AE Rec Loss: 3.227 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.59 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 2.923 
(2.722) - AE Loss: 622477.375 (758948.062) - AE Rec Loss: 4.221 (5.147) - Disc 
Loss: 0.000 (0.000) - 48.50 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 2.711 (0.486) - Batch(s): 3.283 
(2.722) - AE Loss: 238308.219 (758948.062) - AE Rec Loss: 1.616 (5.147) - Disc 
Loss: 0.000 (0.000) - 48.68 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.260 (0.486) - Batch(s): 2.924 
(2.722) - AE Loss: 272894.875 (758948.062) - AE Rec Loss: 1.851 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.10 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 3.279 
(2.722) - AE Loss: 812057.125 (758948.062) - AE Rec Loss: 5.507 (5.147) - Disc 
Loss: 0.000 (0.000) - 48.51 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 2.923 
(2.722) - AE Loss: 1986123.250 (758948.062) - AE Rec Loss: 13.469 (5.147) - Disc
Loss: 0.000 (0.000) - 48.73 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 2.924 
(2.722) - AE Loss: 109122.148 (758948.062) - AE Rec Loss: 0.740 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.13 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 203980.578 (761127.125) - AE Rec Loss: 1.383 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.01 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.652 
(2.607) - AE Loss: 1638345.500 (761127.125) - AE Rec Loss: 11.111 (5.162) - Disc
Loss: 0.000 (0.000) - 48.24 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 3074720.500 (761127.125) - AE Rec Loss: 20.852 (5.162) - Disc
Loss: 0.000 (0.000) - 48.19 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 108214.000 (761127.125) - AE Rec Loss: 0.734 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.02 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 470073.906 (761127.125) - AE Rec Loss: 3.188 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.60 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 356102.250 (761127.125) - AE Rec Loss: 2.415 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.63 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.842 
(2.531) - AE Loss: 664815.375 (743328.562) - AE Rec Loss: 4.509 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.28 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.635 (0.437) - Batch(s): 1.198 
(2.531) - AE Loss: 1957595.000 (743328.562) - AE Rec Loss: 13.276 (5.041) - Disc
Loss: 0.000 (0.000) - 48.06 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.200 
(2.531) - AE Loss: 139128.125 (743328.562) - AE Rec Loss: 0.944 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.66 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.198 
(2.531) - AE Loss: 809962.625 (743328.562) - AE Rec Loss: 5.493 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.23 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.195 
(2.531) - AE Loss: 161305.656 (743328.562) - AE Rec Loss: 1.094 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.07 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.198 
(2.531) - AE Loss: 98026.234 (743328.562) - AE Rec Loss: 0.665 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.63 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.001 (0.428) - Batch(s): 3.234 
(2.578) - AE Loss: 396339.344 (745824.375) - AE Rec Loss: 2.688 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.49 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.001 (0.428) - Batch(s): 3.234 
(2.578) - AE Loss: 229030.891 (745824.375) - AE Rec Loss: 1.553 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.28 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.234 
(2.578) - AE Loss: 1639347.750 (745824.375) - AE Rec Loss: 11.118 (5.058) - Disc
Loss: 0.000 (0.000) - 50.87 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.234 
(2.578) - AE Loss: 184176.328 (745824.375) - AE Rec Loss: 1.249 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.84 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.588 
(2.578) - AE Loss: 1734212.000 (745824.375) - AE Rec Loss: 11.761 (5.058) - Disc
Loss: 0.000 (0.000) - 50.29 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 3.019 (0.428) - Batch(s): 3.593 
(2.578) - AE Loss: 257464.375 (745824.375) - AE Rec Loss: 1.746 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.45 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 02:53:01,594[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 02:53:02,661[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 02:53:02,880[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 02:53:02,887[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 02:53:02,891[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 02:53:02,899[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 02:53:02,903[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 02:53:02,908[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 02:53:02,912[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 02:53:02,920[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 02:53:03,183[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 02:53:04,603[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 02:53:09,429[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 02:53:09,446[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 02:53:11,388[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 02:53:11,388[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 02:53:11,388[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 02:53:11,414[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.129 
(2.944) - AE Loss: 230067.797 (727184.375) - AE Rec Loss: 1.560 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.66 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.129 
(2.944) - AE Loss: 185365.422 (727184.375) - AE Rec Loss: 1.257 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.25 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.001 (0.408) - Batch(s): 0.651 
(2.944) - AE Loss: 241582.844 (727184.375) - AE Rec Loss: 1.638 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.29 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.129 
(2.944) - AE Loss: 241148.969 (727184.375) - AE Rec Loss: 1.635 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.08 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.129 
(2.944) - AE Loss: 395656.438 (727184.375) - AE Rec Loss: 2.683 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.63 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.129 
(2.944) - AE Loss: 369978.000 (727184.375) - AE Rec Loss: 2.509 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.10 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.569 
(2.836) - AE Loss: 97991.172 (728193.562) - AE Rec Loss: 0.665 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.88 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.567 
(2.836) - AE Loss: 355206.969 (728193.562) - AE Rec Loss: 2.409 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.85 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.001 (0.389) - Batch(s): 0.566 
(2.836) - AE Loss: 1536189.500 (728193.562) - AE Rec Loss: 10.418 (4.938) - Disc
Loss: 0.000 (0.000) - 58.32 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.564 
(2.836) - AE Loss: 303811.125 (728193.562) - AE Rec Loss: 2.060 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.33 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.568 
(2.836) - AE Loss: 1642077.750 (728193.562) - AE Rec Loss: 11.136 (4.938) - Disc
Loss: 0.000 (0.000) - 58.52 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.568 
(2.836) - AE Loss: 103863.805 (728193.562) - AE Rec Loss: 0.704 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.48 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (0.372) - Batch(s): 0.567 
(2.737) - AE Loss: 191263.922 (720012.188) - AE Rec Loss: 1.297 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.58 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.570 
(2.737) - AE Loss: 1787614.625 (720012.188) - AE Rec Loss: 12.123 (4.883) - Disc
Loss: 0.000 (0.000) - 58.13 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (0.372) - Batch(s): 0.569 
(2.737) - AE Loss: 98249.766 (720012.188) - AE Rec Loss: 0.666 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.74 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (0.372) - Batch(s): 0.565 
(2.737) - AE Loss: 970014.125 (720012.188) - AE Rec Loss: 6.578 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.60 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (0.372) - Batch(s): 0.568 
(2.737) - AE Loss: 178251.062 (720012.188) - AE Rec Loss: 1.209 (4.883) - Disc 
Loss: 0.000 (0.000) - 58.10 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (0.372) - Batch(s): 0.570 
(2.737) - AE Loss: 502632.438 (720012.188) - AE Rec Loss: 3.409 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.78 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.658 
(2.651) - AE Loss: 188528.812 (705130.312) - AE Rec Loss: 1.279 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.49 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.660 
(2.651) - AE Loss: 92640.031 (705130.312) - AE Rec Loss: 0.628 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.15 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.658 
(2.651) - AE Loss: 278375.188 (705130.312) - AE Rec Loss: 1.888 (4.782) - Disc 
Loss: 0.000 (0.000) - 56.96 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.658 
(2.651) - AE Loss: 395724.281 (705130.312) - AE Rec Loss: 2.684 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.47 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.658 
(2.651) - AE Loss: 294761.500 (705130.312) - AE Rec Loss: 1.999 (4.782) - Disc 
Loss: 0.000 (0.000) - 56.97 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.661 
(2.651) - AE Loss: 219411.875 (705130.312) - AE Rec Loss: 1.488 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.11 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.570 
(2.567) - AE Loss: 1661044.750 (707230.625) - AE Rec Loss: 11.265 (4.796) - Disc
Loss: 0.000 (0.000) - 56.48 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.570 
(2.567) - AE Loss: 340900.469 (707230.625) - AE Rec Loss: 2.312 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.81 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.567 
(2.567) - AE Loss: 1723192.000 (707230.625) - AE Rec Loss: 11.686 (4.796) - Disc
Loss: 0.000 (0.000) - 56.29 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.570 
(2.567) - AE Loss: 1618433.875 (707230.625) - AE Rec Loss: 10.976 (4.796) - Disc
Loss: 0.000 (0.000) - 56.44 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.569 
(2.567) - AE Loss: 176466.219 (707230.625) - AE Rec Loss: 1.197 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.78 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.566 
(2.567) - AE Loss: 294524.188 (707230.625) - AE Rec Loss: 1.997 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.30 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.570 
(2.491) - AE Loss: 374800.156 (708197.750) - AE Rec Loss: 2.542 (4.803) - Disc 
Loss: 0.000 (0.000) - 55.83 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.571 
(2.491) - AE Loss: 310204.875 (708197.750) - AE Rec Loss: 2.104 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.15 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.568 
(2.491) - AE Loss: 344623.688 (708197.750) - AE Rec Loss: 2.337 (4.803) - Disc 
Loss: 0.000 (0.000) - 55.64 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.570 
(2.491) - AE Loss: 1467128.500 (708197.750) - AE Rec Loss: 9.950 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.13 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.565 
(2.491) - AE Loss: 1826943.750 (708197.750) - AE Rec Loss: 12.390 (4.803) - Disc
Loss: 0.000 (0.000) - 55.66 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.570 
(2.491) - AE Loss: 161620.812 (708197.750) - AE Rec Loss: 1.096 (4.803) - Disc 
Loss: 0.000 (0.000) - 55.79 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:53:32,643[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,774[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,785[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,831[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,862[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:33,003[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:53:34,806[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:34,907[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:34,920[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:34,967[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,008[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,120[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,552[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,561[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,629[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,683[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,760[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 02:53:35,761[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:53:35,761[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataset) = 54706
[[36m2023-11-29 02:53:35,764[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 02:53:35,764[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(train_dataset) = 54706
[[36m2023-11-29 02:53:35,765[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
[[36m2023-11-29 02:53:35,767[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Running in inference mode: False
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
=> Preparing opt_ae 
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.3 on node 2Reached 3 on node 5

Reached 1.4 on node 2
Reached 5 on node 5
Reached 2 on node 2
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 0
=> Preparing opt_ae 
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1 on node 0
Reached 1.2 on node 3
Reached 1.2 on node 0
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4Reached 1.3 on node 0

Reached 1.4 on node 0
Reached 2 on node 4
Reached 2 on node 0
Reached 3 on node 4
Reached 3 on node 0Reached 5 on node 4

Reached end on node 4
Reached 5 on node 0Reached 1.3 on node 3

Reached 1.4 on node 3
Reached end on node 0
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 3
Reached 2 on node 5
Reached 3 on node 3
Reached 3 on node 5
Reached 5 on node 3
Reached 5 on node 5Reached end on node 3

Reached end on node 5
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 3 on node 1
Reached 2 on node 2Reached 5 on node 1

Reached end on node 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3Reached 1 on node 2

Reached 1.4 on node 2
Reached 2 on node 2Reached 1.4 on node 3

Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2Reached 1.4 on node 3

Reached 2 on node 2Reached 2 on node 3

Reached end on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 4
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 1 on node 3Reached 2 on node 4

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 1.4 on node 4Reached 2 on node 5

Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 0
Reached 1 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 02:53:37,465[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
[[36m2023-11-29 02:53:40,089[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 02:53:41,296[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:53:41,296[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 02:53:41,310[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 02:53:41,313[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:53:41,314[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <041/2280>] - Data(s): 7.564 (5.979) - Batch(s): 10.119 
(10.088) - AE Loss: 241246.234 (354775.531) - AE Rec Loss: 1.636 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.25 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 5.849 (5.979) - Batch(s): 10.148 
(10.088) - AE Loss: 241654.594 (354775.531) - AE Rec Loss: 1.639 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 7.753 (5.979) - Batch(s): 10.138 
(10.088) - AE Loss: 186586.859 (354775.531) - AE Rec Loss: 1.265 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 4.101 (5.979) - Batch(s): 10.141 
(10.088) - AE Loss: 229973.531 (354775.531) - AE Rec Loss: 1.560 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 5.370 (5.979) - Batch(s): 10.137 
(10.088) - AE Loss: 370459.938 (354775.531) - AE Rec Loss: 2.512 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 4.903 (5.979) - Batch(s): 10.135 
(10.088) - AE Loss: 395176.000 (354775.531) - AE Rec Loss: 2.680 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.377 (3.005) - Batch(s): 0.944 
(5.470) - AE Loss: 354529.125 (552625.312) - AE Rec Loss: 2.404 (3.748) - Disc 
Loss: 0.000 (0.000) - 10.00 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.586 
(5.470) - AE Loss: 1537734.500 (552625.312) - AE Rec Loss: 10.428 (3.748) - Disc
Loss: 0.000 (0.000) - 10.00 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.939 
(5.470) - AE Loss: 308931.406 (552625.312) - AE Rec Loss: 2.095 (3.748) - Disc 
Loss: 0.000 (0.000) - 10.00 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.586 
(5.470) - AE Loss: 1647528.250 (552625.312) - AE Rec Loss: 11.173 (3.748) - Disc
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.586 
(5.470) - AE Loss: 103309.891 (552625.312) - AE Rec Loss: 0.701 (3.748) - Disc 
Loss: 0.000 (0.000) - 10.00 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.942 
(5.470) - AE Loss: 109740.234 (552625.312) - AE Rec Loss: 0.744 (3.748) - Disc 
Loss: 0.000 (0.000) - 10.00 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.686 
(3.876) - AE Loss: 963580.938 (545897.938) - AE Rec Loss: 6.535 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.49 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.686 
(3.876) - AE Loss: 164414.812 (545897.938) - AE Rec Loss: 1.115 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.49 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.687 
(3.876) - AE Loss: 1779452.750 (545897.938) - AE Rec Loss: 12.068 (3.702) - Disc
Loss: 0.000 (0.000) - 10.49 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.686 
(3.876) - AE Loss: 185795.375 (545897.938) - AE Rec Loss: 1.260 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.49 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.688 
(3.876) - AE Loss: 103311.359 (545897.938) - AE Rec Loss: 0.701 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.49 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.687 
(3.876) - AE Loss: 490132.438 (545897.938) - AE Rec Loss: 3.324 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.48 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.539) - Batch(s): 1.213 
(3.274) - AE Loss: 91225.031 (496945.500) - AE Rec Loss: 0.619 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.67 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.721 (1.539) - Batch(s): 1.287 
(3.274) - AE Loss: 264502.938 (496945.500) - AE Rec Loss: 1.794 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.68 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.539) - Batch(s): 1.290 
(3.274) - AE Loss: 172042.125 (496945.500) - AE Rec Loss: 1.167 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.68 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.566 
(3.274) - AE Loss: 267248.031 (496945.500) - AE Rec Loss: 1.812 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.68 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 1.003 (1.539) - Batch(s): 1.570 
(3.274) - AE Loss: 203233.984 (496945.500) - AE Rec Loss: 1.378 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.68 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.287 
(3.274) - AE Loss: 379597.875 (496945.500) - AE Rec Loss: 2.574 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.68 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.568 
(2.749) - AE Loss: 1729784.000 (547931.812) - AE Rec Loss: 11.731 (3.716) - Disc
Loss: 0.000 (0.000) - 12.11 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.677 
(2.749) - AE Loss: 280608.750 (547931.812) - AE Rec Loss: 1.903 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.11 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.115 (1.233) - Batch(s): 0.682 
(2.749) - AE Loss: 164471.438 (547931.812) - AE Rec Loss: 1.115 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.10 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.570 
(2.749) - AE Loss: 345541.312 (547931.812) - AE Rec Loss: 2.343 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.11 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (1.233) - Batch(s): 0.570 
(2.749) - AE Loss: 1665277.375 (547931.812) - AE Rec Loss: 11.293 (3.716) - Disc
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.679 
(2.749) - AE Loss: 1600994.000 (547931.812) - AE Rec Loss: 10.857 (3.716) - Disc
Loss: 0.000 (0.000) - 12.11 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.031 (1.060) - Batch(s): 3.005 
(2.792) - AE Loss: 362092.938 (577584.938) - AE Rec Loss: 2.456 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.34 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.005 
(2.792) - AE Loss: 327230.031 (577584.938) - AE Rec Loss: 2.219 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.007 
(2.792) - AE Loss: 1454396.750 (577584.938) - AE Rec Loss: 9.863 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.008 
(2.792) - AE Loss: 1831493.125 (577584.938) - AE Rec Loss: 12.421 (3.917) - Disc
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.007 
(2.792) - AE Loss: 317895.781 (577584.938) - AE Rec Loss: 2.156 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 2.310 (1.060) - Batch(s): 3.007 
(2.792) - AE Loss: 155442.844 (577584.938) - AE Rec Loss: 1.054 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.001 (0.934) - Batch(s): 2.680 
(2.772) - AE Loss: 120180.281 (618374.750) - AE Rec Loss: 0.815 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.325 
(2.772) - AE Loss: 1719718.000 (618374.750) - AE Rec Loss: 11.663 (4.194) - Disc
Loss: 0.000 (0.000) - 16.24 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.681 
(2.772) - AE Loss: 1762588.250 (618374.750) - AE Rec Loss: 11.953 (4.194) - Disc
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.677 
(2.772) - AE Loss: 676625.125 (618374.750) - AE Rec Loss: 4.589 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 2.111 (0.934) - Batch(s): 2.682 
(2.772) - AE Loss: 273006.250 (618374.750) - AE Rec Loss: 1.851 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.683 
(2.772) - AE Loss: 583003.812 (618374.750) - AE Rec Loss: 3.954 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.001 (0.817) - Batch(s): 0.566 
(2.496) - AE Loss: 1692357.250 (625452.438) - AE Rec Loss: 11.477 (4.242) - Disc
Loss: 0.000 (0.000) - 16.46 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.001 (0.817) - Batch(s): 0.571 
(2.496) - AE Loss: 1442922.000 (625452.438) - AE Rec Loss: 9.785 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.46 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.001 (0.817) - Batch(s): 0.566 
(2.496) - AE Loss: 1528224.000 (625452.438) - AE Rec Loss: 10.364 (4.242) - Disc
Loss: 0.000 (0.000) - 16.46 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.569 
(2.496) - AE Loss: 116715.234 (625452.438) - AE Rec Loss: 0.792 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.46 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.569 
(2.496) - AE Loss: 114685.062 (625452.438) - AE Rec Loss: 0.778 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.45 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.570 
(2.496) - AE Loss: 242815.953 (625452.438) - AE Rec Loss: 1.647 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.46 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.763) - Batch(s): 3.150 
(2.569) - AE Loss: 324866.188 (601630.125) - AE Rec Loss: 2.203 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.57 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 2.499 (0.763) - Batch(s): 3.149 
(2.569) - AE Loss: 198625.828 (601630.125) - AE Rec Loss: 1.347 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.59 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.763) - Batch(s): 3.150 
(2.569) - AE Loss: 205011.328 (601630.125) - AE Rec Loss: 1.390 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.59 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.763) - Batch(s): 3.150 
(2.569) - AE Loss: 181173.016 (601630.125) - AE Rec Loss: 1.229 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.59 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.150 
(2.569) - AE Loss: 194132.812 (601630.125) - AE Rec Loss: 1.317 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.59 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.763) - Batch(s): 3.150 
(2.569) - AE Loss: 1596882.500 (601630.125) - AE Rec Loss: 10.830 (4.080) - Disc
Loss: 0.000 (0.000) - 18.59 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 12.681 (0.896) - Batch(s): 13.255 
(3.637) - AE Loss: 715949.250 (610211.000) - AE Rec Loss: 4.855 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.98 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.896) - Batch(s): 13.252 
(3.637) - AE Loss: 106973.344 (610211.000) - AE Rec Loss: 0.725 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.99 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.896) - Batch(s): 13.255 
(3.637) - AE Loss: 231857.125 (610211.000) - AE Rec Loss: 1.572 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.99 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 5.409 (0.896) - Batch(s): 13.251 
(3.637) - AE Loss: 346782.031 (610211.000) - AE Rec Loss: 2.352 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.99 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.896) - Batch(s): 13.250 
(3.637) - AE Loss: 156205.906 (610211.000) - AE Rec Loss: 1.059 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.99 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 7.081 (0.896) - Batch(s): 13.252 
(3.637) - AE Loss: 1775117.500 (610211.000) - AE Rec Loss: 12.038 (4.138) - Disc
Loss: 0.000 (0.000) - 27.99 m remaining

bouta write to tb
wrote to tb
[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 0.570 
(3.409) - AE Loss: 1694359.500 (610047.562) - AE Rec Loss: 11.491 (4.137) - Disc
Loss: 0.000 (0.000) - 28.38 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.182 
(3.409) - AE Loss: 238779.594 (610047.562) - AE Rec Loss: 1.619 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.40 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.185 
(3.409) - AE Loss: 204003.781 (610047.562) - AE Rec Loss: 1.383 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.40 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.182 
(3.409) - AE Loss: 1702695.250 (610047.562) - AE Rec Loss: 11.547 (4.137) - Disc
Loss: 0.000 (0.000) - 28.40 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.815) - Batch(s): 1.179 
(3.409) - AE Loss: 103577.297 (610047.562) - AE Rec Loss: 0.702 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.40 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.180 
(3.409) - AE Loss: 454735.000 (610047.562) - AE Rec Loss: 3.084 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.40 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.319 
(3.402) - AE Loss: 1816134.125 (614117.875) - AE Rec Loss: 12.316 (4.165) - Disc
Loss: 0.000 (0.000) - 30.27 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 2.613 (0.765) - Batch(s): 3.319 
(3.402) - AE Loss: 200157.906 (614117.875) - AE Rec Loss: 1.357 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.28 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 392332.906 (614117.875) - AE Rec Loss: 2.661 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.28 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 103665.273 (614117.875) - AE Rec Loss: 0.703 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.28 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.319 
(3.402) - AE Loss: 372110.812 (614117.875) - AE Rec Loss: 2.524 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.28 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.319 
(3.402) - AE Loss: 176465.953 (614117.875) - AE Rec Loss: 1.197 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.28 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.568 
(3.184) - AE Loss: 271913.438 (624953.438) - AE Rec Loss: 1.844 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.571 
(3.184) - AE Loss: 489879.500 (624953.438) - AE Rec Loss: 3.322 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.565 
(3.184) - AE Loss: 101276.062 (624953.438) - AE Rec Loss: 0.687 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.566 
(3.184) - AE Loss: 1692677.375 (624953.438) - AE Rec Loss: 11.479 (4.238) - Disc
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.570 
(3.184) - AE Loss: 268624.750 (624953.438) - AE Rec Loss: 1.822 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.20 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.569 
(3.184) - AE Loss: 1911739.000 (624953.438) - AE Rec Loss: 12.965 (4.238) - Disc
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.569 
(2.997) - AE Loss: 1560414.625 (649675.875) - AE Rec Loss: 10.582 (4.406) - Disc
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.571 
(2.997) - AE Loss: 161318.344 (649675.875) - AE Rec Loss: 1.094 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.13 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.572 
(2.997) - AE Loss: 186903.000 (649675.875) - AE Rec Loss: 1.268 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.565 
(2.997) - AE Loss: 1738988.250 (649675.875) - AE Rec Loss: 11.793 (4.406) - Disc
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.568 
(2.997) - AE Loss: 1562200.750 (649675.875) - AE Rec Loss: 10.594 (4.406) - Disc
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.568 
(2.997) - AE Loss: 171955.828 (649675.875) - AE Rec Loss: 1.166 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.152 (0.646) - Batch(s): 6.576 
(3.236) - AE Loss: 307342.969 (644607.750) - AE Rec Loss: 2.084 (4.372) - Disc 
Loss: 0.000 (0.000) - 34.05 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.001 (0.646) - Batch(s): 6.575 
(3.236) - AE Loss: 257524.547 (644607.750) - AE Rec Loss: 1.746 (4.372) - Disc 
Loss: 0.000 (0.000) - 34.04 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 5.924 (0.646) - Batch(s): 6.575 
(3.236) - AE Loss: 220709.562 (644607.750) - AE Rec Loss: 1.497 (4.372) - Disc 
Loss: 0.000 (0.000) - 34.05 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.575 
(3.236) - AE Loss: 94338.391 (644607.750) - AE Rec Loss: 0.640 (4.372) - Disc 
Loss: 0.000 (0.000) - 34.05 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.575 
(3.236) - AE Loss: 3106836.500 (644607.750) - AE Rec Loss: 21.070 (4.372) - Disc
Loss: 0.000 (0.000) - 34.05 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.001 (0.646) - Batch(s): 6.575 
(3.236) - AE Loss: 220522.172 (644607.750) - AE Rec Loss: 1.496 (4.372) - Disc 
Loss: 0.000 (0.000) - 34.05 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.568 
(3.069) - AE Loss: 334471.062 (663976.812) - AE Rec Loss: 2.268 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.92 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.571 
(3.069) - AE Loss: 502775.875 (663976.812) - AE Rec Loss: 3.410 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.92 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.569 
(3.069) - AE Loss: 1659478.750 (663976.812) - AE Rec Loss: 11.254 (4.503) - Disc
Loss: 0.000 (0.000) - 33.92 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.565 
(3.069) - AE Loss: 2591411.750 (663976.812) - AE Rec Loss: 17.574 (4.503) - Disc
Loss: 0.000 (0.000) - 33.92 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.566 
(3.069) - AE Loss: 365543.250 (663976.812) - AE Rec Loss: 2.479 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.92 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.570 
(3.069) - AE Loss: 100851.906 (663976.812) - AE Rec Loss: 0.684 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.91 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.805 
(2.943) - AE Loss: 303878.656 (681705.250) - AE Rec Loss: 2.061 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.16 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 403879.312 (681705.250) - AE Rec Loss: 2.739 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.16 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 2256641.750 (681705.250) - AE Rec Loss: 15.304 (4.623) - Disc
Loss: 0.000 (0.000) - 34.16 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 1823106.000 (681705.250) - AE Rec Loss: 12.364 (4.623) - Disc
Loss: 0.000 (0.000) - 34.16 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 204052.047 (681705.250) - AE Rec Loss: 1.384 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.16 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 208714.375 (681705.250) - AE Rec Loss: 1.415 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.15 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.115 
(3.286) - AE Loss: 140664.750 (686901.750) - AE Rec Loss: 0.954 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.39 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.597) - Batch(s): 9.115 
(3.286) - AE Loss: 1612141.750 (686901.750) - AE Rec Loss: 10.933 (4.658) - Disc
Loss: 0.000 (0.000) - 39.38 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.115 
(3.286) - AE Loss: 329915.875 (686901.750) - AE Rec Loss: 2.237 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.39 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.115 
(3.286) - AE Loss: 99310.141 (686901.750) - AE Rec Loss: 0.673 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.39 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 8.444 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 372244.438 (686901.750) - AE Rec Loss: 2.524 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.39 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.115 
(3.286) - AE Loss: 142983.344 (686901.750) - AE Rec Loss: 0.970 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.39 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.570 
(3.143) - AE Loss: 1755810.750 (694935.000) - AE Rec Loss: 11.907 (4.713) - Disc
Loss: 0.000 (0.000) - 39.16 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.568 
(3.143) - AE Loss: 180147.266 (694935.000) - AE Rec Loss: 1.222 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.17 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.001 (0.565) - Batch(s): 0.567 
(3.143) - AE Loss: 1696655.750 (694935.000) - AE Rec Loss: 11.506 (4.713) - Disc
Loss: 0.000 (0.000) - 39.17 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.568 
(3.143) - AE Loss: 94302.938 (694935.000) - AE Rec Loss: 0.640 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.17 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.571 
(3.143) - AE Loss: 1610106.250 (694935.000) - AE Rec Loss: 10.919 (4.713) - Disc
Loss: 0.000 (0.000) - 39.17 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.566 
(3.143) - AE Loss: 329970.750 (694935.000) - AE Rec Loss: 2.238 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.17 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.571 
(3.014) - AE Loss: 223888.250 (691524.375) - AE Rec Loss: 1.518 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.94 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.567 
(3.014) - AE Loss: 643826.062 (691524.375) - AE Rec Loss: 4.366 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.95 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.570 
(3.014) - AE Loss: 522650.031 (691524.375) - AE Rec Loss: 3.544 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.95 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.566 
(3.014) - AE Loss: 92162.812 (691524.375) - AE Rec Loss: 0.625 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.95 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.573 
(3.014) - AE Loss: 137908.281 (691524.375) - AE Rec Loss: 0.935 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.95 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.570 
(3.014) - AE Loss: 1887156.000 (691524.375) - AE Rec Loss: 12.798 (4.690) - Disc
Loss: 0.000 (0.000) - 38.95 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 02:54:46,247[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 02:54:50,281[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:55:05,980[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:05,996[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,027[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,076[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,076[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,504[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:55:08,182[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:08,187[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:08,192[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:08,222[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:08,306[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:08,721[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:08,888[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:08,929[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:08,930[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:08,942[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:08,993[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,226[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 02:55:09,697[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 02:55:09,698[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 02:55:09,700[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 02:55:09,701[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:55:09,701[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:55:09,701[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 3 on node 4
Reached 5 on node 0
Reached 5 on node 4
Reached end on node 0
Reached end on node 4
Reached 3 on node 5
Reached 3 on node 2Reached 5 on node 5

Reached 5 on node 2Reached end on node 5

Reached end on node 2
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0Reached 1.3 on node 1

Reached 1.4 on node 0Reached 1.4 on node 1

Reached 2 on node 0Reached 2 on node 1

Reached 3 on node 0
Reached 3 on node 1
Reached 5 on node 0Reached 5 on node 1

Reached 1.3 on node 4Reached 1.3 on node 2

Reached end on node 1Reached end on node 0Reached 1.3 on node 3

Reached 1.4 on node 2
Reached 1.4 on node 4

Reached 1.4 on node 3
Reached 2 on node 2
Reached 2 on node 3Reached 2 on node 4

Reached 3 on node 2
Reached 1.3 on node 5Reached 3 on node 3
Reached 3 on node 4
Reached 5 on node 2

Reached 1.4 on node 5
Reached 5 on node 3
Reached 5 on node 4
Reached 2 on node 5
Reached end on node 2
Reached end on node 3Reached end on node 4

Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 1 on node 2Reached 2 on node 3

Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 1 on node 4
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 1 on node 4Reached 2 on node 2

Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2Reached 1 on node 4

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 1.4 on node 4Reached 3 on node 2

Reached 2 on node 4Reached 1 on node 5
Reached 3 on node 2

Reached 5 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1 on node 4Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5Reached 3 on node 4

Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 1.4 on node 5
Reached 5 on node 4Reached 2 on node 5

Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 0
Reached end on node 1
[[36m2023-11-29 02:55:11,498[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 2
Reached end on node 3
[[36m2023-11-29 02:55:12,783[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 02:55:13,284[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:55:13,284[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 02:55:13,284[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 02:55:13,304[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:55:13,308[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <041/2280>] - Data(s): 5.842 (5.637) - Batch(s): 10.149 
(10.136) - AE Loss: 241246.234 (354579.156) - AE Rec Loss: 1.636 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.27 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 7.690 (5.637) - Batch(s): 9.986 
(10.136) - AE Loss: 185751.438 (354579.156) - AE Rec Loss: 1.260 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 5.966 (5.637) - Batch(s): 10.307 
(10.136) - AE Loss: 396820.469 (354579.156) - AE Rec Loss: 2.691 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.41 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 5.766 (5.637) - Batch(s): 10.151 
(10.136) - AE Loss: 241543.094 (354579.156) - AE Rec Loss: 1.638 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 3.818 (5.637) - Batch(s): 9.967 
(10.136) - AE Loss: 230721.281 (354579.156) - AE Rec Loss: 1.565 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.11 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 4.665 (5.637) - Batch(s): 10.009 
(10.136) - AE Loss: 368924.406 (354579.156) - AE Rec Loss: 2.502 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.720 
(5.472) - AE Loss: 108604.312 (552517.875) - AE Rec Loss: 0.737 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.720 
(5.472) - AE Loss: 355203.875 (552517.875) - AE Rec Loss: 2.409 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.27 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.720 
(5.472) - AE Loss: 1537639.875 (552517.875) - AE Rec Loss: 10.428 (3.747) - Disc
Loss: 0.000 (0.000) - 10.12 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.719 
(5.472) - AE Loss: 103921.602 (552517.875) - AE Rec Loss: 0.705 (3.747) - Disc 
Loss: 0.000 (0.000) - 9.97 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.719 
(5.472) - AE Loss: 307330.750 (552517.875) - AE Rec Loss: 2.084 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.720 
(5.472) - AE Loss: 1647528.250 (552517.875) - AE Rec Loss: 11.173 (3.747) - Disc
Loss: 0.000 (0.000) - 10.13 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.803 
(3.918) - AE Loss: 102863.117 (545726.000) - AE Rec Loss: 0.698 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.60 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.809 
(3.918) - AE Loss: 184496.719 (545726.000) - AE Rec Loss: 1.251 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.71 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.808 
(3.918) - AE Loss: 163905.344 (545726.000) - AE Rec Loss: 1.112 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.85 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.809 
(3.918) - AE Loss: 490132.438 (545726.000) - AE Rec Loss: 3.324 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.72 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.809 
(3.918) - AE Loss: 963077.188 (545726.000) - AE Rec Loss: 6.531 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.60 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (1.895) - Batch(s): 0.809 
(3.918) - AE Loss: 1779297.875 (545726.000) - AE Rec Loss: 12.067 (3.701) - Disc
Loss: 0.000 (0.000) - 10.57 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.364 
(4.089) - AE Loss: 380018.000 (496894.125) - AE Rec Loss: 2.577 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.65 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.514) - Batch(s): 4.716 
(4.089) - AE Loss: 268793.000 (496894.125) - AE Rec Loss: 1.823 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.41 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.295 (1.514) - Batch(s): 4.364 
(4.089) - AE Loss: 264751.625 (496894.125) - AE Rec Loss: 1.795 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.51 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 4.151 (1.514) - Batch(s): 4.722 
(4.089) - AE Loss: 203697.781 (496894.125) - AE Rec Loss: 1.381 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.40 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.514) - Batch(s): 4.364 
(4.089) - AE Loss: 91163.383 (496894.125) - AE Rec Loss: 0.618 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.52 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.514) - Batch(s): 4.364 
(4.089) - AE Loss: 171363.219 (496894.125) - AE Rec Loss: 1.162 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.570 
(3.384) - AE Loss: 164348.094 (547952.562) - AE Rec Loss: 1.115 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.92 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.569 
(3.384) - AE Loss: 1601843.625 (547952.562) - AE Rec Loss: 10.863 (3.716) - Disc
Loss: 0.000 (0.000) - 14.68 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.566 
(3.384) - AE Loss: 281180.188 (547952.562) - AE Rec Loss: 1.907 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.68 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.569 
(3.384) - AE Loss: 1666382.500 (547952.562) - AE Rec Loss: 11.301 (3.716) - Disc
Loss: 0.000 (0.000) - 14.79 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.567 
(3.384) - AE Loss: 1730904.500 (547952.562) - AE Rec Loss: 11.738 (3.716) - Disc
Loss: 0.000 (0.000) - 14.78 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.572 
(3.384) - AE Loss: 346498.156 (547952.562) - AE Rec Loss: 2.350 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.65 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.739 
(2.944) - AE Loss: 156496.578 (577704.750) - AE Rec Loss: 1.061 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.07 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.739 
(2.944) - AE Loss: 1454543.250 (577704.750) - AE Rec Loss: 9.864 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.31 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.741 
(2.944) - AE Loss: 1833076.500 (577704.750) - AE Rec Loss: 12.431 (3.918) - Disc
Loss: 0.000 (0.000) - 15.08 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.745 
(2.944) - AE Loss: 327577.125 (577704.750) - AE Rec Loss: 2.222 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.17 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.741 
(2.944) - AE Loss: 361723.438 (577704.750) - AE Rec Loss: 2.453 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.19 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.741 
(2.944) - AE Loss: 319045.812 (577704.750) - AE Rec Loss: 2.164 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.04 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.267 
(2.688) - AE Loss: 674987.250 (618207.062) - AE Rec Loss: 4.578 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.130 (0.875) - Batch(s): 0.914 
(2.688) - AE Loss: 273132.844 (618207.062) - AE Rec Loss: 1.852 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.96 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.706 (0.875) - Batch(s): 1.273 
(2.688) - AE Loss: 118894.688 (618207.062) - AE Rec Loss: 0.806 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 0.914 
(2.688) - AE Loss: 1762172.125 (618207.062) - AE Rec Loss: 11.950 (4.192) - Disc
Loss: 0.000 (0.000) - 16.10 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 0.914 
(2.688) - AE Loss: 577937.062 (618207.062) - AE Rec Loss: 3.919 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.84 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 0.914 
(2.688) - AE Loss: 1719921.250 (618207.062) - AE Rec Loss: 11.664 (4.192) - Disc
Loss: 0.000 (0.000) - 15.98 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.571 
(2.423) - AE Loss: 109306.453 (624856.000) - AE Rec Loss: 0.741 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.20 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.570 
(2.423) - AE Loss: 107400.156 (624856.000) - AE Rec Loss: 0.728 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.32 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.567 
(2.423) - AE Loss: 1692512.875 (624856.000) - AE Rec Loss: 11.478 (4.238) - Disc
Loss: 0.000 (0.000) - 16.10 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.574 
(2.423) - AE Loss: 1436382.625 (624856.000) - AE Rec Loss: 9.741 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.07 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.570 
(2.423) - AE Loss: 242157.250 (624856.000) - AE Rec Loss: 1.642 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.10 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.569 
(2.423) - AE Loss: 1524354.125 (624856.000) - AE Rec Loss: 10.338 (4.238) - Disc
Loss: 0.000 (0.000) - 16.19 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.220 
(2.622) - AE Loss: 324926.656 (600989.625) - AE Rec Loss: 2.204 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.13 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.714) - Batch(s): 4.218 
(2.622) - AE Loss: 194375.875 (600989.625) - AE Rec Loss: 1.318 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.03 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.219 
(2.622) - AE Loss: 181427.531 (600989.625) - AE Rec Loss: 1.230 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.11 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.714) - Batch(s): 4.220 
(2.622) - AE Loss: 202535.734 (600989.625) - AE Rec Loss: 1.374 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 3.515 (0.714) - Batch(s): 4.219 
(2.622) - AE Loss: 194462.969 (600989.625) - AE Rec Loss: 1.319 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.02 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.714) - Batch(s): 4.221 
(2.622) - AE Loss: 1597051.000 (600989.625) - AE Rec Loss: 10.831 (4.076) - Disc
Loss: 0.000 (0.000) - 18.99 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.827 
(2.531) - AE Loss: 155065.906 (609591.000) - AE Rec Loss: 1.052 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.10 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.474 
(2.531) - AE Loss: 345723.688 (609591.000) - AE Rec Loss: 2.345 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.18 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.474 
(2.531) - AE Loss: 104519.844 (609591.000) - AE Rec Loss: 0.709 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.31 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.474 
(2.531) - AE Loss: 716142.062 (609591.000) - AE Rec Loss: 4.857 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.20 m remaining

bouta write to tb
[Epoch <000/100>: Step <050/2280>] - Data(s): 1.264 (0.653) - Batch(s): 1.831 
(2.531) - AE Loss: 1776047.000 (609591.000) - AE Rec Loss: 12.045 (4.134) - Disc
Loss: 0.000 (0.000) - 20.09 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.474 
(2.531) - AE Loss: 230765.734 (609591.000) - AE Rec Loss: 1.565 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.06 m remaining

wrote to tb
[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.410 
(2.423) - AE Loss: 1702792.625 (609393.938) - AE Rec Loss: 11.548 (4.133) - Disc
Loss: 0.000 (0.000) - 20.82 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.593) - Batch(s): 1.408 
(2.423) - AE Loss: 236991.141 (609393.938) - AE Rec Loss: 1.607 (4.133) - Disc 
Loss: 0.000 (0.000) - 21.04 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.593) - Batch(s): 0.572 
(2.423) - AE Loss: 1694672.250 (609393.938) - AE Rec Loss: 11.493 (4.133) - Disc
Loss: 0.000 (0.000) - 20.92 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.593) - Batch(s): 1.406 
(2.423) - AE Loss: 99876.359 (609393.938) - AE Rec Loss: 0.677 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.83 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.408 
(2.423) - AE Loss: 455260.531 (609393.938) - AE Rec Loss: 3.087 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.91 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.593) - Batch(s): 1.413 
(2.423) - AE Loss: 203028.344 (609393.938) - AE Rec Loss: 1.377 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.80 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 391699.000 (613470.000) - AE Rec Loss: 2.656 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.81 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 3.698 (0.570) - Batch(s): 4.381 
(2.586) - AE Loss: 200217.562 (613470.000) - AE Rec Loss: 1.358 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.60 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 372631.750 (613470.000) - AE Rec Loss: 2.527 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.61 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 174731.719 (613470.000) - AE Rec Loss: 1.185 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.69 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 102235.875 (613470.000) - AE Rec Loss: 0.693 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.57 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.381 
(2.586) - AE Loss: 1814957.000 (613470.000) - AE Rec Loss: 12.308 (4.160) - Disc
Loss: 0.000 (0.000) - 23.70 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.571 
(2.431) - AE Loss: 270137.125 (624265.625) - AE Rec Loss: 1.832 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.86 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.571 
(2.431) - AE Loss: 1911903.000 (624265.625) - AE Rec Loss: 12.966 (4.234) - Disc
Loss: 0.000 (0.000) - 23.66 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.001 (0.526) - Batch(s): 0.567 
(2.431) - AE Loss: 97328.789 (624265.625) - AE Rec Loss: 0.660 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.66 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.575 
(2.431) - AE Loss: 486659.312 (624265.625) - AE Rec Loss: 3.300 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.63 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.568 
(2.431) - AE Loss: 1692530.250 (624265.625) - AE Rec Loss: 11.478 (4.234) - Disc
Loss: 0.000 (0.000) - 23.74 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.571 
(2.431) - AE Loss: 267967.562 (624265.625) - AE Rec Loss: 1.817 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.76 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.569 
(2.298) - AE Loss: 169069.750 (648929.625) - AE Rec Loss: 1.147 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.80 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.572 
(2.298) - AE Loss: 159578.938 (648929.625) - AE Rec Loss: 1.082 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.81 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.567 
(2.298) - AE Loss: 1739047.750 (648929.625) - AE Rec Loss: 11.794 (4.401) - Disc
Loss: 0.000 (0.000) - 23.72 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.001 (0.488) - Batch(s): 0.575 
(2.298) - AE Loss: 183758.500 (648929.625) - AE Rec Loss: 1.246 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.69 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.572 
(2.298) - AE Loss: 1559375.250 (648929.625) - AE Rec Loss: 10.575 (4.401) - Disc
Loss: 0.000 (0.000) - 23.92 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.571 
(2.298) - AE Loss: 1560493.750 (648929.625) - AE Rec Loss: 10.583 (4.401) - Disc
Loss: 0.000 (0.000) - 23.71 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 255843.812 (643791.312) - AE Rec Loss: 1.735 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 94729.555 (643791.312) - AE Rec Loss: 0.642 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.23 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 3106959.500 (643791.312) - AE Rec Loss: 21.070 (4.366) - Disc
Loss: 0.000 (0.000) - 26.20 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 219422.531 (643791.312) - AE Rec Loss: 1.488 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.31 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.001 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 304786.688 (643791.312) - AE Rec Loss: 2.067 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.43 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 3.555 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 218285.406 (643791.312) - AE Rec Loss: 1.480 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.23 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.569 
(2.315) - AE Loss: 1659469.000 (663304.875) - AE Rec Loss: 11.254 (4.498) - Disc
Loss: 0.000 (0.000) - 26.23 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.567 
(2.315) - AE Loss: 2592180.000 (663304.875) - AE Rec Loss: 17.579 (4.498) - Disc
Loss: 0.000 (0.000) - 26.24 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.571 
(2.315) - AE Loss: 102226.812 (663304.875) - AE Rec Loss: 0.693 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.33 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.568 
(2.315) - AE Loss: 364499.281 (663304.875) - AE Rec Loss: 2.472 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.575 
(2.315) - AE Loss: 505658.625 (663304.875) - AE Rec Loss: 3.429 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.21 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.570 
(2.315) - AE Loss: 334439.000 (663304.875) - AE Rec Loss: 2.268 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.43 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.568 
(2.212) - AE Loss: 1829251.625 (681181.000) - AE Rec Loss: 12.405 (4.620) - Disc
Loss: 0.000 (0.000) - 26.24 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.572 
(2.212) - AE Loss: 204358.781 (681181.000) - AE Rec Loss: 1.386 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.24 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.573 
(2.212) - AE Loss: 213710.625 (681181.000) - AE Rec Loss: 1.449 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.33 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.567 
(2.212) - AE Loss: 2258699.500 (681181.000) - AE Rec Loss: 15.318 (4.620) - Disc
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.575 
(2.212) - AE Loss: 306142.062 (681181.000) - AE Rec Loss: 2.076 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.21 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.571 
(2.212) - AE Loss: 406983.250 (681181.000) - AE Rec Loss: 2.760 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.43 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 3.816 (0.414) - Batch(s): 4.513 
(2.340) - AE Loss: 377677.125 (686529.750) - AE Rec Loss: 2.561 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.72 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.513 
(2.340) - AE Loss: 335036.125 (686529.750) - AE Rec Loss: 2.272 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.90 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 142299.562 (686529.750) - AE Rec Loss: 0.965 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.79 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.513 
(2.340) - AE Loss: 99905.773 (686529.750) - AE Rec Loss: 0.678 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.69 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.516 
(2.340) - AE Loss: 1614517.750 (686529.750) - AE Rec Loss: 10.949 (4.656) - Disc
Loss: 0.000 (0.000) - 28.80 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.516 
(2.340) - AE Loss: 146378.062 (686529.750) - AE Rec Loss: 0.993 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.72 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.570 
(2.247) - AE Loss: 174781.438 (694349.812) - AE Rec Loss: 1.185 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.86 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.571 
(2.247) - AE Loss: 1748756.000 (694349.812) - AE Rec Loss: 11.860 (4.709) - Disc
Loss: 0.000 (0.000) - 28.77 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.567 
(2.247) - AE Loss: 318954.844 (694349.812) - AE Rec Loss: 2.163 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.68 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.570 
(2.247) - AE Loss: 92027.547 (694349.812) - AE Rec Loss: 0.624 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.68 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.568 
(2.247) - AE Loss: 1694950.875 (694349.812) - AE Rec Loss: 11.495 (4.709) - Disc
Loss: 0.000 (0.000) - 28.76 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.575 
(2.247) - AE Loss: 1605436.875 (694349.812) - AE Rec Loss: 10.888 (4.709) - Disc
Loss: 0.000 (0.000) - 28.65 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.571 
(2.163) - AE Loss: 1879183.375 (690796.000) - AE Rec Loss: 12.744 (4.685) - Disc
Loss: 0.000 (0.000) - 28.64 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.575 
(2.163) - AE Loss: 130994.297 (690796.000) - AE Rec Loss: 0.888 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.62 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.568 
(2.163) - AE Loss: 94490.781 (690796.000) - AE Rec Loss: 0.641 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.64 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.571 
(2.163) - AE Loss: 519627.906 (690796.000) - AE Rec Loss: 3.524 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.82 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.569 
(2.163) - AE Loss: 638756.812 (690796.000) - AE Rec Loss: 4.332 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.72 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.573 
(2.163) - AE Loss: 221348.688 (690796.000) - AE Rec Loss: 1.501 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.73 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 02:56:01,288[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 02:56:03,242[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 02:56:03,854[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 02:56:03,858[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 02:56:03,863[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 02:56:03,867[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 02:56:03,872[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 02:56:03,876[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 02:56:03,880[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 02:56:03,885[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 02:56:04,146[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 02:56:06,015[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 02:56:10,997[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 02:56:11,010[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 02:56:13,186[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 02:56:13,187[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 02:56:13,191[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 02:56:13,202[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.685 
(2.640) - AE Loss: 95589.898 (690581.562) - AE Rec Loss: 0.648 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.23 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.858 (0.358) - Batch(s): 13.222 
(2.640) - AE Loss: 258562.609 (690581.562) - AE Rec Loss: 1.753 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.15 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.222 
(2.640) - AE Loss: 1532067.750 (690581.562) - AE Rec Loss: 10.390 (4.683) - Disc
Loss: 0.000 (0.000) - 36.12 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.222 
(2.640) - AE Loss: 1524741.875 (690581.562) - AE Rec Loss: 10.340 (4.683) - Disc
Loss: 0.000 (0.000) - 36.32 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.222 
(2.640) - AE Loss: 203163.938 (690581.562) - AE Rec Loss: 1.378 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.22 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 1511090.000 (690581.562) - AE Rec Loss: 10.248 (4.683) - Disc
Loss: 0.000 (0.000) - 36.15 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.576 
(2.546) - AE Loss: 543960.125 (686442.438) - AE Rec Loss: 3.689 (4.655) - Disc 
Loss: 0.000 (0.000) - 35.96 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.571 
(2.546) - AE Loss: 299506.375 (686442.438) - AE Rec Loss: 2.031 (4.655) - Disc 
Loss: 0.000 (0.000) - 35.99 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.571 
(2.546) - AE Loss: 2028567.375 (686442.438) - AE Rec Loss: 13.757 (4.655) - Disc
Loss: 0.000 (0.000) - 36.07 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.571 
(2.546) - AE Loss: 264600.156 (686442.438) - AE Rec Loss: 1.794 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.16 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.566 
(2.546) - AE Loss: 1781967.500 (686442.438) - AE Rec Loss: 12.085 (4.655) - Disc
Loss: 0.000 (0.000) - 35.99 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.568 
(2.546) - AE Loss: 551694.438 (686442.438) - AE Rec Loss: 3.741 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.06 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.572 
(2.460) - AE Loss: 1419424.500 (678890.188) - AE Rec Loss: 9.626 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.91 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.575 
(2.460) - AE Loss: 555759.625 (678890.188) - AE Rec Loss: 3.769 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.81 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.572 
(2.460) - AE Loss: 321210.625 (678890.188) - AE Rec Loss: 2.178 (4.604) - Disc 
Loss: 0.000 (0.000) - 36.00 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.568 
(2.460) - AE Loss: 132883.500 (678890.188) - AE Rec Loss: 0.901 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.90 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.567 
(2.460) - AE Loss: 358679.188 (678890.188) - AE Rec Loss: 2.432 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.571 
(2.460) - AE Loss: 1607565.250 (678890.188) - AE Rec Loss: 10.902 (4.604) - Disc
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 134103.828 (681374.875) - AE Rec Loss: 0.909 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 1713013.000 (681374.875) - AE Rec Loss: 11.617 (4.621) - Disc
Loss: 0.000 (0.000) - 35.73 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.703 
(2.387) - AE Loss: 227731.000 (681374.875) - AE Rec Loss: 1.544 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.75 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 2159042.250 (681374.875) - AE Rec Loss: 14.642 (4.621) - Disc
Loss: 0.000 (0.000) - 35.76 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 311591.625 (681374.875) - AE Rec Loss: 2.113 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 1494312.125 (681374.875) - AE Rec Loss: 10.134 (4.621) - Disc
Loss: 0.000 (0.000) - 35.92 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.570 
(2.314) - AE Loss: 411454.594 (685363.062) - AE Rec Loss: 2.790 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.61 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.573 
(2.314) - AE Loss: 183665.422 (685363.062) - AE Rec Loss: 1.246 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.69 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.575 
(2.314) - AE Loss: 3346565.000 (685363.062) - AE Rec Loss: 22.695 (4.648) - Disc
Loss: 0.000 (0.000) - 35.59 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.571 
(2.314) - AE Loss: 173685.328 (685363.062) - AE Rec Loss: 1.178 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.77 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.570 
(2.314) - AE Loss: 368854.688 (685363.062) - AE Rec Loss: 2.501 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.68 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (0.301) - Batch(s): 0.567 
(2.314) - AE Loss: 290666.375 (685363.062) - AE Rec Loss: 1.971 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.61 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.576 
(2.247) - AE Loss: 369266.938 (684622.562) - AE Rec Loss: 2.504 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.44 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.571 
(2.247) - AE Loss: 199497.594 (684622.562) - AE Rec Loss: 1.353 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.47 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.572 
(2.247) - AE Loss: 1678402.125 (684622.562) - AE Rec Loss: 11.382 (4.643) - Disc
Loss: 0.000 (0.000) - 35.63 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.571 
(2.247) - AE Loss: 1619056.625 (684622.562) - AE Rec Loss: 10.980 (4.643) - Disc
Loss: 0.000 (0.000) - 35.53 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.574 
(2.247) - AE Loss: 123735.750 (684622.562) - AE Rec Loss: 0.839 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.54 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.568 
(2.247) - AE Loss: 239993.625 (684622.562) - AE Rec Loss: 1.628 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.47 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:56:43,043[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,157[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,182[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,187[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,192[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,222[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:56:45,195[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,338[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,352[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,352[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,362[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,418[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:45,737[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,020[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,048[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,125[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,130[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,140[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 02:56:46,596[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 02:56:46,598[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 02:56:46,601[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataset) = 4
[[36m2023-11-29 02:56:46,605[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:56:46,605[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:56:46,605[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Preparing opt_disc 
=> Running in inference mode: False
=> Instantiating train dataloader 
Reached 3 on node 5
Reached 5 on node 5
=> Instantiating the optimizer 
Reached end on node 5
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 4
=> Preparing model 
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 1.3 on node 5Reached 5 on node 1

Reached 1.4 on node 5Reached end on node 1

Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.3 on node 3Reached end on node 4

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
=> Preparing opt_ae 
Reached 5 on node 0
Reached 3 on node 1
Reached end on node 0
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 0
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 1

Reached 1.4 on node 2
Reached 1.4 on node 1
Reached 2 on node 2
Reached 2 on node 1
Reached 3 on node 2
Reached 5 on node 2Reached 3 on node 1

Reached end on node 2
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 4
Reached 1.3 on node 0
Reached 1.4 on node 4
Reached 1.4 on node 0
Reached 2 on node 4
Reached 1.3 on node 5
Reached 1.4 on node 5Reached 2 on node 0

Reached 2 on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached 3 on node 0Reached 1.3 on node 3

Reached 1.4 on node 3Reached 3 on node 5

Reached end on node 4
Reached 5 on node 5Reached 2 on node 3
Reached 5 on node 0

Reached end on node 5
Reached end on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4Reached 1 on node 3

Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5Reached 1 on node 2

Reached end on node 1Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 1.4 on node 3Reached 2 on node 4

Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 2
Reached 2 on node 5
Reached 1.4 on node 2
Reached 1 on node 4Reached 2 on node 2Reached 1 on node 3


Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2Reached 1.4 on node 4
Reached 1.4 on node 3

Reached 3 on node 2Reached 2 on node 4
Reached 2 on node 3

Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4Reached 1 on node 3

Reached 1.4 on node 4Reached 1.4 on node 3

Reached 2 on node 4Reached 2 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 02:56:48,305[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 4
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 2
Reached end on node 1
[[36m2023-11-29 02:56:50,468[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 02:56:51,598[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:56:51,598[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
[[36m2023-11-29 02:56:51,598[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 02:56:51,601[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:56:51,613[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <061/2280>] - Data(s): 6.089 (5.597) - Batch(s): 9.383 
(9.018) - AE Loss: 97022.273 (686166.625) - AE Rec Loss: 0.658 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 6.827 (5.597) - Batch(s): 9.400 
(9.018) - AE Loss: 1511482.250 (686166.625) - AE Rec Loss: 10.250 (4.653) - Disc
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 6.743 (5.597) - Batch(s): 9.409 
(9.018) - AE Loss: 1524002.750 (686166.625) - AE Rec Loss: 10.335 (4.653) - Disc
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 4.550 (5.597) - Batch(s): 9.402 
(9.018) - AE Loss: 202274.875 (686166.625) - AE Rec Loss: 1.372 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 5.335 (5.597) - Batch(s): 9.410 
(9.018) - AE Loss: 258416.641 (686166.625) - AE Rec Loss: 1.752 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 6.316 (5.597) - Batch(s): 9.405 
(9.018) - AE Loss: 1532081.250 (686166.625) - AE Rec Loss: 10.390 (4.653) - Disc
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.566 
(4.793) - AE Loss: 1788203.500 (645467.188) - AE Rec Loss: 12.127 (4.377) - Disc
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.566 
(4.793) - AE Loss: 544583.500 (645467.188) - AE Rec Loss: 3.693 (4.377) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.569 
(4.793) - AE Loss: 270167.938 (645467.188) - AE Rec Loss: 1.832 (4.377) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.569 
(4.793) - AE Loss: 2022509.750 (645467.188) - AE Rec Loss: 13.716 (4.377) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.568 
(4.793) - AE Loss: 303036.062 (645467.188) - AE Rec Loss: 2.055 (4.377) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.573 
(4.793) - AE Loss: 555568.500 (645467.188) - AE Rec Loss: 3.768 (4.377) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <063/2280>] - Data(s): 0.975 (2.198) - Batch(s): 6.265 
(5.284) - AE Loss: 139559.172 (603111.750) - AE Rec Loss: 0.946 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.73 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 5.612 (2.198) - Batch(s): 6.265 
(5.284) - AE Loss: 315557.688 (603111.750) - AE Rec Loss: 2.140 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.73 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.001 (2.198) - Batch(s): 6.265 
(5.284) - AE Loss: 1428013.125 (603111.750) - AE Rec Loss: 9.684 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.72 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 2.377 (2.198) - Batch(s): 6.263 
(5.284) - AE Loss: 372934.344 (603111.750) - AE Rec Loss: 2.529 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.73 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.198) - Batch(s): 6.265 
(5.284) - AE Loss: 1615439.500 (603111.750) - AE Rec Loss: 10.955 (4.090) - Disc
Loss: 0.000 (0.000) - 9.73 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 1.232 (2.198) - Batch(s): 6.265 
(5.284) - AE Loss: 562172.000 (603111.750) - AE Rec Loss: 3.812 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.73 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.001 (1.648) - Batch(s): 0.567 
(4.105) - AE Loss: 317355.625 (636837.625) - AE Rec Loss: 2.152 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.001 (1.648) - Batch(s): 0.568 
(4.105) - AE Loss: 1493006.375 (636837.625) - AE Rec Loss: 10.125 (4.319) - Disc
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.001 (1.648) - Batch(s): 0.572 
(4.105) - AE Loss: 1708398.875 (636837.625) - AE Rec Loss: 11.586 (4.319) - Disc
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.001 (1.648) - Batch(s): 0.567 
(4.105) - AE Loss: 238450.438 (636837.625) - AE Rec Loss: 1.617 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.001 (1.648) - Batch(s): 0.570 
(4.105) - AE Loss: 133047.156 (636837.625) - AE Rec Loss: 0.902 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.565 
(4.105) - AE Loss: 2154042.500 (636837.625) - AE Rec Loss: 14.608 (4.319) - Disc
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.568 
(3.398) - AE Loss: 380065.469 (665625.062) - AE Rec Loss: 2.577 (4.514) - Disc 
Loss: 0.000 (0.000) - 10.25 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.566 
(3.398) - AE Loss: 281007.562 (665625.062) - AE Rec Loss: 1.906 (4.514) - Disc 
Loss: 0.000 (0.000) - 10.25 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.569 
(3.398) - AE Loss: 179651.250 (665625.062) - AE Rec Loss: 1.218 (4.514) - Disc 
Loss: 0.000 (0.000) - 10.25 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.568 
(3.398) - AE Loss: 423898.062 (665625.062) - AE Rec Loss: 2.875 (4.514) - Disc 
Loss: 0.000 (0.000) - 10.25 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (1.319) - Batch(s): 0.571 
(3.398) - AE Loss: 188164.297 (665625.062) - AE Rec Loss: 1.276 (4.514) - Disc 
Loss: 0.000 (0.000) - 10.24 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.574 
(3.398) - AE Loss: 3350298.500 (665625.062) - AE Rec Loss: 22.721 (4.514) - Disc
Loss: 0.000 (0.000) - 10.25 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 2.222 (1.132) - Batch(s): 2.880 
(3.312) - AE Loss: 1685259.000 (665944.188) - AE Rec Loss: 11.429 (4.516) - Disc
Loss: 0.000 (0.000) - 11.77 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 1632615.500 (665944.188) - AE Rec Loss: 11.072 (4.516) - Disc
Loss: 0.000 (0.000) - 11.77 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.132) - Batch(s): 2.880 
(3.312) - AE Loss: 92629.820 (665944.188) - AE Rec Loss: 0.628 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.76 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 383878.312 (665944.188) - AE Rec Loss: 2.603 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.77 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.123 (1.132) - Batch(s): 2.882 
(3.312) - AE Loss: 231049.531 (665944.188) - AE Rec Loss: 1.567 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.77 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 217295.953 (665944.188) - AE Rec Loss: 1.474 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.77 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.568 
(2.920) - AE Loss: 1404386.500 (679314.188) - AE Rec Loss: 9.524 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.574 
(2.920) - AE Loss: 159121.156 (679314.188) - AE Rec Loss: 1.079 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.570 
(2.920) - AE Loss: 96515.125 (679314.188) - AE Rec Loss: 0.655 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.570 
(2.920) - AE Loss: 105131.523 (679314.188) - AE Rec Loss: 0.713 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.98 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.569 
(2.920) - AE Loss: 472247.250 (679314.188) - AE Rec Loss: 3.203 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.566 
(2.920) - AE Loss: 1808461.875 (679314.188) - AE Rec Loss: 12.264 (4.607) - Disc
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.568 
(2.626) - AE Loss: 1434450.875 (681051.438) - AE Rec Loss: 9.728 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.575 
(2.626) - AE Loss: 396751.750 (681051.438) - AE Rec Loss: 2.691 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.570 
(2.626) - AE Loss: 239589.125 (681051.438) - AE Rec Loss: 1.625 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.001 (0.849) - Batch(s): 0.570 
(2.626) - AE Loss: 190533.219 (681051.438) - AE Rec Loss: 1.292 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.19 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.001 (0.849) - Batch(s): 0.569 
(2.626) - AE Loss: 97717.023 (681051.438) - AE Rec Loss: 0.663 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.566 
(2.626) - AE Loss: 172370.781 (681051.438) - AE Rec Loss: 1.169 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.001 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 290711.531 (700792.438) - AE Rec Loss: 1.972 (4.753) - Disc 
Loss: 0.000 (0.000) - 13.15 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 1.329 (0.782) - Batch(s): 1.973 
(2.554) - AE Loss: 813315.500 (700792.438) - AE Rec Loss: 5.516 (4.753) - Disc 
Loss: 0.000 (0.000) - 13.14 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 187712.656 (700792.438) - AE Rec Loss: 1.273 (4.753) - Disc 
Loss: 0.000 (0.000) - 13.14 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.360 (0.782) - Batch(s): 1.973 
(2.554) - AE Loss: 104713.789 (700792.438) - AE Rec Loss: 0.710 (4.753) - Disc 
Loss: 0.000 (0.000) - 13.15 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.975 
(2.554) - AE Loss: 266323.656 (700792.438) - AE Rec Loss: 1.806 (4.753) - Disc 
Loss: 0.000 (0.000) - 13.13 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.975 
(2.554) - AE Loss: 1673126.000 (700792.438) - AE Rec Loss: 11.347 (4.753) - Disc
Loss: 0.000 (0.000) - 13.14 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 3.319 (0.732) - Batch(s): 3.897 
(2.681) - AE Loss: 261841.297 (717482.688) - AE Rec Loss: 1.776 (4.866) - Disc 
Loss: 0.000 (0.000) - 15.06 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.890 
(2.681) - AE Loss: 115309.250 (717482.688) - AE Rec Loss: 0.782 (4.866) - Disc 
Loss: 0.000 (0.000) - 15.05 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.534 
(2.681) - AE Loss: 412563.812 (717482.688) - AE Rec Loss: 2.798 (4.866) - Disc 
Loss: 0.000 (0.000) - 15.05 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.534 
(2.681) - AE Loss: 178139.328 (717482.688) - AE Rec Loss: 1.208 (4.866) - Disc 
Loss: 0.000 (0.000) - 15.04 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.888 
(2.681) - AE Loss: 2312275.500 (717482.688) - AE Rec Loss: 15.681 (4.866) - Disc
Loss: 0.000 (0.000) - 15.06 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.890 
(2.681) - AE Loss: 1620801.000 (717482.688) - AE Rec Loss: 10.992 (4.866) - Disc
Loss: 0.000 (0.000) - 15.05 m remaining

bouta write to tb
wrote to tb
[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 211130.547 (720890.375) - AE Rec Loss: 1.432 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.93 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 1658902.000 (720890.375) - AE Rec Loss: 11.250 (4.889) - Disc
Loss: 0.000 (0.000) - 15.93 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 2206194.750 (720890.375) - AE Rec Loss: 14.962 (4.889) - Disc
Loss: 0.000 (0.000) - 15.92 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 221135.781 (720890.375) - AE Rec Loss: 1.500 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.93 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 270182.719 (720890.375) - AE Rec Loss: 1.832 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.92 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.048 
(2.593) - AE Loss: 409438.531 (720890.375) - AE Rec Loss: 2.777 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.92 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 5.420 (0.691) - Batch(s): 6.113 
(2.886) - AE Loss: 299078.594 (729916.500) - AE Rec Loss: 2.028 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.86 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 323773.688 (729916.500) - AE Rec Loss: 2.196 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.87 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.113 
(2.886) - AE Loss: 1413755.000 (729916.500) - AE Rec Loss: 9.588 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.86 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 360550.188 (729916.500) - AE Rec Loss: 2.445 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.86 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.113 
(2.886) - AE Loss: 225776.781 (729916.500) - AE Rec Loss: 1.531 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.86 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 3.161 (0.691) - Batch(s): 6.113 
(2.886) - AE Loss: 1472552.250 (729916.500) - AE Rec Loss: 9.986 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.87 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.001 (0.678) - Batch(s): 5.415 
(3.076) - AE Loss: 1662982.750 (727115.875) - AE Rec Loss: 11.278 (4.931) - Disc
Loss: 0.000 (0.000) - 21.38 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.678) - Batch(s): 5.411 
(3.076) - AE Loss: 198811.703 (727115.875) - AE Rec Loss: 1.348 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.38 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.001 (0.678) - Batch(s): 5.059 
(3.076) - AE Loss: 171683.719 (727115.875) - AE Rec Loss: 1.164 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.38 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.001 (0.678) - Batch(s): 5.061 
(3.076) - AE Loss: 88679.203 (727115.875) - AE Rec Loss: 0.601 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.37 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.001 (0.678) - Batch(s): 5.414 
(3.076) - AE Loss: 1818080.250 (727115.875) - AE Rec Loss: 12.330 (4.931) - Disc
Loss: 0.000 (0.000) - 21.38 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 4.843 (0.678) - Batch(s): 5.422 
(3.076) - AE Loss: 1781774.500 (727115.875) - AE Rec Loss: 12.083 (4.931) - Disc
Loss: 0.000 (0.000) - 21.38 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.572 
(2.897) - AE Loss: 1671298.250 (736156.625) - AE Rec Loss: 11.334 (4.992) - Disc
Loss: 0.000 (0.000) - 21.44 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.570 
(2.897) - AE Loss: 261952.844 (736156.625) - AE Rec Loss: 1.776 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.44 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.567 
(2.897) - AE Loss: 250950.000 (736156.625) - AE Rec Loss: 1.702 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.44 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.568 
(2.897) - AE Loss: 1981753.500 (736156.625) - AE Rec Loss: 13.440 (4.992) - Disc
Loss: 0.000 (0.000) - 21.44 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.001 (0.630) - Batch(s): 0.571 
(2.897) - AE Loss: 210981.859 (736156.625) - AE Rec Loss: 1.431 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.43 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.576 
(2.897) - AE Loss: 170789.281 (736156.625) - AE Rec Loss: 1.158 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.44 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.246 
(2.787) - AE Loss: 329816.844 (725494.250) - AE Rec Loss: 2.237 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.246 
(2.787) - AE Loss: 313231.781 (725494.250) - AE Rec Loss: 2.124 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.82 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.246 
(2.787) - AE Loss: 91778.266 (725494.250) - AE Rec Loss: 0.622 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.004 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 267858.062 (725494.250) - AE Rec Loss: 1.817 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.586 (0.591) - Batch(s): 1.246 
(2.787) - AE Loss: 509055.125 (725494.250) - AE Rec Loss: 3.452 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.001 (0.591) - Batch(s): 1.246 
(2.787) - AE Loss: 253612.469 (725494.250) - AE Rec Loss: 1.720 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.569 
(2.649) - AE Loss: 584756.438 (714627.500) - AE Rec Loss: 3.966 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.574 
(2.649) - AE Loss: 235349.828 (714627.500) - AE Rec Loss: 1.596 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.574 
(2.649) - AE Loss: 171085.094 (714627.500) - AE Rec Loss: 1.160 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.569 
(2.649) - AE Loss: 837672.938 (714627.500) - AE Rec Loss: 5.681 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.566 
(2.649) - AE Loss: 1855882.250 (714627.500) - AE Rec Loss: 12.586 (4.846) - Disc
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.567 
(2.649) - AE Loss: 352261.125 (714627.500) - AE Rec Loss: 2.389 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.88 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.528) - Batch(s): 1.895 
(2.601) - AE Loss: 78678.258 (700045.188) - AE Rec Loss: 0.534 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.56 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.528) - Batch(s): 1.538 
(2.601) - AE Loss: 1507955.500 (700045.188) - AE Rec Loss: 10.226 (4.747) - Disc
Loss: 0.000 (0.000) - 22.55 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.528) - Batch(s): 1.895 
(2.601) - AE Loss: 90691.047 (700045.188) - AE Rec Loss: 0.615 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.56 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.891 
(2.601) - AE Loss: 1699967.875 (700045.188) - AE Rec Loss: 11.529 (4.747) - Disc
Loss: 0.000 (0.000) - 22.56 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 1.327 (0.528) - Batch(s): 1.901 
(2.601) - AE Loss: 319286.250 (700045.188) - AE Rec Loss: 2.165 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.56 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.528) - Batch(s): 1.538 
(2.601) - AE Loss: 232010.828 (700045.188) - AE Rec Loss: 1.573 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.56 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.996 
(2.734) - AE Loss: 1575611.500 (693113.312) - AE Rec Loss: 10.685 (4.700) - Disc
Loss: 0.000 (0.000) - 24.66 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.996 
(2.734) - AE Loss: 343967.312 (693113.312) - AE Rec Loss: 2.333 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.66 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.996 
(2.734) - AE Loss: 298191.312 (693113.312) - AE Rec Loss: 2.022 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.66 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.997 
(2.734) - AE Loss: 269193.938 (693113.312) - AE Rec Loss: 1.826 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.65 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.996 
(2.734) - AE Loss: 493558.938 (693113.312) - AE Rec Loss: 3.347 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.66 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 4.341 (0.519) - Batch(s): 4.997 
(2.734) - AE Loss: 218262.766 (693113.312) - AE Rec Loss: 1.480 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.66 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.492) - Batch(s): 0.575 
(2.620) - AE Loss: 75843.531 (692458.438) - AE Rec Loss: 0.514 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.67 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.492) - Batch(s): 0.576 
(2.620) - AE Loss: 1656998.750 (692458.438) - AE Rec Loss: 11.237 (4.696) - Disc
Loss: 0.000 (0.000) - 24.68 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.570 
(2.620) - AE Loss: 1760499.250 (692458.438) - AE Rec Loss: 11.939 (4.696) - Disc
Loss: 0.000 (0.000) - 24.68 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.570 
(2.620) - AE Loss: 347488.375 (692458.438) - AE Rec Loss: 2.357 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.68 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.492) - Batch(s): 0.571 
(2.620) - AE Loss: 117478.812 (692458.438) - AE Rec Loss: 0.797 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.68 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.567 
(2.620) - AE Loss: 220221.609 (692458.438) - AE Rec Loss: 1.493 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.68 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.869 
(2.583) - AE Loss: 611864.750 (687564.312) - AE Rec Loss: 4.149 (4.663) - Disc 
Loss: 0.000 (0.000) - 25.29 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 1.305 (0.474) - Batch(s): 1.876 
(2.583) - AE Loss: 401932.156 (687564.312) - AE Rec Loss: 2.726 (4.663) - Disc 
Loss: 0.000 (0.000) - 25.28 m remaining

bouta write to tb
[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.870 
(2.583) - AE Loss: 1962320.625 (687564.312) - AE Rec Loss: 13.308 (4.663) - Disc
Loss: 0.000 (0.000) - 25.29 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.876 
(2.583) - AE Loss: 258954.375 (687564.312) - AE Rec Loss: 1.756 (4.663) - Disc 
Loss: 0.000 (0.000) - 25.29 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.872 
(2.583) - AE Loss: 375100.188 (687564.312) - AE Rec Loss: 2.544 (4.663) - Disc 
Loss: 0.000 (0.000) - 25.28 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.868 
(2.583) - AE Loss: 319070.219 (687564.312) - AE Rec Loss: 2.164 (4.663) - Disc 
Loss: 0.000 (0.000) - 25.29 m remaining

wrote to tb
attempting to save
[[36m2023-11-29 02:57:48,215[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 02:57:52,021[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 02:57:54,856[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 02:57:54,864[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 02:57:54,872[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 02:57:54,879[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 02:57:54,886[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 02:57:54,902[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 02:57:54,909[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 02:57:54,920[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 02:57:55,216[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 02:57:57,587[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:58:16,395[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:16,636[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:16,665[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:16,749[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:16,767[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,074[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:58:18,551[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:18,806[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:18,869[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:18,891[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:18,900[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,058[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 02:58:19,261[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,451[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,501[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,559[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,570[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:19,757[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 02:58:20,324[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:58:20,324[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 02:58:20,327[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:58:20,327[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:58:20,327[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 02:58:20,331[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.3 on node 3
Reached end on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 5 on node 0Reached 2 on node 4

Reached end on node 0
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 3 on node 2
Reached 5 on node 3
Reached 5 on node 2
Reached end on node 3
Reached end on node 2
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.3 on node 5
Reached 3 on node 0Reached 1.4 on node 5

Reached 5 on node 0Reached 2 on node 5

Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.3 on node 1Reached 1.4 on node 4

Reached 1.4 on node 1
Reached 2 on node 4
Reached 2 on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 1.3 on node 3Reached 3 on node 4

Reached 2 on node 2Reached 3 on node 1Reached 1.4 on node 3Reached 5 on node 4



Reached end on node 4
Reached 5 on node 1Reached 2 on node 3

Reached 3 on node 2Reached end on node 1

Reached 5 on node 2Reached 3 on node 3

Reached 5 on node 3
Reached end on node 2
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 4
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 4Reached 2 on node 5

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 0
Reached end on node 5
[[36m2023-11-29 02:58:22,180[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 02:58:23,680[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 02:58:24,237[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:58:24,237[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 02:58:24,238[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 02:58:24,240[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:58:24,242[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <061/2280>] - Data(s): 8.110 (5.787) - Batch(s): 10.755 
(10.674) - AE Loss: 1532167.250 (686665.875) - AE Rec Loss: 10.391 (4.657) - 
Disc Loss: 0.000 (0.000) - 6.58 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 6.768 (5.787) - Batch(s): 10.496 
(10.674) - AE Loss: 97022.273 (686665.875) - AE Rec Loss: 0.658 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 3.613 (5.787) - Batch(s): 10.907 
(10.674) - AE Loss: 260102.312 (686665.875) - AE Rec Loss: 1.764 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.68 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 9.245 (5.787) - Batch(s): 10.724 
(10.674) - AE Loss: 1527059.500 (686665.875) - AE Rec Loss: 10.356 (4.657) - 
Disc Loss: 0.000 (0.000) - 6.56 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 3.037 (5.787) - Batch(s): 10.507 
(10.674) - AE Loss: 200746.453 (686665.875) - AE Rec Loss: 1.361 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 7.775 (5.787) - Batch(s): 10.508 
(10.674) - AE Loss: 1510754.750 (686665.875) - AE Rec Loss: 10.245 (4.657) - 
Disc Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.894) - Batch(s): 0.568 
(5.621) - AE Loss: 545425.375 (645952.312) - AE Rec Loss: 3.699 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.77 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.894) - Batch(s): 0.574 
(5.621) - AE Loss: 556075.500 (645952.312) - AE Rec Loss: 3.771 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.91 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.567 
(5.621) - AE Loss: 303563.000 (645952.312) - AE Rec Loss: 2.059 (4.381) - Disc 
Loss: 0.000 (0.000) - 7.00 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.894) - Batch(s): 0.570 
(5.621) - AE Loss: 2022509.750 (645952.312) - AE Rec Loss: 13.716 (4.381) - Disc
Loss: 0.000 (0.000) - 6.77 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.894) - Batch(s): 0.570 
(5.621) - AE Loss: 271008.125 (645952.312) - AE Rec Loss: 1.838 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.565 
(5.621) - AE Loss: 1788964.750 (645952.312) - AE Rec Loss: 12.132 (4.381) - Disc
Loss: 0.000 (0.000) - 6.77 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <063/2280>] - Data(s): 0.899 (2.131) - Batch(s): 4.797 
(5.347) - AE Loss: 373585.438 (603362.250) - AE Rec Loss: 2.534 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 2.281 (2.131) - Batch(s): 4.799 
(5.347) - AE Loss: 562657.312 (603362.250) - AE Rec Loss: 3.816 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.66 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 4.071 (2.131) - Batch(s): 4.799 
(5.347) - AE Loss: 315526.750 (603362.250) - AE Rec Loss: 2.140 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.64 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.800 
(5.347) - AE Loss: 139046.031 (603362.250) - AE Rec Loss: 0.943 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.001 (2.131) - Batch(s): 4.800 
(5.347) - AE Loss: 1428013.125 (603362.250) - AE Rec Loss: 9.684 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.52 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.001 (2.131) - Batch(s): 4.799 
(5.347) - AE Loss: 1613944.125 (603362.250) - AE Rec Loss: 10.945 (4.092) - Disc
Loss: 0.000 (0.000) - 9.76 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.569 
(4.153) - AE Loss: 235916.969 (637045.688) - AE Rec Loss: 1.600 (4.320) - Disc 
Loss: 0.000 (0.000) - 10.02 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.572 
(4.153) - AE Loss: 133470.281 (637045.688) - AE Rec Loss: 0.905 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.567 
(4.153) - AE Loss: 2153322.000 (637045.688) - AE Rec Loss: 14.603 (4.320) - Disc
Loss: 0.000 (0.000) - 9.80 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.570 
(4.153) - AE Loss: 1493197.500 (637045.688) - AE Rec Loss: 10.126 (4.320) - Disc
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.570 
(4.153) - AE Loss: 315678.000 (637045.688) - AE Rec Loss: 2.141 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.575 
(4.153) - AE Loss: 1709115.000 (637045.688) - AE Rec Loss: 11.591 (4.320) - Disc
Loss: 0.000 (0.000) - 9.92 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.570 
(3.436) - AE Loss: 422924.375 (665809.625) - AE Rec Loss: 2.868 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.567 
(3.436) - AE Loss: 279836.562 (665809.625) - AE Rec Loss: 1.898 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.06 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.575 
(3.436) - AE Loss: 3350557.000 (665809.625) - AE Rec Loss: 22.722 (4.515) - Disc
Loss: 0.000 (0.000) - 10.19 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.572 
(3.436) - AE Loss: 187293.156 (665809.625) - AE Rec Loss: 1.270 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.05 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (1.279) - Batch(s): 0.571 
(3.436) - AE Loss: 178643.531 (665809.625) - AE Rec Loss: 1.212 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.17 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.568 
(3.436) - AE Loss: 379212.250 (665809.625) - AE Rec Loss: 2.572 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.06 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.433 
(3.269) - AE Loss: 382353.375 (666093.875) - AE Rec Loss: 2.593 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.46 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 1.722 (1.110) - Batch(s): 2.433 
(3.269) - AE Loss: 1685319.250 (666093.875) - AE Rec Loss: 11.429 (4.517) - Disc
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.433 
(3.269) - AE Loss: 1632220.250 (666093.875) - AE Rec Loss: 11.069 (4.517) - Disc
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.110) - Batch(s): 2.435 
(3.269) - AE Loss: 93610.852 (666093.875) - AE Rec Loss: 0.635 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.33 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 1.487 (1.110) - Batch(s): 2.434 
(3.269) - AE Loss: 232341.672 (666093.875) - AE Rec Loss: 1.576 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.435 
(3.269) - AE Loss: 216489.859 (666093.875) - AE Rec Loss: 1.468 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.55 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.570 
(2.883) - AE Loss: 96817.344 (679391.188) - AE Rec Loss: 0.657 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.67 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.572 
(2.883) - AE Loss: 105529.383 (679391.188) - AE Rec Loss: 0.716 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.56 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.570 
(2.883) - AE Loss: 1405377.750 (679391.188) - AE Rec Loss: 9.531 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.56 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.568 
(2.883) - AE Loss: 467293.875 (679391.188) - AE Rec Loss: 3.169 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.78 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.575 
(2.883) - AE Loss: 159906.672 (679391.188) - AE Rec Loss: 1.084 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.69 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.565 
(2.883) - AE Loss: 1806719.250 (679391.188) - AE Rec Loss: 12.253 (4.607) - Disc
Loss: 0.000 (0.000) - 11.57 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.568 
(2.594) - AE Loss: 171412.344 (681123.375) - AE Rec Loss: 1.162 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.79 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.569 
(2.594) - AE Loss: 1434456.750 (681123.375) - AE Rec Loss: 9.728 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.79 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.571 
(2.594) - AE Loss: 240333.469 (681123.375) - AE Rec Loss: 1.630 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.89 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.570 
(2.594) - AE Loss: 99828.445 (681123.375) - AE Rec Loss: 0.677 (4.619) - Disc 
Loss: 0.000 (0.000) - 12.00 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.576 
(2.594) - AE Loss: 394262.375 (681123.375) - AE Rec Loss: 2.674 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.91 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.572 
(2.594) - AE Loss: 190312.000 (681123.375) - AE Rec Loss: 1.291 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.78 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 1.982 (0.782) - Batch(s): 3.221 
(2.664) - AE Loss: 105704.141 (700779.938) - AE Rec Loss: 0.717 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.40 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.001 (0.782) - Batch(s): 3.221 
(2.664) - AE Loss: 287925.750 (700779.938) - AE Rec Loss: 1.953 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.52 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.222 
(2.664) - AE Loss: 1674186.250 (700779.938) - AE Rec Loss: 11.354 (4.752) - Disc
Loss: 0.000 (0.000) - 13.60 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.001 (0.782) - Batch(s): 3.220 
(2.664) - AE Loss: 265701.750 (700779.938) - AE Rec Loss: 1.802 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 2.514 (0.782) - Batch(s): 3.223 
(2.664) - AE Loss: 807193.688 (700779.938) - AE Rec Loss: 5.474 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.50 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.223 
(2.664) - AE Loss: 186397.750 (700779.938) - AE Rec Loss: 1.264 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.40 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 1.858 (0.719) - Batch(s): 2.437 
(2.635) - AE Loss: 260317.219 (717431.562) - AE Rec Loss: 1.765 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.67 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.429 
(2.635) - AE Loss: 115199.477 (717431.562) - AE Rec Loss: 0.781 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.65 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.431 
(2.635) - AE Loss: 1621298.500 (717431.562) - AE Rec Loss: 10.995 (4.865) - Disc
Loss: 0.000 (0.000) - 14.75 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.426 
(2.635) - AE Loss: 2311908.000 (717431.562) - AE Rec Loss: 15.679 (4.865) - Disc
Loss: 0.000 (0.000) - 14.55 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.074 
(2.635) - AE Loss: 411786.594 (717431.562) - AE Rec Loss: 2.793 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.55 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.074 
(2.635) - AE Loss: 177454.906 (717431.562) - AE Rec Loss: 1.203 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.54 m remaining

bouta write to tb
wrote to tb
[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.312 
(2.509) - AE Loss: 221138.562 (720778.812) - AE Rec Loss: 1.500 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.10 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.001 (0.654) - Batch(s): 0.572 
(2.509) - AE Loss: 408787.125 (720778.812) - AE Rec Loss: 2.772 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.09 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.001 (0.654) - Batch(s): 1.315 
(2.509) - AE Loss: 2205668.000 (720778.812) - AE Rec Loss: 14.958 (4.888) - Disc
Loss: 0.000 (0.000) - 15.20 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.315 
(2.509) - AE Loss: 211400.625 (720778.812) - AE Rec Loss: 1.434 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.10 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.316 
(2.509) - AE Loss: 269142.375 (720778.812) - AE Rec Loss: 1.825 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.30 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.001 (0.654) - Batch(s): 1.321 
(2.509) - AE Loss: 1657952.500 (720778.812) - AE Rec Loss: 11.244 (4.888) - Disc
Loss: 0.000 (0.000) - 15.22 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.256 
(2.488) - AE Loss: 322520.781 (729793.875) - AE Rec Loss: 2.187 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.22 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.255 
(2.488) - AE Loss: 226706.750 (729793.875) - AE Rec Loss: 1.537 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.30 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.256 
(2.488) - AE Loss: 1413396.250 (729793.875) - AE Rec Loss: 9.585 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.10 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.256 
(2.488) - AE Loss: 360110.531 (729793.875) - AE Rec Loss: 2.442 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.10 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 1.533 (0.610) - Batch(s): 2.256 
(2.488) - AE Loss: 301090.250 (729793.875) - AE Rec Loss: 2.042 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.20 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.257 
(2.488) - AE Loss: 1472585.000 (729793.875) - AE Rec Loss: 9.987 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.567 
(2.342) - AE Loss: 199453.562 (727051.438) - AE Rec Loss: 1.353 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.27 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.575 
(2.342) - AE Loss: 1781874.250 (727051.438) - AE Rec Loss: 12.084 (4.931) - Disc
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.570 
(2.342) - AE Loss: 1818314.750 (727051.438) - AE Rec Loss: 12.331 (4.931) - Disc
Loss: 0.000 (0.000) - 16.47 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.572 
(2.342) - AE Loss: 89778.500 (727051.438) - AE Rec Loss: 0.609 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.27 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.568 
(2.342) - AE Loss: 172921.750 (727051.438) - AE Rec Loss: 1.173 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.27 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.569 
(2.342) - AE Loss: 1662669.875 (727051.438) - AE Rec Loss: 11.276 (4.931) - Disc
Loss: 0.000 (0.000) - 16.37 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.576 
(2.215) - AE Loss: 172673.062 (736152.750) - AE Rec Loss: 1.171 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.52 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.571 
(2.215) - AE Loss: 263062.688 (736152.750) - AE Rec Loss: 1.784 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.60 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.574 
(2.215) - AE Loss: 213089.859 (736152.750) - AE Rec Loss: 1.445 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.568 
(2.215) - AE Loss: 251274.203 (736152.750) - AE Rec Loss: 1.704 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.41 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.571 
(2.215) - AE Loss: 1670946.500 (736152.750) - AE Rec Loss: 11.332 (4.992) - Disc
Loss: 0.000 (0.000) - 16.51 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.569 
(2.215) - AE Loss: 1981827.750 (736152.750) - AE Rec Loss: 13.440 (4.992) - Disc
Loss: 0.000 (0.000) - 16.41 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.237 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 92544.961 (725531.562) - AE Rec Loss: 0.628 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.11 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 270023.500 (725531.562) - AE Rec Loss: 1.831 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.21 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 330386.938 (725531.562) - AE Rec Loss: 2.241 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.13 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 315057.875 (725531.562) - AE Rec Loss: 2.137 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.01 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.813 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 505922.062 (725531.562) - AE Rec Loss: 3.431 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.02 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 255155.984 (725531.562) - AE Rec Loss: 1.730 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.02 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.570 
(2.073) - AE Loss: 587119.375 (714697.250) - AE Rec Loss: 3.982 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.27 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.567 
(2.073) - AE Loss: 1857365.750 (714697.250) - AE Rec Loss: 12.596 (4.847) - Disc
Loss: 0.000 (0.000) - 17.18 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.571 
(2.073) - AE Loss: 840523.375 (714697.250) - AE Rec Loss: 5.700 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.37 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.464) - Batch(s): 0.569 
(2.073) - AE Loss: 352668.406 (714697.250) - AE Rec Loss: 2.392 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.18 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.572 
(2.073) - AE Loss: 236285.953 (714697.250) - AE Rec Loss: 1.602 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.17 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.575 
(2.073) - AE Loss: 169691.406 (714697.250) - AE Rec Loss: 1.151 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.29 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.572 
(1.985) - AE Loss: 75965.094 (700115.000) - AE Rec Loss: 0.515 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.40 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.568 
(1.985) - AE Loss: 1698939.750 (700115.000) - AE Rec Loss: 11.522 (4.748) - Disc
Loss: 0.000 (0.000) - 17.30 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.437) - Batch(s): 0.573 
(1.985) - AE Loss: 87814.992 (700115.000) - AE Rec Loss: 0.596 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.49 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.578 
(1.985) - AE Loss: 319354.188 (700115.000) - AE Rec Loss: 2.166 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.41 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.570 
(1.985) - AE Loss: 233893.859 (700115.000) - AE Rec Loss: 1.586 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.30 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.575 
(1.985) - AE Loss: 1508595.250 (700115.000) - AE Rec Loss: 10.231 (4.748) - Disc
Loss: 0.000 (0.000) - 17.30 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.303 
(2.114) - AE Loss: 345625.625 (693217.938) - AE Rec Loss: 2.344 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.304 
(2.114) - AE Loss: 1574134.750 (693217.938) - AE Rec Loss: 10.675 (4.701) - Disc
Loss: 0.000 (0.000) - 19.15 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.303 
(2.114) - AE Loss: 300348.562 (693217.938) - AE Rec Loss: 2.037 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.303 
(2.114) - AE Loss: 494619.250 (693217.938) - AE Rec Loss: 3.354 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.25 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.303 
(2.114) - AE Loss: 270250.344 (693217.938) - AE Rec Loss: 1.833 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.14 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 3.581 (0.429) - Batch(s): 4.303 
(2.114) - AE Loss: 218481.172 (693217.938) - AE Rec Loss: 1.482 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.15 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.571 
(2.032) - AE Loss: 116248.641 (692584.250) - AE Rec Loss: 0.788 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.570 
(2.032) - AE Loss: 1762056.000 (692584.250) - AE Rec Loss: 11.950 (4.697) - Disc
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.573 
(2.032) - AE Loss: 75374.500 (692584.250) - AE Rec Loss: 0.511 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.407) - Batch(s): 0.567 
(2.032) - AE Loss: 222091.219 (692584.250) - AE Rec Loss: 1.506 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.407) - Batch(s): 0.572 
(2.032) - AE Loss: 350289.719 (692584.250) - AE Rec Loss: 2.376 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.576 
(2.032) - AE Loss: 1656371.750 (692584.250) - AE Rec Loss: 11.233 (4.697) - Disc
Loss: 0.000 (0.000) - 19.35 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.570 
(1.959) - AE Loss: 616166.562 (687702.438) - AE Rec Loss: 4.179 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.575 
(1.959) - AE Loss: 402529.625 (687702.438) - AE Rec Loss: 2.730 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

bouta write to tb
[Epoch <000/100>: Step <080/2280>] - Data(s): 0.001 (0.387) - Batch(s): 0.572 
(1.959) - AE Loss: 1961779.250 (687702.438) - AE Rec Loss: 13.304 (4.664) - Disc
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.567 
(1.959) - AE Loss: 321484.438 (687702.438) - AE Rec Loss: 2.180 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.576 
(1.959) - AE Loss: 254896.000 (687702.438) - AE Rec Loss: 1.729 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.43 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.572 
(1.959) - AE Loss: 378109.750 (687702.438) - AE Rec Loss: 2.564 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.51 m remaining

wrote to tb
attempting to save
[[36m2023-11-29 02:59:07,710[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 02:59:08,270[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 02:59:09,340[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 02:59:09,359[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 02:59:09,375[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 02:59:09,385[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 02:59:09,398[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 02:59:09,412[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 02:59:09,423[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 02:59:09,432[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 02:59:10,161[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 02:59:11,950[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 02:59:15,616[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 02:59:15,682[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 02:59:23,268[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 02:59:23,268[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 02:59:23,269[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 02:59:23,280[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.044 
(2.613) - AE Loss: 69680.508 (689631.250) - AE Rec Loss: 0.473 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.86 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.043 
(2.613) - AE Loss: 186604.562 (689631.250) - AE Rec Loss: 1.265 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.88 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.416 (0.379) - Batch(s): 17.043 
(2.613) - AE Loss: 1724115.375 (689631.250) - AE Rec Loss: 11.692 (4.677) - Disc
Loss: 0.000 (0.000) - 26.78 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 2.162 (0.379) - Batch(s): 17.044 
(2.613) - AE Loss: 80087.023 (689631.250) - AE Rec Loss: 0.543 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.78 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.001 (0.379) - Batch(s): 0.686 
(2.613) - AE Loss: 1612796.250 (689631.250) - AE Rec Loss: 10.937 (4.677) - Disc
Loss: 0.000 (0.000) - 26.77 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.001 (0.379) - Batch(s): 17.043 
(2.613) - AE Loss: 236158.594 (689631.250) - AE Rec Loss: 1.602 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.95 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.570 
(2.520) - AE Loss: 426753.688 (691733.812) - AE Rec Loss: 2.894 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.576 
(2.520) - AE Loss: 318050.375 (691733.812) - AE Rec Loss: 2.157 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.86 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.567 
(2.520) - AE Loss: 185562.672 (691733.812) - AE Rec Loss: 1.258 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.77 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.573 
(2.520) - AE Loss: 1814080.000 (691733.812) - AE Rec Loss: 12.303 (4.691) - Disc
Loss: 0.000 (0.000) - 26.76 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.569 
(2.520) - AE Loss: 1398201.625 (691733.812) - AE Rec Loss: 9.482 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.76 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.570 
(2.520) - AE Loss: 1718397.250 (691733.812) - AE Rec Loss: 11.654 (4.691) - Disc
Loss: 0.000 (0.000) - 26.94 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.572 
(2.435) - AE Loss: 284700.750 (692697.188) - AE Rec Loss: 1.931 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.84 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.568 
(2.435) - AE Loss: 359509.812 (692697.188) - AE Rec Loss: 2.438 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.76 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.569 
(2.435) - AE Loss: 711453.562 (692697.188) - AE Rec Loss: 4.825 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.75 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.574 
(2.435) - AE Loss: 431347.875 (692697.188) - AE Rec Loss: 2.925 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.75 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.577 
(2.435) - AE Loss: 424626.875 (692697.188) - AE Rec Loss: 2.880 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.573 
(2.435) - AE Loss: 282256.562 (692697.188) - AE Rec Loss: 1.914 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.93 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.001 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 374759.750 (689099.125) - AE Rec Loss: 2.542 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 352835.312 (689099.125) - AE Rec Loss: 2.393 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.91 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.731 
(2.364) - AE Loss: 153819.109 (689099.125) - AE Rec Loss: 1.043 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.98 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 240263.156 (689099.125) - AE Rec Loss: 1.629 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 189161.938 (689099.125) - AE Rec Loss: 1.283 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.001 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 1972050.125 (689099.125) - AE Rec Loss: 13.374 (4.673) - Disc
Loss: 0.000 (0.000) - 26.90 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.572 
(2.292) - AE Loss: 94306.844 (681847.188) - AE Rec Loss: 0.640 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.001 (0.319) - Batch(s): 0.573 
(2.292) - AE Loss: 246749.625 (681847.188) - AE Rec Loss: 1.673 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.89 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.571 
(2.292) - AE Loss: 1846659.750 (681847.188) - AE Rec Loss: 12.523 (4.624) - Disc
Loss: 0.000 (0.000) - 26.97 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.576 
(2.292) - AE Loss: 251331.969 (681847.188) - AE Rec Loss: 1.704 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.90 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.568 
(2.292) - AE Loss: 1911066.250 (681847.188) - AE Rec Loss: 12.960 (4.624) - Disc
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.575 
(2.292) - AE Loss: 228938.062 (681847.188) - AE Rec Loss: 1.553 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.570 
(2.226) - AE Loss: 464124.469 (694412.938) - AE Rec Loss: 3.148 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.574 
(2.226) - AE Loss: 990196.750 (694412.938) - AE Rec Loss: 6.715 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.576 
(2.226) - AE Loss: 284168.625 (694412.938) - AE Rec Loss: 1.927 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.79 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.573 
(2.226) - AE Loss: 562797.062 (694412.938) - AE Rec Loss: 3.817 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.88 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.578 
(2.226) - AE Loss: 97703.469 (694412.938) - AE Rec Loss: 0.663 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.89 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.572 
(2.226) - AE Loss: 1767505.000 (694412.938) - AE Rec Loss: 11.987 (4.709) - Disc
Loss: 0.000 (0.000) - 26.96 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.726 
(2.171) - AE Loss: 1484906.250 (694243.188) - AE Rec Loss: 10.070 (4.708) - Disc
Loss: 0.000 (0.000) - 26.93 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.726 
(2.171) - AE Loss: 1473903.000 (694243.188) - AE Rec Loss: 9.996 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.724 
(2.171) - AE Loss: 157565.016 (694243.188) - AE Rec Loss: 1.069 (4.708) - Disc 
Loss: 0.000 (0.000) - 27.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 265495.375 (694243.188) - AE Rec Loss: 1.801 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.94 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 134262.750 (694243.188) - AE Rec Loss: 0.911 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 192820.062 (694243.188) - AE Rec Loss: 1.308 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:59:50,294[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,351[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,446[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,565[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,609[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,613[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:59:52,457[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,518[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,605[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,738[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,758[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,775[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,095[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,236[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,375[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,426[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,449[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 02:59:53,820[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,821[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
[[36m2023-11-29 02:59:53,826[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,826[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,826[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,826[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Mixed precision: no
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
len(train_dataloader) = 2279
=> Preparing model 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3Reached 3 on node 2

Reached 5 on node 2Reached 5 on node 3

Reached end on node 2
Reached end on node 3
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 1
Reached 1.4 on node 1
=> Preparing opt_ae 
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 4Reached 3 on node 2

Reached 5 on node 4Reached 5 on node 2

Reached end on node 2Reached end on node 4

Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 0

Reached 1.4 on node 0Reached 1.3 on node 1
Reached 1.4 on node 3

Reached 1.4 on node 1
Reached 2 on node 0
Reached 1.3 on node 5Reached 2 on node 3

Reached 2 on node 1Reached 1.4 on node 5

Reached 2 on node 5
Reached 3 on node 0
Reached 3 on node 3
Reached 3 on node 1
Reached 5 on node 3
Reached 3 on node 5
Reached 5 on node 0
Reached 5 on node 1
Reached 5 on node 5Reached end on node 3

Reached end on node 0Reached 1.3 on node 2
Reached 1.3 on node 4

Reached end on node 1Reached end on node 5

Reached 1.4 on node 4Reached 1.4 on node 2

Reached 2 on node 4
Reached 2 on node 2
Reached 3 on node 4Reached 3 on node 2

Reached 5 on node 2
Reached 5 on node 4
Reached end on node 2
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 1.4 on node 3Reached 2 on node 5

Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1 on node 4
Reached 5 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 5
Reached 1 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 5
Reached end on node 1
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 0
Reached end on node 3
[[36m2023-11-29 02:59:55,594[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 02:59:57,780[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 02:59:58,901[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 02:59:58,902[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 02:59:58,916[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 02:59:58,919[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 02:59:58,920[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <081/2280>] - Data(s): 9.036 (6.058) - Batch(s): 10.723 
(10.220) - AE Loss: 1612036.625 (728560.500) - AE Rec Loss: 10.932 (4.941) - 
Disc Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 7.081 (6.058) - Batch(s): 10.732 
(10.220) - AE Loss: 1724681.750 (728560.500) - AE Rec Loss: 11.696 (4.941) - 
Disc Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 7.966 (6.058) - Batch(s): 10.734 
(10.220) - AE Loss: 80151.508 (728560.500) - AE Rec Loss: 0.544 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 4.665 (6.058) - Batch(s): 10.740 
(10.220) - AE Loss: 186526.594 (728560.500) - AE Rec Loss: 1.265 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 7.589 (6.058) - Batch(s): 10.725 
(10.220) - AE Loss: 237696.375 (728560.500) - AE Rec Loss: 1.612 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 2.806 (6.058) - Batch(s): 10.738 
(10.220) - AE Loss: 69969.734 (728560.500) - AE Rec Loss: 0.475 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.566 
(5.394) - AE Loss: 189894.594 (737082.688) - AE Rec Loss: 1.288 (4.999) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.002 (3.029) - Batch(s): 0.568 
(5.394) - AE Loss: 1731325.375 (737082.688) - AE Rec Loss: 11.741 (4.999) - Disc
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.568 
(5.394) - AE Loss: 1396980.875 (737082.688) - AE Rec Loss: 9.474 (4.999) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.575 
(5.394) - AE Loss: 325282.312 (737082.688) - AE Rec Loss: 2.206 (4.999) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.001 (3.029) - Batch(s): 0.571 
(5.394) - AE Loss: 1823409.250 (737082.688) - AE Rec Loss: 12.366 (4.999) - Disc
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.569 
(5.394) - AE Loss: 445330.250 (737082.688) - AE Rec Loss: 3.020 (4.999) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <083/2280>] - Data(s): 0.001 (2.243) - Batch(s): 5.279 
(5.357) - AE Loss: 353113.500 (733088.125) - AE Rec Loss: 2.395 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.280 
(5.357) - AE Loss: 296267.219 (733088.125) - AE Rec Loss: 2.009 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.282 
(5.357) - AE Loss: 742119.125 (733088.125) - AE Rec Loss: 5.033 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.281 
(5.357) - AE Loss: 440172.438 (733088.125) - AE Rec Loss: 2.985 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.511 (2.243) - Batch(s): 5.280 
(5.357) - AE Loss: 308981.969 (733088.125) - AE Rec Loss: 2.095 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.001 (2.243) - Batch(s): 5.281 
(5.357) - AE Loss: 445854.938 (733088.125) - AE Rec Loss: 3.024 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.566 
(4.160) - AE Loss: 188492.938 (701973.562) - AE Rec Loss: 1.278 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.569 
(4.160) - AE Loss: 157624.406 (701973.562) - AE Rec Loss: 1.069 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.001 (1.682) - Batch(s): 0.569 
(4.160) - AE Loss: 374008.188 (701973.562) - AE Rec Loss: 2.536 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.571 
(4.160) - AE Loss: 242674.719 (701973.562) - AE Rec Loss: 1.646 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.001 (1.682) - Batch(s): 0.576 
(4.160) - AE Loss: 355732.812 (701973.562) - AE Rec Loss: 2.412 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.570 
(4.160) - AE Loss: 1972510.250 (701973.562) - AE Rec Loss: 13.377 (4.761) - Disc
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.570 
(3.442) - AE Loss: 1846719.000 (663181.438) - AE Rec Loss: 12.524 (4.497) - Disc
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.567 
(3.442) - AE Loss: 1913748.625 (663181.438) - AE Rec Loss: 12.978 (4.497) - Disc
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.001 (1.346) - Batch(s): 0.576 
(3.442) - AE Loss: 251456.875 (663181.438) - AE Rec Loss: 1.705 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.571 
(3.442) - AE Loss: 249020.172 (663181.438) - AE Rec Loss: 1.689 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.569 
(3.442) - AE Loss: 90126.555 (663181.438) - AE Rec Loss: 0.611 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.001 (1.346) - Batch(s): 0.573 
(3.442) - AE Loss: 224793.078 (663181.438) - AE Rec Loss: 1.524 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.736 
(2.991) - AE Loss: 461187.562 (720977.688) - AE Rec Loss: 3.128 (4.889) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.736 
(2.991) - AE Loss: 1769071.750 (720977.688) - AE Rec Loss: 11.997 (4.889) - Disc
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.736 
(2.991) - AE Loss: 563772.875 (720977.688) - AE Rec Loss: 3.823 (4.889) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.737 
(2.991) - AE Loss: 283705.250 (720977.688) - AE Rec Loss: 1.924 (4.889) - Disc 
Loss: 0.000 (0.000) - 8.24 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.737 
(2.991) - AE Loss: 996400.562 (720977.688) - AE Rec Loss: 6.757 (4.889) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.738 
(2.991) - AE Loss: 93450.266 (720977.688) - AE Rec Loss: 0.634 (4.889) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.961) - Batch(s): 0.568 
(2.645) - AE Loss: 1481525.000 (717636.125) - AE Rec Loss: 10.047 (4.867) - Disc
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.961) - Batch(s): 0.571 
(2.645) - AE Loss: 171042.531 (717636.125) - AE Rec Loss: 1.160 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.961) - Batch(s): 0.576 
(2.645) - AE Loss: 272179.656 (717636.125) - AE Rec Loss: 1.846 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.961) - Batch(s): 0.570 
(2.645) - AE Loss: 146294.156 (717636.125) - AE Rec Loss: 0.992 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.961) - Batch(s): 0.573 
(2.645) - AE Loss: 203056.469 (717636.125) - AE Rec Loss: 1.377 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.573 
(2.645) - AE Loss: 1492340.750 (717636.125) - AE Rec Loss: 10.121 (4.867) - Disc
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.465 
(3.012) - AE Loss: 332489.281 (775261.500) - AE Rec Loss: 2.255 (5.258) - Disc 
Loss: 0.000 (0.000) - 10.81 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.464 
(3.012) - AE Loss: 1641635.250 (775261.500) - AE Rec Loss: 11.133 (5.258) - Disc
Loss: 0.000 (0.000) - 10.81 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.463 
(3.012) - AE Loss: 1576222.750 (775261.500) - AE Rec Loss: 10.689 (5.258) - Disc
Loss: 0.000 (0.000) - 10.81 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.463 
(3.012) - AE Loss: 1696366.750 (775261.500) - AE Rec Loss: 11.504 (5.258) - Disc
Loss: 0.000 (0.000) - 10.81 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.463 
(3.012) - AE Loss: 155192.484 (775261.500) - AE Rec Loss: 1.052 (5.258) - Disc 
Loss: 0.000 (0.000) - 10.81 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.463 
(3.012) - AE Loss: 147632.328 (775261.500) - AE Rec Loss: 1.001 (5.258) - Disc 
Loss: 0.000 (0.000) - 10.80 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 109289.562 (793137.188) - AE Rec Loss: 0.741 (5.379) - Disc 
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 355626.500 (793137.188) - AE Rec Loss: 2.412 (5.379) - Disc 
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 445292.625 (793137.188) - AE Rec Loss: 3.020 (5.379) - Disc 
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 1574581.000 (793137.188) - AE Rec Loss: 10.678 (5.379) - Disc
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 206578.047 (793137.188) - AE Rec Loss: 1.401 (5.379) - Disc 
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 1556649.250 (793137.188) - AE Rec Loss: 10.557 (5.379) - Disc
Loss: 0.000 (0.000) - 11.32 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.001 (0.723) - Batch(s): 0.575 
(2.608) - AE Loss: 153289.141 (801428.000) - AE Rec Loss: 1.040 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.49 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.572 
(2.608) - AE Loss: 1770199.250 (801428.000) - AE Rec Loss: 12.005 (5.435) - Disc
Loss: 0.000 (0.000) - 11.48 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.566 
(2.608) - AE Loss: 332718.844 (801428.000) - AE Rec Loss: 2.256 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.49 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.570 
(2.608) - AE Loss: 381375.656 (801428.000) - AE Rec Loss: 2.586 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.49 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.001 (0.723) - Batch(s): 0.570 
(2.608) - AE Loss: 317379.781 (801428.000) - AE Rec Loss: 2.152 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.49 m remaining

bouta write to tb
[Epoch <000/100>: Step <090/2280>] - Data(s): 0.001 (0.723) - Batch(s): 0.568 
(2.608) - AE Loss: 1399643.750 (801428.000) - AE Rec Loss: 9.492 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.49 m remaining

wrote to tb
[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.597 
(2.611) - AE Loss: 1649524.375 (782866.438) - AE Rec Loss: 11.187 (5.309) - Disc
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.597 
(2.611) - AE Loss: 356554.625 (782866.438) - AE Rec Loss: 2.418 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.597 
(2.611) - AE Loss: 209978.938 (782866.438) - AE Rec Loss: 1.424 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.597 
(2.611) - AE Loss: 306094.500 (782866.438) - AE Rec Loss: 2.076 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.597 
(2.611) - AE Loss: 1544325.000 (782866.438) - AE Rec Loss: 10.473 (5.309) - Disc
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.001 (0.675) - Batch(s): 1.771 
(2.611) - AE Loss: 87643.062 (782866.438) - AE Rec Loss: 0.594 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.001 (0.619) - Batch(s): 0.707 
(2.453) - AE Loss: 91687.328 (766855.562) - AE Rec Loss: 0.622 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.707 
(2.453) - AE Loss: 1772453.000 (766855.562) - AE Rec Loss: 12.020 (5.201) - Disc
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.707 
(2.453) - AE Loss: 182067.062 (766855.562) - AE Rec Loss: 1.235 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.001 (0.619) - Batch(s): 0.707 
(2.453) - AE Loss: 281469.562 (766855.562) - AE Rec Loss: 1.909 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.001 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 300209.938 (766855.562) - AE Rec Loss: 2.036 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.001 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 555739.000 (766855.562) - AE Rec Loss: 3.769 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.78 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.570 
(2.308) - AE Loss: 213436.125 (742416.562) - AE Rec Loss: 1.447 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.569 
(2.308) - AE Loss: 148785.250 (742416.562) - AE Rec Loss: 1.009 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.568 
(2.308) - AE Loss: 215899.906 (742416.562) - AE Rec Loss: 1.464 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.573 
(2.308) - AE Loss: 74970.047 (742416.562) - AE Rec Loss: 0.508 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.571 
(2.308) - AE Loss: 345371.250 (742416.562) - AE Rec Loss: 2.342 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.576 
(2.308) - AE Loss: 1656319.875 (742416.562) - AE Rec Loss: 11.233 (5.035) - Disc
Loss: 0.000 (0.000) - 12.93 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 197215.000 (728715.312) - AE Rec Loss: 1.337 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 117939.953 (728715.312) - AE Rec Loss: 0.800 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 308537.938 (728715.312) - AE Rec Loss: 2.092 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.52 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 403988.062 (728715.312) - AE Rec Loss: 2.740 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 196578.906 (728715.312) - AE Rec Loss: 1.333 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 293199.719 (728715.312) - AE Rec Loss: 1.988 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.068 
(2.240) - AE Loss: 347776.250 (751182.750) - AE Rec Loss: 2.359 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.23 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.001 (0.510) - Batch(s): 2.069 
(2.240) - AE Loss: 342307.625 (751182.750) - AE Rec Loss: 2.321 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.23 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.069 
(2.240) - AE Loss: 348367.750 (751182.750) - AE Rec Loss: 2.363 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.22 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.001 (0.510) - Batch(s): 2.070 
(2.240) - AE Loss: 500505.406 (751182.750) - AE Rec Loss: 3.394 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.23 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.069 
(2.240) - AE Loss: 282936.188 (751182.750) - AE Rec Loss: 1.919 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.23 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.001 (0.510) - Batch(s): 2.069 
(2.240) - AE Loss: 550383.625 (751182.750) - AE Rec Loss: 3.733 (5.094) - Disc 
Loss: 0.000 (0.000) - 14.23 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.573 
(2.135) - AE Loss: 371601.562 (748906.188) - AE Rec Loss: 2.520 (5.079) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.570 
(2.135) - AE Loss: 257336.938 (748906.188) - AE Rec Loss: 1.745 (5.079) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.568 
(2.135) - AE Loss: 323471.750 (748906.188) - AE Rec Loss: 2.194 (5.079) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.571 
(2.135) - AE Loss: 1549328.500 (748906.188) - AE Rec Loss: 10.507 (5.079) - Disc
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.571 
(2.135) - AE Loss: 211309.188 (748906.188) - AE Rec Loss: 1.433 (5.079) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.001 (0.478) - Batch(s): 0.577 
(2.135) - AE Loss: 126737.367 (748906.188) - AE Rec Loss: 0.859 (5.079) - Disc 
Loss: 0.000 (0.000) - 14.35 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.001 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 139675.594 (731494.125) - AE Rec Loss: 0.947 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.82 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 95363.719 (731494.125) - AE Rec Loss: 0.647 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.82 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.150 
(2.084) - AE Loss: 172025.938 (731494.125) - AE Rec Loss: 1.167 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.82 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.001 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 101168.578 (731494.125) - AE Rec Loss: 0.686 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 111774.438 (731494.125) - AE Rec Loss: 0.758 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.82 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 293786.406 (731494.125) - AE Rec Loss: 1.992 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.82 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.191 
(2.201) - AE Loss: 218930.797 (730670.938) - AE Rec Loss: 1.485 (4.955) - Disc 
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.191 
(2.201) - AE Loss: 1515775.375 (730670.938) - AE Rec Loss: 10.280 (4.955) - Disc
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.191 
(2.201) - AE Loss: 1560295.750 (730670.938) - AE Rec Loss: 10.581 (4.955) - Disc
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.191 
(2.201) - AE Loss: 1684842.500 (730670.938) - AE Rec Loss: 11.426 (4.955) - Disc
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.191 
(2.201) - AE Loss: 1748867.875 (730670.938) - AE Rec Loss: 11.860 (4.955) - Disc
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 3.488 (0.456) - Batch(s): 4.192 
(2.201) - AE Loss: 496585.750 (730670.938) - AE Rec Loss: 3.368 (4.955) - Disc 
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.571 
(2.117) - AE Loss: 98198.109 (729270.875) - AE Rec Loss: 0.666 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.576 
(2.117) - AE Loss: 101035.719 (729270.875) - AE Rec Loss: 0.685 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.574 
(2.117) - AE Loss: 398479.844 (729270.875) - AE Rec Loss: 2.702 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.39 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.569 
(2.117) - AE Loss: 95678.812 (729270.875) - AE Rec Loss: 0.649 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.572 
(2.117) - AE Loss: 385721.500 (729270.875) - AE Rec Loss: 2.616 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.569 
(2.117) - AE Loss: 2921247.500 (729270.875) - AE Rec Loss: 19.811 (4.946) - Disc
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.574 
(2.039) - AE Loss: 167814.438 (726559.062) - AE Rec Loss: 1.138 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.49 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.001 (0.411) - Batch(s): 0.576 
(2.039) - AE Loss: 608876.250 (726559.062) - AE Rec Loss: 4.129 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.50 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.571 
(2.039) - AE Loss: 191372.406 (726559.062) - AE Rec Loss: 1.298 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.50 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.568 
(2.039) - AE Loss: 1489573.000 (726559.062) - AE Rec Loss: 10.102 (4.927) - Disc
Loss: 0.000 (0.000) - 16.50 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.572 
(2.039) - AE Loss: 1731903.500 (726559.062) - AE Rec Loss: 11.745 (4.927) - Disc
Loss: 0.000 (0.000) - 16.50 m remaining

bouta write to tb
[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.570 
(2.039) - AE Loss: 219215.125 (726559.062) - AE Rec Loss: 1.487 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.50 m remaining

wrote to tb
attempting to save
[[36m2023-11-29 03:00:45,578[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:00:46,219[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:00:46,458[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:00:46,472[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:00:46,481[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:00:46,485[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:00:46,490[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:00:46,494[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:00:46,499[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:00:46,505[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:00:46,841[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:00:47,660[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:00:54,912[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:00:54,918[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 03:00:59,315[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:00:59,315[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 03:00:59,341[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 03:00:59,356[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 1594541.250 (728511.438) - AE Rec Loss: 10.814 (4.941) - Disc
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 0.685 
(2.612) - AE Loss: 104790.805 (728511.438) - AE Rec Loss: 0.711 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.82 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 4.203 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 198885.031 (728511.438) - AE Rec Loss: 1.349 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 1601942.625 (728511.438) - AE Rec Loss: 10.864 (4.941) - Disc
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 274432.688 (728511.438) - AE Rec Loss: 1.861 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 15.293 
(2.612) - AE Loss: 1462709.500 (728511.438) - AE Rec Loss: 9.920 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.83 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.572 
(2.520) - AE Loss: 401098.062 (738646.938) - AE Rec Loss: 2.720 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.575 
(2.520) - AE Loss: 240264.672 (738646.938) - AE Rec Loss: 1.629 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.569 
(2.520) - AE Loss: 1489264.750 (738646.938) - AE Rec Loss: 10.100 (5.009) - Disc
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.570 
(2.520) - AE Loss: 142063.719 (738646.938) - AE Rec Loss: 0.963 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.570 
(2.520) - AE Loss: 1632097.000 (738646.938) - AE Rec Loss: 11.068 (5.009) - Disc
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.567 
(2.520) - AE Loss: 1640769.750 (738646.938) - AE Rec Loss: 11.127 (5.009) - Disc
Loss: 0.000 (0.000) - 21.86 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.573 
(2.435) - AE Loss: 1435182.000 (732324.500) - AE Rec Loss: 9.733 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.89 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.577 
(2.435) - AE Loss: 1989007.625 (732324.500) - AE Rec Loss: 13.489 (4.966) - Disc
Loss: 0.000 (0.000) - 21.90 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.570 
(2.435) - AE Loss: 267641.219 (732324.500) - AE Rec Loss: 1.815 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.90 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.573 
(2.435) - AE Loss: 399204.000 (732324.500) - AE Rec Loss: 2.707 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.90 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.572 
(2.435) - AE Loss: 1630208.250 (732324.500) - AE Rec Loss: 11.056 (4.966) - Disc
Loss: 0.000 (0.000) - 21.90 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.568 
(2.435) - AE Loss: 165432.094 (732324.500) - AE Rec Loss: 1.122 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.90 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.746 
(2.364) - AE Loss: 252303.859 (722362.750) - AE Rec Loss: 1.711 (4.899) - Disc 
Loss: 0.000 (0.000) - 22.00 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.747 
(2.364) - AE Loss: 128583.469 (722362.750) - AE Rec Loss: 0.872 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.99 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.747 
(2.364) - AE Loss: 205842.031 (722362.750) - AE Rec Loss: 1.396 (4.899) - Disc 
Loss: 0.000 (0.000) - 22.00 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.747 
(2.364) - AE Loss: 1982706.500 (722362.750) - AE Rec Loss: 13.446 (4.899) - Disc
Loss: 0.000 (0.000) - 22.00 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.749 
(2.364) - AE Loss: 96003.273 (722362.750) - AE Rec Loss: 0.651 (4.899) - Disc 
Loss: 0.000 (0.000) - 22.00 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.748 
(2.364) - AE Loss: 273540.625 (722362.750) - AE Rec Loss: 1.855 (4.899) - Disc 
Loss: 0.000 (0.000) - 22.00 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.577 
(2.293) - AE Loss: 171998.359 (732170.500) - AE Rec Loss: 1.166 (4.965) - Disc 
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.572 
(2.293) - AE Loss: 232802.094 (732170.500) - AE Rec Loss: 1.579 (4.965) - Disc 
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.572 
(2.293) - AE Loss: 1571862.500 (732170.500) - AE Rec Loss: 10.660 (4.965) - Disc
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.573 
(2.293) - AE Loss: 2891621.500 (732170.500) - AE Rec Loss: 19.610 (4.965) - Disc
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.569 
(2.293) - AE Loss: 225434.406 (732170.500) - AE Rec Loss: 1.529 (4.965) - Disc 
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.575 
(2.293) - AE Loss: 247591.391 (732170.500) - AE Rec Loss: 1.679 (4.965) - Disc 
Loss: 0.000 (0.000) - 22.03 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.575 
(2.227) - AE Loss: 590499.250 (718624.688) - AE Rec Loss: 4.005 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.07 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.579 
(2.227) - AE Loss: 439101.562 (718624.688) - AE Rec Loss: 2.978 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.07 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.573 
(2.227) - AE Loss: 482583.312 (718624.688) - AE Rec Loss: 3.273 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.07 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (0.334) - Batch(s): 0.575 
(2.227) - AE Loss: 115836.430 (718624.688) - AE Rec Loss: 0.786 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.06 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.573 
(2.227) - AE Loss: 318960.688 (718624.688) - AE Rec Loss: 2.163 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.07 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.572 
(2.227) - AE Loss: 1373486.750 (718624.688) - AE Rec Loss: 9.315 (4.873) - Disc 
Loss: 0.000 (0.000) - 22.07 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.702 
(2.170) - AE Loss: 1655700.250 (718917.750) - AE Rec Loss: 11.228 (4.875) - Disc
Loss: 0.000 (0.000) - 22.15 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.702 
(2.170) - AE Loss: 1654187.250 (718917.750) - AE Rec Loss: 11.218 (4.875) - Disc
Loss: 0.000 (0.000) - 22.15 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.703 
(2.170) - AE Loss: 313540.719 (718917.750) - AE Rec Loss: 2.126 (4.875) - Disc 
Loss: 0.000 (0.000) - 22.15 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.704 
(2.170) - AE Loss: 173264.781 (718917.750) - AE Rec Loss: 1.175 (4.875) - Disc 
Loss: 0.000 (0.000) - 22.15 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.704 
(2.170) - AE Loss: 146220.859 (718917.750) - AE Rec Loss: 0.992 (4.875) - Disc 
Loss: 0.000 (0.000) - 22.14 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (0.321) - Batch(s): 0.704 
(2.170) - AE Loss: 1730380.375 (718917.750) - AE Rec Loss: 11.735 (4.875) - Disc
Loss: 0.000 (0.000) - 22.15 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.341) - Batch(s): 3.364 
(2.218) - AE Loss: 201205.281 (711529.438) - AE Rec Loss: 1.365 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 1.775 (0.341) - Batch(s): 3.364 
(2.218) - AE Loss: 333040.688 (711529.438) - AE Rec Loss: 2.259 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.341) - Batch(s): 3.365 
(2.218) - AE Loss: 247920.578 (711529.438) - AE Rec Loss: 1.681 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 1.244 (0.341) - Batch(s): 3.365 
(2.218) - AE Loss: 333791.406 (711529.438) - AE Rec Loss: 2.264 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 1.102 (0.341) - Batch(s): 3.365 
(2.218) - AE Loss: 404082.188 (711529.438) - AE Rec Loss: 2.740 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 1.447 (0.341) - Batch(s): 3.364 
(2.218) - AE Loss: 314980.438 (711529.438) - AE Rec Loss: 2.136 (4.825) - Disc 
Loss: 0.000 (0.000) - 23.22 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:01:24,163[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,175[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,282[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,362[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,411[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,602[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:01:26,323[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:26,332[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:26,474[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:26,508[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:26,670[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:26,801[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:26,898[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:26,926[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,067[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,124[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,333[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:01:28,173[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,174[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,174[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:01:28,176[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,176[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,176[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3Reached 3 on node 5

Reached 5 on node 3
Reached 5 on node 5
Reached end on node 3
Reached end on node 5
=> Preparing model 
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:05:58,569[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:58,708[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:58,866[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:58,888[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:58,898[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,038[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:06:00,835[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,026[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,029[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,037[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,047[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,179[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,415[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,643[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,663[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,758[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,764[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:01,848[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 03:06:02,500[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:06:02,502[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
[[36m2023-11-29 03:06:02,502[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
[[36m2023-11-29 03:06:02,504[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
[[36m2023-11-29 03:06:02,505[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
[[36m2023-11-29 03:06:02,505[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataloader) = 1
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:07:31,366[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,511[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,522[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,531[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,558[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,565[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:07:33,533[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:33,687[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:33,737[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:33,742[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:33,755[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:33,781[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,086[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,374[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,383[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,457[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,487[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,501[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 03:07:34,936[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:07:34,940[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:07:34,940[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 03:07:34,941[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
[[36m2023-11-29 03:07:34,942[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:07:34,943[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Running in inference mode: False
Reached 3 on node 2
len(train_dataloader) = 2279
Reached 5 on node 2
Reached end on node 2
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
=> Instantiating the optimizer 
Reached end on node 3
=> Instantiating the optimizer 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:10:34,872[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:34,883[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,160[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,177[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,183[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,591[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:10:37,020[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,182[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,287[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,337[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,382[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,466[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,742[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:10:37,785[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,928[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,940[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,982[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:38,226[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 03:10:38,596[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:10:38,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
[[36m2023-11-29 03:10:38,600[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:10:38,601[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:10:38,602[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Running in inference mode: False
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Preparing opt_disc 
[[36m2023-11-29 03:10:38,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Mixed precision: no
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 4
len(valid_dataset) = 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:12:07,200[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:07,283[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:07,370[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:07,457[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:07,527[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:07,660[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:12:09,326[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:09,473[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:09,478[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:09,686[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:09,720[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:09,804[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 03:12:09,818[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,045[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,100[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,309[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,359[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,371[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 03:12:11,168[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:12:11,168[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 03:12:11,170[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating valid dataloader 
[[36m2023-11-29 03:12:11,172[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
[[36m2023-11-29 03:12:11,172[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
[[36m2023-11-29 03:12:11,174[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataset) = 4
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing model 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 5
Reached 1.3 on node 0Reached 1.3 on node 2


Reached 1.4 on node 3Reached 1.4 on node 2Reached 1.4 on node 0Reached 1.4 on node 5



Reached 1.3 on node 4Reached 1.3 on node 1

Reached 1.4 on node 4Reached 2 on node 2Reached 1.4 on node 1
Reached 2 on node 3
Reached 2 on node 0

Reached 2 on node 5

Reached 2 on node 4
Reached 2 on node 1
Reached 3 on node 2
Reached 3 on node 5Reached 3 on node 3
Reached 3 on node 0
Reached 3 on node 4
Reached 5 on node 2

Reached 3 on node 1
Reached 5 on node 5Reached 5 on node 0
Reached 5 on node 4

Reached end on node 2
Reached 5 on node 1
Reached end on node 5Reached end on node 0Reached end on node 4


Reached end on node 1
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1Reached 1.4 on node 2

Reached 3 on node 1
Reached 2 on node 2
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4Reached 1.4 on node 2

Reached 2 on node 4Reached 2 on node 2

Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached end on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 1.4 on node 4Reached 3 on node 2

Reached 2 on node 4
Reached 5 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 2Reached 1.4 on node 5

Reached 2 on node 5Reached 2 on node 2

Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 0
Reached 1 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
[[36m2023-11-29 03:12:12,943[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached end on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 03:12:15,600[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 03:12:16,820[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:12:16,820[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:12:16,820[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:12:16,823[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:12:16,824[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <101/2280>] - Data(s): 6.146 (6.839) - Batch(s): 11.080 
(11.012) - AE Loss: 106226.773 (767528.188) - AE Rec Loss: 0.720 (5.205) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 9.597 (6.839) - Batch(s): 11.086 
(11.012) - AE Loss: 1595463.875 (767528.188) - AE Rec Loss: 10.820 (5.205) - 
Disc Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 6.209 (6.839) - Batch(s): 11.064 
(11.012) - AE Loss: 1601776.250 (767528.188) - AE Rec Loss: 10.863 (5.205) - 
Disc Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 5.577 (6.839) - Batch(s): 11.078 
(11.012) - AE Loss: 273677.656 (767528.188) - AE Rec Loss: 1.856 (5.205) - Disc 
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 7.697 (6.839) - Batch(s): 11.060 
(11.012) - AE Loss: 1462836.500 (767528.188) - AE Rec Loss: 9.920 (5.205) - Disc
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 7.818 (6.839) - Batch(s): 11.073 
(11.012) - AE Loss: 199429.672 (767528.188) - AE Rec Loss: 1.352 (5.205) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.001 (3.420) - Batch(s): 0.565 
(5.787) - AE Loss: 259605.500 (863225.500) - AE Rec Loss: 1.761 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.001 (3.420) - Batch(s): 0.567 
(5.787) - AE Loss: 1642483.750 (863225.500) - AE Rec Loss: 11.139 (5.854) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.001 (3.420) - Batch(s): 0.565 
(5.787) - AE Loss: 151839.922 (863225.500) - AE Rec Loss: 1.030 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.562 
(5.787) - AE Loss: 1648996.625 (863225.500) - AE Rec Loss: 11.183 (5.854) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.001 (3.420) - Batch(s): 0.563 
(5.787) - AE Loss: 419354.000 (863225.500) - AE Rec Loss: 2.844 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.562 
(5.787) - AE Loss: 1485320.500 (863225.500) - AE Rec Loss: 10.073 (5.854) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.299) - Batch(s): 1.345 
(4.308) - AE Loss: 187083.516 (776412.375) - AE Rec Loss: 1.269 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.346 
(4.308) - AE Loss: 410173.469 (776412.375) - AE Rec Loss: 2.782 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.348 
(4.308) - AE Loss: 272859.469 (776412.375) - AE Rec Loss: 1.850 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.349 
(4.308) - AE Loss: 1638633.000 (776412.375) - AE Rec Loss: 11.113 (5.265) - Disc
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.349 
(4.308) - AE Loss: 1997570.250 (776412.375) - AE Rec Loss: 13.547 (5.265) - Disc
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.349 
(4.308) - AE Loss: 1429293.750 (776412.375) - AE Rec Loss: 9.693 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 3.845 
(4.258) - AE Loss: 254911.062 (705747.188) - AE Rec Loss: 1.729 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 3.629 (1.806) - Batch(s): 4.204 
(4.258) - AE Loss: 92340.469 (705747.188) - AE Rec Loss: 0.626 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 3.845 
(4.258) - AE Loss: 210174.031 (705747.188) - AE Rec Loss: 1.425 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.199 
(4.258) - AE Loss: 273291.500 (705747.188) - AE Rec Loss: 1.853 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 3.844 
(4.258) - AE Loss: 127836.547 (705747.188) - AE Rec Loss: 0.867 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.197 
(4.258) - AE Loss: 1980618.375 (705747.188) - AE Rec Loss: 13.432 (4.786) - Disc
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.562 
(3.519) - AE Loss: 213366.469 (755522.812) - AE Rec Loss: 1.447 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.563 
(3.519) - AE Loss: 230007.938 (755522.812) - AE Rec Loss: 1.560 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.565 
(3.519) - AE Loss: 1560554.875 (755522.812) - AE Rec Loss: 10.583 (5.124) - Disc
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.567 
(3.519) - AE Loss: 2892368.750 (755522.812) - AE Rec Loss: 19.615 (5.124) - Disc
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.563 
(3.519) - AE Loss: 223288.688 (755522.812) - AE Rec Loss: 1.514 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.565 
(3.519) - AE Loss: 156092.000 (755522.812) - AE Rec Loss: 1.059 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.661 
(3.043) - AE Loss: 472555.656 (690263.000) - AE Rec Loss: 3.205 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.59 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.662 
(3.043) - AE Loss: 1362917.750 (690263.000) - AE Rec Loss: 9.243 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.60 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.661 
(3.043) - AE Loss: 406645.438 (690263.000) - AE Rec Loss: 2.758 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.60 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.661 
(3.043) - AE Loss: 98626.133 (690263.000) - AE Rec Loss: 0.669 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.59 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.663 
(3.043) - AE Loss: 585027.625 (690263.000) - AE Rec Loss: 3.967 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.59 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.663 
(3.043) - AE Loss: 303608.250 (690263.000) - AE Rec Loss: 2.059 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.60 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.790 
(2.759) - AE Loss: 309308.656 (695561.750) - AE Rec Loss: 2.098 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.582 (1.039) - Batch(s): 1.149 
(2.759) - AE Loss: 1647330.375 (695561.750) - AE Rec Loss: 11.172 (4.717) - Disc
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.790 
(2.759) - AE Loss: 144944.656 (695561.750) - AE Rec Loss: 0.983 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.790 
(2.759) - AE Loss: 1665306.250 (695561.750) - AE Rec Loss: 11.294 (4.717) - Disc
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (1.039) - Batch(s): 1.144 
(2.759) - AE Loss: 175762.188 (695561.750) - AE Rec Loss: 1.192 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.143 
(2.759) - AE Loss: 1733946.250 (695561.750) - AE Rec Loss: 11.759 (4.717) - Disc
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.001 (0.909) - Batch(s): 0.565 
(2.485) - AE Loss: 319709.250 (673984.438) - AE Rec Loss: 2.168 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.563 
(2.485) - AE Loss: 341557.688 (673984.438) - AE Rec Loss: 2.316 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.564 
(2.485) - AE Loss: 219970.094 (673984.438) - AE Rec Loss: 1.492 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.567 
(2.485) - AE Loss: 267237.500 (673984.438) - AE Rec Loss: 1.812 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.566 
(2.485) - AE Loss: 416464.750 (673984.438) - AE Rec Loss: 2.824 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.563 
(2.485) - AE Loss: 341539.094 (673984.438) - AE Rec Loss: 2.316 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.001 (0.816) - Batch(s): 1.399 
(2.364) - AE Loss: 327115.188 (681904.750) - AE Rec Loss: 2.218 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.001 (0.816) - Batch(s): 1.396 
(2.364) - AE Loss: 169093.859 (681904.750) - AE Rec Loss: 1.147 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.001 (0.816) - Batch(s): 1.397 
(2.364) - AE Loss: 328841.781 (681904.750) - AE Rec Loss: 2.230 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.001 (0.816) - Batch(s): 1.397 
(2.364) - AE Loss: 1627496.500 (681904.750) - AE Rec Loss: 11.037 (4.624) - Disc
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.397 
(2.364) - AE Loss: 1579302.000 (681904.750) - AE Rec Loss: 10.710 (4.624) - Disc
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.746 (0.816) - Batch(s): 1.398 
(2.364) - AE Loss: 226582.234 (681904.750) - AE Rec Loss: 1.537 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 1.127 (0.757) - Batch(s): 1.690 
(2.294) - AE Loss: 181126.109 (661720.375) - AE Rec Loss: 1.228 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.12 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.687 
(2.294) - AE Loss: 432414.000 (661720.375) - AE Rec Loss: 2.932 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.12 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.001 (0.757) - Batch(s): 1.334 
(2.294) - AE Loss: 97580.719 (661720.375) - AE Rec Loss: 0.662 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.12 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.868 (0.757) - Batch(s): 1.691 
(2.294) - AE Loss: 1814447.000 (661720.375) - AE Rec Loss: 12.305 (4.488) - Disc
Loss: 0.000 (0.000) - 8.12 m remaining

bouta write to tb
[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.690 
(2.294) - AE Loss: 96130.383 (661720.375) - AE Rec Loss: 0.652 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.12 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.691 
(2.294) - AE Loss: 155980.047 (661720.375) - AE Rec Loss: 1.058 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.12 m remaining

wrote to tb
[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.127 
(2.274) - AE Loss: 566267.250 (654375.625) - AE Rec Loss: 3.840 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.84 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 1.562 (0.719) - Batch(s): 2.128 
(2.274) - AE Loss: 354901.875 (654375.625) - AE Rec Loss: 2.407 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.85 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 1.979 
(2.274) - AE Loss: 319598.688 (654375.625) - AE Rec Loss: 2.167 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.85 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.001 (0.719) - Batch(s): 1.372 
(2.274) - AE Loss: 162843.062 (654375.625) - AE Rec Loss: 1.104 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.84 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.001 (0.719) - Batch(s): 1.979 
(2.274) - AE Loss: 1568824.500 (654375.625) - AE Rec Loss: 10.639 (4.438) - Disc
Loss: 0.000 (0.000) - 8.84 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.125 
(2.274) - AE Loss: 127644.117 (654375.625) - AE Rec Loss: 0.866 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.85 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.690 
(2.475) - AE Loss: 1599236.625 (661263.688) - AE Rec Loss: 10.846 (4.484) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 488866.812 (661263.688) - AE Rec Loss: 3.315 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.001 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 310158.188 (661263.688) - AE Rec Loss: 2.103 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.693 
(2.475) - AE Loss: 149097.719 (661263.688) - AE Rec Loss: 1.011 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.001 (0.704) - Batch(s): 4.693 
(2.475) - AE Loss: 1756807.000 (661263.688) - AE Rec Loss: 11.914 (4.484) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 2.486 (0.704) - Batch(s): 4.692 
(2.475) - AE Loss: 222071.828 (661263.688) - AE Rec Loss: 1.506 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.567 
(2.328) - AE Loss: 80628.062 (657788.062) - AE Rec Loss: 0.547 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.567 
(2.328) - AE Loss: 197772.000 (657788.062) - AE Rec Loss: 1.341 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.001 (0.650) - Batch(s): 0.562 
(2.328) - AE Loss: 2983421.000 (657788.062) - AE Rec Loss: 20.233 (4.461) - Disc
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.563 
(2.328) - AE Loss: 88636.883 (657788.062) - AE Rec Loss: 0.601 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.562 
(2.328) - AE Loss: 1415877.000 (657788.062) - AE Rec Loss: 9.602 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.567 
(2.328) - AE Loss: 94016.578 (657788.062) - AE Rec Loss: 0.638 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.45 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 153504.469 (660829.375) - AE Rec Loss: 1.041 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.550 
(2.712) - AE Loss: 201266.953 (660829.375) - AE Rec Loss: 1.365 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.001 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 309821.375 (660829.375) - AE Rec Loss: 2.101 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 1661338.000 (660829.375) - AE Rec Loss: 11.267 (4.482) - Disc
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 4.539 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 84627.094 (660829.375) - AE Rec Loss: 0.574 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 1512102.250 (660829.375) - AE Rec Loss: 10.255 (4.482) - Disc
Loss: 0.000 (0.000) - 12.88 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 216972.656 (654723.875) - AE Rec Loss: 1.471 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 143649.219 (654723.875) - AE Rec Loss: 0.974 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 231807.641 (654723.875) - AE Rec Loss: 1.572 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.536 
(2.967) - AE Loss: 1654453.000 (654723.875) - AE Rec Loss: 11.220 (4.440) - Disc
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 1721748.625 (654723.875) - AE Rec Loss: 11.676 (4.440) - Disc
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.536 
(2.967) - AE Loss: 95795.531 (654723.875) - AE Rec Loss: 0.650 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.85 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.564 
(2.817) - AE Loss: 213324.734 (648743.500) - AE Rec Loss: 1.447 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.567 
(2.817) - AE Loss: 227613.781 (648743.500) - AE Rec Loss: 1.544 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 1502594.500 (648743.500) - AE Rec Loss: 10.190 (4.400) - Disc
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 252334.844 (648743.500) - AE Rec Loss: 1.711 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.563 
(2.817) - AE Loss: 138820.562 (648743.500) - AE Rec Loss: 0.941 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 180092.609 (648743.500) - AE Rec Loss: 1.221 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.94 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(2.684) - AE Loss: 344465.406 (651085.312) - AE Rec Loss: 2.336 (4.415) - Disc 
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(2.684) - AE Loss: 1149780.750 (651085.312) - AE Rec Loss: 7.797 (4.415) - Disc 
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.567 
(2.684) - AE Loss: 167542.578 (651085.312) - AE Rec Loss: 1.136 (4.415) - Disc 
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.565 
(2.684) - AE Loss: 1813314.250 (651085.312) - AE Rec Loss: 12.297 (4.415) - Disc
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.564 
(2.684) - AE Loss: 494733.250 (651085.312) - AE Rec Loss: 3.355 (4.415) - Disc 
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.566 
(2.684) - AE Loss: 237562.609 (651085.312) - AE Rec Loss: 1.611 (4.415) - Disc 
Loss: 0.000 (0.000) - 15.03 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 923162.500 (635765.500) - AE Rec Loss: 6.261 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.41 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.741 
(3.354) - AE Loss: 294201.875 (635765.500) - AE Rec Loss: 1.995 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.40 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 103049.125 (635765.500) - AE Rec Loss: 0.699 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.40 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.741 
(3.354) - AE Loss: 196657.688 (635765.500) - AE Rec Loss: 1.334 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.41 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 90322.953 (635765.500) - AE Rec Loss: 0.613 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.41 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 1588525.125 (635765.500) - AE Rec Loss: 10.773 (4.312) - Disc
Loss: 0.000 (0.000) - 19.40 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.569 
(3.207) - AE Loss: 752914.312 (648574.375) - AE Rec Loss: 5.106 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.563 
(3.207) - AE Loss: 134576.406 (648574.375) - AE Rec Loss: 0.913 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.564 
(3.207) - AE Loss: 1646164.875 (648574.375) - AE Rec Loss: 11.164 (4.398) - Disc
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.567 
(3.207) - AE Loss: 1686661.500 (648574.375) - AE Rec Loss: 11.438 (4.398) - Disc
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(3.207) - AE Loss: 79592.016 (648574.375) - AE Rec Loss: 0.540 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(3.207) - AE Loss: 518118.281 (648574.375) - AE Rec Loss: 3.514 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.568 
(3.075) - AE Loss: 1499878.750 (658991.438) - AE Rec Loss: 10.172 (4.469) - Disc
Loss: 0.000 (0.000) - 19.50 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.567 
(3.075) - AE Loss: 193690.594 (658991.438) - AE Rec Loss: 1.314 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.50 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.567 
(3.075) - AE Loss: 304841.062 (658991.438) - AE Rec Loss: 2.067 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.50 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.001 (0.557) - Batch(s): 0.565 
(3.075) - AE Loss: 327552.750 (658991.438) - AE Rec Loss: 2.221 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.50 m remaining

bouta write to tb
[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.564 
(3.075) - AE Loss: 83000.789 (658991.438) - AE Rec Loss: 0.563 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.50 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.567 
(3.075) - AE Loss: 1743123.375 (658991.438) - AE Rec Loss: 11.821 (4.469) - Disc
Loss: 0.000 (0.000) - 19.50 m remaining

wrote to tb
attempting to save
[[36m2023-11-29 03:13:23,227[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:13:24,052[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:13:24,253[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:13:24,261[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:13:24,267[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:13:24,274[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:13:24,282[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:13:24,288[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:13:24,294[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:13:24,300[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:13:24,984[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:13:40,986[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:40,986[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,295[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,304[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,343[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,375[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:13:43,133[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:43,151[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:43,435[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:43,482[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:43,492[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:43,594[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:43,678[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:43,713[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,068[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,104[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,121[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,141[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:13:44,948[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:13:44,950[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 03:13:44,951[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:13:44,951[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:13:44,954[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:13:44,956[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:16:44,784[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:44,846[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:44,869[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,052[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,068[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,080[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:16:46,930[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:46,984[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,016[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,175[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,183[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,213[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,554[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,618[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,643[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,771[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,856[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:47,877[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 03:16:48,616[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:16:48,616[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
[[36m2023-11-29 03:16:48,618[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
[[36m2023-11-29 03:16:48,621[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating the optimizer 
[[36m2023-11-29 03:16:48,623[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataset) = 54706
[[36m2023-11-29 03:16:48,623[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
len(train_dataloader) = 2279
=> Mixed precision: no
=> Preparing model 
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Preparing model 
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing opt_disc 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 1.3 on node 4
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 2
Reached 1.3 on node 3Reached 3 on node 4

Reached 5 on node 2Reached 1.4 on node 3

Reached end on node 2
Reached 2 on node 3
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 1
Reached 3 on node 0
Reached 5 on node 1
Reached end on node 1
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2Reached 3 on node 4Reached 3 on node 3


Reached 5 on node 3Reached 5 on node 4

Reached end on node 3Reached end on node 4

=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1 on node 0
Reached 1.2 on node 3
Reached 1.2 on node 0
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 0Reached 1.3 on node 1


Reached 1.3 on node 4
Reached 1.4 on node 1Reached 1.4 on node 0Reached 1.4 on node 3
Reached 1.4 on node 4


Reached 2 on node 3
Reached 2 on node 1Reached 2 on node 0
Reached 2 on node 4

Reached 3 on node 3
Reached 3 on node 1Reached 3 on node 0

Reached 3 on node 4
Reached 5 on node 3
Reached 5 on node 0Reached 5 on node 1

Reached 5 on node 4
Reached end on node 3
Reached end on node 0
Reached end on node 4Reached 1.3 on node 5Reached end on node 1Reached 1.3 on node 2



Reached 1.4 on node 5
Reached 1.4 on node 2
Reached 2 on node 5Reached 2 on node 2

Reached 3 on node 2Reached 3 on node 5

Reached 5 on node 5
Reached 5 on node 2
Reached end on node 2Reached end on node 5

=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4Reached 1.4 on node 2

Reached 2 on node 4Reached 2 on node 2

Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 2
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 2Reached 1.4 on node 5

Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4Reached 3 on node 2

Reached 2 on node 4Reached 3 on node 2

Reached end on node 1
Reached 3 on node 2
Reached 1 on node 3Reached 3 on node 2

Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1 on node 5
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:16:50,308[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached end on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
[[36m2023-11-29 03:16:51,606[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:16:52,143[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:16:52,143[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:16:52,144[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:16:52,147[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:16:52,149[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <101/2280>] - Data(s): 6.061 (6.633) - Batch(s): 10.726 
(10.709) - AE Loss: 106226.773 (767327.188) - AE Rec Loss: 0.720 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 9.109 (6.633) - Batch(s): 10.553 
(10.709) - AE Loss: 1601434.000 (767327.188) - AE Rec Loss: 10.860 (5.204) - 
Disc Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 4.987 (6.633) - Batch(s): 10.527 
(10.709) - AE Loss: 1462706.250 (767327.188) - AE Rec Loss: 9.920 (5.204) - Disc
Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 5.279 (6.633) - Batch(s): 10.769 
(10.709) - AE Loss: 198879.281 (767327.188) - AE Rec Loss: 1.349 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 5.940 (6.633) - Batch(s): 10.552 
(10.709) - AE Loss: 273226.812 (767327.188) - AE Rec Loss: 1.853 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 7.923 (6.633) - Batch(s): 10.557 
(10.709) - AE Loss: 1595175.250 (767327.188) - AE Rec Loss: 10.818 (5.204) - 
Disc Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.560 
(5.636) - AE Loss: 1485730.625 (863161.812) - AE Rec Loss: 10.076 (5.854) - Disc
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.561 
(5.636) - AE Loss: 1648129.625 (863161.812) - AE Rec Loss: 11.177 (5.854) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.001 (3.317) - Batch(s): 0.564 
(5.636) - AE Loss: 152226.625 (863161.812) - AE Rec Loss: 1.032 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.564 
(5.636) - AE Loss: 259266.812 (863161.812) - AE Rec Loss: 1.758 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.562 
(5.636) - AE Loss: 419354.000 (863161.812) - AE Rec Loss: 2.844 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.565 
(5.636) - AE Loss: 1643308.250 (863161.812) - AE Rec Loss: 11.144 (5.854) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.951 
(4.408) - AE Loss: 273710.625 (776363.312) - AE Rec Loss: 1.856 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.950 
(4.408) - AE Loss: 1638234.500 (776363.312) - AE Rec Loss: 11.110 (5.265) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.952 
(4.408) - AE Loss: 1996697.500 (776363.312) - AE Rec Loss: 13.541 (5.265) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 1.043 (2.292) - Batch(s): 1.953 
(4.408) - AE Loss: 187467.078 (776363.312) - AE Rec Loss: 1.271 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 1.293 (2.292) - Batch(s): 1.952 
(4.408) - AE Loss: 409886.969 (776363.312) - AE Rec Loss: 2.780 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.952 
(4.408) - AE Loss: 1429293.750 (776363.312) - AE Rec Loss: 9.693 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.634 
(4.443) - AE Loss: 1980469.750 (705540.312) - AE Rec Loss: 13.431 (4.785) - Disc
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 4.071 (1.807) - Batch(s): 4.641 
(4.443) - AE Loss: 92534.461 (705540.312) - AE Rec Loss: 0.628 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.639 
(4.443) - AE Loss: 274504.281 (705540.312) - AE Rec Loss: 1.862 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.284 
(4.443) - AE Loss: 252408.891 (705540.312) - AE Rec Loss: 1.712 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.284 
(4.443) - AE Loss: 206347.688 (705540.312) - AE Rec Loss: 1.399 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.284 
(4.443) - AE Loss: 127324.852 (705540.312) - AE Rec Loss: 0.863 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.565 
(3.667) - AE Loss: 1560776.125 (755310.188) - AE Rec Loss: 10.585 (5.122) - Disc
Loss: 0.000 (0.000) - 6.56 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.562 
(3.667) - AE Loss: 213900.141 (755310.188) - AE Rec Loss: 1.451 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.57 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.566 
(3.667) - AE Loss: 2892523.500 (755310.188) - AE Rec Loss: 19.616 (5.122) - Disc
Loss: 0.000 (0.000) - 6.56 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (1.446) - Batch(s): 0.563 
(3.667) - AE Loss: 230169.062 (755310.188) - AE Rec Loss: 1.561 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.63 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.565 
(3.667) - AE Loss: 153212.156 (755310.188) - AE Rec Loss: 1.039 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.57 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (1.446) - Batch(s): 0.562 
(3.667) - AE Loss: 220127.719 (755310.188) - AE Rec Loss: 1.493 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.205) - Batch(s): 0.654 
(3.165) - AE Loss: 586703.875 (690040.562) - AE Rec Loss: 3.979 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.205) - Batch(s): 0.654 
(3.165) - AE Loss: 1363528.750 (690040.562) - AE Rec Loss: 9.247 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.654 
(3.165) - AE Loss: 97791.594 (690040.562) - AE Rec Loss: 0.663 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.205) - Batch(s): 0.654 
(3.165) - AE Loss: 401841.219 (690040.562) - AE Rec Loss: 2.725 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.655 
(3.165) - AE Loss: 304202.844 (690040.562) - AE Rec Loss: 2.063 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.655 
(3.165) - AE Loss: 472636.594 (690040.562) - AE Rec Loss: 3.205 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.85 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.048 
(2.850) - AE Loss: 177101.562 (695518.000) - AE Rec Loss: 1.201 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.692 
(2.850) - AE Loss: 311512.438 (695518.000) - AE Rec Loss: 2.113 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.693 
(2.850) - AE Loss: 144525.844 (695518.000) - AE Rec Loss: 0.980 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.045 
(2.850) - AE Loss: 1734251.000 (695518.000) - AE Rec Loss: 11.761 (4.717) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 0.693 
(2.850) - AE Loss: 1665338.000 (695518.000) - AE Rec Loss: 11.294 (4.717) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.485 (1.039) - Batch(s): 1.051 
(2.850) - AE Loss: 1648578.500 (695518.000) - AE Rec Loss: 11.180 (4.717) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.565 
(2.564) - AE Loss: 320971.562 (674048.250) - AE Rec Loss: 2.177 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.562 
(2.564) - AE Loss: 343544.750 (674048.250) - AE Rec Loss: 2.330 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.562 
(2.564) - AE Loss: 342072.438 (674048.250) - AE Rec Loss: 2.320 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.563 
(2.564) - AE Loss: 218574.656 (674048.250) - AE Rec Loss: 1.482 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.566 
(2.564) - AE Loss: 417141.625 (674048.250) - AE Rec Loss: 2.829 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.567 
(2.564) - AE Loss: 266792.750 (674048.250) - AE Rec Loss: 1.809 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.447 
(2.551) - AE Loss: 328229.250 (682014.938) - AE Rec Loss: 2.226 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.15 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.447 
(2.551) - AE Loss: 1629002.125 (682014.938) - AE Rec Loss: 11.047 (4.625) - Disc
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 1.805 (0.832) - Batch(s): 2.447 
(2.551) - AE Loss: 168970.625 (682014.938) - AE Rec Loss: 1.146 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.125 (0.832) - Batch(s): 2.448 
(2.551) - AE Loss: 1578920.625 (682014.938) - AE Rec Loss: 10.708 (4.625) - Disc
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.447 
(2.551) - AE Loss: 328868.062 (682014.938) - AE Rec Loss: 2.230 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.14 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.449 
(2.551) - AE Loss: 227152.781 (682014.938) - AE Rec Loss: 1.540 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.563 
(2.361) - AE Loss: 428222.500 (661724.000) - AE Rec Loss: 2.904 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.30 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.001 (0.750) - Batch(s): 0.567 
(2.361) - AE Loss: 1812376.000 (661724.000) - AE Rec Loss: 12.291 (4.488) - Disc
Loss: 0.000 (0.000) - 8.30 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.564 
(2.361) - AE Loss: 181373.047 (661724.000) - AE Rec Loss: 1.230 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.37 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.567 
(2.361) - AE Loss: 96783.523 (661724.000) - AE Rec Loss: 0.656 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.30 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.567 
(2.361) - AE Loss: 155456.578 (661724.000) - AE Rec Loss: 1.054 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.30 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.565 
(2.361) - AE Loss: 97509.266 (661724.000) - AE Rec Loss: 0.661 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.37 m remaining

bouta write to tb
wrote to tb
[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.255 
(2.337) - AE Loss: 566518.062 (654334.062) - AE Rec Loss: 3.842 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.253 
(2.337) - AE Loss: 127675.781 (654334.062) - AE Rec Loss: 0.866 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 1.900 
(2.337) - AE Loss: 1569169.625 (654334.062) - AE Rec Loss: 10.642 (4.437) - Disc
Loss: 0.000 (0.000) - 9.07 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 1.692 (0.712) - Batch(s): 2.259 
(2.337) - AE Loss: 355012.844 (654334.062) - AE Rec Loss: 2.408 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 1.900 
(2.337) - AE Loss: 319435.750 (654334.062) - AE Rec Loss: 2.166 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.001 (0.712) - Batch(s): 1.059 
(2.337) - AE Loss: 162145.625 (654334.062) - AE Rec Loss: 1.100 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.07 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 1.495 (0.689) - Batch(s): 3.082 
(2.399) - AE Loss: 308546.781 (661161.750) - AE Rec Loss: 2.092 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.03 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 1.328 (0.689) - Batch(s): 3.082 
(2.399) - AE Loss: 1756142.000 (661161.750) - AE Rec Loss: 11.910 (4.484) - Disc
Loss: 0.000 (0.000) - 9.96 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.083 
(2.399) - AE Loss: 148867.375 (661161.750) - AE Rec Loss: 1.010 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.02 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.085 
(2.399) - AE Loss: 1598973.875 (661161.750) - AE Rec Loss: 10.844 (4.484) - Disc
Loss: 0.000 (0.000) - 9.96 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 2.423 (0.689) - Batch(s): 3.084 
(2.399) - AE Loss: 220950.250 (661161.750) - AE Rec Loss: 1.498 (4.484) - Disc 
Loss: 0.000 (0.000) - 9.96 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.082 
(2.399) - AE Loss: 487776.469 (661161.750) - AE Rec Loss: 3.308 (4.484) - Disc 
Loss: 0.000 (0.000) - 9.96 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.001 (0.636) - Batch(s): 0.567 
(2.258) - AE Loss: 82167.984 (657686.750) - AE Rec Loss: 0.557 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.563 
(2.258) - AE Loss: 1415345.250 (657686.750) - AE Rec Loss: 9.598 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.562 
(2.258) - AE Loss: 2983632.750 (657686.750) - AE Rec Loss: 20.234 (4.460) - Disc
Loss: 0.000 (0.000) - 10.16 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.567 
(2.258) - AE Loss: 93277.930 (657686.750) - AE Rec Loss: 0.633 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.565 
(2.258) - AE Loss: 88333.633 (657686.750) - AE Rec Loss: 0.599 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.16 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.565 
(2.258) - AE Loss: 198076.125 (657686.750) - AE Rec Loss: 1.343 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 1.651 
(2.233) - AE Loss: 310755.188 (660758.438) - AE Rec Loss: 2.107 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.75 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 1.652 
(2.233) - AE Loss: 153050.516 (660758.438) - AE Rec Loss: 1.038 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.68 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.003 
(2.233) - AE Loss: 1661356.500 (660758.438) - AE Rec Loss: 11.267 (4.481) - Disc
Loss: 0.000 (0.000) - 10.68 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 1.651 
(2.233) - AE Loss: 1511976.125 (660758.438) - AE Rec Loss: 10.254 (4.481) - Disc
Loss: 0.000 (0.000) - 10.74 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.005 
(2.233) - AE Loss: 201918.781 (660758.438) - AE Rec Loss: 1.369 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.68 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 1.443 (0.605) - Batch(s): 2.009 
(2.233) - AE Loss: 85571.969 (660758.438) - AE Rec Loss: 0.580 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.68 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.001 (0.564) - Batch(s): 0.663 
(2.129) - AE Loss: 1653864.500 (654648.500) - AE Rec Loss: 11.216 (4.440) - Disc
Loss: 0.000 (0.000) - 10.84 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.001 (0.564) - Batch(s): 0.662 
(2.129) - AE Loss: 216865.484 (654648.500) - AE Rec Loss: 1.471 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.91 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.662 
(2.129) - AE Loss: 232252.578 (654648.500) - AE Rec Loss: 1.575 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.84 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.001 (0.564) - Batch(s): 0.663 
(2.129) - AE Loss: 1721388.500 (654648.500) - AE Rec Loss: 11.674 (4.440) - Disc
Loss: 0.000 (0.000) - 10.84 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.663 
(2.129) - AE Loss: 144265.250 (654648.500) - AE Rec Loss: 0.978 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.84 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.663 
(2.129) - AE Loss: 95385.789 (654648.500) - AE Rec Loss: 0.647 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 180502.781 (648665.062) - AE Rec Loss: 1.224 (4.399) - Disc 
Loss: 0.000 (0.000) - 10.97 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 1502564.000 (648665.062) - AE Rec Loss: 10.190 (4.399) - Disc
Loss: 0.000 (0.000) - 10.97 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 251797.859 (648665.062) - AE Rec Loss: 1.708 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.03 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.568 
(2.031) - AE Loss: 227217.188 (648665.062) - AE Rec Loss: 1.541 (4.399) - Disc 
Loss: 0.000 (0.000) - 10.97 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.001 (0.529) - Batch(s): 0.563 
(2.031) - AE Loss: 139307.906 (648665.062) - AE Rec Loss: 0.945 (4.399) - Disc 
Loss: 0.000 (0.000) - 10.97 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.001 (0.529) - Batch(s): 0.564 
(2.031) - AE Loss: 212446.578 (648665.062) - AE Rec Loss: 1.441 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.04 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.461 
(2.131) - AE Loss: 1807607.625 (650948.000) - AE Rec Loss: 12.259 (4.415) - Disc
Loss: 0.000 (0.000) - 12.16 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.461 
(2.131) - AE Loss: 236993.484 (650948.000) - AE Rec Loss: 1.607 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.15 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 3.246 (0.521) - Batch(s): 3.821 
(2.131) - AE Loss: 166637.031 (650948.000) - AE Rec Loss: 1.130 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.461 
(2.131) - AE Loss: 342202.250 (650948.000) - AE Rec Loss: 2.321 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.816 
(2.131) - AE Loss: 1151110.375 (650948.000) - AE Rec Loss: 7.806 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.814 
(2.131) - AE Loss: 493211.906 (650948.000) - AE Rec Loss: 3.345 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.986 (0.499) - Batch(s): 1.631 
(2.103) - AE Loss: 91264.188 (635599.438) - AE Rec Loss: 0.619 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.53 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.631 
(2.103) - AE Loss: 1588975.750 (635599.438) - AE Rec Loss: 10.776 (4.310) - Disc
Loss: 0.000 (0.000) - 12.59 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.633 
(2.103) - AE Loss: 292809.500 (635599.438) - AE Rec Loss: 1.986 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.58 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.632 
(2.103) - AE Loss: 103426.844 (635599.438) - AE Rec Loss: 0.701 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.53 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.630 
(2.103) - AE Loss: 922737.000 (635599.438) - AE Rec Loss: 6.258 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.53 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.001 (0.499) - Batch(s): 1.631 
(2.103) - AE Loss: 195020.406 (635599.438) - AE Rec Loss: 1.323 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.53 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.566 
(2.022) - AE Loss: 516790.469 (648384.188) - AE Rec Loss: 3.505 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.64 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.567 
(2.022) - AE Loss: 751254.500 (648384.188) - AE Rec Loss: 5.095 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.64 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.567 
(2.022) - AE Loss: 1685632.375 (648384.188) - AE Rec Loss: 11.431 (4.397) - Disc
Loss: 0.000 (0.000) - 12.64 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.563 
(2.022) - AE Loss: 1645448.875 (648384.188) - AE Rec Loss: 11.159 (4.397) - Disc
Loss: 0.000 (0.000) - 12.70 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.565 
(2.022) - AE Loss: 79833.820 (648384.188) - AE Rec Loss: 0.541 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.69 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.562 
(2.022) - AE Loss: 134281.484 (648384.188) - AE Rec Loss: 0.911 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.64 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.382 
(1.998) - AE Loss: 1501473.250 (658773.375) - AE Rec Loss: 10.183 (4.468) - Disc
Loss: 0.000 (0.000) - 13.09 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.857 (0.458) - Batch(s): 1.426 
(1.998) - AE Loss: 303960.750 (658773.375) - AE Rec Loss: 2.061 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.09 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.381 
(1.998) - AE Loss: 193279.203 (658773.375) - AE Rec Loss: 1.311 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.15 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.090 (0.458) - Batch(s): 1.423 
(1.998) - AE Loss: 1742368.750 (658773.375) - AE Rec Loss: 11.816 (4.468) - Disc
Loss: 0.000 (0.000) - 13.09 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.421 
(1.998) - AE Loss: 83661.656 (658773.375) - AE Rec Loss: 0.567 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.09 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.381 
(1.998) - AE Loss: 326545.250 (658773.375) - AE Rec Loss: 2.215 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.16 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 03:17:37,277[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:17:38,477[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:17:38,613[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:17:38,620[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:17:38,625[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:17:38,629[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:17:38,634[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:17:38,639[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:17:38,645[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:17:38,650[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:17:39,920[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:17:45,495[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:17:49,929[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:17:49,934[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 03:17:51,979[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:17:51,979[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 03:17:51,979[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 03:17:51,989[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.295 
(2.617) - AE Loss: 81188.328 (676453.562) - AE Rec Loss: 0.551 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.83 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.001 (0.436) - Batch(s): 0.641 
(2.617) - AE Loss: 135489.859 (676453.562) - AE Rec Loss: 0.919 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.295 
(2.617) - AE Loss: 1422708.500 (676453.562) - AE Rec Loss: 9.648 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.295 
(2.617) - AE Loss: 3070930.250 (676453.562) - AE Rec Loss: 20.826 (4.587) - Disc
Loss: 0.000 (0.000) - 17.83 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.295 
(2.617) - AE Loss: 298444.188 (676453.562) - AE Rec Loss: 2.024 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.83 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.001 (0.436) - Batch(s): 16.295 
(2.617) - AE Loss: 330757.500 (676453.562) - AE Rec Loss: 2.243 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.83 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.566 
(2.524) - AE Loss: 122236.375 (665528.125) - AE Rec Loss: 0.829 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.567 
(2.524) - AE Loss: 492965.562 (665528.125) - AE Rec Loss: 3.343 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.563 
(2.524) - AE Loss: 139069.531 (665528.125) - AE Rec Loss: 0.943 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.568 
(2.524) - AE Loss: 85160.273 (665528.125) - AE Rec Loss: 0.578 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.567 
(2.524) - AE Loss: 365264.375 (665528.125) - AE Rec Loss: 2.477 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.564 
(2.524) - AE Loss: 163423.469 (665528.125) - AE Rec Loss: 1.108 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.89 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.567 
(2.438) - AE Loss: 352057.688 (650271.625) - AE Rec Loss: 2.388 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (0.399) - Batch(s): 0.567 
(2.438) - AE Loss: 79171.500 (650271.625) - AE Rec Loss: 0.537 (4.410) - Disc 
Loss: 0.000 (0.000) - 18.00 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.567 
(2.438) - AE Loss: 137382.969 (650271.625) - AE Rec Loss: 0.932 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.564 
(2.438) - AE Loss: 205401.391 (650271.625) - AE Rec Loss: 1.393 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.564 
(2.438) - AE Loss: 223158.828 (650271.625) - AE Rec Loss: 1.513 (4.410) - Disc 
Loss: 0.000 (0.000) - 18.01 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (0.399) - Batch(s): 0.568 
(2.438) - AE Loss: 402937.375 (650271.625) - AE Rec Loss: 2.733 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.95 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 146300.828 (648486.250) - AE Rec Loss: 0.992 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.04 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 283390.812 (648486.250) - AE Rec Loss: 1.922 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.04 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.682 
(2.365) - AE Loss: 3038891.750 (648486.250) - AE Rec Loss: 20.609 (4.398) - Disc
Loss: 0.000 (0.000) - 18.04 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.682 
(2.365) - AE Loss: 818649.062 (648486.250) - AE Rec Loss: 5.552 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.683 
(2.365) - AE Loss: 126543.125 (648486.250) - AE Rec Loss: 0.858 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.04 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (0.382) - Batch(s): 0.683 
(2.365) - AE Loss: 118461.555 (648486.250) - AE Rec Loss: 0.803 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.564 
(2.293) - AE Loss: 78233.172 (645571.188) - AE Rec Loss: 0.531 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.16 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (0.367) - Batch(s): 0.568 
(2.293) - AE Loss: 191715.844 (645571.188) - AE Rec Loss: 1.300 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.568 
(2.293) - AE Loss: 1664321.750 (645571.188) - AE Rec Loss: 11.287 (4.378) - Disc
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.565 
(2.293) - AE Loss: 2221512.500 (645571.188) - AE Rec Loss: 15.066 (4.378) - Disc
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.566 
(2.293) - AE Loss: 448944.875 (645571.188) - AE Rec Loss: 3.045 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.15 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.569 
(2.293) - AE Loss: 1532163.000 (645571.188) - AE Rec Loss: 10.391 (4.378) - Disc
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.565 
(2.227) - AE Loss: 1457793.125 (646239.062) - AE Rec Loss: 9.886 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.21 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.567 
(2.227) - AE Loss: 1990597.250 (646239.062) - AE Rec Loss: 13.500 (4.383) - Disc
Loss: 0.000 (0.000) - 18.21 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.568 
(2.227) - AE Loss: 143363.766 (646239.062) - AE Rec Loss: 0.972 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.15 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.567 
(2.227) - AE Loss: 248612.109 (646239.062) - AE Rec Loss: 1.686 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.15 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.570 
(2.227) - AE Loss: 185775.141 (646239.062) - AE Rec Loss: 1.260 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.15 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.565 
(2.227) - AE Loss: 338514.562 (646239.062) - AE Rec Loss: 2.296 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.15 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 1842537.500 (648069.312) - AE Rec Loss: 12.496 (4.395) - Disc
Loss: 0.000 (0.000) - 18.63 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 1.212 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 76135.891 (648069.312) - AE Rec Loss: 0.516 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.63 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 1822839.625 (648069.312) - AE Rec Loss: 12.362 (4.395) - Disc
Loss: 0.000 (0.000) - 18.57 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.343) - Batch(s): 1.881 
(2.214) - AE Loss: 111732.406 (648069.312) - AE Rec Loss: 0.758 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.57 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.343) - Batch(s): 1.879 
(2.214) - AE Loss: 105238.109 (648069.312) - AE Rec Loss: 0.714 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.57 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.880 
(2.214) - AE Loss: 1483546.375 (648069.312) - AE Rec Loss: 10.061 (4.395) - Disc
Loss: 0.000 (0.000) - 18.57 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:18:18,261[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:18,417[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:18,581[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:18,603[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:18,639[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:18,657[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:18:20,452[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:20,522[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:20,758[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:20,768[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:20,802[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,042[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,055[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:18:21,092[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,371[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,408[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,453[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,572[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:18:22,264[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:18:22,268[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,268[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating the optimizer 
[[36m2023-11-29 03:18:22,271[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:18:22,271[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,271[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 3 on node 4
Reached 2 on node 1
Reached 3 on node 1Reached 5 on node 4

Reached end on node 4
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 3 on node 3
Reached 2 on node 5
Reached 5 on node 3
Reached 3 on node 5
Reached end on node 3
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached 3 on node 1
Reached end on node 4
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 5
Reached 5 on node 5
=> Preparing criterion 
Reached end on node 5
Reached 3 on node 3=> Preparing criterion 

Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 0
Reached 1.3 on node 4
Reached 1.4 on node 0

Reached 1.4 on node 2
Reached 1.4 on node 4
Reached 2 on node 0
Reached 2 on node 2Reached 2 on node 4

Reached 3 on node 0
Reached 3 on node 2Reached 3 on node 4Reached 5 on node 0


Reached 5 on node 4Reached 5 on node 2

Reached end on node 0
Reached end on node 2Reached end on node 4

Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 1.3 on node 5
Reached 3 on node 1
Reached 1.4 on node 5Reached 2 on node 3

Reached 5 on node 1
Reached 2 on node 5
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached 3 on node 5
Reached end on node 3
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 1.4 on node 3
Reached 2 on node 2
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4Reached 1 on node 5

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 1 on node 5
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:18:23,984[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 2
Reached end on node 4
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 5
Reached end on node 3
[[36m2023-11-29 03:18:26,821[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:18:28,039[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:18:28,040[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:18:28,040[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
[[36m2023-11-29 03:18:28,042[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 03:18:28,046[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <121/2280>] - Data(s): 7.550 (6.198) - Batch(s): 10.827 
(10.670) - AE Loss: 1422781.500 (1030141.250) - AE Rec Loss: 9.649 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 9.420 (6.198) - Batch(s): 10.842 
(10.670) - AE Loss: 3071030.750 (1030141.250) - AE Rec Loss: 20.827 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.754 (6.198) - Batch(s): 10.824 
(10.670) - AE Loss: 135907.906 (1030141.250) - AE Rec Loss: 0.922 (6.986) - Disc
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 4.199 (6.198) - Batch(s): 10.842 
(10.670) - AE Loss: 81600.031 (1030141.250) - AE Rec Loss: 0.553 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 6.676 (6.198) - Batch(s): 10.827 
(10.670) - AE Loss: 298741.500 (1030141.250) - AE Rec Loss: 2.026 (6.986) - Disc
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 2.819 (6.198) - Batch(s): 10.827 
(10.670) - AE Loss: 330189.500 (1030141.250) - AE Rec Loss: 2.239 (6.986) - Disc
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.566 
(5.618) - AE Loss: 373411.750 (735981.500) - AE Rec Loss: 2.532 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.568 
(5.618) - AE Loss: 496327.062 (735981.500) - AE Rec Loss: 3.366 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.569 
(5.618) - AE Loss: 89596.117 (735981.500) - AE Rec Loss: 0.608 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.566 
(5.618) - AE Loss: 144249.438 (735981.500) - AE Rec Loss: 0.978 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.568 
(5.618) - AE Loss: 128603.617 (735981.500) - AE Rec Loss: 0.872 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.563 
(5.618) - AE Loss: 171170.562 (735981.500) - AE Rec Loss: 1.161 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.46 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.353 
(4.531) - AE Loss: 356766.750 (597390.625) - AE Rec Loss: 2.419 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.353 
(4.531) - AE Loss: 214180.656 (597390.625) - AE Rec Loss: 1.453 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (2.111) - Batch(s): 2.356 
(4.531) - AE Loss: 145866.656 (597390.625) - AE Rec Loss: 0.989 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (2.111) - Batch(s): 2.356 
(4.531) - AE Loss: 230111.281 (597390.625) - AE Rec Loss: 1.561 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 1.620 (2.111) - Batch(s): 2.357 
(4.531) - AE Loss: 408270.344 (597390.625) - AE Rec Loss: 2.769 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.355 
(4.531) - AE Loss: 85863.125 (597390.625) - AE Rec Loss: 0.582 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.567 
(3.540) - AE Loss: 277728.125 (599354.625) - AE Rec Loss: 1.883 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.566 
(3.540) - AE Loss: 819874.250 (599354.625) - AE Rec Loss: 5.560 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.571 
(3.540) - AE Loss: 3042420.500 (599354.625) - AE Rec Loss: 20.633 (4.065) - Disc
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.564 
(3.540) - AE Loss: 142142.344 (599354.625) - AE Rec Loss: 0.964 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.568 
(3.540) - AE Loss: 115211.742 (599354.625) - AE Rec Loss: 0.781 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.568 
(3.540) - AE Loss: 123138.523 (599354.625) - AE Rec Loss: 0.835 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.753 
(2.979) - AE Loss: 1662671.000 (594055.250) - AE Rec Loss: 11.276 (4.029) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.754 
(2.979) - AE Loss: 1539297.625 (594055.250) - AE Rec Loss: 10.439 (4.029) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.189 (1.270) - Batch(s): 0.753 
(2.979) - AE Loss: 82543.281 (594055.250) - AE Rec Loss: 0.560 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.568 
(2.979) - AE Loss: 440919.875 (594055.250) - AE Rec Loss: 2.990 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.752 
(2.979) - AE Loss: 180010.422 (594055.250) - AE Rec Loss: 1.221 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.270) - Batch(s): 0.749 
(2.979) - AE Loss: 2224608.250 (594055.250) - AE Rec Loss: 15.087 (4.029) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.357 
(3.042) - AE Loss: 333360.375 (605202.250) - AE Rec Loss: 2.261 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 1.797 (1.122) - Batch(s): 3.357 
(3.042) - AE Loss: 141053.938 (605202.250) - AE Rec Loss: 0.957 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 235849.000 (605202.250) - AE Rec Loss: 1.599 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 1464217.000 (605202.250) - AE Rec Loss: 9.930 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 2.647 (1.122) - Batch(s): 3.359 
(3.042) - AE Loss: 176171.609 (605202.250) - AE Rec Loss: 1.195 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.359 
(3.042) - AE Loss: 1988594.000 (605202.250) - AE Rec Loss: 13.486 (4.104) - Disc
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.976) - Batch(s): 1.766 
(2.843) - AE Loss: 1485681.375 (618324.500) - AE Rec Loss: 10.075 (4.193) - Disc
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.411 
(2.843) - AE Loss: 109228.188 (618324.500) - AE Rec Loss: 0.741 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 1.204 (0.976) - Batch(s): 1.770 
(2.843) - AE Loss: 1825845.000 (618324.500) - AE Rec Loss: 12.382 (4.193) - Disc
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.976) - Batch(s): 1.412 
(2.843) - AE Loss: 99897.609 (618324.500) - AE Rec Loss: 0.677 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.976) - Batch(s): 1.412 
(2.843) - AE Loss: 1861615.500 (618324.500) - AE Rec Loss: 12.625 (4.193) - Disc
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.976) - Batch(s): 1.412 
(2.843) - AE Loss: 76346.531 (618324.500) - AE Rec Loss: 0.518 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.569 
(2.558) - AE Loss: 2870844.750 (614960.812) - AE Rec Loss: 19.469 (4.170) - Disc
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.001 (0.854) - Batch(s): 0.570 
(2.558) - AE Loss: 171631.891 (614960.812) - AE Rec Loss: 1.164 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.566 
(2.558) - AE Loss: 71288.688 (614960.812) - AE Rec Loss: 0.483 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.569 
(2.558) - AE Loss: 276316.625 (614960.812) - AE Rec Loss: 1.874 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.001 (0.854) - Batch(s): 0.566 
(2.558) - AE Loss: 138026.438 (614960.812) - AE Rec Loss: 0.936 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.569 
(2.558) - AE Loss: 322141.969 (614960.812) - AE Rec Loss: 2.185 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 78005.062 (622506.375) - AE Rec Loss: 0.529 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.442 
(2.545) - AE Loss: 1512858.250 (622506.375) - AE Rec Loss: 10.260 (4.222) - Disc
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 258314.969 (622506.375) - AE Rec Loss: 1.752 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 1.719 (0.782) - Batch(s): 2.443 
(2.545) - AE Loss: 1539249.250 (622506.375) - AE Rec Loss: 10.439 (4.222) - Disc
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.443 
(2.545) - AE Loss: 319487.438 (622506.375) - AE Rec Loss: 2.167 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.443 
(2.545) - AE Loss: 103510.719 (622506.375) - AE Rec Loss: 0.702 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.001 (0.723) - Batch(s): 2.932 
(2.572) - AE Loss: 175788.531 (640037.875) - AE Rec Loss: 1.192 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.579 
(2.572) - AE Loss: 1571653.500 (640037.875) - AE Rec Loss: 10.658 (4.341) - Disc
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.579 
(2.572) - AE Loss: 1504154.250 (640037.875) - AE Rec Loss: 10.201 (4.341) - Disc
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.580 
(2.572) - AE Loss: 171988.781 (640037.875) - AE Rec Loss: 1.166 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.580 
(2.572) - AE Loss: 257334.766 (640037.875) - AE Rec Loss: 1.745 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

bouta write to tb
[Epoch <000/100>: Step <130/2280>] - Data(s): 2.363 (0.723) - Batch(s): 2.937 
(2.572) - AE Loss: 280648.406 (640037.875) - AE Rec Loss: 1.903 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

wrote to tb
[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.239 
(2.446) - AE Loss: 314069.312 (634236.438) - AE Rec Loss: 2.130 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.95 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.567 
(2.446) - AE Loss: 1790619.500 (634236.438) - AE Rec Loss: 12.143 (4.301) - Disc
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.233 
(2.446) - AE Loss: 1518926.000 (634236.438) - AE Rec Loss: 10.301 (4.301) - Disc
Loss: 0.000 (0.000) - 7.95 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.233 
(2.446) - AE Loss: 128454.180 (634236.438) - AE Rec Loss: 0.871 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.657) - Batch(s): 1.235 
(2.446) - AE Loss: 493233.562 (634236.438) - AE Rec Loss: 3.345 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.95 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.236 
(2.446) - AE Loss: 392210.812 (634236.438) - AE Rec Loss: 2.660 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 184189.281 (608966.375) - AE Rec Loss: 1.249 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 226170.875 (608966.375) - AE Rec Loss: 1.534 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.759 
(2.389) - AE Loss: 135806.703 (608966.375) - AE Rec Loss: 0.921 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.760 
(2.389) - AE Loss: 314167.781 (608966.375) - AE Rec Loss: 2.131 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 201121.234 (608966.375) - AE Rec Loss: 1.364 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 113292.805 (608966.375) - AE Rec Loss: 0.768 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.514 (0.617) - Batch(s): 8.071 
(2.830) - AE Loss: 665147.375 (609563.000) - AE Rec Loss: 4.511 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.071 
(2.830) - AE Loss: 149667.578 (609563.000) - AE Rec Loss: 1.015 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 278630.688 (609563.000) - AE Rec Loss: 1.890 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 226722.016 (609563.000) - AE Rec Loss: 1.538 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.071 
(2.830) - AE Loss: 248439.984 (609563.000) - AE Rec Loss: 1.685 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 1532478.750 (609563.000) - AE Rec Loss: 10.393 (4.134) - Disc
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 395094.562 (634922.188) - AE Rec Loss: 2.679 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 1555176.000 (634922.188) - AE Rec Loss: 10.547 (4.306) - Disc
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 282972.688 (634922.188) - AE Rec Loss: 1.919 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 129129.367 (634922.188) - AE Rec Loss: 0.876 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.001 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 295681.188 (634922.188) - AE Rec Loss: 2.005 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.519 
(2.747) - AE Loss: 1829696.625 (634922.188) - AE Rec Loss: 12.408 (4.306) - Disc
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 152247.844 (661038.688) - AE Rec Loss: 1.032 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.001 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 3346071.000 (661038.688) - AE Rec Loss: 22.692 (4.483) - Disc
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 286780.594 (661038.688) - AE Rec Loss: 1.945 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 1656890.125 (661038.688) - AE Rec Loss: 11.237 (4.483) - Disc
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 258858.188 (661038.688) - AE Rec Loss: 1.755 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.001 (0.542) - Batch(s): 0.701 
(2.611) - AE Loss: 86669.219 (661038.688) - AE Rec Loss: 0.588 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.22 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 263893.750 (683722.688) - AE Rec Loss: 1.790 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 1520773.250 (683722.688) - AE Rec Loss: 10.313 (4.637) - Disc
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 681775.750 (683722.688) - AE Rec Loss: 4.624 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 1615795.375 (683722.688) - AE Rec Loss: 10.958 (4.637) - Disc
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 1747302.250 (683722.688) - AE Rec Loss: 11.850 (4.637) - Disc
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 2969951.750 (683722.688) - AE Rec Loss: 20.141 (4.637) - Disc
Loss: 0.000 (0.000) - 11.60 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 424605.562 (664769.750) - AE Rec Loss: 2.880 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 218411.969 (664769.750) - AE Rec Loss: 1.481 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 165445.469 (664769.750) - AE Rec Loss: 1.122 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 292310.781 (664769.750) - AE Rec Loss: 1.982 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 213376.641 (664769.750) - AE Rec Loss: 1.447 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 225189.125 (664769.750) - AE Rec Loss: 1.527 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.84 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 95615.766 (671219.875) - AE Rec Loss: 0.648 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 1357172.250 (671219.875) - AE Rec Loss: 9.204 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 1633731.375 (671219.875) - AE Rec Loss: 11.079 (4.552) - Disc
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 567791.688 (671219.875) - AE Rec Loss: 3.851 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 295172.969 (671219.875) - AE Rec Loss: 2.002 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.705 
(2.761) - AE Loss: 1593797.000 (671219.875) - AE Rec Loss: 10.809 (4.552) - Disc
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.567 
(2.646) - AE Loss: 359823.688 (656165.812) - AE Rec Loss: 2.440 (4.450) - Disc 
Loss: 0.000 (0.000) - 14.03 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.569 
(2.646) - AE Loss: 370814.562 (656165.812) - AE Rec Loss: 2.515 (4.450) - Disc 
Loss: 0.000 (0.000) - 14.03 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.001 (0.475) - Batch(s): 0.572 
(2.646) - AE Loss: 547536.125 (656165.812) - AE Rec Loss: 3.713 (4.450) - Disc 
Loss: 0.000 (0.000) - 14.03 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.001 (0.475) - Batch(s): 0.568 
(2.646) - AE Loss: 1870339.500 (656165.812) - AE Rec Loss: 12.684 (4.450) - Disc
Loss: 0.000 (0.000) - 14.04 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.001 (0.475) - Batch(s): 0.572 
(2.646) - AE Loss: 225613.828 (656165.812) - AE Rec Loss: 1.530 (4.450) - Disc 
Loss: 0.000 (0.000) - 14.03 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.001 (0.475) - Batch(s): 0.570 
(2.646) - AE Loss: 628211.000 (656165.812) - AE Rec Loss: 4.260 (4.450) - Disc 
Loss: 0.000 (0.000) - 14.03 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 76250.172 (641367.188) - AE Rec Loss: 0.517 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 255265.984 (641367.188) - AE Rec Loss: 1.731 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 859950.375 (641367.188) - AE Rec Loss: 5.832 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 241669.016 (641367.188) - AE Rec Loss: 1.639 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 111717.531 (641367.188) - AE Rec Loss: 0.758 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 134060.188 (641367.188) - AE Rec Loss: 0.909 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.45 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 03:19:25,954[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:19:29,112[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:19:31,303[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:19:31,318[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:19:31,331[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:19:31,346[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:19:31,357[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:19:31,368[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:19:31,383[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:19:31,393[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:19:32,094[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        


            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:21:27,390[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:27,450[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:27,524[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:27,591[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:27,621[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:27,625[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:21:29,543[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:29,618[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:29,660[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:29,741[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:29,757[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,124[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,132[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,265[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,330[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,392[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,420[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:21:31,248[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:21:31,249[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 03:21:31,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 03:21:31,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:21:31,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:21:31,254[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 0batch_size = 2, learning rate = 4.5e-06

Reached 5 on node 0
Reached end on node 0
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Preparing model 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 3
Reached 1.3 on node 5
Reached 1.4 on node 3
Reached 1.4 on node 5
Reached 2 on node 3
Reached 2 on node 5
Reached 3 on node 3
Reached 3 on node 5
Reached 5 on node 3
Reached 5 on node 5
Reached end on node 3
Reached end on node 5
=> Preparing opt_ae 
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 5 on node 1
Reached end on node 1Reached 2 on node 0

Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 2
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 3
Reached 1.4 on node 3Reached 3 on node 1

Reached 1.3 on node 5Reached 5 on node 1

Reached 1.3 on node 2Reached 2 on node 3Reached 1.4 on node 5


Reached 1.4 on node 2
Reached end on node 1
Reached 2 on node 5
Reached 2 on node 2
Reached 3 on node 3
Reached 3 on node 5
Reached 5 on node 3
Reached 3 on node 2Reached 5 on node 5

Reached end on node 3
Reached end on node 5Reached 5 on node 2

Reached end on node 2
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 1.3 on node 4Reached 2 on node 0

Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 0
Reached 5 on node 0
Reached 3 on node 4
Reached end on node 0
Reached 5 on node 4
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 1 on node 3
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 5Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 1 on node 4Reached 3 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 4
Reached end on node 2
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1 on node 2Reached 1.4 on node 3

Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:21:32,904[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 1
Reached end on node 3
[[36m2023-11-29 03:21:34,127[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:21:34,603[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:21:34,603[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:21:34,603[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:21:34,606[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:21:34,608[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <121/2280>] - Data(s): 4.379 (6.180) - Batch(s): 11.024 
(10.774) - AE Loss: 135907.906 (1030179.500) - AE Rec Loss: 0.922 (6.986) - Disc
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 4.363 (6.180) - Batch(s): 10.511 
(10.774) - AE Loss: 81466.641 (1030179.500) - AE Rec Loss: 0.552 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 8.555 (6.180) - Batch(s): 10.496 
(10.774) - AE Loss: 1422599.250 (1030179.500) - AE Rec Loss: 9.648 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 6.134 (6.180) - Batch(s): 10.555 
(10.774) - AE Loss: 298148.875 (1030179.500) - AE Rec Loss: 2.022 (6.986) - Disc
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 9.546 (6.180) - Batch(s): 11.046 
(10.774) - AE Loss: 3070819.750 (1030179.500) - AE Rec Loss: 20.825 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.34 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 3.048 (6.180) - Batch(s): 10.546 
(10.774) - AE Loss: 331472.125 (1030179.500) - AE Rec Loss: 2.248 (6.986) - Disc
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.090) - Batch(s): 0.566 
(5.669) - AE Loss: 496563.250 (736020.188) - AE Rec Loss: 3.368 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.567 
(5.669) - AE Loss: 90226.922 (736020.188) - AE Rec Loss: 0.612 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.090) - Batch(s): 0.565 
(5.669) - AE Loss: 373196.875 (736020.188) - AE Rec Loss: 2.531 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.562 
(5.669) - AE Loss: 143828.938 (736020.188) - AE Rec Loss: 0.975 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.561 
(5.669) - AE Loss: 170409.547 (736020.188) - AE Rec Loss: 1.156 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.090) - Batch(s): 0.565 
(5.669) - AE Loss: 128603.617 (736020.188) - AE Rec Loss: 0.872 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.658 
(4.999) - AE Loss: 144844.953 (597454.125) - AE Rec Loss: 0.982 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.657 
(4.999) - AE Loss: 85863.125 (597454.125) - AE Rec Loss: 0.582 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 1.358 (2.179) - Batch(s): 3.659 
(4.999) - AE Loss: 356711.875 (597454.125) - AE Rec Loss: 2.419 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.658 
(4.999) - AE Loss: 230304.141 (597454.125) - AE Rec Loss: 1.562 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.659 
(4.999) - AE Loss: 214651.578 (597454.125) - AE Rec Loss: 1.456 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 2.921 (2.179) - Batch(s): 3.659 
(4.999) - AE Loss: 408976.188 (597454.125) - AE Rec Loss: 2.774 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.565 
(3.890) - AE Loss: 277917.375 (599375.688) - AE Rec Loss: 1.885 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.566 
(3.890) - AE Loss: 3042299.500 (599375.688) - AE Rec Loss: 20.632 (4.065) - Disc
Loss: 0.000 (0.000) - 4.63 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (1.634) - Batch(s): 0.565 
(3.890) - AE Loss: 115193.070 (599375.688) - AE Rec Loss: 0.781 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.76 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.562 
(3.890) - AE Loss: 818325.938 (599375.688) - AE Rec Loss: 5.550 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.561 
(3.890) - AE Loss: 143004.625 (599375.688) - AE Rec Loss: 0.970 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.63 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (1.634) - Batch(s): 0.565 
(3.890) - AE Loss: 122849.094 (599375.688) - AE Rec Loss: 0.833 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.565 
(3.225) - AE Loss: 440808.344 (594076.562) - AE Rec Loss: 2.989 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.565 
(3.225) - AE Loss: 180540.516 (594076.562) - AE Rec Loss: 1.224 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.563 
(3.225) - AE Loss: 82954.219 (594076.562) - AE Rec Loss: 0.563 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.79 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.568 
(3.225) - AE Loss: 1539300.875 (594076.562) - AE Rec Loss: 10.439 (4.029) - Disc
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.561 
(3.225) - AE Loss: 2224936.000 (594076.562) - AE Rec Loss: 15.089 (4.029) - Disc
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.308) - Batch(s): 0.565 
(3.225) - AE Loss: 1662608.000 (594076.562) - AE Rec Loss: 11.275 (4.029) - Disc
Loss: 0.000 (0.000) - 4.79 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 2.780 (1.166) - Batch(s): 3.482 
(3.268) - AE Loss: 141536.203 (605218.250) - AE Rec Loss: 0.960 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.479 
(3.268) - AE Loss: 235394.359 (605218.250) - AE Rec Loss: 1.596 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 2.674 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 176428.953 (605218.250) - AE Rec Loss: 1.196 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.479 
(3.268) - AE Loss: 334053.312 (605218.250) - AE Rec Loss: 2.265 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 1464847.250 (605218.250) - AE Rec Loss: 9.934 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.482 
(3.268) - AE Loss: 1988567.125 (605218.250) - AE Rec Loss: 13.486 (4.104) - Disc
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.999) - Batch(s): 0.566 
(2.881) - AE Loss: 99717.812 (618269.562) - AE Rec Loss: 0.676 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.999) - Batch(s): 0.568 
(2.881) - AE Loss: 107237.445 (618269.562) - AE Rec Loss: 0.727 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.95 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.562 
(2.881) - AE Loss: 1485668.625 (618269.562) - AE Rec Loss: 10.075 (4.193) - Disc
Loss: 0.000 (0.000) - 5.95 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.563 
(2.881) - AE Loss: 1861367.000 (618269.562) - AE Rec Loss: 12.623 (4.193) - Disc
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.566 
(2.881) - AE Loss: 76031.672 (618269.562) - AE Rec Loss: 0.516 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.566 
(2.881) - AE Loss: 1825909.000 (618269.562) - AE Rec Loss: 12.383 (4.193) - Disc
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.568 
(2.592) - AE Loss: 171311.859 (614864.312) - AE Rec Loss: 1.162 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.564 
(2.592) - AE Loss: 137335.250 (614864.312) - AE Rec Loss: 0.931 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.563 
(2.592) - AE Loss: 71522.844 (614864.312) - AE Rec Loss: 0.485 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.09 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.566 
(2.592) - AE Loss: 321535.250 (614864.312) - AE Rec Loss: 2.181 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.23 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.566 
(2.592) - AE Loss: 2870773.250 (614864.312) - AE Rec Loss: 19.469 (4.170) - Disc
Loss: 0.000 (0.000) - 6.23 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.567 
(2.592) - AE Loss: 275339.844 (614864.312) - AE Rec Loss: 1.867 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.09 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.813 
(2.728) - AE Loss: 258048.453 (622381.062) - AE Rec Loss: 1.750 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 3.122 (0.815) - Batch(s): 3.813 
(2.728) - AE Loss: 1539793.375 (622381.062) - AE Rec Loss: 10.442 (4.221) - Disc
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.815 
(2.728) - AE Loss: 77753.375 (622381.062) - AE Rec Loss: 0.527 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.381 (0.815) - Batch(s): 3.815 
(2.728) - AE Loss: 104513.156 (622381.062) - AE Rec Loss: 0.709 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.553 (0.815) - Batch(s): 3.815 
(2.728) - AE Loss: 318467.719 (622381.062) - AE Rec Loss: 2.160 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.001 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 1512366.250 (622381.062) - AE Rec Loss: 10.256 (4.221) - Disc
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.001 (0.736) - Batch(s): 0.569 
(2.530) - AE Loss: 256949.328 (639872.938) - AE Rec Loss: 1.743 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.49 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.001 (0.736) - Batch(s): 0.845 
(2.530) - AE Loss: 175571.750 (639872.938) - AE Rec Loss: 1.191 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.566 
(2.530) - AE Loss: 1503795.500 (639872.938) - AE Rec Loss: 10.198 (4.339) - Disc
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.571 
(2.530) - AE Loss: 1571673.000 (639872.938) - AE Rec Loss: 10.659 (4.339) - Disc
Loss: 0.000 (0.000) - 7.36 m remaining

bouta write to tb
[Epoch <000/100>: Step <130/2280>] - Data(s): 0.285 (0.736) - Batch(s): 0.849 
(2.530) - AE Loss: 279048.188 (639872.938) - AE Rec Loss: 1.892 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.50 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.569 
(2.530) - AE Loss: 171587.031 (639872.938) - AE Rec Loss: 1.164 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

wrote to tb
[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 0.566 
(2.403) - AE Loss: 1790232.250 (634068.125) - AE Rec Loss: 12.141 (4.300) - Disc
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.179 
(2.403) - AE Loss: 1520881.250 (634068.125) - AE Rec Loss: 10.314 (4.300) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.176 
(2.403) - AE Loss: 129042.555 (634068.125) - AE Rec Loss: 0.875 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.181 
(2.403) - AE Loss: 313864.719 (634068.125) - AE Rec Loss: 2.129 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.669) - Batch(s): 1.179 
(2.403) - AE Loss: 493001.812 (634068.125) - AE Rec Loss: 3.343 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.66 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.179 
(2.403) - AE Loss: 392391.188 (634068.125) - AE Rec Loss: 2.661 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.66 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.733 
(2.264) - AE Loss: 183405.719 (608760.562) - AE Rec Loss: 1.244 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 225967.953 (608760.562) - AE Rec Loss: 1.532 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 112775.648 (608760.562) - AE Rec Loss: 0.765 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.84 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.738 
(2.264) - AE Loss: 135141.438 (608760.562) - AE Rec Loss: 0.916 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.735 
(2.264) - AE Loss: 312717.969 (608760.562) - AE Rec Loss: 2.121 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.84 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.735 
(2.264) - AE Loss: 201274.672 (608760.562) - AE Rec Loss: 1.365 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 238649.047 (609790.438) - AE Rec Loss: 1.618 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.84 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.417 
(2.357) - AE Loss: 666359.500 (609790.438) - AE Rec Loss: 4.519 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 260114.891 (609790.438) - AE Rec Loss: 1.764 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.84 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 1539781.125 (609790.438) - AE Rec Loss: 10.442 (4.135) - Disc
Loss: 0.000 (0.000) - 8.83 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.417 
(2.357) - AE Loss: 155233.500 (609790.438) - AE Rec Loss: 1.053 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.96 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.417 
(2.357) - AE Loss: 281500.750 (609790.438) - AE Rec Loss: 1.909 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.83 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.567 
(2.229) - AE Loss: 1554651.500 (635441.875) - AE Rec Loss: 10.543 (4.309) - Disc
Loss: 0.000 (0.000) - 9.09 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.568 
(2.229) - AE Loss: 136109.562 (635441.875) - AE Rec Loss: 0.923 (4.309) - Disc 
Loss: 0.000 (0.000) - 8.96 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.561 
(2.229) - AE Loss: 283350.250 (635441.875) - AE Rec Loss: 1.922 (4.309) - Disc 
Loss: 0.000 (0.000) - 8.96 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.565 
(2.229) - AE Loss: 296467.188 (635441.875) - AE Rec Loss: 2.011 (4.309) - Disc 
Loss: 0.000 (0.000) - 8.95 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.566 
(2.229) - AE Loss: 407264.125 (635441.875) - AE Rec Loss: 2.762 (4.309) - Disc 
Loss: 0.000 (0.000) - 9.09 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.566 
(2.229) - AE Loss: 1829743.750 (635441.875) - AE Rec Loss: 12.409 (4.309) - Disc
Loss: 0.000 (0.000) - 8.95 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.387 (0.555) - Batch(s): 6.005 
(2.481) - AE Loss: 85042.234 (661692.438) - AE Rec Loss: 0.577 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.51 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.004 
(2.481) - AE Loss: 3346023.000 (661692.438) - AE Rec Loss: 22.692 (4.487) - Disc
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.004 
(2.481) - AE Loss: 156512.062 (661692.438) - AE Rec Loss: 1.061 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.64 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.004 
(2.481) - AE Loss: 1655371.375 (661692.438) - AE Rec Loss: 11.226 (4.487) - Disc
Loss: 0.000 (0.000) - 10.51 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 258642.641 (661692.438) - AE Rec Loss: 1.754 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 5.319 (0.555) - Batch(s): 6.004 
(2.481) - AE Loss: 291046.938 (661692.438) - AE Rec Loss: 1.974 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.566 
(2.361) - AE Loss: 1517941.250 (684229.250) - AE Rec Loss: 10.294 (4.640) - Disc
Loss: 0.000 (0.000) - 10.75 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.566 
(2.361) - AE Loss: 2970276.000 (684229.250) - AE Rec Loss: 20.143 (4.640) - Disc
Loss: 0.000 (0.000) - 10.61 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.569 
(2.361) - AE Loss: 1614648.750 (684229.250) - AE Rec Loss: 10.950 (4.640) - Disc
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.568 
(2.361) - AE Loss: 256581.031 (684229.250) - AE Rec Loss: 1.740 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.74 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.521) - Batch(s): 0.567 
(2.361) - AE Loss: 1744254.750 (684229.250) - AE Rec Loss: 11.829 (4.640) - Disc
Loss: 0.000 (0.000) - 10.61 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.563 
(2.361) - AE Loss: 679283.000 (684229.250) - AE Rec Loss: 4.607 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.564 
(2.255) - AE Loss: 217891.594 (665083.438) - AE Rec Loss: 1.478 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.73 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.568 
(2.255) - AE Loss: 210729.172 (665083.438) - AE Rec Loss: 1.429 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.72 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.567 
(2.255) - AE Loss: 218874.438 (665083.438) - AE Rec Loss: 1.484 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.86 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.566 
(2.255) - AE Loss: 291904.625 (665083.438) - AE Rec Loss: 1.980 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.72 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.569 
(2.255) - AE Loss: 420607.000 (665083.438) - AE Rec Loss: 2.852 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.73 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.568 
(2.255) - AE Loss: 162630.188 (665083.438) - AE Rec Loss: 1.103 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.85 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.482) - Batch(s): 4.427 
(2.376) - AE Loss: 1355827.625 (671393.250) - AE Rec Loss: 9.195 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.83 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.482) - Batch(s): 4.427 
(2.376) - AE Loss: 293972.906 (671393.250) - AE Rec Loss: 1.994 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.95 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.482) - Batch(s): 4.427 
(2.376) - AE Loss: 565110.875 (671393.250) - AE Rec Loss: 3.832 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.94 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.482) - Batch(s): 4.428 
(2.376) - AE Loss: 92606.617 (671393.250) - AE Rec Loss: 0.628 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.83 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 3.728 (0.482) - Batch(s): 4.428 
(2.376) - AE Loss: 1589251.250 (671393.250) - AE Rec Loss: 10.778 (4.553) - Disc
Loss: 0.000 (0.000) - 11.81 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.001 (0.482) - Batch(s): 4.428 
(2.376) - AE Loss: 1633533.125 (671393.250) - AE Rec Loss: 11.078 (4.553) - Disc
Loss: 0.000 (0.000) - 11.81 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.569 
(2.281) - AE Loss: 224218.500 (656303.375) - AE Rec Loss: 1.521 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.92 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.567 
(2.281) - AE Loss: 547126.125 (656303.375) - AE Rec Loss: 3.710 (4.451) - Disc 
Loss: 0.000 (0.000) - 12.04 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.567 
(2.281) - AE Loss: 370800.500 (656303.375) - AE Rec Loss: 2.515 (4.451) - Disc 
Loss: 0.000 (0.000) - 12.04 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.563 
(2.281) - AE Loss: 356741.750 (656303.375) - AE Rec Loss: 2.419 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.92 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.565 
(2.281) - AE Loss: 1873654.125 (656303.375) - AE Rec Loss: 12.707 (4.451) - Disc
Loss: 0.000 (0.000) - 11.91 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.568 
(2.281) - AE Loss: 630004.625 (656303.375) - AE Rec Loss: 4.272 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.91 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.434) - Batch(s): 0.569 
(2.195) - AE Loss: 258269.891 (641518.812) - AE Rec Loss: 1.752 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.567 
(2.195) - AE Loss: 113257.414 (641518.812) - AE Rec Loss: 0.768 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.14 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.434) - Batch(s): 0.568 
(2.195) - AE Loss: 133681.344 (641518.812) - AE Rec Loss: 0.907 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.00 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.564 
(2.195) - AE Loss: 859155.750 (641518.812) - AE Rec Loss: 5.827 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.568 
(2.195) - AE Loss: 74779.141 (641518.812) - AE Rec Loss: 0.507 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.13 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.434) - Batch(s): 0.566 
(2.195) - AE Loss: 243044.203 (641518.812) - AE Rec Loss: 1.648 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.01 m remaining

bouta write to tb
wrote to tb
attempting to save
[[36m2023-11-29 03:22:23,407[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:22:27,480[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:22:27,705[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:22:27,729[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:22:27,747[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:22:27,766[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:22:27,784[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:22:27,802[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:22:27,820[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:22:27,841[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:22:29,806[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:22:31,746[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:22:35,740[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:22:35,749[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 03:22:40,062[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:22:40,062[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 03:22:40,062[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 03:22:40,086[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 322632.219 (647573.188) - AE Rec Loss: 2.188 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.54 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 282120.781 (647573.188) - AE Rec Loss: 1.913 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.66 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 1.743 (0.420) - Batch(s): 18.220 
(2.889) - AE Loss: 100036.562 (647573.188) - AE Rec Loss: 0.678 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.53 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.677 
(2.889) - AE Loss: 450832.094 (647573.188) - AE Rec Loss: 3.057 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.66 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 99805.922 (647573.188) - AE Rec Loss: 0.677 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.54 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 117041.414 (647573.188) - AE Rec Loss: 0.794 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.53 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.569 
(2.783) - AE Loss: 202859.531 (649543.438) - AE Rec Loss: 1.376 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.60 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.567 
(2.783) - AE Loss: 1494608.875 (649543.438) - AE Rec Loss: 10.136 (4.405) - Disc
Loss: 0.000 (0.000) - 16.72 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.565 
(2.783) - AE Loss: 226170.656 (649543.438) - AE Rec Loss: 1.534 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.59 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.567 
(2.783) - AE Loss: 199187.625 (649543.438) - AE Rec Loss: 1.351 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.59 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (0.401) - Batch(s): 0.568 
(2.783) - AE Loss: 337530.125 (649543.438) - AE Rec Loss: 2.289 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.71 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.562 
(2.783) - AE Loss: 203400.125 (649543.438) - AE Rec Loss: 1.379 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.60 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (0.383) - Batch(s): 0.568 
(2.687) - AE Loss: 545124.750 (662540.250) - AE Rec Loss: 3.697 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.77 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (0.383) - Batch(s): 0.565 
(2.687) - AE Loss: 338415.125 (662540.250) - AE Rec Loss: 2.295 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.65 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.563 
(2.687) - AE Loss: 1486215.000 (662540.250) - AE Rec Loss: 10.079 (4.493) - Disc
Loss: 0.000 (0.000) - 16.66 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (0.383) - Batch(s): 0.568 
(2.687) - AE Loss: 164169.516 (662540.250) - AE Rec Loss: 1.113 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.64 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.568 
(2.687) - AE Loss: 3146175.000 (662540.250) - AE Rec Loss: 21.336 (4.493) - Disc
Loss: 0.000 (0.000) - 16.78 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.571 
(2.687) - AE Loss: 1451855.500 (662540.250) - AE Rec Loss: 9.846 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.66 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 73640.445 (660221.438) - AE Rec Loss: 0.499 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.74 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 62563.043 (660221.438) - AE Rec Loss: 0.424 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.86 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 80764.414 (660221.438) - AE Rec Loss: 0.548 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.85 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 128148.406 (660221.438) - AE Rec Loss: 0.869 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.74 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 253364.422 (660221.438) - AE Rec Loss: 1.718 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.73 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (0.367) - Batch(s): 0.679 
(2.603) - AE Loss: 3187494.500 (660221.438) - AE Rec Loss: 21.617 (4.477) - Disc
Loss: 0.000 (0.000) - 16.73 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.568 
(2.522) - AE Loss: 91572.375 (650157.000) - AE Rec Loss: 0.621 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.91 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.565 
(2.522) - AE Loss: 295848.250 (650157.000) - AE Rec Loss: 2.006 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.80 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.571 
(2.522) - AE Loss: 138644.062 (650157.000) - AE Rec Loss: 0.940 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.80 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.568 
(2.522) - AE Loss: 384860.656 (650157.000) - AE Rec Loss: 2.610 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.91 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.568 
(2.522) - AE Loss: 240757.469 (650157.000) - AE Rec Loss: 1.633 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.78 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.565 
(2.522) - AE Loss: 605769.438 (650157.000) - AE Rec Loss: 4.108 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.78 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.572 
(2.447) - AE Loss: 750498.375 (666274.125) - AE Rec Loss: 5.090 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.85 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.568 
(2.447) - AE Loss: 3125939.750 (666274.125) - AE Rec Loss: 21.199 (4.518) - Disc
Loss: 0.000 (0.000) - 16.97 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.571 
(2.447) - AE Loss: 74606.375 (666274.125) - AE Rec Loss: 0.506 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.96 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.569 
(2.447) - AE Loss: 459405.875 (666274.125) - AE Rec Loss: 3.116 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.84 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.568 
(2.447) - AE Loss: 2478763.000 (666274.125) - AE Rec Loss: 16.810 (4.518) - Disc
Loss: 0.000 (0.000) - 16.84 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.565 
(2.447) - AE Loss: 193405.656 (666274.125) - AE Rec Loss: 1.312 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.85 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 178294.281 (659674.688) - AE Rec Loss: 1.209 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.93 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 937324.000 (659674.688) - AE Rec Loss: 6.357 (4.474) - Disc 
Loss: 0.000 (0.000) - 17.05 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 1474382.250 (659674.688) - AE Rec Loss: 9.999 (4.474) - Disc 
Loss: 0.000 (0.000) - 17.04 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 200368.969 (659674.688) - AE Rec Loss: 1.359 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.92 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 194078.219 (659674.688) - AE Rec Loss: 1.316 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.92 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.685 
(2.381) - AE Loss: 180515.312 (659674.688) - AE Rec Loss: 1.224 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.93 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:23:02,911[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,077[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,101[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,254[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,270[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,402[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:23:05,218[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:05,238[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:05,408[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:05,426[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:05,575[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:05,738[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 03:23:05,796[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:05,825[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,006[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,026[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,155[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,275[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 03:23:06,711[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:23:06,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:23:06,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 03:23:06,714[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:23:06,715[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 03:23:06,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
Reached 3 on node 0
len(valid_dataset) = 4
Reached 5 on node 0
Reached end on node 0
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
=> Preparing opt_disc 
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 3Reached 1.25 on node 5

devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1 on node 4
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:24:35,891[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:35,956[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,102[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,165[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,185[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,259[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:24:38,032[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,064[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,242[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,303[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,356[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,388[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:38,636[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:38,651[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:38,866[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:38,965[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,018[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,022[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:24:39,800[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,801[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
[[36m2023-11-29 03:24:39,803[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
[[36m2023-11-29 03:24:39,804[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Running in inference mode: False
[[36m2023-11-29 03:24:39,805[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,805[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Running in inference mode: False
=> Instantiating the optimizer 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
len(train_dataset) = 54706
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataset) = 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:26:08,100[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:08,111[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:08,142[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:08,190[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:08,283[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:08,335[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:26:10,287[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:10,305[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:10,314[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:10,354[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:10,438[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:10,462[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:10,919[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:10,967[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,092[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,104[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,158[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,165[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 03:26:11,958[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 03:26:11,962[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:26:11,963[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:26:11,963[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
[[36m2023-11-29 03:26:11,967[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataset) = 4
[[36m2023-11-29 03:26:11,967[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Preparing model 
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 1.3 on node 4Reached 5 on node 1

=> Preparing opt_ae 
Reached 1.4 on node 4
Reached end on node 1
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
=> Preparing opt_ae 
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 5
=> Preparing criterion 
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 4
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.3 on node 1
Reached 1.4 on node 2
Reached 1.4 on node 1
Reached 1.3 on node 0Reached 2 on node 2
Reached 2 on node 1

Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 2Reached 3 on node 1

Reached 5 on node 2
Reached 5 on node 1Reached 3 on node 0

Reached end on node 2
Reached 5 on node 0
Reached end on node 1
Reached end on node 0
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.3 on node 3
Reached 3 on node 4Reached 1.4 on node 3

Reached 5 on node 4
Reached 2 on node 3
Reached end on node 4
Reached 1.3 on node 5
Reached 3 on node 3Reached 1.4 on node 5

Reached 5 on node 3
Reached 2 on node 5
Reached end on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 1 on node 5Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 1 on node 5Reached 2 on node 4

Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached end on node 3Reached 2 on node 5

Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3Reached 1 on node 4

Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3Reached 1 on node 4

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:26:13,605[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
[[36m2023-11-29 03:26:16,189[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 03:26:17,312[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
Loaded from checkpoint
[[36m2023-11-29 03:26:17,312[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:26:17,312[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:26:17,318[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:26:17,319[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <141/2280>] - Data(s): 4.029 (5.639) - Batch(s): 11.407 
(11.231) - AE Loss: 451182.500 (768796.000) - AE Rec Loss: 3.060 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.459 (5.639) - Batch(s): 11.411 
(11.231) - AE Loss: 99478.008 (768796.000) - AE Rec Loss: 0.675 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 7.323 (5.639) - Batch(s): 11.411 
(11.231) - AE Loss: 282647.875 (768796.000) - AE Rec Loss: 1.917 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.661 (5.639) - Batch(s): 11.405 
(11.231) - AE Loss: 99713.469 (768796.000) - AE Rec Loss: 0.676 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.464 (5.639) - Batch(s): 11.410 
(11.231) - AE Loss: 322756.688 (768796.000) - AE Rec Loss: 2.189 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 4.374 (5.639) - Batch(s): 11.410 
(11.231) - AE Loss: 116765.680 (768796.000) - AE Rec Loss: 0.792 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.565 
(5.897) - AE Loss: 187832.438 (725867.312) - AE Rec Loss: 1.274 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.562 
(5.897) - AE Loss: 219724.188 (725867.312) - AE Rec Loss: 1.490 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.820) - Batch(s): 0.564 
(5.897) - AE Loss: 1491081.375 (725867.312) - AE Rec Loss: 10.112 (4.923) - Disc
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.559 
(5.897) - AE Loss: 198655.641 (725867.312) - AE Rec Loss: 1.347 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.564 
(5.897) - AE Loss: 322963.562 (725867.312) - AE Rec Loss: 2.190 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.565 
(5.897) - AE Loss: 190016.578 (725867.312) - AE Rec Loss: 1.289 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.954 
(4.250) - AE Loss: 3145777.500 (797648.438) - AE Rec Loss: 21.334 (5.409) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.063 (1.904) - Batch(s): 0.955 
(4.250) - AE Loss: 531907.750 (797648.438) - AE Rec Loss: 3.607 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.34 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.954 
(4.250) - AE Loss: 1455485.000 (797648.438) - AE Rec Loss: 9.871 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.953 
(4.250) - AE Loss: 153522.469 (797648.438) - AE Rec Loss: 1.041 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.34 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.955 
(4.250) - AE Loss: 1480085.250 (797648.438) - AE Rec Loss: 10.037 (5.409) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.955 
(4.250) - AE Loss: 337860.906 (797648.438) - AE Rec Loss: 2.291 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.566 
(3.328) - AE Loss: 63789.461 (749024.438) - AE Rec Loss: 0.433 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.564 
(3.328) - AE Loss: 78611.477 (749024.438) - AE Rec Loss: 0.533 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.560 
(3.328) - AE Loss: 126351.555 (749024.438) - AE Rec Loss: 0.857 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.567 
(3.328) - AE Loss: 249655.500 (749024.438) - AE Rec Loss: 1.693 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.568 
(3.328) - AE Loss: 72340.281 (749024.438) - AE Rec Loss: 0.491 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.563 
(3.328) - AE Loss: 3185336.250 (749024.438) - AE Rec Loss: 21.602 (5.080) - Disc
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.196 
(3.349) - AE Loss: 590836.312 (679969.562) - AE Rec Loss: 4.007 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.196 
(3.349) - AE Loss: 140333.719 (679969.562) - AE Rec Loss: 0.952 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.547 
(3.349) - AE Loss: 296663.250 (679969.562) - AE Rec Loss: 2.012 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.196 
(3.349) - AE Loss: 228460.906 (679969.562) - AE Rec Loss: 1.549 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.196 
(3.349) - AE Loss: 379032.250 (679969.562) - AE Rec Loss: 2.570 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 2.983 (1.192) - Batch(s): 3.554 
(3.349) - AE Loss: 89805.523 (679969.562) - AE Rec Loss: 0.609 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.294 
(3.007) - AE Loss: 186186.812 (744299.438) - AE Rec Loss: 1.263 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.295 
(3.007) - AE Loss: 3125563.250 (744299.438) - AE Rec Loss: 21.197 (5.048) - Disc
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.294 
(3.007) - AE Loss: 68915.969 (744299.438) - AE Rec Loss: 0.467 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.294 
(3.007) - AE Loss: 2472211.500 (744299.438) - AE Rec Loss: 16.766 (5.048) - Disc
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.296 
(3.007) - AE Loss: 446312.375 (744299.438) - AE Rec Loss: 3.027 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.296 
(3.007) - AE Loss: 745298.375 (744299.438) - AE Rec Loss: 5.054 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 942463.438 (707155.875) - AE Rec Loss: 6.391 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 172744.500 (707155.875) - AE Rec Loss: 1.171 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.293 
(2.766) - AE Loss: 189869.344 (707155.875) - AE Rec Loss: 1.288 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 167732.656 (707155.875) - AE Rec Loss: 1.138 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 190118.047 (707155.875) - AE Rec Loss: 1.289 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 1469665.250 (707155.875) - AE Rec Loss: 9.967 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.564 
(2.491) - AE Loss: 514837.906 (679896.938) - AE Rec Loss: 3.491 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.001 (0.768) - Batch(s): 0.566 
(2.491) - AE Loss: 212723.812 (679896.938) - AE Rec Loss: 1.443 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.563 
(2.491) - AE Loss: 237984.031 (679896.938) - AE Rec Loss: 1.614 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.561 
(2.491) - AE Loss: 277259.094 (679896.938) - AE Rec Loss: 1.880 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.566 
(2.491) - AE Loss: 120480.203 (679896.938) - AE Rec Loss: 0.817 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.566 
(2.491) - AE Loss: 120131.336 (679896.938) - AE Rec Loss: 0.815 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.574 
(3.167) - AE Loss: 239289.531 (656988.000) - AE Rec Loss: 1.623 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.573 
(3.167) - AE Loss: 94819.484 (656988.000) - AE Rec Loss: 0.643 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.574 
(3.167) - AE Loss: 351142.812 (656988.000) - AE Rec Loss: 2.381 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.573 
(3.167) - AE Loss: 259331.781 (656988.000) - AE Rec Loss: 1.759 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.573 
(3.167) - AE Loss: 343953.875 (656988.000) - AE Rec Loss: 2.333 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.574 
(3.167) - AE Loss: 405803.812 (656988.000) - AE Rec Loss: 2.752 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.564 
(2.907) - AE Loss: 346457.500 (685899.125) - AE Rec Loss: 2.350 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.563 
(2.907) - AE Loss: 228693.172 (685899.125) - AE Rec Loss: 1.551 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.566 
(2.907) - AE Loss: 319730.938 (685899.125) - AE Rec Loss: 2.168 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.561 
(2.907) - AE Loss: 1599244.250 (685899.125) - AE Rec Loss: 10.846 (4.652) - Disc
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.566 
(2.907) - AE Loss: 227082.062 (685899.125) - AE Rec Loss: 1.540 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.566 
(2.907) - AE Loss: 1780660.500 (685899.125) - AE Rec Loss: 12.076 (4.652) - Disc
Loss: 0.000 (0.000) - 7.39 m remaining

bouta write to tb
wrote to tb
[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.253 
(2.751) - AE Loss: 1709183.000 (687129.375) - AE Rec Loss: 11.591 (4.660) - Disc
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 1.259 
(2.751) - AE Loss: 330235.094 (687129.375) - AE Rec Loss: 2.240 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 1.256 
(2.751) - AE Loss: 508124.438 (687129.375) - AE Rec Loss: 3.446 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 1.258 
(2.751) - AE Loss: 92266.133 (687129.375) - AE Rec Loss: 0.626 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 0.564 
(2.751) - AE Loss: 82491.148 (687129.375) - AE Rec Loss: 0.559 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 1.259 
(2.751) - AE Loss: 324225.688 (687129.375) - AE Rec Loss: 2.199 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.715 
(2.665) - AE Loss: 355963.562 (666986.688) - AE Rec Loss: 2.414 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.639) - Batch(s): 1.718 
(2.665) - AE Loss: 266265.156 (666986.688) - AE Rec Loss: 1.806 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.717 
(2.665) - AE Loss: 511535.812 (666986.688) - AE Rec Loss: 3.469 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.639) - Batch(s): 1.717 
(2.665) - AE Loss: 321859.000 (666986.688) - AE Rec Loss: 2.183 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.639) - Batch(s): 1.718 
(2.665) - AE Loss: 234111.016 (666986.688) - AE Rec Loss: 1.588 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.639) - Batch(s): 1.718 
(2.665) - AE Loss: 444061.938 (666986.688) - AE Rec Loss: 3.011 (4.523) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.563 
(2.504) - AE Loss: 309292.500 (638132.938) - AE Rec Loss: 2.098 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.567 
(2.504) - AE Loss: 397050.625 (638132.938) - AE Rec Loss: 2.693 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.567 
(2.504) - AE Loss: 474431.656 (638132.938) - AE Rec Loss: 3.217 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.567 
(2.504) - AE Loss: 347334.281 (638132.938) - AE Rec Loss: 2.356 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.564 
(2.504) - AE Loss: 126727.219 (638132.938) - AE Rec Loss: 0.859 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.567 
(2.504) - AE Loss: 70899.641 (638132.938) - AE Rec Loss: 0.481 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.16 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.563 
(2.365) - AE Loss: 236340.594 (641162.188) - AE Rec Loss: 1.603 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.568 
(2.365) - AE Loss: 224840.766 (641162.188) - AE Rec Loss: 1.525 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.565 
(2.365) - AE Loss: 1512036.500 (641162.188) - AE Rec Loss: 10.254 (4.348) - Disc
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.568 
(2.365) - AE Loss: 1732909.250 (641162.188) - AE Rec Loss: 11.752 (4.348) - Disc
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.567 
(2.365) - AE Loss: 181617.844 (641162.188) - AE Rec Loss: 1.232 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.001 (0.548) - Batch(s): 0.568 
(2.365) - AE Loss: 178460.906 (641162.188) - AE Rec Loss: 1.210 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 65126.922 (640587.750) - AE Rec Loss: 0.442 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 1502579.000 (640587.750) - AE Rec Loss: 10.190 (4.344) - Disc
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.001 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 131101.875 (640587.750) - AE Rec Loss: 0.889 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.113 
(2.482) - AE Loss: 98694.234 (640587.750) - AE Rec Loss: 0.669 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.113 
(2.482) - AE Loss: 315759.500 (640587.750) - AE Rec Loss: 2.141 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 2019540.500 (640587.750) - AE Rec Loss: 13.696 (4.344) - Disc
Loss: 0.000 (0.000) - 9.18 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 69260.828 (656661.625) - AE Rec Loss: 0.470 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 580750.625 (656661.625) - AE Rec Loss: 3.938 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 173202.094 (656661.625) - AE Rec Loss: 1.175 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 202014.828 (656661.625) - AE Rec Loss: 1.370 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 3540081.000 (656661.625) - AE Rec Loss: 24.008 (4.453) - Disc
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 246666.031 (656661.625) - AE Rec Loss: 1.673 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.471 
(2.760) - AE Loss: 107654.398 (641788.875) - AE Rec Loss: 0.730 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 276111.969 (641788.875) - AE Rec Loss: 1.873 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 252708.938 (641788.875) - AE Rec Loss: 1.714 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 93280.367 (641788.875) - AE Rec Loss: 0.633 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 163851.531 (641788.875) - AE Rec Loss: 1.111 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 1416872.000 (641788.875) - AE Rec Loss: 9.609 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.45 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 517433.938 (634833.750) - AE Rec Loss: 3.509 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.84 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 195671.359 (634833.750) - AE Rec Loss: 1.327 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.84 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 130866.438 (634833.750) - AE Rec Loss: 0.887 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.84 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 171133.750 (634833.750) - AE Rec Loss: 1.161 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.83 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 126362.070 (634833.750) - AE Rec Loss: 0.857 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.84 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.426 
(2.964) - AE Loss: 1517358.000 (634833.750) - AE Rec Loss: 10.290 (4.305) - Disc
Loss: 0.000 (0.000) - 12.84 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.567 
(2.839) - AE Loss: 277689.188 (628641.625) - AE Rec Loss: 1.883 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.563 
(2.839) - AE Loss: 926865.875 (628641.625) - AE Rec Loss: 6.286 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.568 
(2.839) - AE Loss: 207526.500 (628641.625) - AE Rec Loss: 1.407 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.001 (0.580) - Batch(s): 0.568 
(2.839) - AE Loss: 500025.750 (628641.625) - AE Rec Loss: 3.391 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.565 
(2.839) - AE Loss: 234792.766 (628641.625) - AE Rec Loss: 1.592 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.567 
(2.839) - AE Loss: 248304.016 (628641.625) - AE Rec Loss: 1.684 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.95 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 1349276.250 (622898.375) - AE Rec Loss: 9.150 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.001 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 116622.578 (622898.375) - AE Rec Loss: 0.791 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 209212.547 (622898.375) - AE Rec Loss: 1.419 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 84235.922 (622898.375) - AE Rec Loss: 0.571 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 113579.852 (622898.375) - AE Rec Loss: 0.770 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

bouta write to tb
[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 118468.734 (622898.375) - AE Rec Loss: 0.803 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.24 m remaining

wrote to tb
attempting to save
[[36m2023-11-29 03:27:18,451[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:27:25,161[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:27:25,410[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:27:25,424[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:27:25,429[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:27:25,433[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:27:25,438[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:27:25,442[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:27:25,447[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:27:25,451[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:29:13,284[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:13,286[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:13,617[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:13,623[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:13,629[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:13,647[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:29:15,421[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:15,655[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:15,784[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:15,790[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:15,806[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:15,933[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 03:29:16,155[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:16,279[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:16,377[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:16,404[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:16,435[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:16,650[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:29:17,431[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:29:17,431[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
[[36m2023-11-29 03:29:17,436[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
[[36m2023-11-29 03:29:17,439[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:29:17,439[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:29:17,439[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3Reached 3 on node 0

Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5Reached 5 on node 0

Reached end on node 0
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 2

Reached 1.4 on node 3Reached 1.4 on node 2

Reached 2 on node 3
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 3
Reached 5 on node 2
Reached 5 on node 3
Reached end on node 2
Reached end on node 3Reached 1.3 on node 0Reached 1.3 on node 4


Reached 1.3 on node 5Reached 1.4 on node 0

Reached 1.4 on node 4
Reached 1.4 on node 5
Reached 2 on node 0
Reached 2 on node 4
Reached 2 on node 5
Reached 3 on node 0Reached 3 on node 5Reached 3 on node 4


Reached 5 on node 5Reached 5 on node 0

Reached 5 on node 4
Reached end on node 5
Reached end on node 0
Reached end on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 4Reached 1.4 on node 5

Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1.4 on node 2Reached 2 on node 5

Reached 2 on node 2
Reached 3 on node 5
Reached 3 on node 5Reached 1 on node 4

Reached 3 on node 2Reached 3 on node 5

Reached 3 on node 5
Reached 3 on node 2
Reached 3 on node 5
Reached 3 on node 2Reached 1.4 on node 4
Reached 5 on node 5

Reached 3 on node 2Reached 2 on node 4

Reached 3 on node 2
Reached 3 on node 4Reached 5 on node 2

Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 5
Reached end on node 3
Reached end on node 4
Reached end on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 0Reached 1 on node 5

Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 1.4 on node 0Reached 5 on node 5

Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 5
Reached end on node 0
[[36m2023-11-29 03:29:19,141[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
[[36m2023-11-29 03:29:20,643[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:29:21,156[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:29:21,157[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:29:21,157[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:29:21,160[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:29:21,165[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <141/2280>] - Data(s): 4.240 (5.420) - Batch(s): 9.544 
(9.671) - AE Loss: 451182.500 (768541.250) - AE Rec Loss: 3.060 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 7.760 (5.420) - Batch(s): 9.738 
(9.671) - AE Loss: 282132.000 (768541.250) - AE Rec Loss: 1.913 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.572 (5.420) - Batch(s): 9.646 
(9.671) - AE Loss: 99361.773 (768541.250) - AE Rec Loss: 0.674 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.194 (5.420) - Batch(s): 9.642 
(9.671) - AE Loss: 322355.625 (768541.250) - AE Rec Loss: 2.186 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.49 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.608 (5.420) - Batch(s): 9.858 
(9.671) - AE Loss: 100240.422 (768541.250) - AE Rec Loss: 0.680 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 4.043 (5.420) - Batch(s): 9.551 
(9.671) - AE Loss: 117366.648 (768541.250) - AE Rec Loss: 0.796 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.710) - Batch(s): 1.196 
(5.406) - AE Loss: 190508.062 (725758.812) - AE Rec Loss: 1.292 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.194 
(5.406) - AE Loss: 219937.656 (725758.812) - AE Rec Loss: 1.492 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 0.564 
(5.406) - AE Loss: 322963.562 (725758.812) - AE Rec Loss: 2.190 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.194 
(5.406) - AE Loss: 1491010.375 (725758.812) - AE Rec Loss: 10.112 (4.922) - Disc
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.192 
(5.406) - AE Loss: 198898.953 (725758.812) - AE Rec Loss: 1.349 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.198 
(5.406) - AE Loss: 187527.984 (725758.812) - AE Rec Loss: 1.272 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <143/2280>] - Data(s): 1.156 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 337878.156 (797599.125) - AE Rec Loss: 2.291 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 3145711.750 (797599.125) - AE Rec Loss: 21.333 (5.409) - Disc
Loss: 0.000 (0.000) - 3.58 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.912) - Batch(s): 2.269 
(4.560) - AE Loss: 531907.750 (797599.125) - AE Rec Loss: 3.607 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 1455372.625 (797599.125) - AE Rec Loss: 9.870 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 153308.688 (797599.125) - AE Rec Loss: 1.040 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 1480931.250 (797599.125) - AE Rec Loss: 10.043 (5.409) - Disc
Loss: 0.000 (0.000) - 3.61 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.100 
(3.684) - AE Loss: 62654.676 (749023.312) - AE Rec Loss: 0.425 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.100 
(3.684) - AE Loss: 3185238.250 (749023.312) - AE Rec Loss: 21.601 (5.080) - Disc
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 0.563 
(3.684) - AE Loss: 78625.859 (749023.312) - AE Rec Loss: 0.533 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (1.434) - Batch(s): 1.103 
(3.684) - AE Loss: 72376.492 (749023.312) - AE Rec Loss: 0.491 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (1.434) - Batch(s): 1.102 
(3.684) - AE Loss: 250316.469 (749023.312) - AE Rec Loss: 1.698 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.098 
(3.684) - AE Loss: 125851.688 (749023.312) - AE Rec Loss: 0.853 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.209 (1.151) - Batch(s): 1.321 
(3.198) - AE Loss: 89866.547 (679972.188) - AE Rec Loss: 0.609 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.322 
(3.198) - AE Loss: 227895.312 (679972.188) - AE Rec Loss: 1.546 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.318 
(3.198) - AE Loss: 296180.312 (679972.188) - AE Rec Loss: 2.009 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.321 
(3.198) - AE Loss: 590976.312 (679972.188) - AE Rec Loss: 4.008 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.18 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.001 (1.151) - Batch(s): 0.565 
(3.198) - AE Loss: 379175.750 (679972.188) - AE Rec Loss: 2.571 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.001 (1.151) - Batch(s): 1.324 
(3.198) - AE Loss: 141145.016 (679972.188) - AE Rec Loss: 0.957 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.241 
(3.029) - AE Loss: 3125726.250 (744320.875) - AE Rec Loss: 21.198 (5.048) - Disc
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.241 
(3.029) - AE Loss: 746069.188 (744320.875) - AE Rec Loss: 5.060 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.241 
(3.029) - AE Loss: 447318.625 (744320.875) - AE Rec Loss: 3.034 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.243 
(3.029) - AE Loss: 186126.500 (744320.875) - AE Rec Loss: 1.262 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.78 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (0.983) - Batch(s): 1.543 
(3.029) - AE Loss: 68824.211 (744320.875) - AE Rec Loss: 0.467 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.242 
(3.029) - AE Loss: 2472119.500 (744320.875) - AE Rec Loss: 16.765 (5.048) - Disc
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 940970.375 (707127.438) - AE Rec Loss: 6.381 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 189322.094 (707127.438) - AE Rec Loss: 1.284 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 172388.781 (707127.438) - AE Rec Loss: 1.169 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 168036.156 (707127.438) - AE Rec Loss: 1.140 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.863) - Batch(s): 1.332 
(2.868) - AE Loss: 1469394.000 (707127.438) - AE Rec Loss: 9.965 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 190371.250 (707127.438) - AE Rec Loss: 1.291 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.130 
(2.645) - AE Loss: 121351.023 (679810.812) - AE Rec Loss: 0.823 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.57 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.129 
(2.645) - AE Loss: 238914.859 (679810.812) - AE Rec Loss: 1.620 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.132 
(2.645) - AE Loss: 209908.234 (679810.812) - AE Rec Loss: 1.424 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.127 
(2.645) - AE Loss: 276439.438 (679810.812) - AE Rec Loss: 1.875 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.133 
(2.645) - AE Loss: 118926.156 (679810.812) - AE Rec Loss: 0.807 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.54 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.001 (0.755) - Batch(s): 0.565 
(2.645) - AE Loss: 514480.500 (679810.812) - AE Rec Loss: 3.489 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.001 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 344579.375 (656885.562) - AE Rec Loss: 2.337 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.11 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 350424.688 (656885.562) - AE Rec Loss: 2.376 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.001 (0.745) - Batch(s): 5.829 
(3.070) - AE Loss: 239188.188 (656885.562) - AE Rec Loss: 1.622 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 94132.789 (656885.562) - AE Rec Loss: 0.638 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.001 (0.745) - Batch(s): 6.530 
(3.070) - AE Loss: 405748.625 (656885.562) - AE Rec Loss: 2.752 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 259962.875 (656885.562) - AE Rec Loss: 1.763 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.049 
(2.864) - AE Loss: 319642.125 (685805.438) - AE Rec Loss: 2.168 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.050 
(2.864) - AE Loss: 229983.297 (685805.438) - AE Rec Loss: 1.560 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.052 
(2.864) - AE Loss: 227097.469 (685805.438) - AE Rec Loss: 1.540 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.047 
(2.864) - AE Loss: 1599775.250 (685805.438) - AE Rec Loss: 10.849 (4.651) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 0.565 
(2.864) - AE Loss: 346353.625 (685805.438) - AE Rec Loss: 2.349 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.053 
(2.864) - AE Loss: 1780467.625 (685805.438) - AE Rec Loss: 12.075 (4.651) - Disc
Loss: 0.000 (0.000) - 7.32 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.134 
(2.703) - AE Loss: 507567.031 (687031.062) - AE Rec Loss: 3.442 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.136 
(2.703) - AE Loss: 90739.406 (687031.062) - AE Rec Loss: 0.615 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.60 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.137 
(2.703) - AE Loss: 330306.062 (687031.062) - AE Rec Loss: 2.240 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 0.566 
(2.703) - AE Loss: 81658.391 (687031.062) - AE Rec Loss: 0.554 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.138 
(2.703) - AE Loss: 323786.250 (687031.062) - AE Rec Loss: 2.196 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.57 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.133 
(2.703) - AE Loss: 1709057.750 (687031.062) - AE Rec Loss: 11.590 (4.659) - Disc
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.559) - Batch(s): 1.194 
(2.574) - AE Loss: 234262.688 (666926.438) - AE Rec Loss: 1.589 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.83 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 0.669 
(2.574) - AE Loss: 444890.312 (666926.438) - AE Rec Loss: 3.017 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.81 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.001 (0.559) - Batch(s): 1.198 
(2.574) - AE Loss: 266210.438 (666926.438) - AE Rec Loss: 1.805 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.81 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.198 
(2.574) - AE Loss: 321958.625 (666926.438) - AE Rec Loss: 2.183 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.84 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.196 
(2.574) - AE Loss: 513458.438 (666926.438) - AE Rec Loss: 3.482 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.196 
(2.574) - AE Loss: 355104.125 (666926.438) - AE Rec Loss: 2.408 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.001 (0.516) - Batch(s): 1.157 
(2.461) - AE Loss: 127892.016 (638127.875) - AE Rec Loss: 0.867 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.158 
(2.461) - AE Loss: 348932.812 (638127.875) - AE Rec Loss: 2.366 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.06 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.001 (0.516) - Batch(s): 1.154 
(2.461) - AE Loss: 311539.312 (638127.875) - AE Rec Loss: 2.113 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.14 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.001 (0.516) - Batch(s): 1.157 
(2.461) - AE Loss: 398417.188 (638127.875) - AE Rec Loss: 2.702 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.001 (0.516) - Batch(s): 0.566 
(2.461) - AE Loss: 70956.203 (638127.875) - AE Rec Loss: 0.481 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.06 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.159 
(2.461) - AE Loss: 476328.000 (638127.875) - AE Rec Loss: 3.230 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.253 
(2.370) - AE Loss: 1733279.500 (641277.812) - AE Rec Loss: 11.755 (4.349) - Disc
Loss: 0.000 (0.000) - 8.35 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.001 (0.479) - Batch(s): 0.570 
(2.370) - AE Loss: 182819.828 (641277.812) - AE Rec Loss: 1.240 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.33 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.251 
(2.370) - AE Loss: 1513273.000 (641277.812) - AE Rec Loss: 10.263 (4.349) - Disc
Loss: 0.000 (0.000) - 8.36 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.001 (0.479) - Batch(s): 1.254 
(2.370) - AE Loss: 182870.594 (641277.812) - AE Rec Loss: 1.240 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.33 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.252 
(2.370) - AE Loss: 224977.734 (641277.812) - AE Rec Loss: 1.526 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.37 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.248 
(2.370) - AE Loss: 236885.250 (641277.812) - AE Rec Loss: 1.606 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.400 
(2.302) - AE Loss: 101669.305 (640812.375) - AE Rec Loss: 0.689 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.67 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.400 
(2.302) - AE Loss: 133404.656 (640812.375) - AE Rec Loss: 0.905 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.65 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.402 
(2.302) - AE Loss: 1503838.750 (640812.375) - AE Rec Loss: 10.199 (4.346) - Disc
Loss: 0.000 (0.000) - 8.65 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.710 
(2.302) - AE Loss: 318009.250 (640812.375) - AE Rec Loss: 2.157 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.63 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.401 
(2.302) - AE Loss: 2020515.625 (640812.375) - AE Rec Loss: 13.702 (4.346) - Disc
Loss: 0.000 (0.000) - 8.63 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.401 
(2.302) - AE Loss: 66458.992 (640812.375) - AE Rec Loss: 0.451 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.70 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.259 
(2.233) - AE Loss: 175026.375 (656901.500) - AE Rec Loss: 1.187 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.92 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.419) - Batch(s): 0.566 
(2.233) - AE Loss: 580937.562 (656901.500) - AE Rec Loss: 3.940 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.89 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.259 
(2.233) - AE Loss: 248860.938 (656901.500) - AE Rec Loss: 1.688 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.89 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.255 
(2.233) - AE Loss: 202059.812 (656901.500) - AE Rec Loss: 1.370 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.96 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.259 
(2.233) - AE Loss: 3539496.000 (656901.500) - AE Rec Loss: 24.004 (4.455) - Disc
Loss: 0.000 (0.000) - 8.93 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.261 
(2.233) - AE Loss: 73690.477 (656901.500) - AE Rec Loss: 0.500 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.91 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.331 
(2.177) - AE Loss: 276975.812 (642163.500) - AE Rec Loss: 1.878 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.27 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.001 (0.399) - Batch(s): 1.334 
(2.177) - AE Loss: 1419175.375 (642163.500) - AE Rec Loss: 9.624 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.24 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.333 
(2.177) - AE Loss: 167547.359 (642163.500) - AE Rec Loss: 1.136 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.22 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.335 
(2.177) - AE Loss: 97337.719 (642163.500) - AE Rec Loss: 0.660 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.22 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.001 (0.399) - Batch(s): 0.567 
(2.177) - AE Loss: 253335.562 (642163.500) - AE Rec Loss: 1.718 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.20 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.334 
(2.177) - AE Loss: 111281.797 (642163.500) - AE Rec Loss: 0.755 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.20 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.393) - Batch(s): 4.178 
(2.286) - AE Loss: 196508.500 (635277.312) - AE Rec Loss: 1.333 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.393) - Batch(s): 4.178 
(2.286) - AE Loss: 132733.156 (635277.312) - AE Rec Loss: 0.900 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.17 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.179 
(2.286) - AE Loss: 1519058.500 (635277.312) - AE Rec Loss: 10.302 (4.308) - Disc
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.393) - Batch(s): 4.179 
(2.286) - AE Loss: 128722.273 (635277.312) - AE Rec Loss: 0.873 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.13 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.393) - Batch(s): 3.570 
(2.286) - AE Loss: 172938.750 (635277.312) - AE Rec Loss: 1.173 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.001 (0.393) - Batch(s): 4.180 
(2.286) - AE Loss: 516860.000 (635277.312) - AE Rec Loss: 3.505 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.12 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.150 
(2.223) - AE Loss: 927326.938 (629123.938) - AE Rec Loss: 6.289 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.39 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.152 
(2.223) - AE Loss: 250280.172 (629123.938) - AE Rec Loss: 1.697 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.37 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.001 (0.373) - Batch(s): 0.567 
(2.223) - AE Loss: 500806.562 (629123.938) - AE Rec Loss: 3.396 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.32 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.152 
(2.223) - AE Loss: 237860.047 (629123.938) - AE Rec Loss: 1.613 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.35 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.154 
(2.223) - AE Loss: 210370.938 (629123.938) - AE Rec Loss: 1.427 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.34 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.154 
(2.223) - AE Loss: 279368.125 (629123.938) - AE Rec Loss: 1.895 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.32 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.566 
(2.166) - AE Loss: 84224.812 (623425.625) - AE Rec Loss: 0.571 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.127 
(2.166) - AE Loss: 117204.977 (623425.625) - AE Rec Loss: 0.795 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.125 
(2.166) - AE Loss: 113339.883 (623425.625) - AE Rec Loss: 0.769 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.56 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.001 (0.354) - Batch(s): 1.129 
(2.166) - AE Loss: 1350701.750 (623425.625) - AE Rec Loss: 9.160 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.56 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.126 
(2.166) - AE Loss: 211680.578 (623425.625) - AE Rec Loss: 1.436 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.58 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.123 
(2.166) - AE Loss: 120503.547 (623425.625) - AE Rec Loss: 0.817 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.61 m remaining

attempting to save
[[36m2023-11-29 03:30:09,980[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:30:11,539[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:30:11,905[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:30:11,913[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:30:11,919[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:30:11,926[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:30:11,934[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:30:11,940[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:30:11,945[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:30:11,953[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:30:12,713[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:30:14,843[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:30:20,476[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:30:20,491[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 03:30:23,050[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:30:23,051[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 03:30:23,058[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 03:30:23,091[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <161/2280>] - Data(s): 0.001 (0.354) - Batch(s): 14.590 
(2.702) - AE Loss: 270877.344 (632527.125) - AE Rec Loss: 1.837 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.71 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.001 (0.354) - Batch(s): 14.588 
(2.702) - AE Loss: 213067.422 (632527.125) - AE Rec Loss: 1.445 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.75 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.001 (0.354) - Batch(s): 14.590 
(2.702) - AE Loss: 1698983.250 (632527.125) - AE Rec Loss: 11.522 (4.290) - Disc
Loss: 0.000 (0.000) - 13.72 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.001 (0.354) - Batch(s): 14.590 
(2.702) - AE Loss: 465976.688 (632527.125) - AE Rec Loss: 3.160 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.68 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.658 
(2.702) - AE Loss: 3048770.000 (632527.125) - AE Rec Loss: 20.676 (4.290) - Disc
Loss: 0.000 (0.000) - 13.68 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.001 (0.354) - Batch(s): 14.589 
(2.702) - AE Loss: 1594454.000 (632527.125) - AE Rec Loss: 10.813 (4.290) - Disc
Loss: 0.000 (0.000) - 13.70 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (0.338) - Batch(s): 0.567 
(2.629) - AE Loss: 195350.219 (646554.938) - AE Rec Loss: 1.325 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.132 
(2.629) - AE Loss: 242590.812 (646554.938) - AE Rec Loss: 1.645 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.90 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.133 
(2.629) - AE Loss: 121025.922 (646554.938) - AE Rec Loss: 0.821 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.91 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.130 
(2.629) - AE Loss: 123241.992 (646554.938) - AE Rec Loss: 0.836 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.94 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.133 
(2.629) - AE Loss: 319559.750 (646554.938) - AE Rec Loss: 2.167 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.135 
(2.629) - AE Loss: 1568498.875 (646554.938) - AE Rec Loss: 10.637 (4.385) - Disc
Loss: 0.000 (0.000) - 13.89 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.159 
(2.563) - AE Loss: 652202.062 (652551.562) - AE Rec Loss: 4.423 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.10 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.156 
(2.563) - AE Loss: 1512307.000 (652551.562) - AE Rec Loss: 10.256 (4.425) - Disc
Loss: 0.000 (0.000) - 14.13 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (0.323) - Batch(s): 1.162 
(2.563) - AE Loss: 1656777.250 (652551.562) - AE Rec Loss: 11.236 (4.425) - Disc
Loss: 0.000 (0.000) - 14.08 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (0.323) - Batch(s): 0.568 
(2.563) - AE Loss: 1769326.625 (652551.562) - AE Rec Loss: 11.999 (4.425) - Disc
Loss: 0.000 (0.000) - 14.06 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (0.323) - Batch(s): 1.159 
(2.563) - AE Loss: 187610.016 (652551.562) - AE Rec Loss: 1.272 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.06 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.159 
(2.563) - AE Loss: 1950934.750 (652551.562) - AE Rec Loss: 13.231 (4.425) - Disc
Loss: 0.000 (0.000) - 14.09 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 1529427.000 (665338.312) - AE Rec Loss: 10.372 (4.512) - Disc
Loss: 0.000 (0.000) - 14.31 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 1978350.500 (665338.312) - AE Rec Loss: 13.417 (4.512) - Disc
Loss: 0.000 (0.000) - 14.32 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.350 
(2.510) - AE Loss: 1559004.375 (665338.312) - AE Rec Loss: 10.573 (4.512) - Disc
Loss: 0.000 (0.000) - 14.29 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (0.310) - Batch(s): 1.350 
(2.510) - AE Loss: 213245.484 (665338.312) - AE Rec Loss: 1.446 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.34 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (0.310) - Batch(s): 1.351 
(2.510) - AE Loss: 528451.500 (665338.312) - AE Rec Loss: 3.584 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.36 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (0.310) - Batch(s): 0.676 
(2.510) - AE Loss: 1444733.000 (665338.312) - AE Rec Loss: 9.798 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.30 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.130 
(2.453) - AE Loss: 1442212.125 (670601.750) - AE Rec Loss: 9.781 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.50 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (0.297) - Batch(s): 0.567 
(2.453) - AE Loss: 217316.500 (670601.750) - AE Rec Loss: 1.474 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.48 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (0.297) - Batch(s): 1.134 
(2.453) - AE Loss: 234214.312 (670601.750) - AE Rec Loss: 1.588 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.49 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.128 
(2.453) - AE Loss: 1534009.500 (670601.750) - AE Rec Loss: 10.403 (4.548) - Disc
Loss: 0.000 (0.000) - 14.54 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (0.297) - Batch(s): 1.131 
(2.453) - AE Loss: 1620506.375 (670601.750) - AE Rec Loss: 10.990 (4.548) - Disc
Loss: 0.000 (0.000) - 14.52 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (0.297) - Batch(s): 1.131 
(2.453) - AE Loss: 74280.062 (670601.750) - AE Rec Loss: 0.504 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.48 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (0.286) - Batch(s): 1.272 
(2.405) - AE Loss: 136229.688 (679626.875) - AE Rec Loss: 0.924 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.73 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (0.286) - Batch(s): 1.278 
(2.405) - AE Loss: 1697332.625 (679626.875) - AE Rec Loss: 11.511 (4.609) - Disc
Loss: 0.000 (0.000) - 14.70 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.270 
(2.405) - AE Loss: 1587628.500 (679626.875) - AE Rec Loss: 10.767 (4.609) - Disc
Loss: 0.000 (0.000) - 14.75 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (0.286) - Batch(s): 0.567 
(2.405) - AE Loss: 1587315.500 (679626.875) - AE Rec Loss: 10.765 (4.609) - Disc
Loss: 0.000 (0.000) - 14.69 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (0.286) - Batch(s): 1.273 
(2.405) - AE Loss: 191925.594 (679626.875) - AE Rec Loss: 1.302 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.71 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (0.286) - Batch(s): 1.274 
(2.405) - AE Loss: 1596998.500 (679626.875) - AE Rec Loss: 10.830 (4.609) - Disc
Loss: 0.000 (0.000) - 14.69 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:35:19,980[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,090[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,122[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,238[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,258[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,264[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:35:22,236[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:22,266[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:22,274[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:22,382[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:22,402[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:22,414[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:22,924[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:22,991[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:22,994[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:23,121[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:23,126[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:23,140[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 03:35:24,004[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 03:35:24,008[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:35:24,008[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 03:35:24,011[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:35:24,011[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:35:24,011[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Mixed precision: no
=> Running in inference mode: False
=> Preparing opt_disc 
len(valid_dataset) = 4
len(valid_dataset) = 4
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached 3 on node 4
Reached end on node 2
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 4
Reached 1.3 on node 3
Reached 5 on node 4
Reached 1.4 on node 3
Reached end on node 4Reached 3 on node 2

Reached 2 on node 3
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 3
Reached 1.3 on node 1Reached 5 on node 3

Reached 1.4 on node 1
Reached end on node 3
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 5Reached 1.3 on node 2
Reached 1.4 on node 2

Reached 1.4 on node 5
Reached 2 on node 2
Reached 2 on node 5
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 3 on node 2Reached 1.3 on node 4

Reached 3 on node 5
Reached 1.4 on node 4
Reached 2 on node 0Reached 5 on node 2

Reached 5 on node 5
Reached 2 on node 4
Reached end on node 2Reached end on node 5

Reached 1.3 on node 1
Reached 3 on node 0
Reached 1.4 on node 1
Reached 3 on node 4
Reached 2 on node 1Reached 1.3 on node 3
Reached 5 on node 0Reached 5 on node 4


Reached 1.4 on node 3
Reached end on node 0Reached end on node 4

Reached 2 on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached 3 on node 3Reached end on node 1

Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3Reached 1 on node 4

Reached 5 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached end on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 1 on node 2Reached 2 on node 3

Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 5
Reached 1.4 on node 4Reached 2 on node 5

Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 2Reached 1 on node 5

Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 5
Reached end on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 0
Reached 1 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 0
Reached end on node 4
[[36m2023-11-29 03:35:25,825[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 03:35:28,632[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:35:29,798[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:35:29,799[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:35:29,799[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 03:35:29,801[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
=> Starting model training 
[[36m2023-11-29 03:35:29,802[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <161/2280>] - Data(s): 12.441 (7.360) - Batch(s): 13.885 
(13.805) - AE Loss: 3048706.500 (814676.750) - AE Rec Loss: 20.675 (5.525) - 
Disc Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 3.161 (7.360) - Batch(s): 13.881 
(13.805) - AE Loss: 213506.859 (814676.750) - AE Rec Loss: 1.448 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 5.904 (7.360) - Batch(s): 13.874 
(13.805) - AE Loss: 466163.969 (814676.750) - AE Rec Loss: 3.161 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 11.407 (7.360) - Batch(s): 13.862 
(13.805) - AE Loss: 1594789.000 (814676.750) - AE Rec Loss: 10.815 (5.525) - 
Disc Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 7.258 (7.360) - Batch(s): 13.877 
(13.805) - AE Loss: 1700007.125 (814676.750) - AE Rec Loss: 11.529 (5.525) - 
Disc Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 4.634 (7.360) - Batch(s): 13.877 
(13.805) - AE Loss: 271808.375 (814676.750) - AE Rec Loss: 1.843 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (3.680) - Batch(s): 0.561 
(7.461) - AE Loss: 191375.016 (875303.812) - AE Rec Loss: 1.298 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.170 
(7.461) - AE Loss: 1565816.500 (875303.812) - AE Rec Loss: 10.619 (5.936) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.168 
(7.461) - AE Loss: 106288.273 (875303.812) - AE Rec Loss: 0.721 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.168 
(7.461) - AE Loss: 241047.688 (875303.812) - AE Rec Loss: 1.635 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.171 
(7.461) - AE Loss: 102817.984 (875303.812) - AE Rec Loss: 0.697 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (3.680) - Batch(s): 1.172 
(7.461) - AE Loss: 316733.312 (875303.812) - AE Rec Loss: 2.148 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.778 
(5.552) - AE Loss: 1508884.750 (843348.875) - AE Rec Loss: 10.233 (5.719) - Disc
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.777 
(5.552) - AE Loss: 1955768.250 (843348.875) - AE Rec Loss: 13.263 (5.719) - Disc
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (2.484) - Batch(s): 1.226 
(5.552) - AE Loss: 1772014.000 (843348.875) - AE Rec Loss: 12.017 (5.719) - Disc
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 1.072 (2.484) - Batch(s): 1.779 
(5.552) - AE Loss: 1647292.000 (843348.875) - AE Rec Loss: 11.171 (5.719) - Disc
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.779 
(5.552) - AE Loss: 176424.906 (843348.875) - AE Rec Loss: 1.196 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.779 
(5.552) - AE Loss: 640289.000 (843348.875) - AE Rec Loss: 4.342 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.097 
(4.427) - AE Loss: 222994.969 (873964.312) - AE Rec Loss: 1.512 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.099 
(4.427) - AE Loss: 1560784.250 (873964.312) - AE Rec Loss: 10.585 (5.927) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (1.863) - Batch(s): 0.565 
(4.427) - AE Loss: 1446803.750 (873964.312) - AE Rec Loss: 9.812 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.098 
(4.427) - AE Loss: 1530480.375 (873964.312) - AE Rec Loss: 10.379 (5.927) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.096 
(4.427) - AE Loss: 543386.000 (873964.312) - AE Rec Loss: 3.685 (5.927) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.097 
(4.427) - AE Loss: 1981059.250 (873964.312) - AE Rec Loss: 13.435 (5.927) - Disc
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.301 
(3.790) - AE Loss: 1444126.250 (860321.562) - AE Rec Loss: 9.794 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (1.490) - Batch(s): 0.564 
(3.790) - AE Loss: 227779.125 (860321.562) - AE Rec Loss: 1.545 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.303 
(3.790) - AE Loss: 262100.641 (860321.562) - AE Rec Loss: 1.777 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.304 
(3.790) - AE Loss: 1622081.750 (860321.562) - AE Rec Loss: 11.000 (5.834) - Disc
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.299 
(3.790) - AE Loss: 1535185.625 (860321.562) - AE Rec Loss: 10.411 (5.834) - Disc
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.304 
(3.790) - AE Loss: 87320.844 (860321.562) - AE Rec Loss: 0.592 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.294 
(3.366) - AE Loss: 155470.781 (869722.750) - AE Rec Loss: 1.054 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.295 
(3.366) - AE Loss: 1705563.500 (869722.750) - AE Rec Loss: 11.567 (5.898) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.294 
(3.366) - AE Loss: 1601043.125 (869722.750) - AE Rec Loss: 10.858 (5.898) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.296 
(3.366) - AE Loss: 215791.641 (869722.750) - AE Rec Loss: 1.463 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (1.242) - Batch(s): 0.739 
(3.366) - AE Loss: 1606519.750 (869722.750) - AE Rec Loss: 10.895 (5.898) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.296 
(3.366) - AE Loss: 1603162.250 (869722.750) - AE Rec Loss: 10.872 (5.898) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 0.565 
(3.040) - AE Loss: 434523.062 (848410.125) - AE Rec Loss: 2.947 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.129 
(3.040) - AE Loss: 3062833.500 (848410.125) - AE Rec Loss: 20.771 (5.754) - Disc
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.126 
(3.040) - AE Loss: 81787.234 (848410.125) - AE Rec Loss: 0.555 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.130 
(3.040) - AE Loss: 309483.969 (848410.125) - AE Rec Loss: 2.099 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.129 
(3.040) - AE Loss: 168962.531 (848410.125) - AE Rec Loss: 1.146 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.126 
(3.040) - AE Loss: 232560.250 (848410.125) - AE Rec Loss: 1.577 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.163 
(2.799) - AE Loss: 280703.938 (837860.688) - AE Rec Loss: 1.904 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.162 
(2.799) - AE Loss: 507157.406 (837860.688) - AE Rec Loss: 3.439 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.160 
(2.799) - AE Loss: 242053.312 (837860.688) - AE Rec Loss: 1.642 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.935) - Batch(s): 1.163 
(2.799) - AE Loss: 1635351.750 (837860.688) - AE Rec Loss: 11.090 (5.682) - Disc
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.163 
(2.799) - AE Loss: 140480.578 (837860.688) - AE Rec Loss: 0.953 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.935) - Batch(s): 0.565 
(2.799) - AE Loss: 1289096.000 (837860.688) - AE Rec Loss: 8.742 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.474 
(2.645) - AE Loss: 150365.438 (873454.688) - AE Rec Loss: 1.020 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.474 
(2.645) - AE Loss: 188156.000 (873454.688) - AE Rec Loss: 1.276 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.832) - Batch(s): 0.742 
(2.645) - AE Loss: 1840640.250 (873454.688) - AE Rec Loss: 12.483 (5.923) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.476 
(2.645) - AE Loss: 76686.250 (873454.688) - AE Rec Loss: 0.520 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.475 
(2.645) - AE Loss: 1586175.750 (873454.688) - AE Rec Loss: 10.757 (5.923) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.096 (0.832) - Batch(s): 1.476 
(2.645) - AE Loss: 1911454.250 (873454.688) - AE Rec Loss: 12.963 (5.923) - Disc
Loss: 0.000 (0.000) - 5.36 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.001 (0.755) - Batch(s): 1.210 
(2.502) - AE Loss: 423811.312 (815807.188) - AE Rec Loss: 2.874 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.282 
(2.502) - AE Loss: 69765.773 (815807.188) - AE Rec Loss: 0.473 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.281 
(2.502) - AE Loss: 63291.527 (815807.188) - AE Rec Loss: 0.429 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.001 (0.755) - Batch(s): 0.564 
(2.502) - AE Loss: 73845.617 (815807.188) - AE Rec Loss: 0.501 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.718 (0.755) - Batch(s): 1.283 
(2.502) - AE Loss: 444574.781 (815807.188) - AE Rec Loss: 3.015 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.278 
(2.502) - AE Loss: 1419004.250 (815807.188) - AE Rec Loss: 9.623 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.001 (0.712) - Batch(s): 2.706 
(2.531) - AE Loss: 1483694.125 (798588.375) - AE Rec Loss: 10.062 (5.416) - Disc
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.001 (0.712) - Batch(s): 2.706 
(2.531) - AE Loss: 125844.727 (798588.375) - AE Rec Loss: 0.853 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.706 
(2.531) - AE Loss: 212967.469 (798588.375) - AE Rec Loss: 1.444 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.706 
(2.531) - AE Loss: 233613.656 (798588.375) - AE Rec Loss: 1.584 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 1.974 
(2.531) - AE Loss: 268426.062 (798588.375) - AE Rec Loss: 1.820 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.706 
(2.531) - AE Loss: 1509845.875 (798588.375) - AE Rec Loss: 10.239 (5.416) - Disc
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 0.767 
(2.439) - AE Loss: 221682.516 (793862.812) - AE Rec Loss: 1.503 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.487 
(2.439) - AE Loss: 1758169.000 (793862.812) - AE Rec Loss: 11.923 (5.384) - Disc
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.488 
(2.439) - AE Loss: 145280.422 (793862.812) - AE Rec Loss: 0.985 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.487 
(2.439) - AE Loss: 330286.812 (793862.812) - AE Rec Loss: 2.240 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.490 
(2.439) - AE Loss: 660511.062 (793862.812) - AE Rec Loss: 4.479 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.489 
(2.439) - AE Loss: 242984.641 (793862.812) - AE Rec Loss: 1.648 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.54 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.236 
(2.342) - AE Loss: 1480923.250 (780838.688) - AE Rec Loss: 10.043 (5.295) - Disc
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.235 
(2.342) - AE Loss: 72596.500 (780838.688) - AE Rec Loss: 0.492 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.232 
(2.342) - AE Loss: 71662.344 (780838.688) - AE Rec Loss: 0.486 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.001 (0.603) - Batch(s): 1.236 
(2.342) - AE Loss: 1571472.250 (780838.688) - AE Rec Loss: 10.657 (5.295) - Disc
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.001 (0.603) - Batch(s): 0.566 
(2.342) - AE Loss: 64741.570 (780838.688) - AE Rec Loss: 0.439 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.234 
(2.342) - AE Loss: 399425.062 (780838.688) - AE Rec Loss: 2.709 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 207815.578 (776389.188) - AE Rec Loss: 1.409 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.572) - Batch(s): 2.111 
(2.329) - AE Loss: 274723.312 (776389.188) - AE Rec Loss: 1.863 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 1709386.875 (776389.188) - AE Rec Loss: 11.593 (5.265) - Disc
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 128190.273 (776389.188) - AE Rec Loss: 0.869 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.572) - Batch(s): 1.377 
(2.329) - AE Loss: 165764.906 (776389.188) - AE Rec Loss: 1.124 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 1628523.625 (776389.188) - AE Rec Loss: 11.044 (5.265) - Disc
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.001 (0.534) - Batch(s): 1.426 
(2.265) - AE Loss: 118121.867 (771923.000) - AE Rec Loss: 0.801 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.426 
(2.265) - AE Loss: 236106.375 (771923.000) - AE Rec Loss: 1.601 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.001 (0.534) - Batch(s): 0.730 
(2.265) - AE Loss: 65215.035 (771923.000) - AE Rec Loss: 0.442 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.426 
(2.265) - AE Loss: 1478552.000 (771923.000) - AE Rec Loss: 10.027 (5.235) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.427 
(2.265) - AE Loss: 163395.266 (771923.000) - AE Rec Loss: 1.108 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.427 
(2.265) - AE Loss: 142912.031 (771923.000) - AE Rec Loss: 0.969 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.209 
(2.196) - AE Loss: 1853967.250 (762615.688) - AE Rec Loss: 12.573 (5.172) - Disc
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.212 
(2.196) - AE Loss: 136954.469 (762615.688) - AE Rec Loss: 0.929 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.214 
(2.196) - AE Loss: 205526.750 (762615.688) - AE Rec Loss: 1.394 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.001 (0.500) - Batch(s): 1.211 
(2.196) - AE Loss: 151773.047 (762615.688) - AE Rec Loss: 1.029 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.001 (0.500) - Batch(s): 1.213 
(2.196) - AE Loss: 223098.812 (762615.688) - AE Rec Loss: 1.513 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.001 (0.500) - Batch(s): 0.567 
(2.196) - AE Loss: 134213.062 (762615.688) - AE Rec Loss: 0.910 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 126841.547 (743296.000) - AE Rec Loss: 0.860 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.001 (0.477) - Batch(s): 0.744 
(2.156) - AE Loss: 88839.906 (743296.000) - AE Rec Loss: 0.602 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 1763891.625 (743296.000) - AE Rec Loss: 11.962 (5.041) - Disc
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 297344.125 (743296.000) - AE Rec Loss: 2.016 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 87320.578 (743296.000) - AE Rec Loss: 0.592 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 116177.062 (743296.000) - AE Rec Loss: 0.788 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.261 
(2.104) - AE Loss: 194368.094 (735501.188) - AE Rec Loss: 1.318 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.262 
(2.104) - AE Loss: 79484.719 (735501.188) - AE Rec Loss: 0.539 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.001 (0.452) - Batch(s): 0.752 
(2.104) - AE Loss: 1558742.500 (735501.188) - AE Rec Loss: 10.571 (4.988) - Disc
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.263 
(2.104) - AE Loss: 1728470.500 (735501.188) - AE Rec Loss: 11.722 (4.988) - Disc
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.264 
(2.104) - AE Loss: 1407615.000 (735501.188) - AE Rec Loss: 9.546 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.263 
(2.104) - AE Loss: 314492.188 (735501.188) - AE Rec Loss: 2.133 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.203 
(2.054) - AE Loss: 257714.031 (734373.312) - AE Rec Loss: 1.748 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.200 
(2.054) - AE Loss: 271692.156 (734373.312) - AE Rec Loss: 1.843 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.431) - Batch(s): 0.568 
(2.054) - AE Loss: 125989.758 (734373.312) - AE Rec Loss: 0.854 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.431) - Batch(s): 1.202 
(2.054) - AE Loss: 1574988.250 (734373.312) - AE Rec Loss: 10.681 (4.980) - Disc
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.204 
(2.054) - AE Loss: 386149.312 (734373.312) - AE Rec Loss: 2.619 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.584 (0.431) - Batch(s): 1.200 
(2.054) - AE Loss: 1494718.750 (734373.312) - AE Rec Loss: 10.137 (4.980) - Disc
Loss: 0.000 (0.000) - 8.55 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.163 
(2.262) - AE Loss: 547173.750 (725848.062) - AE Rec Loss: 3.711 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.162 
(2.262) - AE Loss: 114314.859 (725848.062) - AE Rec Loss: 0.775 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.914 (0.438) - Batch(s): 5.479 
(2.262) - AE Loss: 298638.281 (725848.062) - AE Rec Loss: 2.025 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.163 
(2.262) - AE Loss: 200678.562 (725848.062) - AE Rec Loss: 1.361 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.161 
(2.262) - AE Loss: 1811552.625 (725848.062) - AE Rec Loss: 12.285 (4.922) - Disc
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.163 
(2.262) - AE Loss: 133060.500 (725848.062) - AE Rec Loss: 0.902 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.79 m remaining

attempting to save
[[36m2023-11-29 03:36:21,207[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:36:25,653[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:36:26,187[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:36:26,193[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:36:26,198[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:36:26,203[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:36:26,208[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:36:26,213[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:36:26,219[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:36:26,224[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:36:26,482[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:36:32,516[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:36:36,602[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:36:36,607[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:36:53,473[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:53,474[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:53,771[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:53,799[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:53,799[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:53,847[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:36:55,624[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:55,739[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:55,988[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,007[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,013[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,080[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 03:36:56,106[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,298[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,598[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,636[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,657[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,675[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:36:57,127[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:36:57,127[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 03:36:57,131[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:36:57,132[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:36:57,132[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:36:57,134[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4Reached 3 on node 5

Reached 5 on node 5
Reached end on node 4
Reached end on node 5Reached 3 on node 0

Reached 5 on node 0
Reached 3 on node 1
Reached end on node 0
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1 on node 5Reached 1.2 on node 4

Reached 1.2 on node 5
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:38:25,835[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:25,877[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:25,916[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,115[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,124[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,146[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:38:27,999[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,010[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,088[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,257[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,289[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,322[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,669[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,745[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,823[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,936[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:28,967[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:38:29,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
[[36m2023-11-29 03:38:29,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
[[36m2023-11-29 03:38:29,620[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 03:38:29,622[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Mixed precision: no
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0=> Running in inference mode: False

=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:39:58,679[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,681[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,811[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,822[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,832[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,868[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:40:00,863[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:00,876[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:00,970[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:00,999[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:01,000[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:01,037[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,396[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,563[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,610[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,723[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,737[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 03:40:02,189[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:40:02,190[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
[[36m2023-11-29 03:40:02,193[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
[[36m2023-11-29 03:40:02,196[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 4=> Running in inference mode: False

Reached 5 on node 4
Reached end on node 4
[[36m2023-11-29 03:40:02,197[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Preparing model 
[[36m2023-11-29 03:40:02,197[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Preparing model 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Instantiating the optimizer 
=> Preparing model 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 3 on node 3
Reached 2 on node 5
Reached 5 on node 3
Reached 3 on node 5
Reached end on node 3
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached 3 on node 5
Reached end on node 3
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 3 on node 2
Reached 5 on node 1
Reached 5 on node 2
Reached end on node 1
Reached end on node 2
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 1.3 on node 2
Reached 5 on node 5Reached 1.4 on node 2

Reached 1.3 on node 3
Reached 1.4 on node 3
Reached end on node 5Reached 2 on node 2

Reached 2 on node 3
Reached 3 on node 2Reached 3 on node 3

Reached 5 on node 2
Reached 5 on node 3
Reached end on node 2
Reached end on node 3
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 1 on node 2Reached 2 on node 3

Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5Reached 1 on node 3

Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 5Reached 1.4 on node 3

Reached 2 on node 3
Reached 1 on node 2Reached 1.4 on node 5

Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 5Reached 1.4 on node 3

Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3Reached 1.4 on node 5

Reached 3 on node 3
Reached 2 on node 5
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:40:03,892[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
[[36m2023-11-29 03:40:05,521[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:40:06,066[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:40:06,066[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:40:06,066[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:40:06,070[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:40:06,072[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <161/2280>] - Data(s): 9.657 (6.171) - Batch(s): 11.095 
(11.345) - AE Loss: 3048706.500 (814762.812) - AE Rec Loss: 20.675 (5.525) - 
Disc Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 3.828 (6.171) - Batch(s): 11.316 
(11.345) - AE Loss: 466213.562 (814762.812) - AE Rec Loss: 3.162 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 8.487 (6.171) - Batch(s): 11.320 
(11.345) - AE Loss: 1699721.125 (814762.812) - AE Rec Loss: 11.527 (5.525) - 
Disc Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 7.708 (6.171) - Batch(s): 11.050 
(11.345) - AE Loss: 1594719.875 (814762.812) - AE Rec Loss: 10.815 (5.525) - 
Disc Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 3.795 (6.171) - Batch(s): 11.286 
(11.345) - AE Loss: 271358.562 (814762.812) - AE Rec Loss: 1.840 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 2.850 (6.171) - Batch(s): 11.253 
(11.345) - AE Loss: 213373.578 (814762.812) - AE Rec Loss: 1.447 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (3.086) - Batch(s): 1.369 
(6.322) - AE Loss: 1565752.500 (875283.812) - AE Rec Loss: 10.618 (5.936) - Disc
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.368 
(6.322) - AE Loss: 100909.094 (875283.812) - AE Rec Loss: 0.684 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.370 
(6.322) - AE Loss: 316495.125 (875283.812) - AE Rec Loss: 2.146 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.006 (3.086) - Batch(s): 1.364 
(6.322) - AE Loss: 105341.516 (875283.812) - AE Rec Loss: 0.714 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (3.086) - Batch(s): 1.367 
(6.322) - AE Loss: 242073.344 (875283.812) - AE Rec Loss: 1.642 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (3.086) - Batch(s): 0.562 
(6.322) - AE Loss: 191375.016 (875283.812) - AE Rec Loss: 1.298 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <163/2280>] - Data(s): 1.852 (2.164) - Batch(s): 2.565 
(5.231) - AE Loss: 1772014.000 (843394.562) - AE Rec Loss: 12.017 (5.720) - Disc
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.090 
(5.231) - AE Loss: 1955764.500 (843394.562) - AE Rec Loss: 13.263 (5.720) - Disc
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.091 
(5.231) - AE Loss: 640640.125 (843394.562) - AE Rec Loss: 4.345 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.090 
(5.231) - AE Loss: 176360.625 (843394.562) - AE Rec Loss: 1.196 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 1.966 (2.164) - Batch(s): 3.091 
(5.231) - AE Loss: 1647138.750 (843394.562) - AE Rec Loss: 11.170 (5.720) - Disc
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.091 
(5.231) - AE Loss: 1508717.375 (843394.562) - AE Rec Loss: 10.232 (5.720) - Disc
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.293 
(4.231) - AE Loss: 223261.062 (874117.000) - AE Rec Loss: 1.514 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.292 
(4.231) - AE Loss: 1530337.250 (874117.000) - AE Rec Loss: 10.378 (5.928) - Disc
Loss: 0.000 (0.000) - 3.76 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.291 
(4.231) - AE Loss: 1982141.500 (874117.000) - AE Rec Loss: 13.442 (5.928) - Disc
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.288 
(4.231) - AE Loss: 544412.375 (874117.000) - AE Rec Loss: 3.692 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.293 
(4.231) - AE Loss: 1561587.625 (874117.000) - AE Rec Loss: 10.590 (5.928) - Disc
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (1.623) - Batch(s): 0.562 
(4.231) - AE Loss: 1447230.875 (874117.000) - AE Rec Loss: 9.815 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.76 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (1.298) - Batch(s): 1.277 
(3.628) - AE Loss: 1535537.750 (860617.625) - AE Rec Loss: 10.414 (5.836) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (1.298) - Batch(s): 1.279 
(3.628) - AE Loss: 1444893.500 (860617.625) - AE Rec Loss: 9.799 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.281 
(3.628) - AE Loss: 263747.250 (860617.625) - AE Rec Loss: 1.789 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (1.298) - Batch(s): 1.280 
(3.628) - AE Loss: 1623516.000 (860617.625) - AE Rec Loss: 11.010 (5.836) - Disc
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.281 
(3.628) - AE Loss: 87896.344 (860617.625) - AE Rec Loss: 0.596 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.001 (1.298) - Batch(s): 0.563 
(3.628) - AE Loss: 228716.891 (860617.625) - AE Rec Loss: 1.551 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 1705210.875 (870101.125) - AE Rec Loss: 11.564 (5.901) - Disc
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 2.019 (1.110) - Batch(s): 2.728 
(3.470) - AE Loss: 156550.016 (870101.125) - AE Rec Loss: 1.062 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.725 
(3.470) - AE Loss: 1603194.750 (870101.125) - AE Rec Loss: 10.872 (5.901) - Disc
Loss: 0.000 (0.000) - 4.68 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.001 (1.110) - Batch(s): 2.147 
(3.470) - AE Loss: 1607223.375 (870101.125) - AE Rec Loss: 10.900 (5.901) - Disc
Loss: 0.000 (0.000) - 4.63 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.729 
(3.470) - AE Loss: 217379.219 (870101.125) - AE Rec Loss: 1.474 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.728 
(3.470) - AE Loss: 1601139.000 (870101.125) - AE Rec Loss: 10.858 (5.901) - Disc
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (0.952) - Batch(s): 0.563 
(3.143) - AE Loss: 434771.219 (848637.125) - AE Rec Loss: 2.948 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.240 
(3.143) - AE Loss: 168204.578 (848637.125) - AE Rec Loss: 1.141 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.236 
(3.143) - AE Loss: 232742.344 (848637.125) - AE Rec Loss: 1.578 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.240 
(3.143) - AE Loss: 307399.000 (848637.125) - AE Rec Loss: 2.085 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.239 
(3.143) - AE Loss: 3062747.750 (848637.125) - AE Rec Loss: 20.771 (5.755) - Disc
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.237 
(3.143) - AE Loss: 80903.156 (848637.125) - AE Rec Loss: 0.549 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.050 
(2.876) - AE Loss: 140194.688 (837975.812) - AE Rec Loss: 0.951 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.049 
(2.876) - AE Loss: 281858.969 (837975.812) - AE Rec Loss: 1.911 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.16 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.047 
(2.876) - AE Loss: 505028.062 (837975.812) - AE Rec Loss: 3.425 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.049 
(2.876) - AE Loss: 1634387.000 (837975.812) - AE Rec Loss: 11.084 (5.683) - Disc
Loss: 0.000 (0.000) - 5.16 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.833) - Batch(s): 1.046 
(2.876) - AE Loss: 241355.625 (837975.812) - AE Rec Loss: 1.637 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.833) - Batch(s): 0.564 
(2.876) - AE Loss: 1288402.000 (837975.812) - AE Rec Loss: 8.738 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.11 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.445 
(2.710) - AE Loss: 1912288.000 (873452.000) - AE Rec Loss: 12.969 (5.923) - Disc
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 1585404.750 (873452.000) - AE Rec Loss: 10.752 (5.923) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.740) - Batch(s): 1.445 
(2.710) - AE Loss: 186936.000 (873452.000) - AE Rec Loss: 1.268 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 149647.281 (873452.000) - AE Rec Loss: 1.015 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.740) - Batch(s): 0.716 
(2.710) - AE Loss: 1839728.625 (873452.000) - AE Rec Loss: 12.476 (5.923) - Disc
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 75705.625 (873452.000) - AE Rec Loss: 0.513 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.322 
(2.565) - AE Loss: 64408.645 (815871.875) - AE Rec Loss: 0.437 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.322 
(2.565) - AE Loss: 70954.055 (815871.875) - AE Rec Loss: 0.481 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.001 (0.666) - Batch(s): 0.565 
(2.565) - AE Loss: 73939.047 (815871.875) - AE Rec Loss: 0.501 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.322 
(2.565) - AE Loss: 445578.312 (815871.875) - AE Rec Loss: 3.022 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.321 
(2.565) - AE Loss: 424438.562 (815871.875) - AE Rec Loss: 2.878 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.320 
(2.565) - AE Loss: 1418718.750 (815871.875) - AE Rec Loss: 9.621 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.286 
(2.443) - AE Loss: 1510206.750 (798714.438) - AE Rec Loss: 10.242 (5.417) - Disc
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.001 (0.606) - Batch(s): 0.564 
(2.443) - AE Loss: 268777.000 (798714.438) - AE Rec Loss: 1.823 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.284 
(2.443) - AE Loss: 214238.047 (798714.438) - AE Rec Loss: 1.453 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.285 
(2.443) - AE Loss: 234186.469 (798714.438) - AE Rec Loss: 1.588 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.284 
(2.443) - AE Loss: 1484268.000 (798714.438) - AE Rec Loss: 10.066 (5.417) - Disc
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.281 
(2.443) - AE Loss: 126498.727 (798714.438) - AE Rec Loss: 0.858 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.164 
(2.582) - AE Loss: 1758497.250 (794005.625) - AE Rec Loss: 11.926 (5.385) - Disc
Loss: 0.000 (0.000) - 6.82 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.166 
(2.582) - AE Loss: 661004.875 (794005.625) - AE Rec Loss: 4.483 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.165 
(2.582) - AE Loss: 242376.062 (794005.625) - AE Rec Loss: 1.644 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.82 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.164 
(2.582) - AE Loss: 330618.094 (794005.625) - AE Rec Loss: 2.242 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 3.449 (0.579) - Batch(s): 4.167 
(2.582) - AE Loss: 145506.031 (794005.625) - AE Rec Loss: 0.987 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.001 (0.579) - Batch(s): 3.479 
(2.582) - AE Loss: 222138.516 (794005.625) - AE Rec Loss: 1.506 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.78 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.080 
(2.463) - AE Loss: 401196.906 (781052.188) - AE Rec Loss: 2.721 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.03 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 0.564 
(2.463) - AE Loss: 64232.023 (781052.188) - AE Rec Loss: 0.436 (5.297) - Disc 
Loss: 0.000 (0.000) - 6.99 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.079 
(2.463) - AE Loss: 70626.500 (781052.188) - AE Rec Loss: 0.479 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.03 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.081 
(2.463) - AE Loss: 1571886.000 (781052.188) - AE Rec Loss: 10.660 (5.297) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.082 
(2.463) - AE Loss: 72246.906 (781052.188) - AE Rec Loss: 0.490 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.081 
(2.463) - AE Loss: 1481878.250 (781052.188) - AE Rec Loss: 10.050 (5.297) - Disc
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.497) - Batch(s): 0.566 
(2.376) - AE Loss: 166982.781 (776708.312) - AE Rec Loss: 1.132 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.308 
(2.376) - AE Loss: 1630014.500 (776708.312) - AE Rec Loss: 11.054 (5.267) - Disc
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.305 
(2.376) - AE Loss: 129811.117 (776708.312) - AE Rec Loss: 0.880 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.309 
(2.376) - AE Loss: 211011.922 (776708.312) - AE Rec Loss: 1.431 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.309 
(2.376) - AE Loss: 279129.375 (776708.312) - AE Rec Loss: 1.893 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.308 
(2.376) - AE Loss: 1710770.000 (776708.312) - AE Rec Loss: 11.602 (5.267) - Disc
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.437 
(2.309) - AE Loss: 165363.797 (772298.938) - AE Rec Loss: 1.121 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.435 
(2.309) - AE Loss: 120363.594 (772298.938) - AE Rec Loss: 0.816 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.435 
(2.309) - AE Loss: 144571.594 (772298.938) - AE Rec Loss: 0.980 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.436 
(2.309) - AE Loss: 237454.234 (772298.938) - AE Rec Loss: 1.610 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.436 
(2.309) - AE Loss: 1477715.625 (772298.938) - AE Rec Loss: 10.021 (5.237) - Disc
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.692 
(2.309) - AE Loss: 65166.336 (772298.938) - AE Rec Loss: 0.442 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.243 
(2.239) - AE Loss: 223006.188 (762932.812) - AE Rec Loss: 1.512 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.244 
(2.239) - AE Loss: 205342.875 (762932.812) - AE Rec Loss: 1.393 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.001 (0.437) - Batch(s): 0.564 
(2.239) - AE Loss: 134383.094 (762932.812) - AE Rec Loss: 0.911 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.75 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.243 
(2.239) - AE Loss: 151063.016 (762932.812) - AE Rec Loss: 1.024 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.240 
(2.239) - AE Loss: 1854101.125 (762932.812) - AE Rec Loss: 12.574 (5.174) - Disc
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.244 
(2.239) - AE Loss: 136636.094 (762932.812) - AE Rec Loss: 0.927 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.225 
(2.176) - AE Loss: 295084.469 (743556.250) - AE Rec Loss: 2.001 (5.043) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.222 
(2.176) - AE Loss: 1764179.750 (743556.250) - AE Rec Loss: 11.964 (5.043) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.001 (0.411) - Batch(s): 0.566 
(2.176) - AE Loss: 88136.172 (743556.250) - AE Rec Loss: 0.598 (5.043) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.224 
(2.176) - AE Loss: 86769.406 (743556.250) - AE Rec Loss: 0.588 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.223 
(2.176) - AE Loss: 127063.531 (743556.250) - AE Rec Loss: 0.862 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.221 
(2.176) - AE Loss: 115092.891 (743556.250) - AE Rec Loss: 0.781 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.592 
(2.196) - AE Loss: 1727578.250 (735706.312) - AE Rec Loss: 11.716 (4.989) - Disc
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.591 
(2.196) - AE Loss: 1406785.625 (735706.312) - AE Rec Loss: 9.540 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.591 
(2.196) - AE Loss: 313157.938 (735706.312) - AE Rec Loss: 2.124 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.001 (0.397) - Batch(s): 1.956 
(2.196) - AE Loss: 1558182.000 (735706.312) - AE Rec Loss: 10.567 (4.989) - Disc
Loss: 0.000 (0.000) - 8.46 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.593 
(2.196) - AE Loss: 78925.031 (735706.312) - AE Rec Loss: 0.535 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.46 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.593 
(2.196) - AE Loss: 194860.047 (735706.312) - AE Rec Loss: 1.321 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.50 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.087 
(2.135) - AE Loss: 386549.250 (734630.062) - AE Rec Loss: 2.621 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.65 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.085 
(2.135) - AE Loss: 1496070.625 (734630.062) - AE Rec Loss: 10.146 (4.982) - Disc
Loss: 0.000 (0.000) - 8.70 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.086 
(2.135) - AE Loss: 1576737.500 (734630.062) - AE Rec Loss: 10.693 (4.982) - Disc
Loss: 0.000 (0.000) - 8.70 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 0.567 
(2.135) - AE Loss: 126777.664 (734630.062) - AE Rec Loss: 0.860 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.66 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.087 
(2.135) - AE Loss: 258861.234 (734630.062) - AE Rec Loss: 1.756 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.70 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 1.083 
(2.135) - AE Loss: 272691.562 (734630.062) - AE Rec Loss: 1.849 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.69 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.511 
(2.101) - AE Loss: 115199.156 (726112.438) - AE Rec Loss: 0.781 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.516 
(2.101) - AE Loss: 200888.609 (726112.438) - AE Rec Loss: 1.362 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.92 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.107 (0.360) - Batch(s): 1.515 
(2.101) - AE Loss: 547763.188 (726112.438) - AE Rec Loss: 3.715 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.200 (0.360) - Batch(s): 0.764 
(2.101) - AE Loss: 298897.000 (726112.438) - AE Rec Loss: 2.027 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.93 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.515 
(2.101) - AE Loss: 135011.250 (726112.438) - AE Rec Loss: 0.916 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.513 
(2.101) - AE Loss: 1811663.625 (726112.438) - AE Rec Loss: 12.286 (4.924) - Disc
Loss: 0.000 (0.000) - 8.97 m remaining

attempting to save
[[36m2023-11-29 03:40:53,178[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:40:55,168[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:40:55,353[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:40:55,358[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:40:55,363[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:40:55,371[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:40:55,375[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:40:55,380[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:40:55,388[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:40:55,395[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:40:56,077[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:40:59,197[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:41:07,445[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:41:07,456[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 03:41:14,636[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:41:14,637[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 03:41:14,637[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 03:41:14,649[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.082 
(3.011) - AE Loss: 72446.367 (731306.812) - AE Rec Loss: 0.491 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.082 
(3.011) - AE Loss: 112762.609 (731306.812) - AE Rec Loss: 0.765 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.34 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 0.670 
(3.011) - AE Loss: 1799792.500 (731306.812) - AE Rec Loss: 12.206 (4.959) - Disc
Loss: 0.000 (0.000) - 13.34 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.082 
(3.011) - AE Loss: 1742543.125 (731306.812) - AE Rec Loss: 11.817 (4.959) - Disc
Loss: 0.000 (0.000) - 13.38 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.082 
(3.011) - AE Loss: 752016.125 (731306.812) - AE Rec Loss: 5.100 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.38 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.082 
(3.011) - AE Loss: 1584479.500 (731306.812) - AE Rec Loss: 10.745 (4.959) - Disc
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.017 
(2.919) - AE Loss: 64462.070 (721530.188) - AE Rec Loss: 0.437 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.48 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.566 
(2.919) - AE Loss: 141278.078 (721530.188) - AE Rec Loss: 0.958 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.49 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.016 
(2.919) - AE Loss: 1582825.500 (721530.188) - AE Rec Loss: 10.734 (4.893) - Disc
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.016 
(2.919) - AE Loss: 628285.500 (721530.188) - AE Rec Loss: 4.261 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.015 
(2.919) - AE Loss: 152408.625 (721530.188) - AE Rec Loss: 1.034 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.013 
(2.919) - AE Loss: 75647.859 (721530.188) - AE Rec Loss: 0.513 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.52 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:41:33,420[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,432[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,557[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,580[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,658[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,662[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:41:35,612[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,665[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,711[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,728[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,783[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,829[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,322[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,405[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,408[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,459[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,503[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,542[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 03:41:36,768[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:41:36,770[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
[[36m2023-11-29 03:41:36,773[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating train dataloader 
[[36m2023-11-29 03:41:36,775[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Instantiating the optimizer 
[[36m2023-11-29 03:41:36,776[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
[[36m2023-11-29 03:41:36,777[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataset) = 4
=> Preparing model 
=> Preparing opt_disc 
=> Mixed precision: no
len(valid_dataloader) = 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Mixed precision: no
=> Mixed precision: no
=> Preparing model 
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2Reached 3 on node 5

Reached 5 on node 2Reached 5 on node 5

Reached end on node 5
Reached end on node 2
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4Reached 1.3 on node 2

Reached 1.4 on node 2Reached 1.4 on node 4

Reached 2 on node 4Reached 2 on node 2

Reached 3 on node 2
Reached 3 on node 4
Reached 5 on node 2
Reached 5 on node 4
Reached end on node 2
Reached end on node 4
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 5 on node 5
Reached 2 on node 3
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 3 on node 0
Reached 2 on node 1
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 2
Reached 3 on node 4Reached 5 on node 2

Reached 5 on node 4
Reached end on node 2
Reached end on node 4
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 3 on node 3
Reached 5 on node 5
Reached 5 on node 3
Reached end on node 5
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 4

Reached 1.4 on node 2
Reached 1.4 on node 4
Reached 2 on node 2
Reached 2 on node 4
Reached 3 on node 2
Reached 3 on node 4
Reached 5 on node 2
Reached 5 on node 4
Reached 1.3 on node 5Reached 1.3 on node 0Reached end on node 2


Reached end on node 4Reached 1.4 on node 5
Reached 1.4 on node 0
Reached 1.3 on node 3

Reached 2 on node 0Reached 2 on node 5Reached 1.4 on node 3


Reached 2 on node 3Reached 3 on node 5

Reached 3 on node 0
Reached 5 on node 5
Reached 5 on node 0
Reached 3 on node 3Reached end on node 5
Reached end on node 0

Reached 1.3 on node 1
Reached 5 on node 3Reached 1.4 on node 1

Reached 2 on node 1
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3Reached 1.4 on node 4

Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 2
Reached 1 on node 5Reached 1.4 on node 2

Reached 2 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2Reached 1 on node 5

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3Reached 1.4 on node 4

Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:41:38,533[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 2
Reached end on node 4
[[36m2023-11-29 03:41:41,355[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 03:41:42,589[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:41:42,589[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 03:41:42,604[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:41:42,606[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:41:42,608[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <181/2280>] - Data(s): 7.943 (6.666) - Batch(s): 13.414 
(13.302) - AE Loss: 1799702.750 (835069.188) - AE Rec Loss: 12.205 (5.663) - 
Disc Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 6.865 (6.666) - Batch(s): 13.431 
(13.302) - AE Loss: 751328.750 (835069.188) - AE Rec Loss: 5.095 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 6.400 (6.666) - Batch(s): 13.418 
(13.302) - AE Loss: 1742014.375 (835069.188) - AE Rec Loss: 11.814 (5.663) - 
Disc Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 2.392 (6.666) - Batch(s): 13.434 
(13.302) - AE Loss: 112077.672 (835069.188) - AE Rec Loss: 0.760 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 6.575 (6.666) - Batch(s): 13.433 
(13.302) - AE Loss: 1584103.000 (835069.188) - AE Rec Loss: 10.743 (5.663) - 
Disc Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 7.830 (6.666) - Batch(s): 13.429 
(13.302) - AE Loss: 72588.789 (835069.188) - AE Rec Loss: 0.492 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (3.333) - Batch(s): 0.565 
(7.213) - AE Loss: 142742.875 (676377.688) - AE Rec Loss: 0.968 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.175 
(7.213) - AE Loss: 152809.656 (676377.688) - AE Rec Loss: 1.036 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.88 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.177 
(7.213) - AE Loss: 67429.109 (676377.688) - AE Rec Loss: 0.457 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.88 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.176 
(7.213) - AE Loss: 632928.375 (676377.688) - AE Rec Loss: 4.292 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.88 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.173 
(7.213) - AE Loss: 70586.016 (676377.688) - AE Rec Loss: 0.479 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.88 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.176 
(7.213) - AE Loss: 1587638.000 (676377.688) - AE Rec Loss: 10.767 (4.587) - Disc
Loss: 0.000 (0.000) - 2.88 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.964 
(6.113) - AE Loss: 133726.094 (603449.812) - AE Rec Loss: 0.907 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.963 
(6.113) - AE Loss: 232071.875 (603449.812) - AE Rec Loss: 1.574 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.963 
(6.113) - AE Loss: 252121.797 (603449.812) - AE Rec Loss: 1.710 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.326) - Batch(s): 3.964 
(6.113) - AE Loss: 417171.312 (603449.812) - AE Rec Loss: 2.829 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.964 
(6.113) - AE Loss: 291561.188 (603449.812) - AE Rec Loss: 1.977 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.348 
(6.113) - AE Loss: 155962.969 (603449.812) - AE Rec Loss: 1.058 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.745) - Batch(s): 0.565 
(4.858) - AE Loss: 151366.875 (572650.438) - AE Rec Loss: 1.027 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.745) - Batch(s): 1.142 
(4.858) - AE Loss: 208544.844 (572650.438) - AE Rec Loss: 1.414 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.142 
(4.858) - AE Loss: 309706.875 (572650.438) - AE Rec Loss: 2.100 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.745) - Batch(s): 1.138 
(4.858) - AE Loss: 103386.852 (572650.438) - AE Rec Loss: 0.701 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.140 
(4.858) - AE Loss: 511209.875 (572650.438) - AE Rec Loss: 3.467 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.745) - Batch(s): 1.141 
(4.858) - AE Loss: 767100.500 (572650.438) - AE Rec Loss: 5.202 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.241 
(4.123) - AE Loss: 1439760.625 (633130.000) - AE Rec Loss: 9.764 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.242 
(4.123) - AE Loss: 442190.625 (633130.000) - AE Rec Loss: 2.999 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.396) - Batch(s): 1.241 
(4.123) - AE Loss: 1621139.000 (633130.000) - AE Rec Loss: 10.994 (4.294) - Disc
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.243 
(4.123) - AE Loss: 130913.406 (633130.000) - AE Rec Loss: 0.888 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.396) - Batch(s): 0.566 
(4.123) - AE Loss: 1441179.750 (633130.000) - AE Rec Loss: 9.774 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.240 
(4.123) - AE Loss: 281316.438 (633130.000) - AE Rec Loss: 1.908 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.184) - Batch(s): 2.107 
(3.778) - AE Loss: 70287.125 (554779.750) - AE Rec Loss: 0.477 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.104 
(3.778) - AE Loss: 167607.656 (554779.750) - AE Rec Loss: 1.137 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.105 
(3.778) - AE Loss: 103947.242 (554779.750) - AE Rec Loss: 0.705 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 1.413 
(3.778) - AE Loss: 371026.594 (554779.750) - AE Rec Loss: 2.516 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.108 
(3.778) - AE Loss: 209999.844 (554779.750) - AE Rec Loss: 1.424 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.107 
(3.778) - AE Loss: 283713.562 (554779.750) - AE Rec Loss: 1.924 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.119 
(3.391) - AE Loss: 1825028.750 (598700.375) - AE Rec Loss: 12.377 (4.060) - Disc
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.118 
(3.391) - AE Loss: 202899.469 (598700.375) - AE Rec Loss: 1.376 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 0.568 
(3.391) - AE Loss: 110997.195 (598700.375) - AE Rec Loss: 0.753 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.117 
(3.391) - AE Loss: 1554628.250 (598700.375) - AE Rec Loss: 10.543 (4.060) - Disc
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.120 
(3.391) - AE Loss: 1490463.250 (598700.375) - AE Rec Loss: 10.108 (4.060) - Disc
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.117 
(3.391) - AE Loss: 2764766.250 (598700.375) - AE Rec Loss: 18.750 (4.060) - Disc
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.106 
(3.100) - AE Loss: 178210.656 (596513.500) - AE Rec Loss: 1.209 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.107 
(3.100) - AE Loss: 324640.250 (596513.500) - AE Rec Loss: 2.202 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.108 
(3.100) - AE Loss: 165170.406 (596513.500) - AE Rec Loss: 1.120 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 0.568 
(3.100) - AE Loss: 289285.562 (596513.500) - AE Rec Loss: 1.962 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.108 
(3.100) - AE Loss: 79269.609 (596513.500) - AE Rec Loss: 0.538 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.105 
(3.100) - AE Loss: 197589.984 (596513.500) - AE Rec Loss: 1.340 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.754 
(2.946) - AE Loss: 149644.828 (600716.812) - AE Rec Loss: 1.015 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.754 
(2.946) - AE Loss: 1471357.250 (600716.812) - AE Rec Loss: 9.978 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.754 
(2.946) - AE Loss: 274977.469 (600716.812) - AE Rec Loss: 1.865 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.262 
(2.946) - AE Loss: 340545.656 (600716.812) - AE Rec Loss: 2.309 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.755 
(2.946) - AE Loss: 78469.695 (600716.812) - AE Rec Loss: 0.532 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.754 
(2.946) - AE Loss: 1532357.500 (600716.812) - AE Rec Loss: 10.392 (4.074) - Disc
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.055 
(2.753) - AE Loss: 2237939.000 (636318.688) - AE Rec Loss: 15.177 (4.315) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.054 
(2.753) - AE Loss: 1549825.125 (636318.688) - AE Rec Loss: 10.510 (4.315) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.054 
(2.753) - AE Loss: 69737.547 (636318.688) - AE Rec Loss: 0.473 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.051 
(2.753) - AE Loss: 1634590.625 (636318.688) - AE Rec Loss: 11.085 (4.315) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.056 
(2.753) - AE Loss: 2787873.250 (636318.688) - AE Rec Loss: 18.906 (4.315) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 0.569 
(2.753) - AE Loss: 82387.570 (636318.688) - AE Rec Loss: 0.559 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.693) - Batch(s): 5.272 
(2.997) - AE Loss: 124554.414 (615716.562) - AE Rec Loss: 0.845 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.693) - Batch(s): 5.272 
(2.997) - AE Loss: 240944.359 (615716.562) - AE Rec Loss: 1.634 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 5.060 (0.693) - Batch(s): 5.627 
(2.997) - AE Loss: 1475849.875 (615716.562) - AE Rec Loss: 10.009 (4.176) - Disc
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.693) - Batch(s): 4.730 
(2.997) - AE Loss: 473803.125 (615716.562) - AE Rec Loss: 3.213 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.272 
(2.997) - AE Loss: 70566.305 (615716.562) - AE Rec Loss: 0.479 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.272 
(2.997) - AE Loss: 1528774.875 (615716.562) - AE Rec Loss: 10.368 (4.176) - Disc
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.293 
(2.851) - AE Loss: 63075.266 (587467.250) - AE Rec Loss: 0.428 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.295 
(2.851) - AE Loss: 190101.359 (587467.250) - AE Rec Loss: 1.289 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.293 
(2.851) - AE Loss: 210013.594 (587467.250) - AE Rec Loss: 1.424 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.796 
(2.851) - AE Loss: 117502.570 (587467.250) - AE Rec Loss: 0.797 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.68 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.295 
(2.851) - AE Loss: 141983.203 (587467.250) - AE Rec Loss: 0.963 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.612 (0.640) - Batch(s): 1.294 
(2.851) - AE Loss: 89585.953 (587467.250) - AE Rec Loss: 0.608 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.101 
(2.716) - AE Loss: 141354.031 (594993.125) - AE Rec Loss: 0.959 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.001 (0.594) - Batch(s): 1.149 
(2.716) - AE Loss: 353229.938 (594993.125) - AE Rec Loss: 2.395 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.585 (0.594) - Batch(s): 1.153 
(2.716) - AE Loss: 304748.750 (594993.125) - AE Rec Loss: 2.067 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.150 
(2.716) - AE Loss: 334777.656 (594993.125) - AE Rec Loss: 2.270 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.001 (0.594) - Batch(s): 0.568 
(2.716) - AE Loss: 1448518.500 (594993.125) - AE Rec Loss: 9.823 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.147 
(2.716) - AE Loss: 2793855.000 (594993.125) - AE Rec Loss: 18.947 (4.035) - Disc
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 3.896 
(2.814) - AE Loss: 112232.203 (583840.188) - AE Rec Loss: 0.761 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.957 (0.594) - Batch(s): 3.896 
(2.814) - AE Loss: 82938.469 (583840.188) - AE Rec Loss: 0.562 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 2.380 (0.594) - Batch(s): 4.249 
(2.814) - AE Loss: 178545.469 (583840.188) - AE Rec Loss: 1.211 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 3.896 
(2.814) - AE Loss: 200780.344 (583840.188) - AE Rec Loss: 1.362 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 3.392 
(2.814) - AE Loss: 330153.625 (583840.188) - AE Rec Loss: 2.239 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 3.679 (0.594) - Batch(s): 4.256 
(2.814) - AE Loss: 1544136.750 (583840.188) - AE Rec Loss: 10.472 (3.959) - Disc
Loss: 0.000 (0.000) - 7.63 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.235 (0.574) - Batch(s): 3.355 
(2.887) - AE Loss: 228519.297 (583514.062) - AE Rec Loss: 1.550 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.946 
(2.887) - AE Loss: 136553.453 (583514.062) - AE Rec Loss: 0.926 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 3.277 (0.574) - Batch(s): 3.946 
(2.887) - AE Loss: 263999.438 (583514.062) - AE Rec Loss: 1.790 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.946 
(2.887) - AE Loss: 196732.500 (583514.062) - AE Rec Loss: 1.334 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.946 
(2.887) - AE Loss: 292884.125 (583514.062) - AE Rec Loss: 1.986 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.948 
(2.887) - AE Loss: 169114.781 (583514.062) - AE Rec Loss: 1.147 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.093 
(2.772) - AE Loss: 272146.781 (580215.438) - AE Rec Loss: 1.846 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.091 
(2.772) - AE Loss: 1625077.750 (580215.438) - AE Rec Loss: 11.021 (3.935) - Disc
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.569 
(2.772) - AE Loss: 484271.000 (580215.438) - AE Rec Loss: 3.284 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.094 
(2.772) - AE Loss: 656592.125 (580215.438) - AE Rec Loss: 4.453 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.097 
(2.772) - AE Loss: 496414.656 (580215.438) - AE Rec Loss: 3.367 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.092 
(2.772) - AE Loss: 302702.562 (580215.438) - AE Rec Loss: 2.053 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.49 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.474 
(2.824) - AE Loss: 166342.406 (584446.375) - AE Rec Loss: 1.128 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.126 (0.523) - Batch(s): 3.828 
(2.824) - AE Loss: 203184.219 (584446.375) - AE Rec Loss: 1.378 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.523) - Batch(s): 2.947 
(2.824) - AE Loss: 77089.562 (584446.375) - AE Rec Loss: 0.523 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.14 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.523) - Batch(s): 3.474 
(2.824) - AE Loss: 131113.938 (584446.375) - AE Rec Loss: 0.889 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 3.260 (0.523) - Batch(s): 3.834 
(2.824) - AE Loss: 376335.188 (584446.375) - AE Rec Loss: 2.552 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.523) - Batch(s): 3.474 
(2.824) - AE Loss: 79134.609 (584446.375) - AE Rec Loss: 0.537 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.15 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.263 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 199403.047 (582335.688) - AE Rec Loss: 1.352 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 2019225.500 (582335.688) - AE Rec Loss: 13.694 (3.949) - Disc
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 1646694.000 (582335.688) - AE Rec Loss: 11.167 (3.949) - Disc
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.495) - Batch(s): 0.659 
(2.742) - AE Loss: 148341.375 (582335.688) - AE Rec Loss: 1.006 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 187091.078 (582335.688) - AE Rec Loss: 1.269 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 544012.500 (582335.688) - AE Rec Loss: 3.689 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.37 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.047 
(2.651) - AE Loss: 158847.047 (606794.688) - AE Rec Loss: 1.077 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.050 
(2.651) - AE Loss: 1620962.250 (606794.688) - AE Rec Loss: 10.993 (4.115) - Disc
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.051 
(2.651) - AE Loss: 1371591.500 (606794.688) - AE Rec Loss: 9.302 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.001 (0.469) - Batch(s): 0.570 
(2.651) - AE Loss: 342123.938 (606794.688) - AE Rec Loss: 2.320 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.52 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.053 
(2.651) - AE Loss: 1666138.625 (606794.688) - AE Rec Loss: 11.299 (4.115) - Disc
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.049 
(2.651) - AE Loss: 2730400.250 (606794.688) - AE Rec Loss: 18.517 (4.115) - Disc
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.794 
(2.694) - AE Loss: 243697.891 (618744.250) - AE Rec Loss: 1.653 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.13 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.659 
(2.694) - AE Loss: 1602240.625 (618744.250) - AE Rec Loss: 10.866 (4.196) - Disc
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.305 
(2.694) - AE Loss: 286577.125 (618744.250) - AE Rec Loss: 1.943 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.305 
(2.694) - AE Loss: 153488.781 (618744.250) - AE Rec Loss: 1.041 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 3.091 (0.458) - Batch(s): 3.663 
(2.694) - AE Loss: 184858.203 (618744.250) - AE Rec Loss: 1.254 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.305 
(2.694) - AE Loss: 1381747.000 (618744.250) - AE Rec Loss: 9.371 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

attempting to save
[[36m2023-11-29 03:42:42,050[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:42:45,122[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:42:45,901[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:42:45,906[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:42:45,911[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:42:45,917[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:42:45,922[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:42:45,926[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:42:45,931[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:42:45,935[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:42:46,885[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:42:50,601[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:43:07,056[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,068[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,200[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,350[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,350[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,357[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:43:09,207[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,215[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,313[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,498[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,501[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,680[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:09,784[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:09,825[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:09,893[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,114[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,124[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,216[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 03:43:10,711[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:43:10,711[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 03:43:10,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
[[36m2023-11-29 03:43:10,713[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Running in inference mode: False
len(valid_dataset) = 4
len(train_dataloader) = 2279
[[36m2023-11-29 03:43:10,715[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
[[36m2023-11-29 03:43:10,716[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
Reached 3 on node 2
Reached 5 on node 2
Reached 3 on node 4Reached end on node 2

Reached 5 on node 4
Reached end on node 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 5
batch_size = 2, learning rate = 4.5e-06
Reached 5 on node 5
Reached end on node 5
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 0
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:50:43,656[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:43,933[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:43,939[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:43,966[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:43,967[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,056[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:50:45,911[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,064[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,106[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,108[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,120[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,212[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,462[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,718[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,802[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,832[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,849[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,879[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 03:50:47,563[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:50:47,563[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 03:50:47,567[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
[[36m2023-11-29 03:50:47,567[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:50:47,567[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:50:47,568[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(train_dataloader) = 2279
len(valid_dataset) = 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 1.3 on node 5
Reached 5 on node 3Reached 1.4 on node 5

Reached end on node 3
Reached 2 on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 5
Reached 3 on node 2Reached 5 on node 5

Reached end on node 5
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached 3 on node 2
Reached end on node 5Reached 5 on node 2

Reached end on node 2
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.3 on node 5Reached 1.4 on node 2

Reached 1.4 on node 5
Reached 1.3 on node 4Reached 1.3 on node 1Reached 2 on node 2


Reached 1.4 on node 4Reached 1.4 on node 1

Reached 2 on node 5
Reached 2 on node 4
Reached 2 on node 1
Reached 3 on node 2
Reached 3 on node 5
Reached 5 on node 2
Reached 3 on node 1Reached 3 on node 4

Reached 5 on node 1
Reached end on node 2Reached 5 on node 4Reached 5 on node 5

Reached 1.3 on node 0
Reached 1.3 on node 3

Reached end on node 1Reached 1.4 on node 0

Reached 1.4 on node 3Reached end on node 4

Reached end on node 5
Reached 2 on node 0
Reached 2 on node 3
Reached 3 on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached 5 on node 0
Reached end on node 3
Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 1 on node 2Reached 2 on node 3

Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3Reached 1 on node 2

Reached 1.4 on node 3Reached 1.4 on node 2

Reached 2 on node 3Reached 2 on node 2

Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached end on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 1.4 on node 3Reached 2 on node 2

Reached 2 on node 3
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 1 on node 4
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 1.4 on node 3Reached 2 on node 5

Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:50:49,239[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 3
Reached end on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 4
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 4
Reached end on node 1
[[36m2023-11-29 03:50:50,555[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:50:51,165[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:50:51,165[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 03:50:51,170[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:50:51,174[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:50:51,176[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <181/2280>] - Data(s): 6.890 (5.574) - Batch(s): 10.046 
(9.963) - AE Loss: 1799702.750 (835197.438) - AE Rec Loss: 12.205 (5.664) - Disc
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 5.526 (5.574) - Batch(s): 10.041 
(9.963) - AE Loss: 72390.273 (835197.438) - AE Rec Loss: 0.491 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 5.882 (5.574) - Batch(s): 9.860 
(9.963) - AE Loss: 1583662.500 (835197.438) - AE Rec Loss: 10.740 (5.664) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 6.271 (5.574) - Batch(s): 10.121 
(9.963) - AE Loss: 1741913.375 (835197.438) - AE Rec Loss: 11.813 (5.664) - Disc
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 2.361 (5.574) - Batch(s): 10.066 
(9.963) - AE Loss: 112029.898 (835197.438) - AE Rec Loss: 0.760 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 5.577 (5.574) - Batch(s): 9.820 
(9.963) - AE Loss: 752223.438 (835197.438) - AE Rec Loss: 5.101 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.94 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.352 
(5.624) - AE Loss: 67026.812 (676363.688) - AE Rec Loss: 0.455 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.349 
(5.624) - AE Loss: 71283.023 (676363.688) - AE Rec Loss: 0.483 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.353 
(5.624) - AE Loss: 632475.000 (676363.688) - AE Rec Loss: 4.289 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.353 
(5.624) - AE Loss: 1588104.250 (676363.688) - AE Rec Loss: 10.770 (4.587) - Disc
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.351 
(5.624) - AE Loss: 153033.297 (676363.688) - AE Rec Loss: 1.038 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (2.787) - Batch(s): 0.563 
(5.624) - AE Loss: 142742.875 (676363.688) - AE Rec Loss: 0.968 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.698 
(5.959) - AE Loss: 133173.406 (603447.812) - AE Rec Loss: 0.903 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.697 
(5.959) - AE Loss: 252997.906 (603447.812) - AE Rec Loss: 1.716 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.697 
(5.959) - AE Loss: 417085.375 (603447.812) - AE Rec Loss: 2.829 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.698 
(5.959) - AE Loss: 232055.016 (603447.812) - AE Rec Loss: 1.574 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.083) - Batch(s): 5.891 
(5.959) - AE Loss: 155962.969 (603447.812) - AE Rec Loss: 1.058 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.698 
(5.959) - AE Loss: 291641.469 (603447.812) - AE Rec Loss: 1.978 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.101 
(4.734) - AE Loss: 103936.156 (572640.938) - AE Rec Loss: 0.705 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.78 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.105 
(4.734) - AE Loss: 309310.688 (572640.938) - AE Rec Loss: 2.098 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.562) - Batch(s): 1.105 
(4.734) - AE Loss: 208069.312 (572640.938) - AE Rec Loss: 1.411 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.562) - Batch(s): 1.105 
(4.734) - AE Loss: 767668.750 (572640.938) - AE Rec Loss: 5.206 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.001 (1.562) - Batch(s): 0.562 
(4.734) - AE Loss: 151364.969 (572640.938) - AE Rec Loss: 1.027 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.103 
(4.734) - AE Loss: 511298.875 (572640.938) - AE Rec Loss: 3.467 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.250) - Batch(s): 1.167 
(4.011) - AE Loss: 129859.312 (633100.562) - AE Rec Loss: 0.881 (4.293) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.250) - Batch(s): 1.168 
(4.011) - AE Loss: 1621146.000 (633100.562) - AE Rec Loss: 10.994 (4.293) - Disc
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.250) - Batch(s): 1.168 
(4.011) - AE Loss: 442128.062 (633100.562) - AE Rec Loss: 2.998 (4.293) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.250) - Batch(s): 0.563 
(4.011) - AE Loss: 1441106.250 (633100.562) - AE Rec Loss: 9.773 (4.293) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.250) - Batch(s): 1.164 
(4.011) - AE Loss: 281569.469 (633100.562) - AE Rec Loss: 1.910 (4.293) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.165 
(4.011) - AE Loss: 1439375.625 (633100.562) - AE Rec Loss: 9.761 (4.293) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 69791.406 (554740.875) - AE Rec Loss: 0.473 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 168271.781 (554740.875) - AE Rec Loss: 1.141 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 103382.906 (554740.875) - AE Rec Loss: 0.701 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.785 
(3.796) - AE Loss: 283901.938 (554740.875) - AE Rec Loss: 1.925 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 211090.562 (554740.875) - AE Rec Loss: 1.432 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.042 
(3.796) - AE Loss: 370793.625 (554740.875) - AE Rec Loss: 2.515 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.135 
(3.409) - AE Loss: 1824465.250 (598665.938) - AE Rec Loss: 12.373 (4.060) - Disc
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.135 
(3.409) - AE Loss: 1490638.250 (598665.938) - AE Rec Loss: 10.109 (4.060) - Disc
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.001 (0.918) - Batch(s): 1.134 
(3.409) - AE Loss: 202828.281 (598665.938) - AE Rec Loss: 1.376 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.132 
(3.409) - AE Loss: 2764609.500 (598665.938) - AE Rec Loss: 18.749 (4.060) - Disc
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.001 (0.918) - Batch(s): 0.564 
(3.409) - AE Loss: 111260.125 (598665.938) - AE Rec Loss: 0.755 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.134 
(3.409) - AE Loss: 1555653.625 (598665.938) - AE Rec Loss: 10.550 (4.060) - Disc
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 164423.219 (596501.688) - AE Rec Loss: 1.115 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.001 (0.804) - Batch(s): 1.276 
(3.135) - AE Loss: 80877.578 (596501.688) - AE Rec Loss: 0.548 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 324852.188 (596501.688) - AE Rec Loss: 2.203 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.272 
(3.135) - AE Loss: 198294.562 (596501.688) - AE Rec Loss: 1.345 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.98 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.274 
(3.135) - AE Loss: 177838.297 (596501.688) - AE Rec Loss: 1.206 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 0.563 
(3.135) - AE Loss: 289039.500 (596501.688) - AE Rec Loss: 1.960 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.346 
(2.929) - AE Loss: 149374.750 (600690.312) - AE Rec Loss: 1.013 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.345 
(2.929) - AE Loss: 1532502.500 (600690.312) - AE Rec Loss: 10.393 (4.074) - Disc
Loss: 0.000 (0.000) - 5.23 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 76764.102 (600690.312) - AE Rec Loss: 0.521 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 1471348.750 (600690.312) - AE Rec Loss: 9.978 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.001 (0.714) - Batch(s): 0.627 
(2.929) - AE Loss: 340369.125 (600690.312) - AE Rec Loss: 2.308 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.345 
(2.929) - AE Loss: 275317.000 (600690.312) - AE Rec Loss: 1.867 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.299 
(2.760) - AE Loss: 1635455.250 (636311.062) - AE Rec Loss: 11.091 (4.315) - Disc
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.302 
(2.760) - AE Loss: 2787534.250 (636311.062) - AE Rec Loss: 18.904 (4.315) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.302 
(2.760) - AE Loss: 2237854.250 (636311.062) - AE Rec Loss: 15.176 (4.315) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.301 
(2.760) - AE Loss: 69717.086 (636311.062) - AE Rec Loss: 0.473 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.643) - Batch(s): 0.564 
(2.760) - AE Loss: 81892.148 (636311.062) - AE Rec Loss: 0.555 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.301 
(2.760) - AE Loss: 1549963.125 (636311.062) - AE Rec Loss: 10.511 (4.315) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.585) - Batch(s): 1.264 
(2.619) - AE Loss: 70188.133 (615732.562) - AE Rec Loss: 0.476 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.263 
(2.619) - AE Loss: 241649.797 (615732.562) - AE Rec Loss: 1.639 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.585) - Batch(s): 1.264 
(2.619) - AE Loss: 1530021.000 (615732.562) - AE Rec Loss: 10.376 (4.176) - Disc
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.585) - Batch(s): 1.262 
(2.619) - AE Loss: 124692.273 (615732.562) - AE Rec Loss: 0.846 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.585) - Batch(s): 0.564 
(2.619) - AE Loss: 474738.312 (615732.562) - AE Rec Loss: 3.220 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.585) - Batch(s): 1.259 
(2.619) - AE Loss: 1475737.375 (615732.562) - AE Rec Loss: 10.008 (4.176) - Disc
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 2.698 (0.568) - Batch(s): 3.337 
(2.674) - AE Loss: 210121.094 (587502.250) - AE Rec Loss: 1.425 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.568) - Batch(s): 3.336 
(2.674) - AE Loss: 63144.625 (587502.250) - AE Rec Loss: 0.428 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.568) - Batch(s): 3.338 
(2.674) - AE Loss: 89054.094 (587502.250) - AE Rec Loss: 0.604 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 2.662 
(2.674) - AE Loss: 118086.133 (587502.250) - AE Rec Loss: 0.801 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.568) - Batch(s): 3.336 
(2.674) - AE Loss: 190974.781 (587502.250) - AE Rec Loss: 1.295 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 3.336 
(2.674) - AE Loss: 141506.453 (587502.250) - AE Rec Loss: 0.960 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.202 
(2.557) - AE Loss: 150527.750 (595288.125) - AE Rec Loss: 1.021 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 0.564 
(2.557) - AE Loss: 1450315.500 (595288.125) - AE Rec Loss: 9.836 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.49 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.204 
(2.557) - AE Loss: 357983.000 (595288.125) - AE Rec Loss: 2.428 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.49 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.001 (0.524) - Batch(s): 1.203 
(2.557) - AE Loss: 305660.750 (595288.125) - AE Rec Loss: 2.073 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.49 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.204 
(2.557) - AE Loss: 334738.969 (595288.125) - AE Rec Loss: 2.270 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.200 
(2.557) - AE Loss: 2793901.500 (595288.125) - AE Rec Loss: 18.947 (4.037) - Disc
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.244 
(2.459) - AE Loss: 118198.414 (584414.188) - AE Rec Loss: 0.802 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.245 
(2.459) - AE Loss: 1546281.625 (584414.188) - AE Rec Loss: 10.486 (3.963) - Disc
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 0.564 
(2.459) - AE Loss: 337736.688 (584414.188) - AE Rec Loss: 2.290 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.71 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.245 
(2.459) - AE Loss: 207861.750 (584414.188) - AE Rec Loss: 1.410 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.71 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 1.245 
(2.459) - AE Loss: 83257.602 (584414.188) - AE Rec Loss: 0.565 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.71 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.244 
(2.459) - AE Loss: 184308.656 (584414.188) - AE Rec Loss: 1.250 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.72 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.001 (0.466) - Batch(s): 2.100 
(2.476) - AE Loss: 235237.547 (584378.875) - AE Rec Loss: 1.595 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.778 
(2.476) - AE Loss: 202889.453 (584378.875) - AE Rec Loss: 1.376 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.777 
(2.476) - AE Loss: 298028.188 (584378.875) - AE Rec Loss: 2.021 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.776 
(2.476) - AE Loss: 174335.531 (584378.875) - AE Rec Loss: 1.182 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.776 
(2.476) - AE Loss: 140936.500 (584378.875) - AE Rec Loss: 0.956 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 2.136 (0.466) - Batch(s): 2.778 
(2.476) - AE Loss: 270375.094 (584378.875) - AE Rec Loss: 1.834 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.123 
(2.389) - AE Loss: 1619891.750 (580707.062) - AE Rec Loss: 10.986 (3.938) - Disc
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.001 (0.437) - Batch(s): 1.125 
(2.389) - AE Loss: 269050.188 (580707.062) - AE Rec Loss: 1.825 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.001 (0.437) - Batch(s): 1.126 
(2.389) - AE Loss: 487927.688 (580707.062) - AE Rec Loss: 3.309 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.123 
(2.389) - AE Loss: 289981.562 (580707.062) - AE Rec Loss: 1.967 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.001 (0.437) - Batch(s): 0.565 
(2.389) - AE Loss: 481397.062 (580707.062) - AE Rec Loss: 3.265 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.126 
(2.389) - AE Loss: 654596.250 (580707.062) - AE Rec Loss: 4.439 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 122014.000 (584585.625) - AE Rec Loss: 0.827 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 189620.125 (584585.625) - AE Rec Loss: 1.286 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.60 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.565 
(2.319) - AE Loss: 75867.047 (584585.625) - AE Rec Loss: 0.515 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 366799.000 (584585.625) - AE Rec Loss: 2.488 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 158862.250 (584585.625) - AE Rec Loss: 1.077 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.260 
(2.319) - AE Loss: 77164.719 (584585.625) - AE Rec Loss: 0.523 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.115 (0.389) - Batch(s): 1.413 
(2.265) - AE Loss: 2013434.250 (582029.438) - AE Rec Loss: 13.654 (3.947) - Disc
Loss: 0.000 (0.000) - 7.83 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.389) - Batch(s): 1.412 
(2.265) - AE Loss: 192808.969 (582029.438) - AE Rec Loss: 1.308 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.411 
(2.265) - AE Loss: 172280.609 (582029.438) - AE Rec Loss: 1.168 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.413 
(2.265) - AE Loss: 538413.938 (582029.438) - AE Rec Loss: 3.651 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.78 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.389) - Batch(s): 0.633 
(2.265) - AE Loss: 140383.469 (582029.438) - AE Rec Loss: 0.952 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.413 
(2.265) - AE Loss: 1642571.250 (582029.438) - AE Rec Loss: 11.139 (3.947) - Disc
Loss: 0.000 (0.000) - 7.78 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.182 
(2.205) - AE Loss: 1611177.250 (605738.500) - AE Rec Loss: 10.926 (4.108) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.001 (0.369) - Batch(s): 1.182 
(2.205) - AE Loss: 1664819.750 (605738.500) - AE Rec Loss: 11.290 (4.108) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.180 
(2.205) - AE Loss: 134580.000 (605738.500) - AE Rec Loss: 0.913 (4.108) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.001 (0.369) - Batch(s): 0.565 
(2.205) - AE Loss: 308695.312 (605738.500) - AE Rec Loss: 2.093 (4.108) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.181 
(2.205) - AE Loss: 2729161.750 (605738.500) - AE Rec Loss: 18.508 (4.108) - Disc
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.183 
(2.205) - AE Loss: 1362198.250 (605738.500) - AE Rec Loss: 9.238 (4.108) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.294 
(2.157) - AE Loss: 109589.703 (617109.375) - AE Rec Loss: 0.743 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.21 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.294 
(2.157) - AE Loss: 180736.359 (617109.375) - AE Rec Loss: 1.226 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.291 
(2.157) - AE Loss: 1599512.625 (617109.375) - AE Rec Loss: 10.847 (4.185) - Disc
Loss: 0.000 (0.000) - 8.23 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.001 (0.350) - Batch(s): 0.565 
(2.157) - AE Loss: 239350.766 (617109.375) - AE Rec Loss: 1.623 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.22 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.293 
(2.157) - AE Loss: 282293.750 (617109.375) - AE Rec Loss: 1.914 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.22 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.292 
(2.157) - AE Loss: 1341441.625 (617109.375) - AE Rec Loss: 9.097 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

attempting to save
[[36m2023-11-29 03:51:39,770[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 03:51:40,336[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:51:40,467[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:51:40,474[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:51:40,481[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:51:40,491[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:51:40,500[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:51:40,510[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:51:40,520[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:51:40,530[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:51:40,880[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:51:42,884[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 03:51:46,490[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 03:51:46,494[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 03:51:47,748[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 03:51:47,749[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 03:51:47,766[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 03:51:47,795[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <201/2280>] - Data(s): 0.000 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 218604.406 (602837.000) - AE Rec Loss: 1.483 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.85 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.628 
(2.477) - AE Loss: 97272.531 (602837.000) - AE Rec Loss: 0.660 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.81 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.628 
(2.477) - AE Loss: 279196.094 (602837.000) - AE Rec Loss: 1.893 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.85 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 0.629 
(2.477) - AE Loss: 467564.281 (602837.000) - AE Rec Loss: 3.171 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.85 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.628 
(2.477) - AE Loss: 262528.000 (602837.000) - AE Rec Loss: 1.780 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.86 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 533475.750 (602837.000) - AE Rec Loss: 3.618 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.81 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.113 
(2.413) - AE Loss: 241731.031 (613918.125) - AE Rec Loss: 1.639 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.110 
(2.413) - AE Loss: 1813561.625 (613918.125) - AE Rec Loss: 12.299 (4.163) - Disc
Loss: 0.000 (0.000) - 9.97 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.109 
(2.413) - AE Loss: 635849.312 (613918.125) - AE Rec Loss: 4.312 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.02 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (0.318) - Batch(s): 0.565 
(2.413) - AE Loss: 1463328.000 (613918.125) - AE Rec Loss: 9.924 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.112 
(2.413) - AE Loss: 1639452.250 (613918.125) - AE Rec Loss: 11.118 (4.163) - Disc
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.111 
(2.413) - AE Loss: 516854.500 (613918.125) - AE Rec Loss: 3.505 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.123 
(2.355) - AE Loss: 199121.125 (638830.250) - AE Rec Loss: 1.350 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.19 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.124 
(2.355) - AE Loss: 194755.109 (638830.250) - AE Rec Loss: 1.321 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (0.305) - Batch(s): 0.565 
(2.355) - AE Loss: 1675438.625 (638830.250) - AE Rec Loss: 11.362 (4.332) - Disc
Loss: 0.000 (0.000) - 10.18 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.125 
(2.355) - AE Loss: 3023841.250 (638830.250) - AE Rec Loss: 20.507 (4.332) - Disc
Loss: 0.000 (0.000) - 10.18 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.125 
(2.355) - AE Loss: 1821264.000 (638830.250) - AE Rec Loss: 12.351 (4.332) - Disc
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.125 
(2.355) - AE Loss: 1450162.125 (638830.250) - AE Rec Loss: 9.835 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.18 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 80260.008 (636527.312) - AE Rec Loss: 0.544 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.35 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.146 
(2.302) - AE Loss: 105677.883 (636527.312) - AE Rec Loss: 0.717 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.34 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.144 
(2.302) - AE Loss: 500984.625 (636527.312) - AE Rec Loss: 3.398 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.30 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.144 
(2.302) - AE Loss: 397558.438 (636527.312) - AE Rec Loss: 2.696 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.34 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.001 (0.292) - Batch(s): 0.629 
(2.302) - AE Loss: 327860.938 (636527.312) - AE Rec Loss: 2.223 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.34 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.144 
(2.302) - AE Loss: 1542175.500 (636527.312) - AE Rec Loss: 10.459 (4.317) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (0.280) - Batch(s): 1.118 
(2.253) - AE Loss: 182650.797 (640285.188) - AE Rec Loss: 1.239 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.116 
(2.253) - AE Loss: 1705577.250 (640285.188) - AE Rec Loss: 11.567 (4.342) - Disc
Loss: 0.000 (0.000) - 10.46 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.115 
(2.253) - AE Loss: 282990.312 (640285.188) - AE Rec Loss: 1.919 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.51 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.568 
(2.253) - AE Loss: 1667947.750 (640285.188) - AE Rec Loss: 11.311 (4.342) - Disc
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.117 
(2.253) - AE Loss: 335295.969 (640285.188) - AE Rec Loss: 2.274 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.47 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.117 
(2.253) - AE Loss: 252491.688 (640285.188) - AE Rec Loss: 1.712 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.086 
(2.207) - AE Loss: 1601898.000 (633752.812) - AE Rec Loss: 10.864 (4.298) - Disc
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.081 
(2.207) - AE Loss: 118266.641 (633752.812) - AE Rec Loss: 0.802 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.61 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.083 
(2.207) - AE Loss: 309163.688 (633752.812) - AE Rec Loss: 2.097 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.083 
(2.207) - AE Loss: 1885557.375 (633752.812) - AE Rec Loss: 12.787 (4.298) - Disc
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 0.568 
(2.207) - AE Loss: 406507.062 (633752.812) - AE Rec Loss: 2.757 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.080 
(2.207) - AE Loss: 64851.516 (633752.812) - AE Rec Loss: 0.440 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.66 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.304 
(2.283) - AE Loss: 3476769.000 (646624.188) - AE Rec Loss: 23.578 (4.385) - Disc
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.305 
(2.283) - AE Loss: 468388.031 (646624.188) - AE Rec Loss: 3.176 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.305 
(2.283) - AE Loss: 269663.375 (646624.188) - AE Rec Loss: 1.829 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.30 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 3.119 (0.269) - Batch(s): 3.750 
(2.283) - AE Loss: 212271.297 (646624.188) - AE Rec Loss: 1.440 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.305 
(2.283) - AE Loss: 1492745.875 (646624.188) - AE Rec Loss: 10.123 (4.385) - Disc
Loss: 0.000 (0.000) - 11.30 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.305 
(2.283) - AE Loss: 1511141.000 (646624.188) - AE Rec Loss: 10.248 (4.385) - Disc
Loss: 0.000 (0.000) - 11.34 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:53:50,153[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,195[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,236[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,269[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,281[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,301[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:53:52,348[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,410[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,437[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,442[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,451[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,451[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,101[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,117[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,226[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,244[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 03:53:53,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:53:53,254[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 03:53:53,255[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
[[36m2023-11-29 03:53:53,256[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
[[36m2023-11-29 03:53:53,260[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
[[36m2023-11-29 03:53:53,260[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(train_dataset) = 54706
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 0
Reached 1.4 on node 0
=> Preparing criterion 
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1 on node 2
Reached 1.2 on node 5
Reached 1.2 on node 2
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 3 on node 1
Reached 2 on node 0
Reached 1.3 on node 3Reached 5 on node 1

Reached 1.4 on node 3
Reached end on node 1
Reached 2 on node 3
Reached 3 on node 0
Reached 5 on node 0
Reached 3 on node 3
Reached end on node 0
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 1.4 on node 2
Reached 2 on node 2Reached 2 on node 4

Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 2
Reached 1 on node 4Reached 1.4 on node 2

Reached 2 on node 2
Reached 3 on node 2Reached 1.4 on node 5

Reached 3 on node 2Reached 1.4 on node 4

Reached 2 on node 5Reached 3 on node 2

Reached 2 on node 4Reached 3 on node 2

Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 1 on node 5
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 1 on node 5Reached 2 on node 4

Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 1.4 on node 5
Reached 3 on node 4
Reached 2 on node 5
Reached 5 on node 4
Reached end on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5Reached end on node 3

Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 03:53:55,011[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 5
Reached end on node 2
[[36m2023-11-29 03:53:57,683[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:53:58,890[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 03:53:58,891[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 03:53:58,895[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 03:53:58,898[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 03:53:58,899[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 5.573 (5.733) - Batch(s): 11.327 
(11.317) - AE Loss: 226666.266 (317748.375) - AE Rec Loss: 1.537 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 2.940 (5.733) - Batch(s): 11.314 
(11.317) - AE Loss: 280418.500 (317748.375) - AE Rec Loss: 1.902 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 3.661 (5.733) - Batch(s): 11.325 
(11.317) - AE Loss: 261893.375 (317748.375) - AE Rec Loss: 1.776 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.281 (5.733) - Batch(s): 11.325 
(11.317) - AE Loss: 94248.547 (317748.375) - AE Rec Loss: 0.639 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 10.009 (5.733) - Batch(s): 11.275 
(11.317) - AE Loss: 467364.375 (317748.375) - AE Rec Loss: 3.170 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.422 (5.733) - Batch(s): 11.315 
(11.317) - AE Loss: 533063.375 (317748.375) - AE Rec Loss: 3.615 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.242 
(6.251) - AE Loss: 1807143.500 (588477.688) - AE Rec Loss: 12.255 (3.991) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.244 
(6.251) - AE Loss: 256024.375 (588477.688) - AE Rec Loss: 1.736 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.244 
(6.251) - AE Loss: 526411.500 (588477.688) - AE Rec Loss: 3.570 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.239 
(6.251) - AE Loss: 644518.000 (588477.688) - AE Rec Loss: 4.371 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 0.564 
(6.251) - AE Loss: 1470734.625 (588477.688) - AE Rec Loss: 9.974 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.241 
(6.251) - AE Loss: 1645327.000 (588477.688) - AE Rec Loss: 11.158 (3.991) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.374 
(4.609) - AE Loss: 201011.828 (791981.438) - AE Rec Loss: 1.363 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.373 
(4.609) - AE Loss: 3025732.000 (791981.438) - AE Rec Loss: 20.520 (5.371) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.375 
(4.609) - AE Loss: 1838622.250 (791981.438) - AE Rec Loss: 12.469 (5.371) - Disc
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.377 
(4.609) - AE Loss: 1470341.500 (791981.438) - AE Rec Loss: 9.971 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.375 
(4.609) - AE Loss: 229101.875 (791981.438) - AE Rec Loss: 1.554 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.923) - Batch(s): 0.762 
(4.609) - AE Loss: 1676085.625 (791981.438) - AE Rec Loss: 11.367 (5.371) - Disc
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.313 
(4.020) - AE Loss: 492242.719 (738389.312) - AE Rec Loss: 3.338 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 1.048 (1.465) - Batch(s): 1.619 
(4.020) - AE Loss: 322197.250 (738389.312) - AE Rec Loss: 2.185 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.317 
(4.020) - AE Loss: 101400.484 (738389.312) - AE Rec Loss: 0.688 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.315 
(4.020) - AE Loss: 392782.344 (738389.312) - AE Rec Loss: 2.664 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.310 
(4.020) - AE Loss: 77328.562 (738389.312) - AE Rec Loss: 0.524 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.314 
(4.020) - AE Loss: 1537127.625 (738389.312) - AE Rec Loss: 10.424 (5.008) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.096 
(3.426) - AE Loss: 1703054.625 (734964.000) - AE Rec Loss: 11.550 (4.984) - Disc
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.172) - Batch(s): 0.564 
(3.426) - AE Loss: 1659806.375 (734964.000) - AE Rec Loss: 11.256 (4.984) - Disc
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.096 
(3.426) - AE Loss: 327817.938 (734964.000) - AE Rec Loss: 2.223 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.092 
(3.426) - AE Loss: 268745.500 (734964.000) - AE Rec Loss: 1.823 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.098 
(3.426) - AE Loss: 171981.172 (734964.000) - AE Rec Loss: 1.166 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.098 
(3.426) - AE Loss: 248016.375 (734964.000) - AE Rec Loss: 1.682 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.095 
(3.133) - AE Loss: 386821.812 (689423.062) - AE Rec Loss: 2.623 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.720 
(3.133) - AE Loss: 111985.164 (689423.062) - AE Rec Loss: 0.759 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.722 
(3.133) - AE Loss: 1878382.875 (689423.062) - AE Rec Loss: 12.739 (4.675) - Disc
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.720 
(3.133) - AE Loss: 1602660.750 (689423.062) - AE Rec Loss: 10.869 (4.675) - Disc
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.721 
(3.133) - AE Loss: 60872.203 (689423.062) - AE Rec Loss: 0.413 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.990) - Batch(s): 1.722 
(3.133) - AE Loss: 290788.750 (689423.062) - AE Rec Loss: 1.972 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.118 
(2.839) - AE Loss: 241961.062 (729835.812) - AE Rec Loss: 1.641 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.120 
(2.839) - AE Loss: 463181.344 (729835.812) - AE Rec Loss: 3.141 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.114 
(2.839) - AE Loss: 3473943.250 (729835.812) - AE Rec Loss: 23.559 (4.950) - Disc
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.121 
(2.839) - AE Loss: 1507533.000 (729835.812) - AE Rec Loss: 10.224 (4.950) - Disc
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.849) - Batch(s): 0.565 
(2.839) - AE Loss: 212345.844 (729835.812) - AE Rec Loss: 1.440 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.118 
(2.839) - AE Loss: 1482335.500 (729835.812) - AE Rec Loss: 10.053 (4.950) - Disc
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.029 
(2.608) - AE Loss: 81638.125 (714499.938) - AE Rec Loss: 0.554 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.033 
(2.608) - AE Loss: 1589768.500 (714499.938) - AE Rec Loss: 10.781 (4.846) - Disc
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.743) - Batch(s): 1.034 
(2.608) - AE Loss: 1734296.625 (714499.938) - AE Rec Loss: 11.761 (4.846) - Disc
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.565 
(2.608) - AE Loss: 371706.688 (714499.938) - AE Rec Loss: 2.521 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.743) - Batch(s): 1.035 
(2.608) - AE Loss: 1907433.125 (714499.938) - AE Rec Loss: 12.936 (4.846) - Disc
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.033 
(2.608) - AE Loss: 97708.086 (714499.938) - AE Rec Loss: 0.663 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.110 
(2.659) - AE Loss: 125511.336 (720151.125) - AE Rec Loss: 0.851 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.110 
(2.659) - AE Loss: 315367.719 (720151.125) - AE Rec Loss: 2.139 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 59553.805 (720151.125) - AE Rec Loss: 0.404 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.110 
(2.659) - AE Loss: 449393.125 (720151.125) - AE Rec Loss: 3.048 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 2.613 
(2.659) - AE Loss: 1776534.500 (720151.125) - AE Rec Loss: 12.048 (4.884) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.112 
(2.659) - AE Loss: 394714.656 (720151.125) - AE Rec Loss: 2.677 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.301 
(2.518) - AE Loss: 118867.461 (714919.375) - AE Rec Loss: 0.806 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.621) - Batch(s): 1.306 
(2.518) - AE Loss: 1554574.250 (714919.375) - AE Rec Loss: 10.543 (4.848) - Disc
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.621) - Batch(s): 1.308 
(2.518) - AE Loss: 185864.719 (714919.375) - AE Rec Loss: 1.260 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 0.564 
(2.518) - AE Loss: 1390831.000 (714919.375) - AE Rec Loss: 9.432 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.306 
(2.518) - AE Loss: 470455.312 (714919.375) - AE Rec Loss: 3.190 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.306 
(2.518) - AE Loss: 120065.406 (714919.375) - AE Rec Loss: 0.814 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 276821.125 (692610.562) - AE Rec Loss: 1.877 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 541021.875 (692610.562) - AE Rec Loss: 3.669 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 327411.000 (692610.562) - AE Rec Loss: 2.220 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 203886.328 (692610.562) - AE Rec Loss: 1.383 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 185880.016 (692610.562) - AE Rec Loss: 1.261 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.13 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 3.204 
(2.634) - AE Loss: 74856.461 (692610.562) - AE Rec Loss: 0.508 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.13 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.000 
(2.911) - AE Loss: 1639184.875 (678535.562) - AE Rec Loss: 11.116 (4.602) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 5.999 
(2.911) - AE Loss: 164166.875 (678535.562) - AE Rec Loss: 1.113 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.001 (0.614) - Batch(s): 5.441 
(2.911) - AE Loss: 224792.328 (678535.562) - AE Rec Loss: 1.524 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.000 
(2.911) - AE Loss: 166013.344 (678535.562) - AE Rec Loss: 1.126 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.000 
(2.911) - AE Loss: 1477643.500 (678535.562) - AE Rec Loss: 10.021 (4.602) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.001 
(2.911) - AE Loss: 168166.203 (678535.562) - AE Rec Loss: 1.140 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.567) - Batch(s): 1.047 
(2.764) - AE Loss: 229451.609 (660731.500) - AE Rec Loss: 1.556 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.049 
(2.764) - AE Loss: 184926.500 (660731.500) - AE Rec Loss: 1.254 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.042 
(2.764) - AE Loss: 114145.648 (660731.500) - AE Rec Loss: 0.774 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.567) - Batch(s): 1.046 
(2.764) - AE Loss: 109183.117 (660731.500) - AE Rec Loss: 0.740 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 0.567 
(2.764) - AE Loss: 1607068.250 (660731.500) - AE Rec Loss: 10.899 (4.481) - Disc
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.046 
(2.764) - AE Loss: 576693.125 (660731.500) - AE Rec Loss: 3.911 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 1435589.500 (686706.812) - AE Rec Loss: 9.736 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 76951.383 (686706.812) - AE Rec Loss: 0.522 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 202421.297 (686706.812) - AE Rec Loss: 1.373 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 777773.375 (686706.812) - AE Rec Loss: 5.275 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 1494777.625 (686706.812) - AE Rec Loss: 10.137 (4.657) - Disc
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.585) - Batch(s): 4.952 
(2.966) - AE Loss: 1659495.000 (686706.812) - AE Rec Loss: 11.254 (4.657) - Disc
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.194 
(2.845) - AE Loss: 286285.438 (688282.500) - AE Rec Loss: 1.941 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.196 
(2.845) - AE Loss: 159480.000 (688282.500) - AE Rec Loss: 1.082 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.37 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.194 
(2.845) - AE Loss: 149480.266 (688282.500) - AE Rec Loss: 1.014 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.194 
(2.845) - AE Loss: 1636786.000 (688282.500) - AE Rec Loss: 11.100 (4.668) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.195 
(2.845) - AE Loss: 1925206.125 (688282.500) - AE Rec Loss: 13.056 (4.668) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.546) - Batch(s): 0.702 
(2.845) - AE Loss: 69694.312 (688282.500) - AE Rec Loss: 0.473 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.37 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 1.100 
(2.733) - AE Loss: 121057.055 (684843.688) - AE Rec Loss: 0.821 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 1.102 
(2.733) - AE Loss: 1567740.250 (684843.688) - AE Rec Loss: 10.632 (4.644) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 1.102 
(2.733) - AE Loss: 121770.289 (684843.688) - AE Rec Loss: 0.826 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 1.096 
(2.733) - AE Loss: 119289.352 (684843.688) - AE Rec Loss: 0.809 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 1.099 
(2.733) - AE Loss: 251143.562 (684843.688) - AE Rec Loss: 1.703 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.512) - Batch(s): 0.567 
(2.733) - AE Loss: 1661397.750 (684843.688) - AE Rec Loss: 11.267 (4.644) - Disc
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.515) - Batch(s): 3.517 
(2.825) - AE Loss: 178440.438 (665709.625) - AE Rec Loss: 1.210 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.24 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 153658.922 (665709.625) - AE Rec Loss: 1.042 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.24 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 86832.305 (665709.625) - AE Rec Loss: 0.589 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 168971.938 (665709.625) - AE Rec Loss: 1.146 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 204241.750 (665709.625) - AE Rec Loss: 1.385 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 205638.719 (665709.625) - AE Rec Loss: 1.395 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.263 
(2.931) - AE Loss: 172733.000 (659210.250) - AE Rec Loss: 1.171 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.763 
(2.931) - AE Loss: 156480.141 (659210.250) - AE Rec Loss: 1.061 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.764 
(2.931) - AE Loss: 265849.875 (659210.250) - AE Rec Loss: 1.803 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.763 
(2.931) - AE Loss: 1646186.750 (659210.250) - AE Rec Loss: 11.164 (4.471) - Disc
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.764 
(2.931) - AE Loss: 1547655.750 (659210.250) - AE Rec Loss: 10.496 (4.471) - Disc
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.763 
(2.931) - AE Loss: 152970.641 (659210.250) - AE Rec Loss: 1.037 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.038 
(2.829) - AE Loss: 105091.211 (674436.188) - AE Rec Loss: 0.713 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.038 
(2.829) - AE Loss: 2846728.750 (674436.188) - AE Rec Loss: 19.306 (4.574) - Disc
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.035 
(2.829) - AE Loss: 186506.500 (674436.188) - AE Rec Loss: 1.265 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.566 
(2.829) - AE Loss: 295324.969 (674436.188) - AE Rec Loss: 2.003 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.11 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.040 
(2.829) - AE Loss: 1670879.125 (674436.188) - AE Rec Loss: 11.331 (4.574) - Disc
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.037 
(2.829) - AE Loss: 1744101.250 (674436.188) - AE Rec Loss: 11.828 (4.574) - Disc
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.027 
(2.738) - AE Loss: 75290.320 (673712.188) - AE Rec Loss: 0.511 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.027 
(2.738) - AE Loss: 3047828.500 (673712.188) - AE Rec Loss: 20.669 (4.569) - Disc
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.027 
(2.738) - AE Loss: 2831031.500 (673712.188) - AE Rec Loss: 19.199 (4.569) - Disc
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.023 
(2.738) - AE Loss: 165209.281 (673712.188) - AE Rec Loss: 1.120 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 0.566 
(2.738) - AE Loss: 340338.188 (673712.188) - AE Rec Loss: 2.308 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.024 
(2.738) - AE Loss: 214314.016 (673712.188) - AE Rec Loss: 1.453 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

attempting to save
[[36m2023-11-29 03:54:59,257[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 03:54:59,914[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 03:55:00,081[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 03:55:00,090[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 03:55:00,097[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 03:55:00,104[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 03:55:00,111[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 03:55:00,120[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 03:55:00,130[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 03:55:00,135[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 03:55:00,638[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 03:55:04,019[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:55:23,279[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,319[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,510[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,601[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,649[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,696[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:55:25,425[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:25,453[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:25,660[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:25,741[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:25,824[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:25,870[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,010[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,013[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,245[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,388[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,432[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,436[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:55:26,974[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:55:26,974[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 03:55:26,977[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:55:26,977[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating valid dataloader 
[[36m2023-11-29 03:55:26,978[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2=> Instantiating the optimizer 

Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:55:26,983[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Mixed precision: no
=> Preparing opt_disc 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Running in inference mode: False
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:56:55,479[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:55,524[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:55,600[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:55,796[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:55,816[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:55,823[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:56:57,619[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:57,741[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:57,750[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:57,944[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:57,967[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:57,970[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,182[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,325[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,382[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,630[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:58,638[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 03:56:59,791[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:56:59,793[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,793[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
[[36m2023-11-29 03:56:59,795[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 03:56:59,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataloader) = 1
=> Preparing model 
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 3
Reached 3 on node 5Reached 5 on node 3

Reached 5 on node 5Reached end on node 3

Reached end on node 5
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing model 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        


            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:03:01,800[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,004[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,015[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,016[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,046[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,059[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:03:03,985[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,131[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,162[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,164[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,171[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,209[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,748[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,791[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,913[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,940[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:04,957[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:03:05,488[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:03:05,489[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:03:05,489[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
[[36m2023-11-29 04:03:05,492[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 04:03:05,494[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating train dataloader 
[[36m2023-11-29 04:03:05,496[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Mixed precision: no
=> Preparing model 
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Preparing model 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:04:34,077[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,108[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,223[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,317[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,326[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,399[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:04:36,221[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,264[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,387[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,477[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,480[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,594[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:36,858[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:36,924[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,017[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,113[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,129[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,212[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:04:37,724[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:04:37,726[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
[[36m2023-11-29 04:04:37,726[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 04:04:37,728[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
[[36m2023-11-29 04:04:37,728[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataset) = 54706
[[36m2023-11-29 04:04:37,731[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 2
=> Mixed precision: no
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing model 
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:07:37,663[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:37,757[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:37,773[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:37,980[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,014[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,032[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:07:39,815[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:39,900[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:39,916[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,114[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,181[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,202[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,322[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,504[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,551[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,719[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,809[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,837[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:07:41,361[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 04:07:41,363[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:07:41,363[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
[[36m2023-11-29 04:07:41,364[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating valid dataloader 
[[36m2023-11-29 04:07:41,365[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Running in inference mode: False
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
[[36m2023-11-29 04:07:41,366[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataset) = 54706
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Running in inference mode: False
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Preparing model 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:09:10,392[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,631[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,766[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,785[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,791[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,799[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:09:12,527[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:12,771[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:12,894[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:12,931[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:12,949[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:12,956[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:12,985[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,359[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,535[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,581[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,609[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:09:14,000[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:09:14,001[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:09:14,003[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
[[36m2023-11-29 04:09:14,007[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:09:14,007[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
[[36m2023-11-29 04:09:14,007[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Running in inference mode: False
len(train_dataset) = 54706
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Preparing model 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 5
=> Preparing model 
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:13:45,142[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,188[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,374[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,499[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,505[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,510[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:13:47,288[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,309[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,505[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,660[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,668[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:47,778[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:47,882[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,093[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 04:13:48,115[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,208[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,250[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,513[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:13:48,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,600[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
[[36m2023-11-29 04:13:48,605[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,605[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,606[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
[[36m2023-11-29 04:13:48,608[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 5=> Preparing opt_disc 

Reached 5 on node 5
Reached end on node 5
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 2
batch_size = 2, learning rate = 4.5e-06
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.3 on node 2
Reached 3 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 5 on node 5
=> Preparing criterion 
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5Reached 3 on node 2

Reached 5 on node 5Reached 5 on node 2

Reached end on node 5
Reached end on node 2
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1Reached 1.3 on node 4
Reached 1.4 on node 4

Reached 1.4 on node 1Reached 2 on node 4

Reached 2 on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached 3 on node 1Reached 1.3 on node 5

Reached 1.4 on node 5Reached end on node 4Reached 5 on node 1


Reached 1.3 on node 3
Reached 1.4 on node 3
Reached end on node 1Reached 2 on node 5

Reached 2 on node 3
Reached 3 on node 5
Reached 3 on node 3
Reached 5 on node 3Reached 5 on node 5

Reached end on node 3Reached end on node 5

Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.3 on node 0Reached end on node 2

Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached end on node 0
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 1.4 on node 4
Reached 2 on node 3
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 1
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5Reached 1 on node 2

Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 4
Reached end on node 3
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 5
Reached end on node 2
Reached 1 on node 1
Reached 1 on node 4
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1.4 on node 0Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 2 on node 0
Reached 5 on node 3
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 1
Reached end on node 4
Reached end on node 0
Reached end on node 3
[[36m2023-11-29 04:13:50,374[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:13:51,938[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:13:52,477[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:13:52,477[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:13:52,477[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:13:52,480[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:13:52,482[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 5.441 (5.274) - Batch(s): 10.564 
(10.046) - AE Loss: 221487.406 (318208.938) - AE Rec Loss: 1.502 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.243 (5.274) - Batch(s): 9.732 
(10.046) - AE Loss: 101062.250 (318208.938) - AE Rec Loss: 0.685 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 8.214 (5.274) - Batch(s): 9.707 
(10.046) - AE Loss: 467364.375 (318208.938) - AE Rec Loss: 3.170 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.196 (5.274) - Batch(s): 9.752 
(10.046) - AE Loss: 533350.375 (318208.938) - AE Rec Loss: 3.617 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 2.833 (5.274) - Batch(s): 9.726 
(10.046) - AE Loss: 279915.062 (318208.938) - AE Rec Loss: 1.898 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 4.893 (5.274) - Batch(s): 10.260 
(10.046) - AE Loss: 261909.047 (318208.938) - AE Rec Loss: 1.776 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.637) - Batch(s): 0.564 
(5.603) - AE Loss: 1470734.625 (588618.438) - AE Rec Loss: 9.974 (3.992) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.637) - Batch(s): 1.216 
(5.603) - AE Loss: 256475.844 (588618.438) - AE Rec Loss: 1.739 (3.992) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.637) - Batch(s): 1.216 
(5.603) - AE Loss: 528413.375 (588618.438) - AE Rec Loss: 3.584 (3.992) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.211 
(5.603) - AE Loss: 642531.375 (588618.438) - AE Rec Loss: 4.357 (3.992) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.637) - Batch(s): 1.215 
(5.603) - AE Loss: 1806966.250 (588618.438) - AE Rec Loss: 12.254 (3.992) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.637) - Batch(s): 1.216 
(5.603) - AE Loss: 1644673.000 (588618.438) - AE Rec Loss: 11.154 (3.992) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 200939.812 (792081.562) - AE Rec Loss: 1.363 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 0.793 
(4.162) - AE Loss: 1676085.625 (792081.562) - AE Rec Loss: 11.367 (5.372) - Disc
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.324 
(4.162) - AE Loss: 3025729.500 (792081.562) - AE Rec Loss: 20.520 (5.372) - Disc
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.667 (1.794) - Batch(s): 1.325 
(4.162) - AE Loss: 1838386.250 (792081.562) - AE Rec Loss: 12.467 (5.372) - Disc
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 1469484.500 (792081.562) - AE Rec Loss: 9.966 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 227598.047 (792081.562) - AE Rec Loss: 1.543 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.333 
(3.439) - AE Loss: 101613.852 (738457.688) - AE Rec Loss: 0.689 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.329 
(3.439) - AE Loss: 76683.070 (738457.688) - AE Rec Loss: 0.520 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.331 
(3.439) - AE Loss: 492042.438 (738457.688) - AE Rec Loss: 3.337 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.017 (1.346) - Batch(s): 0.579 
(3.439) - AE Loss: 322306.812 (738457.688) - AE Rec Loss: 2.186 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.332 
(3.439) - AE Loss: 392743.812 (738457.688) - AE Rec Loss: 2.663 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.332 
(3.439) - AE Loss: 1537153.000 (738457.688) - AE Rec Loss: 10.424 (5.008) - Disc
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.196 
(2.979) - AE Loss: 268100.625 (735066.250) - AE Rec Loss: 1.818 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.199 
(2.979) - AE Loss: 248929.547 (735066.250) - AE Rec Loss: 1.688 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.087) - Batch(s): 0.562 
(2.979) - AE Loss: 1659886.750 (735066.250) - AE Rec Loss: 11.257 (4.985) - Disc
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.087) - Batch(s): 1.158 
(2.979) - AE Loss: 1703169.750 (735066.250) - AE Rec Loss: 11.550 (4.985) - Disc
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.636 (1.087) - Batch(s): 1.201 
(2.979) - AE Loss: 171977.844 (735066.250) - AE Rec Loss: 1.166 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.198 
(2.979) - AE Loss: 328302.875 (735066.250) - AE Rec Loss: 2.226 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (1.025) - Batch(s): 3.713 
(3.213) - AE Loss: 386952.438 (689502.938) - AE Rec Loss: 2.624 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.442 
(3.213) - AE Loss: 291119.594 (689502.938) - AE Rec Loss: 1.974 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.443 
(3.213) - AE Loss: 112707.070 (689502.938) - AE Rec Loss: 0.764 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 1.831 (1.025) - Batch(s): 4.441 
(3.213) - AE Loss: 59822.395 (689502.938) - AE Rec Loss: 0.406 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.441 
(3.213) - AE Loss: 1602720.750 (689502.938) - AE Rec Loss: 10.869 (4.676) - Disc
Loss: 0.000 (0.000) - 3.54 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 3.789 (1.025) - Batch(s): 4.442 
(3.213) - AE Loss: 1879421.625 (689502.938) - AE Rec Loss: 12.746 (4.676) - Disc
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 0.564 
(2.911) - AE Loss: 212964.031 (729972.375) - AE Rec Loss: 1.444 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.150 
(2.911) - AE Loss: 464234.125 (729972.375) - AE Rec Loss: 3.148 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.149 
(2.911) - AE Loss: 1507350.250 (729972.375) - AE Rec Loss: 10.222 (4.950) - Disc
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.150 
(2.911) - AE Loss: 1482626.125 (729972.375) - AE Rec Loss: 10.055 (4.950) - Disc
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.146 
(2.911) - AE Loss: 3474079.750 (729972.375) - AE Rec Loss: 23.560 (4.950) - Disc
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.148 
(2.911) - AE Loss: 242228.484 (729972.375) - AE Rec Loss: 1.643 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.169 
(2.687) - AE Loss: 1908511.500 (714667.812) - AE Rec Loss: 12.943 (4.847) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.563 
(2.687) - AE Loss: 371899.906 (714667.812) - AE Rec Loss: 2.522 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.168 
(2.687) - AE Loss: 1734611.250 (714667.812) - AE Rec Loss: 11.764 (4.847) - Disc
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.166 
(2.687) - AE Loss: 1590419.375 (714667.812) - AE Rec Loss: 10.786 (4.847) - Disc
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.169 
(2.687) - AE Loss: 98046.297 (714667.812) - AE Rec Loss: 0.665 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.165 
(2.687) - AE Loss: 82860.617 (714667.812) - AE Rec Loss: 0.562 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.243 
(2.521) - AE Loss: 125863.328 (720356.875) - AE Rec Loss: 0.854 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.001 (0.684) - Batch(s): 0.669 
(2.521) - AE Loss: 1776675.250 (720356.875) - AE Rec Loss: 12.049 (4.885) - Disc
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.001 (0.684) - Batch(s): 1.244 
(2.521) - AE Loss: 316004.656 (720356.875) - AE Rec Loss: 2.143 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.245 
(2.521) - AE Loss: 449558.438 (720356.875) - AE Rec Loss: 3.049 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.001 (0.684) - Batch(s): 1.245 
(2.521) - AE Loss: 60079.723 (720356.875) - AE Rec Loss: 0.407 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.244 
(2.521) - AE Loss: 397383.625 (720356.875) - AE Rec Loss: 2.695 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.274 
(2.391) - AE Loss: 119784.914 (715067.438) - AE Rec Loss: 0.812 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.276 
(2.391) - AE Loss: 1555674.875 (715067.438) - AE Rec Loss: 10.550 (4.849) - Disc
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.615) - Batch(s): 1.272 
(2.391) - AE Loss: 116126.445 (715067.438) - AE Rec Loss: 0.788 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.31 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.277 
(2.391) - AE Loss: 184617.938 (715067.438) - AE Rec Loss: 1.252 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.276 
(2.391) - AE Loss: 469444.312 (715067.438) - AE Rec Loss: 3.184 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.615) - Batch(s): 0.564 
(2.391) - AE Loss: 1390994.750 (715067.438) - AE Rec Loss: 9.433 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.321 
(2.288) - AE Loss: 327977.531 (692742.062) - AE Rec Loss: 2.224 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.322 
(2.288) - AE Loss: 203662.812 (692742.062) - AE Rec Loss: 1.381 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.559) - Batch(s): 0.566 
(2.288) - AE Loss: 74567.977 (692742.062) - AE Rec Loss: 0.506 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.323 
(2.288) - AE Loss: 278077.062 (692742.062) - AE Rec Loss: 1.886 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.322 
(2.288) - AE Loss: 186030.141 (692742.062) - AE Rec Loss: 1.262 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.319 
(2.288) - AE Loss: 543673.750 (692742.062) - AE Rec Loss: 3.687 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.280 
(2.199) - AE Loss: 169047.219 (678694.875) - AE Rec Loss: 1.146 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.281 
(2.199) - AE Loss: 165065.875 (678694.875) - AE Rec Loss: 1.119 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.281 
(2.199) - AE Loss: 1478202.000 (678694.875) - AE Rec Loss: 10.025 (4.603) - Disc
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.282 
(2.199) - AE Loss: 1639003.750 (678694.875) - AE Rec Loss: 11.115 (4.603) - Disc
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.281 
(2.199) - AE Loss: 166349.281 (678694.875) - AE Rec Loss: 1.128 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.79 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.001 (0.515) - Batch(s): 0.658 
(2.199) - AE Loss: 224367.344 (678694.875) - AE Rec Loss: 1.522 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.401 
(2.134) - AE Loss: 108520.164 (660775.062) - AE Rec Loss: 0.736 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.405 
(2.134) - AE Loss: 576724.750 (660775.062) - AE Rec Loss: 3.911 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.149 (0.477) - Batch(s): 0.713 
(2.134) - AE Loss: 1606661.750 (660775.062) - AE Rec Loss: 10.896 (4.481) - Disc
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.400 
(2.134) - AE Loss: 111495.555 (660775.062) - AE Rec Loss: 0.756 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.403 
(2.134) - AE Loss: 228235.359 (660775.062) - AE Rec Loss: 1.548 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.404 
(2.134) - AE Loss: 183592.594 (660775.062) - AE Rec Loss: 1.245 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.466) - Batch(s): 3.960 
(2.270) - AE Loss: 778646.500 (686693.188) - AE Rec Loss: 5.281 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.58 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.466) - Batch(s): 3.960 
(2.270) - AE Loss: 1434066.500 (686693.188) - AE Rec Loss: 9.725 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.58 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 3.960 
(2.270) - AE Loss: 76522.516 (686693.188) - AE Rec Loss: 0.519 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.58 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.466) - Batch(s): 3.961 
(2.270) - AE Loss: 200344.156 (686693.188) - AE Rec Loss: 1.359 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 3.960 
(2.270) - AE Loss: 1494494.375 (686693.188) - AE Rec Loss: 10.135 (4.657) - Disc
Loss: 0.000 (0.000) - 5.71 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.466) - Batch(s): 3.216 
(2.270) - AE Loss: 1658678.750 (686693.188) - AE Rec Loss: 11.249 (4.657) - Disc
Loss: 0.000 (0.000) - 5.57 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.324 
(2.204) - AE Loss: 159123.719 (688232.188) - AE Rec Loss: 1.079 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.324 
(2.204) - AE Loss: 1923750.000 (688232.188) - AE Rec Loss: 13.046 (4.667) - Disc
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.323 
(2.204) - AE Loss: 1636248.250 (688232.188) - AE Rec Loss: 11.097 (4.667) - Disc
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.435) - Batch(s): 1.325 
(2.204) - AE Loss: 284409.781 (688232.188) - AE Rec Loss: 1.929 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.435) - Batch(s): 0.654 
(2.204) - AE Loss: 68973.219 (688232.188) - AE Rec Loss: 0.468 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.325 
(2.204) - AE Loss: 149622.469 (688232.188) - AE Rec Loss: 1.015 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.300 
(2.143) - AE Loss: 120697.336 (684776.625) - AE Rec Loss: 0.819 (4.644) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.300 
(2.143) - AE Loss: 1567831.000 (684776.625) - AE Rec Loss: 10.633 (4.644) - Disc
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.298 
(2.143) - AE Loss: 250985.938 (684776.625) - AE Rec Loss: 1.702 (4.644) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.296 
(2.143) - AE Loss: 119736.695 (684776.625) - AE Rec Loss: 0.812 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 0.566 
(2.143) - AE Loss: 1660248.125 (684776.625) - AE Rec Loss: 11.259 (4.644) - Disc
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.301 
(2.143) - AE Loss: 120378.586 (684776.625) - AE Rec Loss: 0.816 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.087 
(2.078) - AE Loss: 204980.812 (665626.875) - AE Rec Loss: 1.390 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.384) - Batch(s): 1.085 
(2.078) - AE Loss: 203590.125 (665626.875) - AE Rec Loss: 1.381 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.384) - Batch(s): 1.089 
(2.078) - AE Loss: 169533.891 (665626.875) - AE Rec Loss: 1.150 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.089 
(2.078) - AE Loss: 86222.180 (665626.875) - AE Rec Loss: 0.585 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.384) - Batch(s): 0.565 
(2.078) - AE Loss: 177997.734 (665626.875) - AE Rec Loss: 1.207 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.384) - Batch(s): 1.089 
(2.078) - AE Loss: 153864.500 (665626.875) - AE Rec Loss: 1.043 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 5.004 
(2.238) - AE Loss: 1547535.500 (659110.062) - AE Rec Loss: 10.495 (4.470) - Disc
Loss: 0.000 (0.000) - 6.94 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 157122.281 (659110.062) - AE Rec Loss: 1.066 (4.470) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 264176.781 (659110.062) - AE Rec Loss: 1.792 (4.470) - Disc 
Loss: 0.000 (0.000) - 6.94 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 4.306 
(2.238) - AE Loss: 172833.250 (659110.062) - AE Rec Loss: 1.172 (4.470) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 152810.297 (659110.062) - AE Rec Loss: 1.036 (4.470) - Disc 
Loss: 0.000 (0.000) - 7.02 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 1645389.500 (659110.062) - AE Rec Loss: 11.159 (4.470) - Disc
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.072 
(2.174) - AE Loss: 106790.492 (674364.062) - AE Rec Loss: 0.724 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.565 
(2.174) - AE Loss: 296500.562 (674364.062) - AE Rec Loss: 2.011 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.071 
(2.174) - AE Loss: 1743982.750 (674364.062) - AE Rec Loss: 11.827 (4.573) - Disc
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.072 
(2.174) - AE Loss: 2846804.000 (674364.062) - AE Rec Loss: 19.306 (4.573) - Disc
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.069 
(2.174) - AE Loss: 189275.031 (674364.062) - AE Rec Loss: 1.284 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.073 
(2.174) - AE Loss: 1671120.250 (674364.062) - AE Rec Loss: 11.333 (4.573) - Disc
Loss: 0.000 (0.000) - 7.22 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 1.106 
(2.119) - AE Loss: 213995.828 (673665.750) - AE Rec Loss: 1.451 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.25 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 1.109 
(2.119) - AE Loss: 3047840.500 (673665.750) - AE Rec Loss: 20.669 (4.569) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.105 
(2.119) - AE Loss: 166713.938 (673665.750) - AE Rec Loss: 1.131 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 1.109 
(2.119) - AE Loss: 2831118.250 (673665.750) - AE Rec Loss: 19.200 (4.569) - Disc
Loss: 0.000 (0.000) - 7.25 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.109 
(2.119) - AE Loss: 76813.547 (673665.750) - AE Rec Loss: 0.521 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 0.566 
(2.119) - AE Loss: 339624.188 (673665.750) - AE Rec Loss: 2.303 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.25 m remaining

attempting to save
[[36m2023-11-29 04:14:39,921[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 04:14:42,014[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:14:42,356[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:14:42,380[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:14:42,394[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:14:42,409[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:14:42,444[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:14:42,457[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:14:42,466[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:14:42,482[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:14:45,788[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:14:49,832[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:16:57,865[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:57,983[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,168[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,225[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,263[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,263[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:17:00,026[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:00,142[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:00,307[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:00,377[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:00,428[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:00,447[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:00,553[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:00,749[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:00,951[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,031[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,073[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,086[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 04:17:01,729[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:17:01,729[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 04:17:01,730[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 04:17:01,732[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
[[36m2023-11-29 04:17:01,732[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
[[36m2023-11-29 04:17:01,733[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1 on node 2
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:18:30,384[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,415[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,572[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,652[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,660[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,686[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:18:32,557[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:32,602[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:32,702[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:32,778[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:32,801[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:32,830[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,198[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,211[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,353[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,431[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,487[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,508[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 04:18:34,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,115[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,116[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,116[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_disc 
Reached 3 on node 5
=> Preparing opt_disc 
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 0
=> Preparing model 
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 2
Reached 1.4 on node 2
=> Preparing criterion 
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 1

Reached 1.4 on node 1Reached 1.4 on node 3

Reached 2 on node 3Reached 2 on node 1

Reached 3 on node 3Reached 3 on node 1

Reached 5 on node 3Reached 5 on node 1

Reached 1.3 on node 2
Reached end on node 3Reached 1.4 on node 2
Reached end on node 1

Reached 2 on node 2
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 3 on node 2
Reached 2 on node 4
Reached 5 on node 2
Reached 1.3 on node 5
Reached end on node 2Reached 1.4 on node 5
Reached 1.3 on node 0

Reached 1.4 on node 0
Reached 3 on node 4
Reached 2 on node 5
Reached 2 on node 0
Reached 5 on node 4
Reached 3 on node 5
Reached end on node 4Reached 3 on node 0

Reached 5 on node 5
Reached 5 on node 0Reached end on node 5

Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4Reached 1 on node 5

Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 1.4 on node 5
Reached 3 on node 2
Reached 2 on node 5
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached end on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 1 on node 5
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 1 on node 4Reached 2 on node 5

Reached 3 on node 5
Reached 1.4 on node 3Reached 3 on node 5

Reached 3 on node 5Reached 2 on node 3
Reached 1.4 on node 4

Reached 3 on node 5
Reached 3 on node 5Reached 2 on node 4

Reached 3 on node 3Reached 5 on node 5

Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 5
Reached end on node 3
Reached end on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 04:18:35,865[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 04:18:37,379[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:18:37,883[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:18:37,883[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:18:37,889[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:18:37,896[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:18:37,898[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 5.263 (5.306) - Batch(s): 10.021 
(10.183) - AE Loss: 534270.062 (317813.969) - AE Rec Loss: 3.623 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 8.606 (5.306) - Batch(s): 9.968 
(10.183) - AE Loss: 467364.375 (317813.969) - AE Rec Loss: 3.170 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.76 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.013 (5.306) - Batch(s): 10.247 
(10.183) - AE Loss: 106714.500 (317813.969) - AE Rec Loss: 0.724 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 3.423 (5.306) - Batch(s): 10.334 
(10.183) - AE Loss: 261972.078 (317813.969) - AE Rec Loss: 1.777 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 3.259 (5.306) - Batch(s): 9.965 
(10.183) - AE Loss: 279470.500 (317813.969) - AE Rec Loss: 1.895 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.76 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.188 (5.306) - Batch(s): 10.218 
(10.183) - AE Loss: 219870.875 (317813.969) - AE Rec Loss: 1.491 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.653) - Batch(s): 1.436 
(5.773) - AE Loss: 253551.250 (588347.625) - AE Rec Loss: 1.720 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.653) - Batch(s): 1.438 
(5.773) - AE Loss: 527501.875 (588347.625) - AE Rec Loss: 3.577 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.434 
(5.773) - AE Loss: 1807773.875 (588347.625) - AE Rec Loss: 12.260 (3.990) - Disc
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.653) - Batch(s): 0.561 
(5.773) - AE Loss: 1470734.625 (588347.625) - AE Rec Loss: 9.974 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.653) - Batch(s): 1.434 
(5.773) - AE Loss: 643453.250 (588347.625) - AE Rec Loss: 4.364 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.08 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.437 
(5.773) - AE Loss: 1645219.000 (588347.625) - AE Rec Loss: 11.157 (3.990) - Disc
Loss: 0.000 (0.000) - 2.03 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.774 
(5.087) - AE Loss: 201351.797 (791719.000) - AE Rec Loss: 1.366 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.774 
(5.087) - AE Loss: 226413.219 (791719.000) - AE Rec Loss: 1.535 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.773 
(5.087) - AE Loss: 1839189.750 (791719.000) - AE Rec Loss: 12.473 (5.369) - Disc
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.060 
(5.087) - AE Loss: 1676085.625 (791719.000) - AE Rec Loss: 11.367 (5.369) - Disc
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.856) - Batch(s): 3.777 
(5.087) - AE Loss: 3025569.500 (791719.000) - AE Rec Loss: 20.518 (5.369) - Disc
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.776 
(5.087) - AE Loss: 1467656.750 (791719.000) - AE Rec Loss: 9.953 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.316 
(4.129) - AE Loss: 492148.688 (738246.312) - AE Rec Loss: 3.338 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.316 
(4.129) - AE Loss: 77512.375 (738246.312) - AE Rec Loss: 0.526 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.97 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.320 
(4.129) - AE Loss: 1537051.000 (738246.312) - AE Rec Loss: 10.424 (5.007) - Disc
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.001 (1.392) - Batch(s): 0.561 
(4.129) - AE Loss: 322448.531 (738246.312) - AE Rec Loss: 2.187 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.319 
(4.129) - AE Loss: 101454.195 (738246.312) - AE Rec Loss: 0.688 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.319 
(4.129) - AE Loss: 393121.062 (738246.312) - AE Rec Loss: 2.666 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.092 
(3.513) - AE Loss: 1704026.875 (734903.000) - AE Rec Loss: 11.556 (4.984) - Disc
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.116) - Batch(s): 1.096 
(3.513) - AE Loss: 249053.906 (734903.000) - AE Rec Loss: 1.689 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.093 
(3.513) - AE Loss: 268304.938 (734903.000) - AE Rec Loss: 1.820 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.116) - Batch(s): 1.096 
(3.513) - AE Loss: 172815.438 (734903.000) - AE Rec Loss: 1.172 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.116) - Batch(s): 1.096 
(3.513) - AE Loss: 328047.312 (734903.000) - AE Rec Loss: 2.225 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 0.562 
(3.513) - AE Loss: 1659977.250 (734903.000) - AE Rec Loss: 11.257 (4.984) - Disc
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.970) - Batch(s): 3.556 
(3.513) - AE Loss: 111537.258 (689372.000) - AE Rec Loss: 0.756 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.76 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.555 
(3.513) - AE Loss: 1602600.750 (689372.000) - AE Rec Loss: 10.868 (4.675) - Disc
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.555 
(3.513) - AE Loss: 291805.812 (689372.000) - AE Rec Loss: 1.979 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.556 
(3.513) - AE Loss: 61064.957 (689372.000) - AE Rec Loss: 0.414 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.970) - Batch(s): 3.555 
(3.513) - AE Loss: 1879444.375 (689372.000) - AE Rec Loss: 12.746 (4.675) - Disc
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.970) - Batch(s): 3.000 
(3.513) - AE Loss: 386693.562 (689372.000) - AE Rec Loss: 2.622 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.158 
(3.169) - AE Loss: 1482353.250 (729837.312) - AE Rec Loss: 10.053 (4.950) - Disc
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.158 
(3.169) - AE Loss: 1507846.500 (729837.312) - AE Rec Loss: 10.226 (4.950) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.158 
(3.169) - AE Loss: 463065.594 (729837.312) - AE Rec Loss: 3.140 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.91 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 0.564 
(3.169) - AE Loss: 212743.625 (729837.312) - AE Rec Loss: 1.443 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.91 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.154 
(3.169) - AE Loss: 3474043.000 (729837.312) - AE Rec Loss: 23.560 (4.950) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.154 
(3.169) - AE Loss: 241229.766 (729837.312) - AE Rec Loss: 1.636 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.071 
(2.901) - AE Loss: 1590011.875 (714502.188) - AE Rec Loss: 10.783 (4.846) - Disc
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.074 
(2.901) - AE Loss: 97691.906 (714502.188) - AE Rec Loss: 0.663 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.071 
(2.901) - AE Loss: 83424.062 (714502.188) - AE Rec Loss: 0.566 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 0.562 
(2.901) - AE Loss: 371370.812 (714502.188) - AE Rec Loss: 2.519 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.074 
(2.901) - AE Loss: 1907518.750 (714502.188) - AE Rec Loss: 12.936 (4.846) - Disc
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.728) - Batch(s): 1.075 
(2.901) - AE Loss: 1734107.250 (714502.188) - AE Rec Loss: 11.760 (4.846) - Disc
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.865 
(2.782) - AE Loss: 450182.562 (720205.625) - AE Rec Loss: 3.053 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.865 
(2.782) - AE Loss: 396482.625 (720205.625) - AE Rec Loss: 2.689 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.867 
(2.782) - AE Loss: 60186.469 (720205.625) - AE Rec Loss: 0.408 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.336 
(2.782) - AE Loss: 1776506.500 (720205.625) - AE Rec Loss: 12.048 (4.884) - Disc
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.867 
(2.782) - AE Loss: 317812.625 (720205.625) - AE Rec Loss: 2.155 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.866 
(2.782) - AE Loss: 126105.102 (720205.625) - AE Rec Loss: 0.855 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.172 
(2.615) - AE Loss: 185028.531 (714954.125) - AE Rec Loss: 1.255 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.168 
(2.615) - AE Loss: 119922.273 (714954.125) - AE Rec Loss: 0.813 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.592) - Batch(s): 0.563 
(2.615) - AE Loss: 1391272.750 (714954.125) - AE Rec Loss: 9.435 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.171 
(2.615) - AE Loss: 1554983.000 (714954.125) - AE Rec Loss: 10.545 (4.849) - Disc
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.592) - Batch(s): 1.171 
(2.615) - AE Loss: 469567.188 (714954.125) - AE Rec Loss: 3.184 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.592) - Batch(s): 1.168 
(2.615) - AE Loss: 118371.711 (714954.125) - AE Rec Loss: 0.803 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.539) - Batch(s): 0.564 
(2.492) - AE Loss: 74836.125 (692697.062) - AE Rec Loss: 0.508 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.317 
(2.492) - AE Loss: 327437.812 (692697.062) - AE Rec Loss: 2.221 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.320 
(2.492) - AE Loss: 278388.875 (692697.062) - AE Rec Loss: 1.888 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.321 
(2.492) - AE Loss: 186859.938 (692697.062) - AE Rec Loss: 1.267 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.539) - Batch(s): 1.316 
(2.492) - AE Loss: 542040.750 (692697.062) - AE Rec Loss: 3.676 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.539) - Batch(s): 1.320 
(2.492) - AE Loss: 204278.484 (692697.062) - AE Rec Loss: 1.385 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.381 
(2.394) - AE Loss: 166676.875 (678648.250) - AE Rec Loss: 1.130 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.08 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.001 (0.495) - Batch(s): 0.640 
(2.394) - AE Loss: 224444.469 (678648.250) - AE Rec Loss: 1.522 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.04 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.381 
(2.394) - AE Loss: 168308.609 (678648.250) - AE Rec Loss: 1.141 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.09 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.381 
(2.394) - AE Loss: 164594.156 (678648.250) - AE Rec Loss: 1.116 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.381 
(2.394) - AE Loss: 1638862.125 (678648.250) - AE Rec Loss: 11.114 (4.602) - Disc
Loss: 0.000 (0.000) - 5.04 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.381 
(2.394) - AE Loss: 1478056.125 (678648.250) - AE Rec Loss: 10.024 (4.602) - Disc
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.475) - Batch(s): 2.231 
(2.398) - AE Loss: 109420.438 (660804.000) - AE Rec Loss: 0.742 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.475) - Batch(s): 2.583 
(2.398) - AE Loss: 112839.977 (660804.000) - AE Rec Loss: 0.765 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.834 (0.475) - Batch(s): 2.588 
(2.398) - AE Loss: 576500.062 (660804.000) - AE Rec Loss: 3.910 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.475) - Batch(s): 2.231 
(2.398) - AE Loss: 184494.688 (660804.000) - AE Rec Loss: 1.251 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 2.017 (0.475) - Batch(s): 2.590 
(2.398) - AE Loss: 231070.891 (660804.000) - AE Rec Loss: 1.567 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 1.526 
(2.398) - AE Loss: 1607257.750 (660804.000) - AE Rec Loss: 10.900 (4.481) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.098 
(2.302) - AE Loss: 779735.312 (686788.750) - AE Rec Loss: 5.288 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.101 
(2.302) - AE Loss: 1494860.500 (686788.750) - AE Rec Loss: 10.138 (4.658) - Disc
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.441) - Batch(s): 1.101 
(2.302) - AE Loss: 1435506.375 (686788.750) - AE Rec Loss: 9.735 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.097 
(2.302) - AE Loss: 200394.625 (686788.750) - AE Rec Loss: 1.359 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.001 (0.441) - Batch(s): 0.563 
(2.302) - AE Loss: 1659731.500 (686788.750) - AE Rec Loss: 11.256 (4.658) - Disc
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.101 
(2.302) - AE Loss: 76661.633 (686788.750) - AE Rec Loss: 0.520 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.333 
(2.233) - AE Loss: 1924092.250 (688386.250) - AE Rec Loss: 13.049 (4.668) - Disc
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.333 
(2.233) - AE Loss: 1636863.250 (688386.250) - AE Rec Loss: 11.101 (4.668) - Disc
Loss: 0.000 (0.000) - 5.88 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.412) - Batch(s): 0.658 
(2.233) - AE Loss: 69922.531 (688386.250) - AE Rec Loss: 0.474 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.334 
(2.233) - AE Loss: 151188.000 (688386.250) - AE Rec Loss: 1.025 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.334 
(2.233) - AE Loss: 285585.938 (688386.250) - AE Rec Loss: 1.937 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.334 
(2.233) - AE Loss: 159630.984 (688386.250) - AE Rec Loss: 1.083 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.85 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.314 
(2.172) - AE Loss: 251633.328 (684943.812) - AE Rec Loss: 1.706 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.09 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.311 
(2.172) - AE Loss: 119672.352 (684943.812) - AE Rec Loss: 0.812 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.265 (0.387) - Batch(s): 1.314 
(2.172) - AE Loss: 1568193.500 (684943.812) - AE Rec Loss: 10.635 (4.645) - Disc
Loss: 0.000 (0.000) - 6.05 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.564 
(2.172) - AE Loss: 1660779.500 (684943.812) - AE Rec Loss: 11.263 (4.645) - Disc
Loss: 0.000 (0.000) - 6.05 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.315 
(2.172) - AE Loss: 121090.773 (684943.812) - AE Rec Loss: 0.821 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.315 
(2.172) - AE Loss: 122203.258 (684943.812) - AE Rec Loss: 0.829 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.09 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.314 
(2.118) - AE Loss: 205972.188 (665814.688) - AE Rec Loss: 1.397 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.316 
(2.118) - AE Loss: 154158.922 (665814.688) - AE Rec Loss: 1.045 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.313 
(2.118) - AE Loss: 204027.812 (665814.688) - AE Rec Loss: 1.384 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.365) - Batch(s): 0.564 
(2.118) - AE Loss: 178402.031 (665814.688) - AE Rec Loss: 1.210 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.316 
(2.118) - AE Loss: 169665.328 (665814.688) - AE Rec Loss: 1.151 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.317 
(2.118) - AE Loss: 87231.938 (665814.688) - AE Rec Loss: 0.592 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 2.360 (0.376) - Batch(s): 5.091 
(2.280) - AE Loss: 157253.641 (659316.000) - AE Rec Loss: 1.066 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.376) - Batch(s): 4.336 
(2.280) - AE Loss: 172844.672 (659316.000) - AE Rec Loss: 1.172 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.090 
(2.280) - AE Loss: 264631.531 (659316.000) - AE Rec Loss: 1.795 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.090 
(2.280) - AE Loss: 1645892.750 (659316.000) - AE Rec Loss: 11.162 (4.471) - Disc
Loss: 0.000 (0.000) - 7.08 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.090 
(2.280) - AE Loss: 153811.844 (659316.000) - AE Rec Loss: 1.043 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.090 
(2.280) - AE Loss: 1548025.625 (659316.000) - AE Rec Loss: 10.498 (4.471) - Disc
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 2.759 
(2.316) - AE Loss: 1743941.750 (674545.812) - AE Rec Loss: 11.827 (4.575) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 2.759 
(2.316) - AE Loss: 1670777.500 (674545.812) - AE Rec Loss: 11.331 (4.575) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.001 (0.367) - Batch(s): 2.209 
(2.316) - AE Loss: 295870.312 (674545.812) - AE Rec Loss: 2.006 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 2.547 (0.367) - Batch(s): 3.117 
(2.316) - AE Loss: 2846760.500 (674545.812) - AE Rec Loss: 19.306 (4.575) - Disc
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.116 
(2.316) - AE Loss: 105459.414 (674545.812) - AE Rec Loss: 0.715 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.112 
(2.316) - AE Loss: 187411.031 (674545.812) - AE Rec Loss: 1.271 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.57 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.164 
(2.256) - AE Loss: 166100.609 (673821.812) - AE Rec Loss: 1.126 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.168 
(2.256) - AE Loss: 2831191.250 (673821.812) - AE Rec Loss: 19.200 (4.570) - Disc
Loss: 0.000 (0.000) - 7.69 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.349) - Batch(s): 1.168 
(2.256) - AE Loss: 3048238.250 (673821.812) - AE Rec Loss: 20.672 (4.570) - Disc
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.168 
(2.256) - AE Loss: 74301.852 (673821.812) - AE Rec Loss: 0.504 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.69 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.167 
(2.256) - AE Loss: 214365.016 (673821.812) - AE Rec Loss: 1.454 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.349) - Batch(s): 0.563 
(2.256) - AE Loss: 340943.844 (673821.812) - AE Rec Loss: 2.312 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.69 m remaining

attempting to save
[[36m2023-11-29 04:19:28,279[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 04:19:30,036[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:19:31,434[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:19:31,445[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:19:31,453[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:19:31,465[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:19:31,475[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:19:31,480[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:19:31,485[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:19:31,490[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:19:32,837[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:19:38,727[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 04:19:45,407[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 04:19:45,412[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 04:19:48,956[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 04:19:48,956[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 04:19:48,956[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 04:19:48,971[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:27:39,992[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,095[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,108[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,164[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,179[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,181[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:27:42,161[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,217[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,256[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,319[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,325[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,331[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:42,838[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:42,933[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:42,997[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,011[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,056[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,076[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 04:27:43,486[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:27:43,488[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 04:27:43,492[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:27:43,492[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:27:43,492[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Mixed precision: no
[[36m2023-11-29 04:27:43,493[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Instantiating train dataloader 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing model 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
=> Preparing criterion 
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
Reached 1 on node 4
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 4
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0
Reached 1.3 on node 2
Reached 1.4 on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 2 on node 0
Reached 3 on node 2
Reached 3 on node 0
Reached 5 on node 2
Reached 5 on node 0
Reached end on node 2
Reached end on node 0
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached 2 on node 1
Reached end on node 5
Reached 3 on node 1
Reached 5 on node 1
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached end on node 1
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1Reached 1.4 on node 3

Reached 1 on node 2Reached 2 on node 1
Reached 2 on node 3

Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2Reached 1 on node 1

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 5Reached 1.4 on node 1

Reached 2 on node 1
Reached 2 on node 5
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached end on node 3Reached 3 on node 5

Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 1
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 2
Reached 1 on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 2
Reached end on node 0
[[36m2023-11-29 04:27:45,186[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 04:27:47,897[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 04:27:49,097[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:27:49,097[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:27:49,100[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 04:27:49,105[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:27:49,106[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <221/2280>] - Data(s): 9.120 (5.557) - Batch(s): 10.560 
(10.452) - AE Loss: 227359.797 (384334.250) - AE Rec Loss: 1.542 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 4.301 (5.557) - Batch(s): 10.556 
(10.452) - AE Loss: 437607.188 (384334.250) - AE Rec Loss: 2.968 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 7.304 (5.557) - Batch(s): 10.550 
(10.452) - AE Loss: 189555.641 (384334.250) - AE Rec Loss: 1.286 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 4.915 (5.557) - Batch(s): 10.565 
(10.452) - AE Loss: 79154.156 (384334.250) - AE Rec Loss: 0.537 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 2.610 (5.557) - Batch(s): 10.573 
(10.452) - AE Loss: 1022854.875 (384334.250) - AE Rec Loss: 6.937 (2.606) - Disc
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 3.366 (5.557) - Batch(s): 10.557 
(10.452) - AE Loss: 182851.141 (384334.250) - AE Rec Loss: 1.240 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.379 
(5.882) - AE Loss: 191906.922 (525178.688) - AE Rec Loss: 1.301 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.379 
(5.882) - AE Loss: 382811.094 (525178.688) - AE Rec Loss: 2.596 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.383 
(5.882) - AE Loss: 159567.141 (525178.688) - AE Rec Loss: 1.082 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.381 
(5.882) - AE Loss: 143248.406 (525178.688) - AE Rec Loss: 0.971 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.779) - Batch(s): 0.564 
(5.882) - AE Loss: 1536701.125 (525178.688) - AE Rec Loss: 10.421 (3.562) - Disc
Loss: 0.000 (0.000) - 1.90 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.382 
(5.882) - AE Loss: 1405367.250 (525178.688) - AE Rec Loss: 9.531 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.504 
(4.405) - AE Loss: 177805.000 (561457.062) - AE Rec Loss: 1.206 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.001 (1.877) - Batch(s): 1.504 
(4.405) - AE Loss: 1521655.750 (561457.062) - AE Rec Loss: 10.319 (3.808) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.504 
(4.405) - AE Loss: 382741.062 (561457.062) - AE Rec Loss: 2.596 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.001 (1.877) - Batch(s): 0.860 
(4.405) - AE Loss: 1479102.125 (561457.062) - AE Rec Loss: 10.031 (3.808) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.504 
(4.405) - AE Loss: 456221.438 (561457.062) - AE Rec Loss: 3.094 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.504 
(4.405) - AE Loss: 1523046.875 (561457.062) - AE Rec Loss: 10.329 (3.808) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.135 
(3.575) - AE Loss: 310933.500 (598042.188) - AE Rec Loss: 2.109 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.001 (1.408) - Batch(s): 0.565 
(3.575) - AE Loss: 356891.906 (598042.188) - AE Rec Loss: 2.420 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.136 
(3.575) - AE Loss: 235530.438 (598042.188) - AE Rec Loss: 1.597 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.134 
(3.575) - AE Loss: 233960.203 (598042.188) - AE Rec Loss: 1.587 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.136 
(3.575) - AE Loss: 1591981.250 (598042.188) - AE Rec Loss: 10.796 (4.056) - Disc
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.137 
(3.575) - AE Loss: 251320.453 (598042.188) - AE Rec Loss: 1.704 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.126) - Batch(s): 1.246 
(3.098) - AE Loss: 198122.156 (596834.062) - AE Rec Loss: 1.344 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.126) - Batch(s): 1.248 
(3.098) - AE Loss: 76412.656 (596834.062) - AE Rec Loss: 0.518 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.248 
(3.098) - AE Loss: 170324.125 (596834.062) - AE Rec Loss: 1.155 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.126) - Batch(s): 0.563 
(3.098) - AE Loss: 132431.219 (596834.062) - AE Rec Loss: 0.898 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.247 
(3.098) - AE Loss: 1622338.375 (596834.062) - AE Rec Loss: 11.002 (4.048) - Disc
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.126) - Batch(s): 1.249 
(3.098) - AE Loss: 1521695.750 (596834.062) - AE Rec Loss: 10.320 (4.048) - Disc
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.843 
(2.882) - AE Loss: 701063.500 (659255.562) - AE Rec Loss: 4.754 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.844 
(2.882) - AE Loss: 1517578.375 (659255.562) - AE Rec Loss: 10.292 (4.471) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.001 (0.962) - Batch(s): 1.292 
(2.882) - AE Loss: 81587.367 (659255.562) - AE Rec Loss: 0.553 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.844 
(2.882) - AE Loss: 1783935.875 (659255.562) - AE Rec Loss: 12.098 (4.471) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.845 
(2.882) - AE Loss: 1709573.250 (659255.562) - AE Rec Loss: 11.594 (4.471) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.845 
(2.882) - AE Loss: 132470.156 (659255.562) - AE Rec Loss: 0.898 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.279 
(2.644) - AE Loss: 223535.375 (620250.312) - AE Rec Loss: 1.516 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.825) - Batch(s): 0.565 
(2.644) - AE Loss: 192748.969 (620250.312) - AE Rec Loss: 1.307 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.281 
(2.644) - AE Loss: 377608.875 (620250.312) - AE Rec Loss: 2.561 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.278 
(2.644) - AE Loss: 186260.281 (620250.312) - AE Rec Loss: 1.263 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.281 
(2.644) - AE Loss: 66511.391 (620250.312) - AE Rec Loss: 0.451 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.280 
(2.644) - AE Loss: 101521.633 (620250.312) - AE Rec Loss: 0.688 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.722) - Batch(s): 0.565 
(2.467) - AE Loss: 229071.688 (572314.375) - AE Rec Loss: 1.553 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.288 
(2.467) - AE Loss: 155423.422 (572314.375) - AE Rec Loss: 1.054 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.290 
(2.467) - AE Loss: 284419.844 (572314.375) - AE Rec Loss: 1.929 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.292 
(2.467) - AE Loss: 357787.719 (572314.375) - AE Rec Loss: 2.426 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.292 
(2.467) - AE Loss: 278095.125 (572314.375) - AE Rec Loss: 1.886 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.290 
(2.467) - AE Loss: 188605.500 (572314.375) - AE Rec Loss: 1.279 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.117 
(2.535) - AE Loss: 106089.055 (558195.625) - AE Rec Loss: 0.719 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 93583.227 (558195.625) - AE Rec Loss: 0.635 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.117 
(2.535) - AE Loss: 239317.594 (558195.625) - AE Rec Loss: 1.623 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 272941.438 (558195.625) - AE Rec Loss: 1.851 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.678) - Batch(s): 2.612 
(2.535) - AE Loss: 138356.156 (558195.625) - AE Rec Loss: 0.938 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.172 (0.678) - Batch(s): 3.119 
(2.535) - AE Loss: 1557932.250 (558195.625) - AE Rec Loss: 10.565 (3.786) - Disc
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.706 
(2.441) - AE Loss: 1494168.375 (584214.375) - AE Rec Loss: 10.133 (3.962) - Disc
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.353 
(2.441) - AE Loss: 128089.117 (584214.375) - AE Rec Loss: 0.869 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 1.145 (0.620) - Batch(s): 1.710 
(2.441) - AE Loss: 1709610.500 (584214.375) - AE Rec Loss: 11.594 (3.962) - Disc
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.709 
(2.441) - AE Loss: 141159.625 (584214.375) - AE Rec Loss: 0.957 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.620) - Batch(s): 0.744 
(2.441) - AE Loss: 76623.578 (584214.375) - AE Rec Loss: 0.520 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.708 
(2.441) - AE Loss: 1522679.875 (584214.375) - AE Rec Loss: 10.326 (3.962) - Disc
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.155 
(2.342) - AE Loss: 1592487.250 (576558.688) - AE Rec Loss: 10.800 (3.910) - Disc
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.155 
(2.342) - AE Loss: 485201.750 (576558.688) - AE Rec Loss: 3.290 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.947 (0.571) - Batch(s): 1.511 
(2.342) - AE Loss: 314953.125 (576558.688) - AE Rec Loss: 2.136 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.509 
(2.342) - AE Loss: 375549.250 (576558.688) - AE Rec Loss: 2.547 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.155 
(2.342) - AE Loss: 1739113.750 (576558.688) - AE Rec Loss: 11.794 (3.910) - Disc
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.628 
(2.342) - AE Loss: 205983.094 (576558.688) - AE Rec Loss: 1.397 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.566 
(2.690) - AE Loss: 1584643.000 (599062.250) - AE Rec Loss: 10.747 (4.063) - Disc
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.567 
(2.690) - AE Loss: 183510.344 (599062.250) - AE Rec Loss: 1.245 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 5.994 
(2.690) - AE Loss: 1383043.500 (599062.250) - AE Rec Loss: 9.379 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.567 
(2.690) - AE Loss: 250321.844 (599062.250) - AE Rec Loss: 1.698 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.567 
(2.690) - AE Loss: 3063294.750 (599062.250) - AE Rec Loss: 20.774 (4.063) - Disc
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 185042.094 (599062.250) - AE Rec Loss: 1.255 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.096 
(2.564) - AE Loss: 189187.875 (590506.562) - AE Rec Loss: 1.283 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.099 
(2.564) - AE Loss: 151732.297 (590506.562) - AE Rec Loss: 1.029 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.096 
(2.564) - AE Loss: 1546588.875 (590506.562) - AE Rec Loss: 10.488 (4.005) - Disc
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.001 (0.545) - Batch(s): 0.565 
(2.564) - AE Loss: 319061.219 (590506.562) - AE Rec Loss: 2.164 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.100 
(2.564) - AE Loss: 75338.102 (590506.562) - AE Rec Loss: 0.511 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.098 
(2.564) - AE Loss: 115725.648 (590506.562) - AE Rec Loss: 0.785 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.138 
(2.459) - AE Loss: 67561.508 (597921.938) - AE Rec Loss: 0.458 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.141 
(2.459) - AE Loss: 696851.625 (597921.938) - AE Rec Loss: 4.726 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 0.565 
(2.459) - AE Loss: 1602419.500 (597921.938) - AE Rec Loss: 10.867 (4.055) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.142 
(2.459) - AE Loss: 74433.539 (597921.938) - AE Rec Loss: 0.505 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.138 
(2.459) - AE Loss: 60580.828 (597921.938) - AE Rec Loss: 0.411 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.140 
(2.459) - AE Loss: 251109.297 (597921.938) - AE Rec Loss: 1.703 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.472) - Batch(s): 1.158 
(2.369) - AE Loss: 232592.281 (610322.188) - AE Rec Loss: 1.577 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.158 
(2.369) - AE Loss: 295477.000 (610322.188) - AE Rec Loss: 2.004 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.472) - Batch(s): 0.650 
(2.369) - AE Loss: 1563058.500 (610322.188) - AE Rec Loss: 10.600 (4.139) - Disc
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.158 
(2.369) - AE Loss: 3054253.500 (610322.188) - AE Rec Loss: 20.713 (4.139) - Disc
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.472) - Batch(s): 1.158 
(2.369) - AE Loss: 217908.672 (610322.188) - AE Rec Loss: 1.478 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.158 
(2.369) - AE Loss: 405927.969 (610322.188) - AE Rec Loss: 2.753 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 1.055 
(2.285) - AE Loss: 1916327.750 (607751.188) - AE Rec Loss: 12.996 (4.122) - Disc
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 0.566 
(2.285) - AE Loss: 1514504.000 (607751.188) - AE Rec Loss: 10.271 (4.122) - Disc
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 1.056 
(2.285) - AE Loss: 184844.578 (607751.188) - AE Rec Loss: 1.254 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.058 
(2.285) - AE Loss: 390210.500 (607751.188) - AE Rec Loss: 2.646 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 1.059 
(2.285) - AE Loss: 320185.188 (607751.188) - AE Rec Loss: 2.171 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 1.057 
(2.285) - AE Loss: 69579.141 (607751.188) - AE Rec Loss: 0.472 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.281 
(2.222) - AE Loss: 192329.875 (606358.250) - AE Rec Loss: 1.304 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.278 
(2.222) - AE Loss: 506850.250 (606358.250) - AE Rec Loss: 3.437 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.566 
(2.222) - AE Loss: 174327.172 (606358.250) - AE Rec Loss: 1.182 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.282 
(2.222) - AE Loss: 1643324.125 (606358.250) - AE Rec Loss: 11.145 (4.112) - Disc
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.278 
(2.222) - AE Loss: 265594.656 (606358.250) - AE Rec Loss: 1.801 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.120 (0.417) - Batch(s): 1.279 
(2.222) - AE Loss: 144946.156 (606358.250) - AE Rec Loss: 0.983 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.97 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.208 
(2.163) - AE Loss: 110747.445 (598708.875) - AE Rec Loss: 0.751 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 1.207 
(2.163) - AE Loss: 98984.148 (598708.875) - AE Rec Loss: 0.671 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 1.209 
(2.163) - AE Loss: 195441.656 (598708.875) - AE Rec Loss: 1.325 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 1.209 
(2.163) - AE Loss: 391035.875 (598708.875) - AE Rec Loss: 2.652 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.208 
(2.163) - AE Loss: 1814402.500 (598708.875) - AE Rec Loss: 12.305 (4.060) - Disc
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 0.651 
(2.163) - AE Loss: 337305.781 (598708.875) - AE Rec Loss: 2.288 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.179 
(2.109) - AE Loss: 78200.750 (582979.062) - AE Rec Loss: 0.530 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.174 
(2.109) - AE Loss: 1427920.000 (582979.062) - AE Rec Loss: 9.684 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 0.567 
(2.109) - AE Loss: 188857.766 (582979.062) - AE Rec Loss: 1.281 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.176 
(2.109) - AE Loss: 75209.836 (582979.062) - AE Rec Loss: 0.510 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.177 
(2.109) - AE Loss: 599562.000 (582979.062) - AE Rec Loss: 4.066 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.178 
(2.109) - AE Loss: 235532.031 (582979.062) - AE Rec Loss: 1.597 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.30 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.185 (0.376) - Batch(s): 4.741 
(2.246) - AE Loss: 180363.656 (587034.875) - AE Rec Loss: 1.223 (3.981) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.434 (0.376) - Batch(s): 4.740 
(2.246) - AE Loss: 1712156.750 (587034.875) - AE Rec Loss: 11.611 (3.981) - Disc
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.376) - Batch(s): 4.741 
(2.246) - AE Loss: 133691.719 (587034.875) - AE Rec Loss: 0.907 (3.981) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.376) - Batch(s): 4.740 
(2.246) - AE Loss: 249649.078 (587034.875) - AE Rec Loss: 1.693 (3.981) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.376) - Batch(s): 4.741 
(2.246) - AE Loss: 1831624.000 (587034.875) - AE Rec Loss: 12.421 (3.981) - Disc
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.376) - Batch(s): 4.217 
(2.246) - AE Loss: 90979.102 (587034.875) - AE Rec Loss: 0.617 (3.981) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

attempting to save
[[36m2023-11-29 04:28:39,583[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 04:28:43,766[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:28:43,962[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:28:43,968[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:28:43,973[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:28:43,978[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:28:43,984[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:28:43,989[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:28:43,994[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:28:43,999[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:28:44,189[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:28:49,167[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:29:14,229[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,255[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,543[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,543[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,546[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,555[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:29:16,399[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:16,416[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:16,683[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:16,721[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:16,740[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:16,756[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,035[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,052[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,297[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,399[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,407[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,435[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:29:18,015[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:29:18,016[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:29:18,016[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 04:29:18,021[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:29:18,021[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:29:18,023[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
=> Instantiating the optimizer 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
=> Preparing opt_ae 
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.3 on node 3Reached end on node 2

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 1.3 on node 0
=> Preparing opt_ae 
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 4

Reached 1.4 on node 2
Reached 1.4 on node 4
Reached 2 on node 2
Reached 2 on node 4
Reached 3 on node 2
Reached 3 on node 4
Reached 5 on node 2
Reached 1.3 on node 5Reached 5 on node 4

Reached 1.3 on node 1Reached 1.4 on node 5

Reached 1.4 on node 1
Reached end on node 4Reached end on node 2

Reached 2 on node 5
Reached 2 on node 1
Reached 3 on node 5
Reached 3 on node 1
Reached 5 on node 5
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 5 on node 1Reached end on node 5

Reached 1.3 on node 0
Reached 2 on node 3
Reached 1.4 on node 0Reached end on node 1

Reached 2 on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached 3 on node 0
Reached end on node 3
Reached 5 on node 0
Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2Reached 1 on node 3

Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 1.4 on node 2
Reached 2 on node 4
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2Reached 1 on node 3

Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1 on node 0
Reached end on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached end on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 04:29:19,768[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1 on node 3
Reached end on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 2
Reached end on node 4
[[36m2023-11-29 04:29:21,366[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:29:21,941[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:29:21,941[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:29:21,941[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:29:21,945[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:29:21,946[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <221/2280>] - Data(s): 9.177 (5.680) - Batch(s): 10.591 
(10.820) - AE Loss: 227359.797 (384473.156) - AE Rec Loss: 1.542 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 3.842 (5.680) - Batch(s): 11.152 
(10.820) - AE Loss: 183377.016 (384473.156) - AE Rec Loss: 1.244 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 2.394 (5.680) - Batch(s): 10.588 
(10.820) - AE Loss: 1023333.375 (384473.156) - AE Rec Loss: 6.940 (2.607) - Disc
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 2.750 (5.680) - Batch(s): 10.785 
(10.820) - AE Loss: 437400.812 (384473.156) - AE Rec Loss: 2.966 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 8.822 (5.680) - Batch(s): 10.592 
(10.820) - AE Loss: 190035.375 (384473.156) - AE Rec Loss: 1.289 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 5.265 (5.680) - Batch(s): 10.611 
(10.820) - AE Loss: 80040.875 (384473.156) - AE Rec Loss: 0.543 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.227 
(5.995) - AE Loss: 1405970.875 (525206.562) - AE Rec Loss: 9.535 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.88 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.224 
(5.995) - AE Loss: 191430.734 (525206.562) - AE Rec Loss: 1.298 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.840) - Batch(s): 0.567 
(5.995) - AE Loss: 1536701.125 (525206.562) - AE Rec Loss: 10.421 (3.562) - Disc
Loss: 0.000 (0.000) - 1.89 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.227 
(5.995) - AE Loss: 159845.109 (525206.562) - AE Rec Loss: 1.084 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.89 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.226 
(5.995) - AE Loss: 382165.594 (525206.562) - AE Rec Loss: 2.592 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.225 
(5.995) - AE Loss: 142877.953 (525206.562) - AE Rec Loss: 0.969 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.88 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.717 
(4.550) - AE Loss: 455937.812 (561423.062) - AE Rec Loss: 3.092 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.716 
(4.550) - AE Loss: 1521613.250 (561423.062) - AE Rec Loss: 10.319 (3.807) - Disc
Loss: 0.000 (0.000) - 2.25 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.035 
(4.550) - AE Loss: 1479102.125 (561423.062) - AE Rec Loss: 10.031 (3.807) - Disc
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.717 
(4.550) - AE Loss: 178522.469 (561423.062) - AE Rec Loss: 1.211 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.717 
(4.550) - AE Loss: 1522517.500 (561423.062) - AE Rec Loss: 10.325 (3.807) - Disc
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 382183.344 (561423.062) - AE Rec Loss: 2.592 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.276 
(3.716) - AE Loss: 1592352.375 (598041.938) - AE Rec Loss: 10.799 (4.056) - Disc
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.271 
(3.716) - AE Loss: 311005.531 (598041.938) - AE Rec Loss: 2.109 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.001 (1.440) - Batch(s): 0.568 
(3.716) - AE Loss: 356936.375 (598041.938) - AE Rec Loss: 2.421 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.273 
(3.716) - AE Loss: 234595.031 (598041.938) - AE Rec Loss: 1.591 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.275 
(3.716) - AE Loss: 251104.656 (598041.938) - AE Rec Loss: 1.703 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.273 
(3.716) - AE Loss: 236784.750 (598041.938) - AE Rec Loss: 1.606 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.260 
(3.213) - AE Loss: 76957.562 (596881.312) - AE Rec Loss: 0.522 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.259 
(3.213) - AE Loss: 197546.625 (596881.312) - AE Rec Loss: 1.340 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.257 
(3.213) - AE Loss: 170968.109 (596881.312) - AE Rec Loss: 1.159 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.256 
(3.213) - AE Loss: 1622061.625 (596881.312) - AE Rec Loss: 11.000 (4.048) - Disc
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.152) - Batch(s): 0.568 
(3.213) - AE Loss: 132520.891 (596881.312) - AE Rec Loss: 0.899 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.260 
(3.213) - AE Loss: 1521241.500 (596881.312) - AE Rec Loss: 10.317 (4.048) - Disc
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.701 
(2.951) - AE Loss: 700739.812 (659272.312) - AE Rec Loss: 4.752 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.001 (0.973) - Batch(s): 0.958 
(2.951) - AE Loss: 81902.445 (659272.312) - AE Rec Loss: 0.555 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.85 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 132551.188 (659272.312) - AE Rec Loss: 0.899 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.85 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 1709528.250 (659272.312) - AE Rec Loss: 11.593 (4.471) - Disc
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 1783681.500 (659272.312) - AE Rec Loss: 12.096 (4.471) - Disc
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 1517335.750 (659272.312) - AE Rec Loss: 10.290 (4.471) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.834) - Batch(s): 1.316 
(2.708) - AE Loss: 66457.117 (620228.562) - AE Rec Loss: 0.451 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.834) - Batch(s): 0.570 
(2.708) - AE Loss: 192688.438 (620228.562) - AE Rec Loss: 1.307 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.314 
(2.708) - AE Loss: 185105.359 (620228.562) - AE Rec Loss: 1.255 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.834) - Batch(s): 1.316 
(2.708) - AE Loss: 376820.812 (620228.562) - AE Rec Loss: 2.555 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.312 
(2.708) - AE Loss: 223915.906 (620228.562) - AE Rec Loss: 1.519 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.313 
(2.708) - AE Loss: 101323.914 (620228.562) - AE Rec Loss: 0.687 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.730) - Batch(s): 1.256 
(2.519) - AE Loss: 277973.438 (572260.688) - AE Rec Loss: 1.885 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.254 
(2.519) - AE Loss: 188863.219 (572260.688) - AE Rec Loss: 1.281 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.730) - Batch(s): 1.256 
(2.519) - AE Loss: 357886.250 (572260.688) - AE Rec Loss: 2.427 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.730) - Batch(s): 0.569 
(2.519) - AE Loss: 228763.531 (572260.688) - AE Rec Loss: 1.551 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.730) - Batch(s): 1.254 
(2.519) - AE Loss: 155287.062 (572260.688) - AE Rec Loss: 1.053 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.730) - Batch(s): 1.252 
(2.519) - AE Loss: 284191.062 (572260.688) - AE Rec Loss: 1.927 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.674) - Batch(s): 3.450 
(2.616) - AE Loss: 106054.281 (558137.250) - AE Rec Loss: 0.719 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.674) - Batch(s): 2.700 
(2.616) - AE Loss: 138451.219 (558137.250) - AE Rec Loss: 0.939 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.674) - Batch(s): 3.454 
(2.616) - AE Loss: 1557718.500 (558137.250) - AE Rec Loss: 10.564 (3.785) - Disc
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.674) - Batch(s): 3.450 
(2.616) - AE Loss: 273012.812 (558137.250) - AE Rec Loss: 1.851 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.674) - Batch(s): 3.452 
(2.616) - AE Loss: 238646.422 (558137.250) - AE Rec Loss: 1.618 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.78 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.451 
(2.616) - AE Loss: 93486.195 (558137.250) - AE Rec Loss: 0.634 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.088 
(2.458) - AE Loss: 1709149.625 (584155.188) - AE Rec Loss: 11.591 (3.962) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.569 
(2.458) - AE Loss: 75885.672 (584155.188) - AE Rec Loss: 0.515 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.087 
(2.458) - AE Loss: 141146.391 (584155.188) - AE Rec Loss: 0.957 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.084 
(2.458) - AE Loss: 1522457.750 (584155.188) - AE Rec Loss: 10.325 (3.962) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.606) - Batch(s): 1.085 
(2.458) - AE Loss: 128754.953 (584155.188) - AE Rec Loss: 0.873 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.083 
(2.458) - AE Loss: 1494289.250 (584155.188) - AE Rec Loss: 10.134 (3.962) - Disc
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.001 (0.551) - Batch(s): 0.569 
(2.348) - AE Loss: 205777.969 (576503.875) - AE Rec Loss: 1.396 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.310 
(2.348) - AE Loss: 486862.281 (576503.875) - AE Rec Loss: 3.302 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.306 
(2.348) - AE Loss: 375895.875 (576503.875) - AE Rec Loss: 2.549 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.312 
(2.348) - AE Loss: 1738638.625 (576503.875) - AE Rec Loss: 11.791 (3.910) - Disc
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.309 
(2.348) - AE Loss: 315351.219 (576503.875) - AE Rec Loss: 2.139 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.309 
(2.348) - AE Loss: 1592541.000 (576503.875) - AE Rec Loss: 10.800 (3.910) - Disc
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.142 
(2.493) - AE Loss: 184962.312 (598978.875) - AE Rec Loss: 1.254 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 3.382 
(2.493) - AE Loss: 1382723.000 (598978.875) - AE Rec Loss: 9.377 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.001 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 1584440.500 (598978.875) - AE Rec Loss: 10.745 (4.062) - Disc
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 251308.781 (598978.875) - AE Rec Loss: 1.704 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.001 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 3063321.750 (598978.875) - AE Rec Loss: 20.774 (4.062) - Disc
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 182670.906 (598978.875) - AE Rec Loss: 1.239 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.001 (0.508) - Batch(s): 0.569 
(2.391) - AE Loss: 320779.625 (590414.062) - AE Rec Loss: 2.175 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.229 
(2.391) - AE Loss: 1546773.750 (590414.062) - AE Rec Loss: 10.490 (4.004) - Disc
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.001 (0.508) - Batch(s): 1.234 
(2.391) - AE Loss: 74510.016 (590414.062) - AE Rec Loss: 0.505 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.232 
(2.391) - AE Loss: 188870.938 (590414.062) - AE Rec Loss: 1.281 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.231 
(2.391) - AE Loss: 115778.773 (590414.062) - AE Rec Loss: 0.785 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.233 
(2.391) - AE Loss: 151101.516 (590414.062) - AE Rec Loss: 1.025 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.001 (0.481) - Batch(s): 1.244 
(2.361) - AE Loss: 1602453.000 (597821.875) - AE Rec Loss: 10.867 (4.054) - Disc
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 1.780 
(2.361) - AE Loss: 67017.922 (597821.875) - AE Rec Loss: 0.454 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.26 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 1.780 
(2.361) - AE Loss: 696147.125 (597821.875) - AE Rec Loss: 4.721 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 1.569 (0.481) - Batch(s): 2.136 
(2.361) - AE Loss: 250496.141 (597821.875) - AE Rec Loss: 1.699 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.131 
(2.361) - AE Loss: 60647.680 (597821.875) - AE Rec Loss: 0.411 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 1.779 
(2.361) - AE Loss: 75970.609 (597821.875) - AE Rec Loss: 0.515 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.447 
(2.296) - AE Loss: 406177.844 (610202.688) - AE Rec Loss: 2.755 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.53 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.448 
(2.296) - AE Loss: 294219.156 (610202.688) - AE Rec Loss: 1.995 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.450 
(2.296) - AE Loss: 232591.344 (610202.688) - AE Rec Loss: 1.577 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.449) - Batch(s): 0.732 
(2.296) - AE Loss: 1562810.500 (610202.688) - AE Rec Loss: 10.598 (4.138) - Disc
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.447 
(2.296) - AE Loss: 217408.719 (610202.688) - AE Rec Loss: 1.474 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.450 
(2.296) - AE Loss: 3054293.750 (610202.688) - AE Rec Loss: 20.713 (4.138) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.281 
(2.229) - AE Loss: 319470.562 (607696.812) - AE Rec Loss: 2.167 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.278 
(2.229) - AE Loss: 72886.094 (607696.812) - AE Rec Loss: 0.494 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.280 
(2.229) - AE Loss: 389382.938 (607696.812) - AE Rec Loss: 2.641 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.421) - Batch(s): 0.570 
(2.229) - AE Loss: 1514849.500 (607696.812) - AE Rec Loss: 10.273 (4.121) - Disc
Loss: 0.000 (0.000) - 5.63 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.279 
(2.229) - AE Loss: 184569.391 (607696.812) - AE Rec Loss: 1.252 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.277 
(2.229) - AE Loss: 1917858.625 (607696.812) - AE Rec Loss: 13.006 (4.121) - Disc
Loss: 0.000 (0.000) - 5.71 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.111 
(2.161) - AE Loss: 194002.828 (606332.312) - AE Rec Loss: 1.316 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.110 
(2.161) - AE Loss: 147340.031 (606332.312) - AE Rec Loss: 0.999 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.396) - Batch(s): 0.570 
(2.161) - AE Loss: 174174.953 (606332.312) - AE Rec Loss: 1.181 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.107 
(2.161) - AE Loss: 506025.906 (606332.312) - AE Rec Loss: 3.432 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.110 
(2.161) - AE Loss: 264877.844 (606332.312) - AE Rec Loss: 1.796 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.81 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.114 
(2.161) - AE Loss: 1643098.500 (606332.312) - AE Rec Loss: 11.143 (4.112) - Disc
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.374) - Batch(s): 1.225 
(2.106) - AE Loss: 1814056.625 (598692.938) - AE Rec Loss: 12.302 (4.060) - Disc
Loss: 0.000 (0.000) - 6.04 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.225 
(2.106) - AE Loss: 99835.703 (598692.938) - AE Rec Loss: 0.677 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.95 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.226 
(2.106) - AE Loss: 390909.875 (598692.938) - AE Rec Loss: 2.651 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.226 
(2.106) - AE Loss: 194934.797 (598692.938) - AE Rec Loss: 1.322 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.374) - Batch(s): 1.227 
(2.106) - AE Loss: 111069.594 (598692.938) - AE Rec Loss: 0.753 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.374) - Batch(s): 0.733 
(2.106) - AE Loss: 338324.375 (598692.938) - AE Rec Loss: 2.294 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.264 
(2.059) - AE Loss: 600513.438 (582948.750) - AE Rec Loss: 4.072 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.264 
(2.059) - AE Loss: 1426624.750 (582948.750) - AE Rec Loss: 9.675 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.265 
(2.059) - AE Loss: 74390.953 (582948.750) - AE Rec Loss: 0.504 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.266 
(2.059) - AE Loss: 77890.734 (582948.750) - AE Rec Loss: 0.528 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.571 
(2.059) - AE Loss: 188402.500 (582948.750) - AE Rec Loss: 1.278 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.269 
(2.059) - AE Loss: 236670.016 (582948.750) - AE Rec Loss: 1.605 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.321 
(2.019) - AE Loss: 1712804.250 (586997.438) - AE Rec Loss: 11.616 (3.981) - Disc
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.324 
(2.019) - AE Loss: 250765.516 (586997.438) - AE Rec Loss: 1.701 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.338) - Batch(s): 0.569 
(2.019) - AE Loss: 90435.930 (586997.438) - AE Rec Loss: 0.613 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.32 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.319 
(2.019) - AE Loss: 178447.625 (586997.438) - AE Rec Loss: 1.210 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.40 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.321 
(2.019) - AE Loss: 133166.812 (586997.438) - AE Rec Loss: 0.903 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.32 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.322 
(2.019) - AE Loss: 1831950.250 (586997.438) - AE Rec Loss: 12.424 (3.981) - Disc
Loss: 0.000 (0.000) - 6.34 m remaining

attempting to save
[[36m2023-11-29 04:30:07,659[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 04:30:11,120[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:30:11,302[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:30:11,326[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:30:11,338[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:30:11,345[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:30:11,350[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:30:11,357[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:30:11,363[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:30:11,368[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:30:13,248[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:30:16,146[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 04:30:25,640[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 04:30:25,646[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 04:30:29,943[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 04:30:29,944[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 04:30:29,944[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 04:30:29,956[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 62159.672 (595459.062) - AE Rec Loss: 0.422 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.67 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 1746128.750 (595459.062) - AE Rec Loss: 11.842 (4.038) - Disc
Loss: 0.000 (0.000) - 9.67 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.958 
(2.972) - AE Loss: 114353.570 (595459.062) - AE Rec Loss: 0.776 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.68 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.958 
(2.972) - AE Loss: 1435862.250 (595459.062) - AE Rec Loss: 9.738 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.75 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.958 
(2.972) - AE Loss: 126973.039 (595459.062) - AE Rec Loss: 0.861 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 0.718 
(2.972) - AE Loss: 1673965.000 (595459.062) - AE Rec Loss: 11.352 (4.038) - Disc
Loss: 0.000 (0.000) - 9.67 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.036 
(2.882) - AE Loss: 1526666.000 (597896.125) - AE Rec Loss: 10.353 (4.055) - Disc
Loss: 0.000 (0.000) - 9.88 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 58799.316 (597896.125) - AE Rec Loss: 0.399 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.80 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 1527160.625 (597896.125) - AE Rec Loss: 10.357 (4.055) - Disc
Loss: 0.000 (0.000) - 9.79 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 0.568 
(2.882) - AE Loss: 96463.383 (597896.125) - AE Rec Loss: 0.654 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.80 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.042 
(2.882) - AE Loss: 1595326.750 (597896.125) - AE Rec Loss: 10.819 (4.055) - Disc
Loss: 0.000 (0.000) - 9.80 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 423495.188 (597896.125) - AE Rec Loss: 2.872 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:33:51,162[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,225[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,271[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,310[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,324[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,331[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:33:53,283[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,394[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,423[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,448[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,466[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,477[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:53,907[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,050[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,140[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,195[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,206[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,215[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:33:54,839[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,840[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,840[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:33:54,843[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,843[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
[[36m2023-11-29 04:33:54,844[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Mixed precision: no
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
len(valid_dataloader) = 1
=> Preparing model 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:35:23,429[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,430[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,650[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,659[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,669[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,705[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:35:25,593[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,622[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,792[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,858[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,889[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,985[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,096[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,232[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,454[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,493[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,549[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,592[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 04:35:26,890[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:35:26,894[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
[[36m2023-11-29 04:35:26,896[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
=> Preparing model 
len(train_dataloader) = 2279
[[36m2023-11-29 04:35:26,899[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:35:26,899[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating the optimizer 
[[36m2023-11-29 04:35:26,900[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Mixed precision: no
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.3 on node 1
Reached end on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4Reached 1 on node 5
Reached 1 on node 1

devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 5
Reached 1.2 on node 1
Reached 1.25 on node 5
Reached 1.25 on node 1devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}

devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 1

Reached 1.4 on node 1
Reached 1.4 on node 2
Reached 2 on node 1
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 1
Reached 5 on node 2
Reached 5 on node 1
Reached end on node 2
Reached end on node 1
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.3 on node 0Reached 1.3 on node 4

Reached 1.4 on node 4Reached 1.4 on node 0

Reached 2 on node 4
Reached 3 on node 5Reached 2 on node 0

Reached 5 on node 5
Reached 3 on node 4
Reached 3 on node 0Reached end on node 5

Reached 5 on node 4
Reached 5 on node 0
Reached end on node 4
Reached end on node 0
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 1.4 on node 3
Reached 2 on node 4
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 1.4 on node 5
Reached 2 on node 2
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3Reached 1.4 on node 4

Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2Reached 1.4 on node 5

Reached 3 on node 2Reached 2 on node 5

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2Reached 1 on node 4
Reached 1 on node 3

Reached 1.4 on node 4Reached 1.4 on node 3

Reached 2 on node 4Reached 2 on node 3

Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 4
Reached 1 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 4
Reached end on node 0
[[36m2023-11-29 04:35:28,610[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 2
Reached end on node 1
[[36m2023-11-29 04:35:30,962[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:35:32,052[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:35:32,052[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
[[36m2023-11-29 04:35:32,052[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 04:35:32,055[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:35:32,056[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 7.384 (6.133) - Batch(s): 11.106 
(11.005) - AE Loss: 126293.016 (764854.500) - AE Rec Loss: 0.856 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 6.549 (6.133) - Batch(s): 11.116 
(11.005) - AE Loss: 61980.078 (764854.500) - AE Rec Loss: 0.420 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 7.373 (6.133) - Batch(s): 11.103 
(11.005) - AE Loss: 1674765.125 (764854.500) - AE Rec Loss: 11.358 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.532 (6.133) - Batch(s): 11.116 
(11.005) - AE Loss: 1746473.750 (764854.500) - AE Rec Loss: 11.844 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 8.571 (6.133) - Batch(s): 11.122 
(11.005) - AE Loss: 1435855.000 (764854.500) - AE Rec Loss: 9.738 (5.187) - Disc
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.509 (6.133) - Batch(s): 11.113 
(11.005) - AE Loss: 115417.562 (764854.500) - AE Rec Loss: 0.783 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.001 (3.067) - Batch(s): 0.560 
(6.072) - AE Loss: 94870.930 (708585.750) - AE Rec Loss: 0.643 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.194 
(6.072) - AE Loss: 1529674.000 (708585.750) - AE Rec Loss: 10.374 (4.805) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.191 
(6.072) - AE Loss: 1524967.500 (708585.750) - AE Rec Loss: 10.342 (4.805) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.193 
(6.072) - AE Loss: 427418.750 (708585.750) - AE Rec Loss: 2.899 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.196 
(6.072) - AE Loss: 59629.562 (708585.750) - AE Rec Loss: 0.404 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.194 
(6.072) - AE Loss: 1597918.125 (708585.750) - AE Rec Loss: 10.837 (4.805) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.724 
(5.609) - AE Loss: 1589577.500 (744477.125) - AE Rec Loss: 10.780 (5.049) - Disc
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.729 
(5.609) - AE Loss: 173339.453 (744477.125) - AE Rec Loss: 1.176 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.001 (2.256) - Batch(s): 4.206 
(5.609) - AE Loss: 1760198.500 (744477.125) - AE Rec Loss: 11.937 (5.049) - Disc
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.724 
(5.609) - AE Loss: 1534611.875 (744477.125) - AE Rec Loss: 10.407 (5.049) - Disc
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 4.081 (2.256) - Batch(s): 4.729 
(5.609) - AE Loss: 1468165.375 (744477.125) - AE Rec Loss: 9.957 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.728 
(5.609) - AE Loss: 169668.875 (744477.125) - AE Rec Loss: 1.151 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.017 
(4.451) - AE Loss: 238925.109 (756529.500) - AE Rec Loss: 1.620 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 0.562 
(4.451) - AE Loss: 636170.812 (756529.500) - AE Rec Loss: 4.314 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.014 
(4.451) - AE Loss: 346225.125 (756529.500) - AE Rec Loss: 2.348 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.018 
(4.451) - AE Loss: 1431965.375 (756529.500) - AE Rec Loss: 9.711 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.017 
(4.451) - AE Loss: 266205.438 (756529.500) - AE Rec Loss: 1.805 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.015 
(4.451) - AE Loss: 2695084.000 (756529.500) - AE Rec Loss: 18.277 (5.131) - Disc
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.401 
(3.868) - AE Loss: 113751.461 (747887.250) - AE Rec Loss: 0.771 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 0.863 
(3.868) - AE Loss: 443654.938 (747887.250) - AE Rec Loss: 3.009 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.401 
(3.868) - AE Loss: 1562623.875 (747887.250) - AE Rec Loss: 10.597 (5.072) - Disc
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.401 
(3.868) - AE Loss: 670228.312 (747887.250) - AE Rec Loss: 4.545 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.401 
(3.868) - AE Loss: 382529.688 (747887.250) - AE Rec Loss: 2.594 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.401 
(3.868) - AE Loss: 632602.500 (747887.250) - AE Rec Loss: 4.290 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.149) - Batch(s): 1.151 
(3.408) - AE Loss: 388156.656 (762172.438) - AE Rec Loss: 2.632 (5.169) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.152 
(3.408) - AE Loss: 1526319.500 (762172.438) - AE Rec Loss: 10.351 (5.169) - Disc
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.151 
(3.408) - AE Loss: 134622.062 (762172.438) - AE Rec Loss: 0.913 (5.169) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.152 
(3.408) - AE Loss: 268354.156 (762172.438) - AE Rec Loss: 1.820 (5.169) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 0.633 
(3.408) - AE Loss: 77434.055 (762172.438) - AE Rec Loss: 0.525 (5.169) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.273 (1.149) - Batch(s): 1.152 
(3.408) - AE Loss: 3324957.250 (762172.438) - AE Rec Loss: 22.549 (5.169) - Disc
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.059 
(3.066) - AE Loss: 64311.367 (706478.562) - AE Rec Loss: 0.436 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.056 
(3.066) - AE Loss: 325588.375 (706478.562) - AE Rec Loss: 2.208 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.060 
(3.066) - AE Loss: 94537.367 (706478.562) - AE Rec Loss: 0.641 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.059 
(3.066) - AE Loss: 317018.781 (706478.562) - AE Rec Loss: 2.150 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.056 
(3.066) - AE Loss: 91820.727 (706478.562) - AE Rec Loss: 0.623 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (0.987) - Batch(s): 0.563 
(3.066) - AE Loss: 2700318.500 (706478.562) - AE Rec Loss: 18.313 (4.791) - Disc
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.592 
(3.148) - AE Loss: 375505.000 (718335.438) - AE Rec Loss: 2.547 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.039 
(3.148) - AE Loss: 530797.625 (718335.438) - AE Rec Loss: 3.600 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.592 
(3.148) - AE Loss: 1470308.250 (718335.438) - AE Rec Loss: 9.971 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.872 (0.908) - Batch(s): 3.592 
(3.148) - AE Loss: 2991191.000 (718335.438) - AE Rec Loss: 20.285 (4.872) - Disc
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.592 
(3.148) - AE Loss: 277383.219 (718335.438) - AE Rec Loss: 1.881 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.592 
(3.148) - AE Loss: 73089.086 (718335.438) - AE Rec Loss: 0.496 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 1.812 (0.902) - Batch(s): 8.607 
(3.808) - AE Loss: 110999.414 (704437.750) - AE Rec Loss: 0.753 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 8.489 (0.902) - Batch(s): 9.128 
(3.808) - AE Loss: 259696.016 (704437.750) - AE Rec Loss: 1.761 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.128 
(3.808) - AE Loss: 333228.094 (704437.750) - AE Rec Loss: 2.260 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.128 
(3.808) - AE Loss: 1321225.250 (704437.750) - AE Rec Loss: 8.960 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.128 
(3.808) - AE Loss: 93747.289 (704437.750) - AE Rec Loss: 0.636 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.128 
(3.808) - AE Loss: 1615645.125 (704437.750) - AE Rec Loss: 10.957 (4.777) - Disc
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.563 
(3.523) - AE Loss: 90953.211 (680213.562) - AE Rec Loss: 0.617 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.09 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.995 
(3.523) - AE Loss: 204469.250 (680213.562) - AE Rec Loss: 1.387 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.999 
(3.523) - AE Loss: 291689.438 (680213.562) - AE Rec Loss: 1.978 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.997 
(3.523) - AE Loss: 614261.500 (680213.562) - AE Rec Loss: 4.166 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 1.000 
(3.523) - AE Loss: 1431301.125 (680213.562) - AE Rec Loss: 9.707 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.999 
(3.523) - AE Loss: 169671.672 (680213.562) - AE Rec Loss: 1.151 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.375 
(3.592) - AE Loss: 155375.688 (653895.812) - AE Rec Loss: 1.054 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.378 
(3.592) - AE Loss: 170360.234 (653895.812) - AE Rec Loss: 1.155 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.023 
(3.592) - AE Loss: 193115.641 (653895.812) - AE Rec Loss: 1.310 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 3.809 (0.767) - Batch(s): 4.381 
(3.592) - AE Loss: 91592.664 (653895.812) - AE Rec Loss: 0.621 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.378 
(3.592) - AE Loss: 177265.344 (653895.812) - AE Rec Loss: 1.202 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 3.532 
(3.592) - AE Loss: 187847.156 (653895.812) - AE Rec Loss: 1.274 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 9.309 (0.843) - Batch(s): 9.953 
(4.159) - AE Loss: 1460760.250 (662863.625) - AE Rec Loss: 9.906 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 1.810 (0.843) - Batch(s): 10.432 
(4.159) - AE Loss: 163673.188 (662863.625) - AE Rec Loss: 1.110 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.432 
(4.159) - AE Loss: 429885.875 (662863.625) - AE Rec Loss: 2.915 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 8.998 (0.843) - Batch(s): 10.432 
(4.159) - AE Loss: 417962.438 (662863.625) - AE Rec Loss: 2.834 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.843) - Batch(s): 10.432 
(4.159) - AE Loss: 113840.094 (662863.625) - AE Rec Loss: 0.772 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.432 
(4.159) - AE Loss: 737275.812 (662863.625) - AE Rec Loss: 5.000 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 4.995 (0.810) - Batch(s): 5.564 
(4.252) - AE Loss: 1551369.375 (686191.250) - AE Rec Loss: 10.521 (4.654) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 4.675 
(4.252) - AE Loss: 1513588.500 (686191.250) - AE Rec Loss: 10.265 (4.654) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.209 
(4.252) - AE Loss: 59894.973 (686191.250) - AE Rec Loss: 0.406 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.001 (0.810) - Batch(s): 5.209 
(4.252) - AE Loss: 837762.812 (686191.250) - AE Rec Loss: 5.681 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.209 
(4.252) - AE Loss: 160334.969 (686191.250) - AE Rec Loss: 1.087 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.209 
(4.252) - AE Loss: 3192940.750 (686191.250) - AE Rec Loss: 21.654 (4.654) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.001 (0.752) - Batch(s): 0.566 
(4.018) - AE Loss: 57422.637 (676526.688) - AE Rec Loss: 0.389 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.004 
(4.018) - AE Loss: 1693030.500 (676526.688) - AE Rec Loss: 11.482 (4.588) - Disc
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.006 
(4.018) - AE Loss: 160049.781 (676526.688) - AE Rec Loss: 1.085 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.008 
(4.018) - AE Loss: 121287.656 (676526.688) - AE Rec Loss: 0.823 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.008 
(4.018) - AE Loss: 221912.875 (676526.688) - AE Rec Loss: 1.505 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.001 (0.752) - Batch(s): 1.008 
(4.018) - AE Loss: 1473336.625 (676526.688) - AE Rec Loss: 9.992 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:38:29,408[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,408[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,424[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,442[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,449[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,493[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:38:31,559[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,565[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,581[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,597[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,603[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,686[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,317[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,351[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,393[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,406[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,414[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,418[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:38:32,586[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:38:32,587[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 04:38:32,588[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 04:38:32,591[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating the optimizer 
[[36m2023-11-29 04:38:32,593[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
[[36m2023-11-29 04:38:32,595[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 3 on node 1Reached 5 on node 0

Reached 5 on node 1
Reached end on node 0
Reached end on node 1
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1 on node 2
Reached 1.2 on node 3
Reached 1.2 on node 2
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1 on node 4
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4Reached 1.3 on node 3

Reached 1.4 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 2 on node 3
Reached 3 on node 3Reached 3 on node 4

Reached 5 on node 4
Reached 5 on node 3
Reached end on node 4
Reached end on node 3
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 1.3 on node 1
Reached 1.3 on node 0Reached 1.4 on node 1
Reached 2 on node 2

Reached 1.4 on node 0
Reached 2 on node 1
Reached 2 on node 0
Reached 3 on node 2
Reached 5 on node 2
Reached 3 on node 0Reached 3 on node 1

Reached end on node 2Reached 1.3 on node 5Reached 5 on node 1
Reached 5 on node 0


Reached 1.4 on node 5
Reached end on node 1Reached end on node 0

Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1Reached 1 on node 2

Reached 1.4 on node 1Reached 1.4 on node 2

Reached 2 on node 1Reached 2 on node 2

Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3Reached 1.4 on node 4

Reached 2 on node 4
Reached end on node 0
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 3 on node 1
Reached 1 on node 5Reached 3 on node 1

Reached 1 on node 4Reached 3 on node 1

Reached 1.4 on node 3
Reached 3 on node 1
Reached 2 on node 3Reached 3 on node 1

Reached 5 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 1 on node 3Reached 3 on node 2

Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 1.4 on node 4Reached 3 on node 3

Reached 2 on node 4Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 1 on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 1
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3Reached 1 on node 4

Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 0
Reached end on node 1
[[36m2023-11-29 04:38:34,307[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
[[36m2023-11-29 04:38:35,598[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:38:36,086[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:38:36,086[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:38:36,086[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:38:36,089[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:38:36,091[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 5.322 (5.957) - Batch(s): 13.081 
(13.049) - AE Loss: 1674765.125 (764843.500) - AE Rec Loss: 11.358 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 6.101 (5.957) - Batch(s): 13.116 
(13.049) - AE Loss: 1436292.250 (764843.500) - AE Rec Loss: 9.740 (5.187) - Disc
Loss: 0.000 (0.000) - 1.88 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.227 (5.957) - Batch(s): 12.730 
(13.049) - AE Loss: 115840.023 (764843.500) - AE Rec Loss: 0.786 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 6.935 (5.957) - Batch(s): 13.081 
(13.049) - AE Loss: 125867.789 (764843.500) - AE Rec Loss: 0.854 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.88 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 6.225 (5.957) - Batch(s): 12.722 
(13.049) - AE Loss: 62236.320 (764843.500) - AE Rec Loss: 0.422 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 7.669 (5.957) - Batch(s): 12.824 
(13.049) - AE Loss: 1746843.750 (764843.500) - AE Rec Loss: 11.847 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.84 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.560 
(6.806) - AE Loss: 1525752.750 (708657.188) - AE Rec Loss: 10.347 (4.806) - Disc
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.566 
(6.806) - AE Loss: 1598153.500 (708657.188) - AE Rec Loss: 10.838 (4.806) - Disc
Loss: 0.000 (0.000) - 1.93 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.563 
(6.806) - AE Loss: 1529179.875 (708657.188) - AE Rec Loss: 10.370 (4.806) - Disc
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.564 
(6.806) - AE Loss: 60985.289 (708657.188) - AE Rec Loss: 0.414 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.562 
(6.806) - AE Loss: 426895.000 (708657.188) - AE Rec Loss: 2.895 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.564 
(6.806) - AE Loss: 94870.930 (708657.188) - AE Rec Loss: 0.643 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 168845.328 (744556.875) - AE Rec Loss: 1.145 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.62 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 3.090 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 1469179.000 (744556.875) - AE Rec Loss: 9.964 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 173708.906 (744556.875) - AE Rec Loss: 1.178 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 1760198.500 (744556.875) - AE Rec Loss: 11.937 (5.049) - Disc
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 1535799.000 (744556.875) - AE Rec Loss: 10.415 (5.049) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 1589155.875 (744556.875) - AE Rec Loss: 10.777 (5.049) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.564 
(4.757) - AE Loss: 636374.750 (756369.188) - AE Rec Loss: 4.316 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.561 
(4.757) - AE Loss: 337171.062 (756369.188) - AE Rec Loss: 2.287 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.563 
(4.757) - AE Loss: 2694938.250 (756369.188) - AE Rec Loss: 18.276 (5.129) - Disc
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.001 (1.655) - Batch(s): 0.567 
(4.757) - AE Loss: 265154.469 (756369.188) - AE Rec Loss: 1.798 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.565 
(4.757) - AE Loss: 1432801.000 (756369.188) - AE Rec Loss: 9.717 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.565 
(4.757) - AE Loss: 238526.484 (756369.188) - AE Rec Loss: 1.618 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.562 
(3.918) - AE Loss: 1562415.500 (747658.375) - AE Rec Loss: 10.596 (5.070) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.324) - Batch(s): 0.566 
(3.918) - AE Loss: 667418.062 (747658.375) - AE Rec Loss: 4.526 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.324) - Batch(s): 0.563 
(3.918) - AE Loss: 381450.719 (747658.375) - AE Rec Loss: 2.587 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.324) - Batch(s): 0.567 
(3.918) - AE Loss: 631097.375 (747658.375) - AE Rec Loss: 4.280 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.80 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.324) - Batch(s): 0.565 
(3.918) - AE Loss: 443270.781 (747658.375) - AE Rec Loss: 3.006 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.324) - Batch(s): 0.565 
(3.918) - AE Loss: 114000.773 (747658.375) - AE Rec Loss: 0.773 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.238 
(3.472) - AE Loss: 389045.438 (762029.750) - AE Rec Loss: 2.638 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.237 
(3.472) - AE Loss: 1526691.250 (762029.750) - AE Rec Loss: 10.354 (5.168) - Disc
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.239 
(3.472) - AE Loss: 269396.406 (762029.750) - AE Rec Loss: 1.827 (5.168) - Disc 
Loss: 0.000 (0.000) - 3.01 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.238 
(3.472) - AE Loss: 135584.125 (762029.750) - AE Rec Loss: 0.919 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.97 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.586 (1.116) - Batch(s): 1.238 
(3.472) - AE Loss: 3324533.500 (762029.750) - AE Rec Loss: 22.546 (5.168) - Disc
Loss: 0.000 (0.000) - 3.01 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.116) - Batch(s): 1.238 
(3.472) - AE Loss: 77852.234 (762029.750) - AE Rec Loss: 0.528 (5.168) - Disc 
Loss: 0.000 (0.000) - 3.01 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.564 
(3.056) - AE Loss: 2700101.500 (706268.562) - AE Rec Loss: 18.311 (4.790) - Disc
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (0.957) - Batch(s): 0.563 
(3.056) - AE Loss: 91628.125 (706268.562) - AE Rec Loss: 0.621 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.10 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.567 
(3.056) - AE Loss: 94009.000 (706268.562) - AE Rec Loss: 0.638 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.566 
(3.056) - AE Loss: 62680.023 (706268.562) - AE Rec Loss: 0.425 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.562 
(3.056) - AE Loss: 324895.062 (706268.562) - AE Rec Loss: 2.203 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.10 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.568 
(3.056) - AE Loss: 315962.000 (706268.562) - AE Rec Loss: 2.143 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 2.848 
(3.053) - AE Loss: 1470391.500 (718105.312) - AE Rec Loss: 9.972 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.54 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 2.851 
(3.053) - AE Loss: 73445.500 (718105.312) - AE Rec Loss: 0.498 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 2.849 
(3.053) - AE Loss: 276882.000 (718105.312) - AE Rec Loss: 1.878 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.54 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 2.849 
(3.053) - AE Loss: 373259.000 (718105.312) - AE Rec Loss: 2.531 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 2.849 
(3.053) - AE Loss: 528813.750 (718105.312) - AE Rec Loss: 3.586 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.54 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.864) - Batch(s): 2.849 
(3.053) - AE Loss: 2991273.000 (718105.312) - AE Rec Loss: 20.286 (4.870) - Disc
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.650 
(2.786) - AE Loss: 259720.078 (704160.562) - AE Rec Loss: 1.761 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.650 
(2.786) - AE Loss: 109947.352 (704160.562) - AE Rec Loss: 0.746 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.650 
(2.786) - AE Loss: 1320297.000 (704160.562) - AE Rec Loss: 8.954 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.58 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.001 (0.768) - Batch(s): 0.652 
(2.786) - AE Loss: 1614506.625 (704160.562) - AE Rec Loss: 10.949 (4.775) - Disc
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.652 
(2.786) - AE Loss: 92601.664 (704160.562) - AE Rec Loss: 0.628 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.652 
(2.786) - AE Loss: 332807.125 (704160.562) - AE Rec Loss: 2.257 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.58 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.566 
(2.568) - AE Loss: 1430776.875 (679897.250) - AE Rec Loss: 9.703 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.68 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.568 
(2.568) - AE Loss: 168648.375 (679897.250) - AE Rec Loss: 1.144 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.566 
(2.568) - AE Loss: 290487.625 (679897.250) - AE Rec Loss: 1.970 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.68 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.562 
(2.568) - AE Loss: 204531.734 (679897.250) - AE Rec Loss: 1.387 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.564 
(2.568) - AE Loss: 612768.688 (679897.250) - AE Rec Loss: 4.156 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.566 
(2.568) - AE Loss: 90215.883 (679897.250) - AE Rec Loss: 0.612 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.451 
(2.751) - AE Loss: 90884.367 (653562.688) - AE Rec Loss: 0.616 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.451 
(2.751) - AE Loss: 154940.094 (653562.688) - AE Rec Loss: 1.051 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.451 
(2.751) - AE Loss: 192448.562 (653562.688) - AE Rec Loss: 1.305 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 3.839 
(2.751) - AE Loss: 187978.094 (653562.688) - AE Rec Loss: 1.275 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.451 
(2.751) - AE Loss: 168691.078 (653562.688) - AE Rec Loss: 1.144 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.453 
(2.751) - AE Loss: 176825.156 (653562.688) - AE Rec Loss: 1.199 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 735517.188 (662484.250) - AE Rec Loss: 4.988 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.43 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.607) - Batch(s): 0.656 
(2.577) - AE Loss: 415982.938 (662484.250) - AE Rec Loss: 2.821 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.656 
(2.577) - AE Loss: 1460765.750 (662484.250) - AE Rec Loss: 9.906 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.656 
(2.577) - AE Loss: 425189.906 (662484.250) - AE Rec Loss: 2.884 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 163508.750 (662484.250) - AE Rec Loss: 1.109 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 114678.711 (662484.250) - AE Rec Loss: 0.778 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.568 
(2.422) - AE Loss: 820560.812 (685638.125) - AE Rec Loss: 5.565 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.564 
(2.422) - AE Loss: 3193139.500 (685638.125) - AE Rec Loss: 21.655 (4.650) - Disc
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.566 
(2.422) - AE Loss: 152182.547 (685638.125) - AE Rec Loss: 1.032 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.567 
(2.422) - AE Loss: 62764.609 (685638.125) - AE Rec Loss: 0.426 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.566 
(2.422) - AE Loss: 1511855.500 (685638.125) - AE Rec Loss: 10.253 (4.650) - Disc
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.563 
(2.422) - AE Loss: 1549450.750 (685638.125) - AE Rec Loss: 10.508 (4.650) - Disc
Loss: 0.000 (0.000) - 4.55 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.569 
(2.299) - AE Loss: 118894.805 (675938.688) - AE Rec Loss: 0.806 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.571 
(2.299) - AE Loss: 220374.016 (675938.688) - AE Rec Loss: 1.495 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.571 
(2.299) - AE Loss: 1471021.000 (675938.688) - AE Rec Loss: 9.976 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.001 (0.523) - Batch(s): 0.569 
(2.299) - AE Loss: 59104.340 (675938.688) - AE Rec Loss: 0.401 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.568 
(2.299) - AE Loss: 160147.312 (675938.688) - AE Rec Loss: 1.086 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.565 
(2.299) - AE Loss: 1691057.625 (675938.688) - AE Rec Loss: 11.468 (4.584) - Disc
Loss: 0.000 (0.000) - 4.66 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.323 
(2.434) - AE Loss: 1710266.750 (681074.375) - AE Rec Loss: 11.598 (4.619) - Disc
Loss: 0.000 (0.000) - 5.19 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 3.682 (0.508) - Batch(s): 4.323 
(2.434) - AE Loss: 1414125.625 (681074.375) - AE Rec Loss: 9.590 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.23 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.001 (0.508) - Batch(s): 4.324 
(2.434) - AE Loss: 221571.672 (681074.375) - AE Rec Loss: 1.503 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.324 
(2.434) - AE Loss: 204672.172 (681074.375) - AE Rec Loss: 1.388 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.324 
(2.434) - AE Loss: 63304.379 (681074.375) - AE Rec Loss: 0.429 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.323 
(2.434) - AE Loss: 70282.180 (681074.375) - AE Rec Loss: 0.477 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.23 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.568 
(2.317) - AE Loss: 188538.078 (673834.812) - AE Rec Loss: 1.279 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.26 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.563 
(2.317) - AE Loss: 1497463.000 (673834.812) - AE Rec Loss: 10.155 (4.570) - Disc
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.565 
(2.317) - AE Loss: 1452975.375 (673834.812) - AE Rec Loss: 9.854 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.563 
(2.317) - AE Loss: 103817.211 (673834.812) - AE Rec Loss: 0.704 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.566 
(2.317) - AE Loss: 652256.625 (673834.812) - AE Rec Loss: 4.423 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.565 
(2.317) - AE Loss: 91817.297 (673834.812) - AE Rec Loss: 0.623 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 542409.500 (675058.562) - AE Rec Loss: 3.678 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 196597.953 (675058.562) - AE Rec Loss: 1.333 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 1824051.875 (675058.562) - AE Rec Loss: 12.370 (4.578) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 1390598.500 (675058.562) - AE Rec Loss: 9.431 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 54396.605 (675058.562) - AE Rec Loss: 0.369 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 0.952 
(2.247) - AE Loss: 525825.438 (675058.562) - AE Rec Loss: 3.566 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.845 
(2.780) - AE Loss: 183028.359 (651380.125) - AE Rec Loss: 1.241 (4.417) - Disc 
Loss: 0.000 (0.000) - 7.00 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 11.205 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 143177.031 (651380.125) - AE Rec Loss: 0.971 (4.417) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 257146.453 (651380.125) - AE Rec Loss: 1.744 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 539016.562 (651380.125) - AE Rec Loss: 3.655 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 47586.734 (651380.125) - AE Rec Loss: 0.323 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.846 
(2.780) - AE Loss: 123352.117 (651380.125) - AE Rec Loss: 0.837 (4.417) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.567 
(2.664) - AE Loss: 172837.594 (635454.250) - AE Rec Loss: 1.172 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.564 
(2.664) - AE Loss: 245797.469 (635454.250) - AE Rec Loss: 1.667 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.569 
(2.664) - AE Loss: 832686.625 (635454.250) - AE Rec Loss: 5.647 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.001 (0.454) - Batch(s): 0.566 
(2.664) - AE Loss: 50980.320 (635454.250) - AE Rec Loss: 0.346 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.02 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.564 
(2.664) - AE Loss: 309050.875 (635454.250) - AE Rec Loss: 2.096 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.566 
(2.664) - AE Loss: 203262.094 (635454.250) - AE Rec Loss: 1.378 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.02 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.565 
(2.559) - AE Loss: 669920.625 (631961.750) - AE Rec Loss: 4.543 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.568 
(2.559) - AE Loss: 215341.266 (631961.750) - AE Rec Loss: 1.460 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.569 
(2.559) - AE Loss: 179173.859 (631961.750) - AE Rec Loss: 1.215 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.564 
(2.559) - AE Loss: 1749658.875 (631961.750) - AE Rec Loss: 11.866 (4.286) - Disc
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.567 
(2.559) - AE Loss: 1494913.000 (631961.750) - AE Rec Loss: 10.138 (4.286) - Disc
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.566 
(2.559) - AE Loss: 136423.312 (631961.750) - AE Rec Loss: 0.925 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

attempting to save
[[36m2023-11-29 04:39:32,121[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 04:39:35,549[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:39:35,949[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:39:35,957[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:39:35,962[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:39:35,966[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:39:35,971[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:39:35,976[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:39:35,981[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:39:35,985[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:39:37,624[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:39:43,796[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 04:39:46,685[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 04:39:46,713[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:40:02,826[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:02,958[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:02,975[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:02,980[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,004[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,020[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:40:05,038[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,101[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,135[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,138[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,224[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,249[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,632[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,841[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,859[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,904[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,908[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,935[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:40:06,203[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 04:40:06,206[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:40:06,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
[[36m2023-11-29 04:40:06,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
[[36m2023-11-29 04:40:06,208[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 04:40:06,209[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Preparing opt_disc 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 3 on node 0Reached 5 on node 3

Reached 5 on node 0
Reached end on node 3
Reached end on node 0
=> Preparing model 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0Reached 1 on node 2

Reached 1.2 on node 2
Reached 1.2 on node 0
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:41:34,880[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:34,885[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:35,098[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:35,161[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:35,185[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:35,190[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:41:37,025[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:37,257[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:37,295[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:37,343[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:37,365[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:37,452[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:37,506[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:37,916[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:37,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:37,995[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,030[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,082[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:41:38,908[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:41:38,909[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 04:41:38,910[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:41:38,911[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
[[36m2023-11-29 04:41:38,911[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:41:38,912[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:44:38,305[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,309[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,354[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,580[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,609[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,614[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:44:40,441[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:40,443[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:40,503[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:40,758[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:40,769[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:40,820[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,048[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,144[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,153[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,288[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,443[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,470[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 04:44:42,119[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:44:42,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:44:42,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 04:44:42,121[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:44:42,121[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:44:42,126[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1 on node 2
Reached 1.2 on node 3
Reached 1.2 on node 2
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:46:10,779[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:10,869[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:10,963[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,195[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,195[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,203[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:46:12,897[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:12,986[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:13,103[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:13,355[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:13,369[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:13,444[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:13,495[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 04:46:13,534[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:13,670[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:13,934[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:13,949[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,005[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 04:46:14,805[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:46:14,812[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Preparing opt_disc 
[[36m2023-11-29 04:46:14,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:46:14,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 04:46:14,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
[[36m2023-11-29 04:46:14,815[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1 on node 0
Reached 1.2 on node 5
Reached 1.2 on node 0
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5Reached 1.3 on node 3

Reached 1.4 on node 3Reached 1.4 on node 5

Reached 2 on node 5
Reached 2 on node 3
Reached 3 on node 3Reached 3 on node 5

Reached 5 on node 5Reached 5 on node 3

Reached end on node 5
Reached end on node 3
=> Preparing criterion 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 5Reached 3 on node 3

Reached 5 on node 5Reached 5 on node 3

Reached end on node 5Reached end on node 3

=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 1.3 on node 0Reached 1.3 on node 1

Reached 1.4 on node 0
Reached 2 on node 2Reached 1.4 on node 1

Reached 1.3 on node 3Reached 1.3 on node 5
Reached 2 on node 0
Reached 1.3 on node 4
Reached 1.4 on node 3Reached 1.4 on node 5
Reached 2 on node 1


Reached 1.4 on node 4
Reached 3 on node 2
Reached 2 on node 3Reached 2 on node 5
Reached 2 on node 4

Reached 5 on node 2
Reached 3 on node 0
Reached 3 on node 1
Reached end on node 2
Reached 5 on node 0
Reached 3 on node 3Reached 5 on node 1

Reached 3 on node 5Reached 3 on node 4

Reached end on node 0Reached 5 on node 3
Reached end on node 1

Reached 5 on node 5Reached 5 on node 4

Reached end on node 3
Reached end on node 5
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1Reached 1.4 on node 2

Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4Reached 1 on node 5

Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2Reached 1.4 on node 5

Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 4
Reached 1.4 on node 4Reached 1 on node 2

Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5Reached 3 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 1.4 on node 5
Reached 5 on node 2Reached 2 on node 5

Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1 on node 4Reached 5 on node 3

Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 4Reached 1.4 on node 2

Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 5
Reached end on node 3
Reached 1 on node 1
Reached 1 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 0
Reached 3 on node 1
Reached 2 on node 0
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached end on node 1
[[36m2023-11-29 04:46:16,592[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:46:18,116[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:46:18,656[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:46:18,656[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:46:18,656[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:46:18,659[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:46:18,665[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 6.206 (5.830) - Batch(s): 10.379 
(9.811) - AE Loss: 62524.215 (764911.812) - AE Rec Loss: 0.424 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 7.648 (5.830) - Batch(s): 9.993 
(9.811) - AE Loss: 1747279.250 (764911.812) - AE Rec Loss: 11.849 (5.187) - Disc
Loss: 0.000 (0.000) - 1.45 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.424 (5.830) - Batch(s): 9.493 
(9.811) - AE Loss: 115361.492 (764911.812) - AE Rec Loss: 0.782 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 6.002 (5.830) - Batch(s): 9.487 
(9.811) - AE Loss: 1436150.250 (764911.812) - AE Rec Loss: 9.740 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.462 (5.830) - Batch(s): 9.490 
(9.811) - AE Loss: 1674765.125 (764911.812) - AE Rec Loss: 11.358 (5.187) - Disc
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.818 (5.830) - Batch(s): 9.473 
(9.811) - AE Loss: 127819.023 (764911.812) - AE Rec Loss: 0.867 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.687 
(5.242) - AE Loss: 1598724.250 (708605.688) - AE Rec Loss: 10.842 (4.806) - Disc
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.687 
(5.242) - AE Loss: 60235.562 (708605.688) - AE Rec Loss: 0.408 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.682 
(5.242) - AE Loss: 1524844.375 (708605.688) - AE Rec Loss: 10.341 (4.806) - Disc
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.124 (2.920) - Batch(s): 0.684 
(5.242) - AE Loss: 429517.875 (708605.688) - AE Rec Loss: 2.913 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.48 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.686 
(5.242) - AE Loss: 1529748.250 (708605.688) - AE Rec Loss: 10.374 (4.806) - Disc
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.001 (2.920) - Batch(s): 0.563 
(5.242) - AE Loss: 94870.930 (708605.688) - AE Rec Loss: 0.643 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.48 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 3.480 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 1470121.875 (744516.312) - AE Rec Loss: 9.970 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.031 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 170115.344 (744516.312) - AE Rec Loss: 1.154 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.25 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.310) - Batch(s): 4.858 
(5.115) - AE Loss: 1589233.250 (744516.312) - AE Rec Loss: 10.778 (5.049) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.310) - Batch(s): 4.860 
(5.115) - AE Loss: 173230.906 (744516.312) - AE Rec Loss: 1.175 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.18 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 2.085 (2.310) - Batch(s): 4.860 
(5.115) - AE Loss: 1535265.500 (744516.312) - AE Rec Loss: 10.412 (5.049) - Disc
Loss: 0.000 (0.000) - 2.18 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.798 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 1760198.500 (744516.312) - AE Rec Loss: 11.937 (5.049) - Disc
Loss: 0.000 (0.000) - 2.18 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.001 (1.733) - Batch(s): 0.565 
(3.977) - AE Loss: 238911.422 (756405.812) - AE Rec Loss: 1.620 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.39 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.001 (1.733) - Batch(s): 0.561 
(3.977) - AE Loss: 339322.125 (756405.812) - AE Rec Loss: 2.301 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.563 
(3.977) - AE Loss: 2694924.250 (756405.812) - AE Rec Loss: 18.276 (5.130) - Disc
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.564 
(3.977) - AE Loss: 636302.500 (756405.812) - AE Rec Loss: 4.315 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.567 
(3.977) - AE Loss: 265333.906 (756405.812) - AE Rec Loss: 1.799 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.566 
(3.977) - AE Loss: 1432670.500 (756405.812) - AE Rec Loss: 9.716 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.332 
(3.483) - AE Loss: 113778.258 (747729.000) - AE Rec Loss: 0.772 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.331 
(3.483) - AE Loss: 631962.062 (747729.000) - AE Rec Loss: 4.286 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.331 
(3.483) - AE Loss: 668425.562 (747729.000) - AE Rec Loss: 4.533 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.331 
(3.483) - AE Loss: 443370.000 (747729.000) - AE Rec Loss: 3.007 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.332 
(3.483) - AE Loss: 1563483.750 (747729.000) - AE Rec Loss: 10.603 (5.071) - Disc
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.001 (1.405) - Batch(s): 1.331 
(3.483) - AE Loss: 381341.344 (747729.000) - AE Rec Loss: 2.586 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.731 
(3.025) - AE Loss: 268896.719 (762049.250) - AE Rec Loss: 1.824 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.62 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.172) - Batch(s): 0.731 
(3.025) - AE Loss: 134013.734 (762049.250) - AE Rec Loss: 0.909 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.732 
(3.025) - AE Loss: 3324555.000 (762049.250) - AE Rec Loss: 22.546 (5.168) - Disc
Loss: 0.000 (0.000) - 2.62 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.731 
(3.025) - AE Loss: 388135.000 (762049.250) - AE Rec Loss: 2.632 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.172) - Batch(s): 0.733 
(3.025) - AE Loss: 77571.469 (762049.250) - AE Rec Loss: 0.526 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.62 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.733 
(3.025) - AE Loss: 1526343.250 (762049.250) - AE Rec Loss: 10.351 (5.168) - Disc
Loss: 0.000 (0.000) - 2.62 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (1.005) - Batch(s): 0.567 
(2.679) - AE Loss: 316799.250 (706354.000) - AE Rec Loss: 2.148 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.564 
(2.679) - AE Loss: 2700071.000 (706354.000) - AE Rec Loss: 18.311 (4.790) - Disc
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.566 
(2.679) - AE Loss: 94755.547 (706354.000) - AE Rec Loss: 0.643 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.563 
(2.679) - AE Loss: 92104.453 (706354.000) - AE Rec Loss: 0.625 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (1.005) - Batch(s): 0.566 
(2.679) - AE Loss: 64089.758 (706354.000) - AE Rec Loss: 0.435 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (1.005) - Batch(s): 0.563 
(2.679) - AE Loss: 325132.562 (706354.000) - AE Rec Loss: 2.205 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 276493.531 (718188.000) - AE Rec Loss: 1.875 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 374713.125 (718188.000) - AE Rec Loss: 2.541 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.42 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 74253.781 (718188.000) - AE Rec Loss: 0.504 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 1469831.625 (718188.000) - AE Rec Loss: 9.968 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 1.144 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 2991081.000 (718188.000) - AE Rec Loss: 20.285 (4.871) - Disc
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 3.792 
(2.840) - AE Loss: 529977.250 (718188.000) - AE Rec Loss: 3.594 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.001 (0.826) - Batch(s): 0.660 
(2.598) - AE Loss: 332317.562 (704271.438) - AE Rec Loss: 2.254 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.660 
(2.598) - AE Loss: 93845.742 (704271.438) - AE Rec Loss: 0.636 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.001 (0.826) - Batch(s): 0.661 
(2.598) - AE Loss: 1320961.875 (704271.438) - AE Rec Loss: 8.958 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.660 
(2.598) - AE Loss: 110705.727 (704271.438) - AE Rec Loss: 0.751 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.001 (0.826) - Batch(s): 0.663 
(2.598) - AE Loss: 259773.219 (704271.438) - AE Rec Loss: 1.762 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.663 
(2.598) - AE Loss: 1614706.375 (704271.438) - AE Rec Loss: 10.950 (4.776) - Disc
Loss: 0.000 (0.000) - 3.46 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.563 
(2.394) - AE Loss: 613433.875 (680061.062) - AE Rec Loss: 4.160 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.567 
(2.394) - AE Loss: 1430607.375 (680061.062) - AE Rec Loss: 9.702 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.563 
(2.394) - AE Loss: 206866.422 (680061.062) - AE Rec Loss: 1.403 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.743) - Batch(s): 0.567 
(2.394) - AE Loss: 290998.969 (680061.062) - AE Rec Loss: 1.973 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.564 
(2.394) - AE Loss: 90860.867 (680061.062) - AE Rec Loss: 0.616 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.567 
(2.394) - AE Loss: 168849.047 (680061.062) - AE Rec Loss: 1.145 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.54 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.316 
(2.579) - AE Loss: 155521.281 (653740.625) - AE Rec Loss: 1.055 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.316 
(2.579) - AE Loss: 176859.906 (653740.625) - AE Rec Loss: 1.199 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.315 
(2.579) - AE Loss: 170119.891 (653740.625) - AE Rec Loss: 1.154 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.316 
(2.579) - AE Loss: 192459.766 (653740.625) - AE Rec Loss: 1.305 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.315 
(2.579) - AE Loss: 92022.617 (653740.625) - AE Rec Loss: 0.624 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.001 (0.707) - Batch(s): 3.461 
(2.579) - AE Loss: 187679.391 (653740.625) - AE Rec Loss: 1.273 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.150 (0.649) - Batch(s): 0.783 
(2.429) - AE Loss: 416660.312 (662681.812) - AE Rec Loss: 2.826 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.781 
(2.429) - AE Loss: 426710.000 (662681.812) - AE Rec Loss: 2.894 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.781 
(2.429) - AE Loss: 114050.992 (662681.812) - AE Rec Loss: 0.773 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.649) - Batch(s): 0.781 
(2.429) - AE Loss: 163443.734 (662681.812) - AE Rec Loss: 1.108 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.649) - Batch(s): 0.781 
(2.429) - AE Loss: 736288.562 (662681.812) - AE Rec Loss: 4.993 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.28 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.649) - Batch(s): 0.782 
(2.429) - AE Loss: 1461222.375 (662681.812) - AE Rec Loss: 9.910 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.564 
(2.286) - AE Loss: 3192919.750 (685868.812) - AE Rec Loss: 21.653 (4.651) - Disc
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.001 (0.599) - Batch(s): 0.568 
(2.286) - AE Loss: 822244.938 (685868.812) - AE Rec Loss: 5.576 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.565 
(2.286) - AE Loss: 1513046.875 (685868.812) - AE Rec Loss: 10.261 (4.651) - Disc
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.567 
(2.286) - AE Loss: 155975.938 (685868.812) - AE Rec Loss: 1.058 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.001 (0.599) - Batch(s): 0.566 
(2.286) - AE Loss: 61102.453 (685868.812) - AE Rec Loss: 0.414 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.562 
(2.286) - AE Loss: 1550309.125 (685868.812) - AE Rec Loss: 10.514 (4.651) - Disc
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 1692248.250 (676225.875) - AE Rec Loss: 11.476 (4.586) - Disc
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 58524.227 (676225.875) - AE Rec Loss: 0.397 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 1472658.750 (676225.875) - AE Rec Loss: 9.987 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 121673.414 (676225.875) - AE Rec Loss: 0.825 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 161318.250 (676225.875) - AE Rec Loss: 1.094 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.115 
(2.215) - AE Loss: 221038.703 (676225.875) - AE Rec Loss: 1.499 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.415 
(2.428) - AE Loss: 207450.891 (681404.062) - AE Rec Loss: 1.407 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 69901.094 (681404.062) - AE Rec Loss: 0.474 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.692 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 222975.531 (681404.062) - AE Rec Loss: 1.512 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.001 (0.555) - Batch(s): 5.415 
(2.428) - AE Loss: 62630.691 (681404.062) - AE Rec Loss: 0.425 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 4.779 (0.555) - Batch(s): 5.415 
(2.428) - AE Loss: 1415111.250 (681404.062) - AE Rec Loss: 9.597 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 1711649.500 (681404.062) - AE Rec Loss: 11.608 (4.621) - Disc
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.563 
(2.312) - AE Loss: 102719.742 (674105.250) - AE Rec Loss: 0.697 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.567 
(2.312) - AE Loss: 91480.820 (674105.250) - AE Rec Loss: 0.620 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.569 
(2.312) - AE Loss: 187029.484 (674105.250) - AE Rec Loss: 1.268 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.34 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.568 
(2.312) - AE Loss: 656223.438 (674105.250) - AE Rec Loss: 4.450 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.563 
(2.312) - AE Loss: 1496494.625 (674105.250) - AE Rec Loss: 10.149 (4.572) - Disc
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.564 
(2.312) - AE Loss: 1451799.875 (674105.250) - AE Rec Loss: 9.846 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.566 
(2.209) - AE Loss: 542074.938 (675240.688) - AE Rec Loss: 3.676 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.563 
(2.209) - AE Loss: 525290.250 (675240.688) - AE Rec Loss: 3.562 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.569 
(2.209) - AE Loss: 193996.078 (675240.688) - AE Rec Loss: 1.316 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.568 
(2.209) - AE Loss: 1822524.750 (675240.688) - AE Rec Loss: 12.360 (4.579) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.564 
(2.209) - AE Loss: 1388690.500 (675240.688) - AE Rec Loss: 9.418 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.34 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.567 
(2.209) - AE Loss: 52385.609 (675240.688) - AE Rec Loss: 0.355 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.049 
(2.200) - AE Loss: 180932.312 (651488.562) - AE Rec Loss: 1.227 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 536829.250 (651488.562) - AE Rec Loss: 3.641 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.048 
(2.200) - AE Loss: 254967.688 (651488.562) - AE Rec Loss: 1.729 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 1.387 (0.469) - Batch(s): 2.049 
(2.200) - AE Loss: 141440.438 (651488.562) - AE Rec Loss: 0.959 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 121268.422 (651488.562) - AE Rec Loss: 0.822 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 46667.773 (651488.562) - AE Rec Loss: 0.316 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.568 
(2.114) - AE Loss: 212139.844 (635626.188) - AE Rec Loss: 1.439 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.565 
(2.114) - AE Loss: 172204.375 (635626.188) - AE Rec Loss: 1.168 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.001 (0.444) - Batch(s): 0.569 
(2.114) - AE Loss: 826201.625 (635626.188) - AE Rec Loss: 5.603 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.75 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.564 
(2.114) - AE Loss: 308737.250 (635626.188) - AE Rec Loss: 2.094 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.001 (0.444) - Batch(s): 0.567 
(2.114) - AE Loss: 51017.766 (635626.188) - AE Rec Loss: 0.346 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.564 
(2.114) - AE Loss: 251614.781 (635626.188) - AE Rec Loss: 1.706 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.567 
(2.037) - AE Loss: 1498560.250 (632113.312) - AE Rec Loss: 10.163 (4.287) - Disc
Loss: 0.000 (0.000) - 5.75 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.570 
(2.037) - AE Loss: 178858.469 (632113.312) - AE Rec Loss: 1.213 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.570 
(2.037) - AE Loss: 136847.922 (632113.312) - AE Rec Loss: 0.928 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.565 
(2.037) - AE Loss: 216239.531 (632113.312) - AE Rec Loss: 1.466 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.75 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.564 
(2.037) - AE Loss: 1749257.625 (632113.312) - AE Rec Loss: 11.863 (4.287) - Disc
Loss: 0.000 (0.000) - 5.75 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.563 
(2.037) - AE Loss: 662423.375 (632113.312) - AE Rec Loss: 4.492 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.75 m remaining

attempting to save
[[36m2023-11-29 04:47:04,268[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 04:47:04,875[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:47:05,186[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:47:05,220[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:47:05,230[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:47:05,248[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:47:05,263[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:47:05,275[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:47:05,294[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:47:05,322[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:47:05,800[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:47:07,571[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 04:47:09,376[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 04:47:09,383[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 04:47:14,186[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 04:47:14,187[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 04:47:14,187[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 04:47:14,196[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.585 
(2.448) - AE Loss: 134690.266 (628719.750) - AE Rec Loss: 0.913 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.001 (0.404) - Batch(s): 11.588 
(2.448) - AE Loss: 234808.484 (628719.750) - AE Rec Loss: 1.592 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.662 (0.404) - Batch(s): 11.585 
(2.448) - AE Loss: 208440.344 (628719.750) - AE Rec Loss: 1.414 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.23 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.585 
(2.448) - AE Loss: 211866.984 (628719.750) - AE Rec Loss: 1.437 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.001 (0.404) - Batch(s): 0.635 
(2.448) - AE Loss: 99064.672 (628719.750) - AE Rec Loss: 0.672 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.588 
(2.448) - AE Loss: 225010.953 (628719.750) - AE Rec Loss: 1.526 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.001 (0.386) - Batch(s): 0.565 
(2.362) - AE Loss: 98024.891 (630410.062) - AE Rec Loss: 0.665 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.001 (0.386) - Batch(s): 0.567 
(2.362) - AE Loss: 473053.688 (630410.062) - AE Rec Loss: 3.208 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.567 
(2.362) - AE Loss: 57264.168 (630410.062) - AE Rec Loss: 0.388 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.41 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.565 
(2.362) - AE Loss: 1298281.500 (630410.062) - AE Rec Loss: 8.805 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.569 
(2.362) - AE Loss: 450005.844 (630410.062) - AE Rec Loss: 3.052 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.564 
(2.362) - AE Loss: 3104950.000 (630410.062) - AE Rec Loss: 21.057 (4.275) - Disc
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.001 (0.369) - Batch(s): 0.568 
(2.284) - AE Loss: 680852.562 (628940.188) - AE Rec Loss: 4.617 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.567 
(2.284) - AE Loss: 309343.062 (628940.188) - AE Rec Loss: 2.098 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.563 
(2.284) - AE Loss: 125649.328 (628940.188) - AE Rec Loss: 0.852 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.569 
(2.284) - AE Loss: 3237249.000 (628940.188) - AE Rec Loss: 21.954 (4.265) - Disc
Loss: 0.000 (0.000) - 7.43 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.568 
(2.284) - AE Loss: 236836.859 (628940.188) - AE Rec Loss: 1.606 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.47 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.565 
(2.284) - AE Loss: 204297.719 (628940.188) - AE Rec Loss: 1.385 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.667 
(2.217) - AE Loss: 1449421.000 (638246.062) - AE Rec Loss: 9.830 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.43 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 151485.516 (638246.062) - AE Rec Loss: 1.027 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.43 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 128597.188 (638246.062) - AE Rec Loss: 0.872 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 2554051.750 (638246.062) - AE Rec Loss: 17.321 (4.328) - Disc
Loss: 0.000 (0.000) - 7.43 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 1627214.750 (638246.062) - AE Rec Loss: 11.035 (4.328) - Disc
Loss: 0.000 (0.000) - 7.50 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.669 
(2.217) - AE Loss: 157586.656 (638246.062) - AE Rec Loss: 1.069 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.43 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.564 
(2.151) - AE Loss: 72469.688 (650649.812) - AE Rec Loss: 0.491 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.49 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.566 
(2.151) - AE Loss: 1626416.250 (650649.812) - AE Rec Loss: 11.030 (4.413) - Disc
Loss: 0.000 (0.000) - 7.49 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.570 
(2.151) - AE Loss: 2655291.000 (650649.812) - AE Rec Loss: 18.007 (4.413) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.568 
(2.151) - AE Loss: 1550073.250 (650649.812) - AE Rec Loss: 10.512 (4.413) - Disc
Loss: 0.000 (0.000) - 7.49 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.568 
(2.151) - AE Loss: 241004.172 (650649.812) - AE Rec Loss: 1.634 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.50 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.568 
(2.151) - AE Loss: 1462242.500 (650649.812) - AE Rec Loss: 9.916 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.568 
(2.090) - AE Loss: 87978.461 (646120.000) - AE Rec Loss: 0.597 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.565 
(2.090) - AE Loss: 136047.203 (646120.000) - AE Rec Loss: 0.923 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (0.327) - Batch(s): 0.566 
(2.090) - AE Loss: 256878.297 (646120.000) - AE Rec Loss: 1.742 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.571 
(2.090) - AE Loss: 147685.781 (646120.000) - AE Rec Loss: 1.002 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.62 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.569 
(2.090) - AE Loss: 1684194.750 (646120.000) - AE Rec Loss: 11.422 (4.382) - Disc
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.569 
(2.090) - AE Loss: 2885010.500 (646120.000) - AE Rec Loss: 19.565 (4.382) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 297609.344 (640637.312) - AE Rec Loss: 2.018 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.93 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 131686.844 (640637.312) - AE Rec Loss: 0.893 (4.345) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 1446962.750 (640637.312) - AE Rec Loss: 9.813 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 1489238.500 (640637.312) - AE Rec Loss: 10.100 (4.345) - Disc
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 159093.156 (640637.312) - AE Rec Loss: 1.079 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 2.368 (0.322) - Batch(s): 3.038 
(2.125) - AE Loss: 136885.734 (640637.312) - AE Rec Loss: 0.928 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 1355466.875 (640264.500) - AE Rec Loss: 9.192 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.29 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.755 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 1331044.250 (640264.500) - AE Rec Loss: 9.027 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.40 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 324131.344 (640264.500) - AE Rec Loss: 2.198 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.29 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 301493.562 (640264.500) - AE Rec Loss: 2.045 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.29 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 111847.258 (640264.500) - AE Rec Loss: 0.759 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.29 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 2.674 
(2.150) - AE Loss: 350062.969 (640264.500) - AE Rec Loss: 2.374 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 132676.922 (646060.062) - AE Rec Loss: 0.900 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.48 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.318 
(2.122) - AE Loss: 1510186.750 (646060.062) - AE Rec Loss: 10.242 (4.381) - Disc
Loss: 0.000 (0.000) - 8.59 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.318 
(2.122) - AE Loss: 1566755.500 (646060.062) - AE Rec Loss: 10.625 (4.381) - Disc
Loss: 0.000 (0.000) - 8.48 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 516936.125 (646060.062) - AE Rec Loss: 3.506 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.48 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.001 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 142012.109 (646060.062) - AE Rec Loss: 0.963 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.54 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 1891258.750 (646060.062) - AE Rec Loss: 12.826 (4.381) - Disc
Loss: 0.000 (0.000) - 8.48 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:47:45,423[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,431[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,568[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,667[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,693[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,711[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:47:47,577[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,581[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,712[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,860[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,888[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,918[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,209[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,221[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,332[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,521[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,530[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,557[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 04:47:48,800[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 04:47:48,803[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 04:47:48,804[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 04:47:48,809[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 04:47:48,809[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:47:48,809[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Mixed precision: no
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
=> Preparing criterion 
Reached 5 on node 0
=> Preparing criterion 
Reached end on node 0
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1 on node 0
Reached 1.25 on node 1
Reached 1.2 on node 0devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}

Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0Reached 1.3 on node 2

Reached 1.4 on node 2
Reached 1.3 on node 4
Reached 2 on node 2
Reached 1.4 on node 4
Reached 3 on node 0
Reached 2 on node 4
Reached 5 on node 0Reached 3 on node 2

Reached 5 on node 2Reached end on node 0

Reached 3 on node 4
Reached end on node 2
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 5
Reached 1.3 on node 1Reached 1.4 on node 5

Reached 1.4 on node 1
Reached 2 on node 5
Reached 2 on node 1
Reached 3 on node 5
Reached 3 on node 1Reached 5 on node 5

Reached end on node 5
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached end on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 1 on node 2
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached end on node 1
Reached 1.4 on node 4
Reached 1.4 on node 2
Reached 2 on node 4
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2Reached 1 on node 4

Reached 1 on node 3
Reached 1.4 on node 2
Reached 1.4 on node 4
Reached 2 on node 2
Reached 2 on node 4
Reached 1.4 on node 3Reached 3 on node 2

Reached 3 on node 2Reached 2 on node 3

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1.4 on node 5
Reached 3 on node 3
Reached 2 on node 5
Reached 3 on node 3
Reached 3 on node 5
Reached 5 on node 3
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 4
Reached end on node 5
Reached end on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 1 on node 4Reached 2 on node 2

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1 on node 5
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1 on node 5
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 5
Reached 1 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 5
Reached end on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 04:47:50,482[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 4
Reached end on node 2
[[36m2023-11-29 04:47:52,941[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
[[36m2023-11-29 04:47:54,138[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
=> Starting model training 
[[36m2023-11-29 04:47:54,138[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:47:54,138[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 04:47:54,140[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:47:54,141[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <261/2280>] - Data(s): 3.710 (6.117) - Batch(s): 12.060 
(11.858) - AE Loss: 225027.844 (560690.312) - AE Rec Loss: 1.526 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 10.656 (6.117) - Batch(s): 12.046 
(11.858) - AE Loss: 99054.875 (560690.312) - AE Rec Loss: 0.672 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 8.236 (6.117) - Batch(s): 12.045 
(11.858) - AE Loss: 212739.484 (560690.312) - AE Rec Loss: 1.443 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.154 (6.117) - Batch(s): 12.058 
(11.858) - AE Loss: 206166.031 (560690.312) - AE Rec Loss: 1.398 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.988 (6.117) - Batch(s): 12.070 
(11.858) - AE Loss: 133905.000 (560690.312) - AE Rec Loss: 0.908 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.511 (6.117) - Batch(s): 12.071 
(11.858) - AE Loss: 235217.484 (560690.312) - AE Rec Loss: 1.595 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.001 (3.059) - Batch(s): 0.568 
(6.211) - AE Loss: 500561.219 (621043.625) - AE Rec Loss: 3.395 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 529424.062 (621043.625) - AE Rec Loss: 3.590 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.001 (3.059) - Batch(s): 0.563 
(6.211) - AE Loss: 100470.656 (621043.625) - AE Rec Loss: 0.681 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.562 
(6.211) - AE Loss: 3109178.000 (621043.625) - AE Rec Loss: 21.085 (4.212) - Disc
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.566 
(6.211) - AE Loss: 59932.578 (621043.625) - AE Rec Loss: 0.406 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.001 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 1295903.500 (621043.625) - AE Rec Loss: 8.788 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <263/2280>] - Data(s): 0.864 (2.174) - Batch(s): 2.778 
(5.067) - AE Loss: 3242202.500 (617786.062) - AE Rec Loss: 21.988 (4.190) - Disc
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 2.105 (2.174) - Batch(s): 2.776 
(5.067) - AE Loss: 227150.672 (617786.062) - AE Rec Loss: 1.540 (4.190) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 1.709 (2.174) - Batch(s): 2.777 
(5.067) - AE Loss: 344438.562 (617786.062) - AE Rec Loss: 2.336 (4.190) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.779 
(5.067) - AE Loss: 265314.438 (617786.062) - AE Rec Loss: 1.799 (4.190) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.778 
(5.067) - AE Loss: 118040.914 (617786.062) - AE Rec Loss: 0.801 (4.190) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.779 
(5.067) - AE Loss: 736576.438 (617786.062) - AE Rec Loss: 4.995 (4.190) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.569 
(3.941) - AE Loss: 1629061.875 (676608.750) - AE Rec Loss: 11.048 (4.589) - Disc
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.630) - Batch(s): 0.566 
(3.941) - AE Loss: 1455323.625 (676608.750) - AE Rec Loss: 9.870 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.630) - Batch(s): 0.562 
(3.941) - AE Loss: 149584.828 (676608.750) - AE Rec Loss: 1.014 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.630) - Batch(s): 0.566 
(3.941) - AE Loss: 160014.328 (676608.750) - AE Rec Loss: 1.085 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.567 
(3.941) - AE Loss: 129429.352 (676608.750) - AE Rec Loss: 0.878 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.630) - Batch(s): 0.566 
(3.941) - AE Loss: 2555995.500 (676608.750) - AE Rec Loss: 17.334 (4.589) - Disc
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.564 
(3.266) - AE Loss: 1629713.250 (732463.188) - AE Rec Loss: 11.052 (4.967) - Disc
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.001 (1.304) - Batch(s): 0.569 
(3.266) - AE Loss: 1554947.250 (732463.188) - AE Rec Loss: 10.545 (4.967) - Disc
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.567 
(3.266) - AE Loss: 254259.828 (732463.188) - AE Rec Loss: 1.724 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.570 
(3.266) - AE Loss: 2659777.000 (732463.188) - AE Rec Loss: 18.038 (4.967) - Disc
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.567 
(3.266) - AE Loss: 1468301.000 (732463.188) - AE Rec Loss: 9.958 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.563 
(3.266) - AE Loss: 73539.547 (732463.188) - AE Rec Loss: 0.499 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.162) - Batch(s): 3.156 
(3.248) - AE Loss: 87191.625 (699761.250) - AE Rec Loss: 0.591 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 2.503 (1.162) - Batch(s): 3.154 
(3.248) - AE Loss: 154303.375 (699761.250) - AE Rec Loss: 1.046 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.162) - Batch(s): 3.156 
(3.248) - AE Loss: 152288.062 (699761.250) - AE Rec Loss: 1.033 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 2.256 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 258690.719 (699761.250) - AE Rec Loss: 1.754 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.626 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 2889208.000 (699761.250) - AE Rec Loss: 19.594 (4.746) - Disc
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 1696892.375 (699761.250) - AE Rec Loss: 11.508 (4.746) - Disc
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.966 
(3.065) - AE Loss: 1451941.750 (671487.250) - AE Rec Loss: 9.847 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.964 
(3.065) - AE Loss: 131913.812 (671487.250) - AE Rec Loss: 0.895 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.963 
(3.065) - AE Loss: 162225.625 (671487.250) - AE Rec Loss: 1.100 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.960 
(3.065) - AE Loss: 1491275.000 (671487.250) - AE Rec Loss: 10.113 (4.554) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.964 
(3.065) - AE Loss: 300611.750 (671487.250) - AE Rec Loss: 2.039 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 1.400 (1.013) - Batch(s): 1.966 
(3.065) - AE Loss: 137745.250 (671487.250) - AE Rec Loss: 0.934 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.563 
(2.752) - AE Loss: 319634.688 (665978.062) - AE Rec Loss: 2.168 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.570 
(2.752) - AE Loss: 348633.250 (665978.062) - AE Rec Loss: 2.364 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.565 
(2.752) - AE Loss: 293836.188 (665978.062) - AE Rec Loss: 1.993 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.568 
(2.752) - AE Loss: 1335072.250 (665978.062) - AE Rec Loss: 9.054 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.567 
(2.752) - AE Loss: 97804.336 (665978.062) - AE Rec Loss: 0.663 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.001 (0.886) - Batch(s): 0.568 
(2.752) - AE Loss: 1354472.000 (665978.062) - AE Rec Loss: 9.186 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.243 
(2.807) - AE Loss: 1570781.750 (681738.375) - AE Rec Loss: 10.653 (4.623) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 1895898.500 (681738.375) - AE Rec Loss: 12.857 (4.623) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.444 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 518143.719 (681738.375) - AE Rec Loss: 3.514 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 2.592 (0.816) - Batch(s): 3.243 
(2.807) - AE Loss: 137192.719 (681738.375) - AE Rec Loss: 0.930 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.243 
(2.807) - AE Loss: 132176.922 (681738.375) - AE Rec Loss: 0.896 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.243 
(2.807) - AE Loss: 1513872.250 (681738.375) - AE Rec Loss: 10.267 (4.623) - Disc
Loss: 0.000 (0.000) - 3.35 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 1.976 (0.751) - Batch(s): 2.551 
(2.781) - AE Loss: 78280.508 (701633.875) - AE Rec Loss: 0.531 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.543 
(2.781) - AE Loss: 1527090.500 (701633.875) - AE Rec Loss: 10.356 (4.758) - Disc
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.546 
(2.781) - AE Loss: 167429.922 (701633.875) - AE Rec Loss: 1.135 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.001 (0.751) - Batch(s): 2.549 
(2.781) - AE Loss: 1548098.000 (701633.875) - AE Rec Loss: 10.499 (4.758) - Disc
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.001 (0.751) - Batch(s): 2.547 
(2.781) - AE Loss: 1558011.000 (701633.875) - AE Rec Loss: 10.566 (4.758) - Disc
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.547 
(2.781) - AE Loss: 2009986.875 (701633.875) - AE Rec Loss: 13.631 (4.758) - Disc
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.236 
(2.741) - AE Loss: 147851.688 (703157.188) - AE Rec Loss: 1.003 (4.769) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 1.712 
(2.741) - AE Loss: 1792839.000 (703157.188) - AE Rec Loss: 12.158 (4.769) - Disc
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.236 
(2.741) - AE Loss: 92191.391 (703157.188) - AE Rec Loss: 0.625 (4.769) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.236 
(2.741) - AE Loss: 117662.781 (703157.188) - AE Rec Loss: 0.798 (4.769) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.236 
(2.741) - AE Loss: 340940.875 (703157.188) - AE Rec Loss: 2.312 (4.769) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.235 
(2.741) - AE Loss: 592965.000 (703157.188) - AE Rec Loss: 4.021 (4.769) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.647 
(2.566) - AE Loss: 507413.312 (689498.562) - AE Rec Loss: 3.441 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.647 
(2.566) - AE Loss: 154531.625 (689498.562) - AE Rec Loss: 1.048 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.646 
(2.566) - AE Loss: 266008.906 (689498.562) - AE Rec Loss: 1.804 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.647 
(2.566) - AE Loss: 1413743.500 (689498.562) - AE Rec Loss: 9.588 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.640) - Batch(s): 0.647 
(2.566) - AE Loss: 157268.203 (689498.562) - AE Rec Loss: 1.067 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.640) - Batch(s): 0.647 
(2.566) - AE Loss: 1340873.250 (689498.562) - AE Rec Loss: 9.093 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.001 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 256555.859 (683078.688) - AE Rec Loss: 1.740 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 1.621 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 205754.422 (683078.688) - AE Rec Loss: 1.395 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 489668.781 (683078.688) - AE Rec Loss: 3.321 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 391568.750 (683078.688) - AE Rec Loss: 2.655 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.001 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 76918.883 (683078.688) - AE Rec Loss: 0.522 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 2.943 
(2.609) - AE Loss: 1740986.500 (683078.688) - AE Rec Loss: 11.807 (4.632) - Disc
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.850 
(2.994) - AE Loss: 1526392.125 (692177.312) - AE Rec Loss: 10.352 (4.694) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.849 
(2.994) - AE Loss: 143283.875 (692177.312) - AE Rec Loss: 0.972 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.849 
(2.994) - AE Loss: 261810.141 (692177.312) - AE Rec Loss: 1.776 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.001 (0.638) - Batch(s): 7.849 
(2.994) - AE Loss: 1753520.375 (692177.312) - AE Rec Loss: 11.892 (4.694) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.851 
(2.994) - AE Loss: 160500.453 (692177.312) - AE Rec Loss: 1.088 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.849 
(2.994) - AE Loss: 1540833.000 (692177.312) - AE Rec Loss: 10.449 (4.694) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 104044.000 (675322.938) - AE Rec Loss: 0.706 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 197744.438 (675322.938) - AE Rec Loss: 1.341 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 69156.688 (675322.938) - AE Rec Loss: 0.469 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 156165.797 (675322.938) - AE Rec Loss: 1.059 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 2933261.000 (675322.938) - AE Rec Loss: 19.892 (4.580) - Disc
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.640 
(2.837) - AE Loss: 392035.156 (675322.938) - AE Rec Loss: 2.659 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 2774209.000 (670693.062) - AE Rec Loss: 18.814 (4.548) - Disc
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.001 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 77655.750 (670693.062) - AE Rec Loss: 0.527 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 325003.719 (670693.062) - AE Rec Loss: 2.204 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 276337.281 (670693.062) - AE Rec Loss: 1.874 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 81252.617 (670693.062) - AE Rec Loss: 0.551 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 1611968.250 (670693.062) - AE Rec Loss: 10.932 (4.548) - Disc
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.661) - Batch(s): 9.772 
(3.166) - AE Loss: 261927.469 (670652.688) - AE Rec Loss: 1.776 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 244941.547 (670652.688) - AE Rec Loss: 1.661 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 101166.938 (670652.688) - AE Rec Loss: 0.686 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 3499700.750 (670652.688) - AE Rec Loss: 23.734 (4.548) - Disc
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 93514.094 (670652.688) - AE Rec Loss: 0.634 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 448796.094 (670652.688) - AE Rec Loss: 3.044 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 195752.938 (660251.562) - AE Rec Loss: 1.328 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 69475.422 (660251.562) - AE Rec Loss: 0.471 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 340893.875 (660251.562) - AE Rec Loss: 2.312 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 87138.117 (660251.562) - AE Rec Loss: 0.591 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 486386.719 (660251.562) - AE Rec Loss: 3.299 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.100 
(3.495) - AE Loss: 262699.250 (660251.562) - AE Rec Loss: 1.782 (4.478) - Disc 
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.569 
(3.341) - AE Loss: 1541855.000 (656645.938) - AE Rec Loss: 10.456 (4.453) - Disc
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.563 
(3.341) - AE Loss: 348873.312 (656645.938) - AE Rec Loss: 2.366 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.567 
(3.341) - AE Loss: 230651.859 (656645.938) - AE Rec Loss: 1.564 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.567 
(3.341) - AE Loss: 141580.594 (656645.938) - AE Rec Loss: 0.960 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.570 
(3.341) - AE Loss: 1415784.125 (656645.938) - AE Rec Loss: 9.601 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.566 
(3.341) - AE Loss: 556946.125 (656645.938) - AE Rec Loss: 3.777 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.09 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:50:50,303[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,342[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,449[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,458[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,470[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,672[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:50:52,478[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:52,489[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:52,597[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:52,610[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:52,614[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:52,858[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,051[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,162[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,282[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,295[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,310[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,468[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 04:50:53,956[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:50:53,958[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:50:53,959[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
[[36m2023-11-29 04:50:53,961[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
[[36m2023-11-29 04:50:53,963[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Preparing opt_disc 
[[36m2023-11-29 04:50:53,965[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Preparing model 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Mixed precision: no
len(valid_dataloader) = 1
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataloader) = 1
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1 on node 1
Reached 1.25 on node 0
Reached 1.2 on node 1devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}

Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1Reached 1.3 on node 3

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 1
Reached 3 on node 3
Reached 5 on node 1
Reached end on node 1
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.3 on node 2
Reached 3 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 1.3 on node 5
Reached 1.3 on node 3Reached 2 on node 2
Reached 1.4 on node 5

Reached 1.4 on node 3
Reached 2 on node 5
Reached 2 on node 3
Reached 3 on node 2
Reached 3 on node 5
Reached 5 on node 2
Reached 3 on node 3Reached 5 on node 5

Reached end on node 2
Reached end on node 5
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4Reached 1.3 on node 0

Reached 1.4 on node 0
Reached 1.3 on node 1Reached 2 on node 4

Reached 2 on node 0Reached 1.4 on node 1

Reached 2 on node 1
Reached 3 on node 4
Reached 3 on node 0
Reached 5 on node 4
Reached 5 on node 0Reached 3 on node 1

Reached end on node 4
Reached end on node 0Reached 5 on node 1

Reached end on node 1
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1Reached 1 on node 2

Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 3 on node 1Reached 1 on node 3

Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1Reached 1.4 on node 2

Reached 3 on node 1Reached 2 on node 2

Reached 5 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 1 on node 3Reached 1.4 on node 4Reached 2 on node 2


Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4Reached 1 on node 3

Reached 1.4 on node 4Reached 1.4 on node 3

Reached 2 on node 4Reached 2 on node 3

Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 1 on node 3Reached 3 on node 2

Reached 3 on node 2Reached 1 on node 4

Reached 3 on node 2
Reached 3 on node 2
Reached 1.4 on node 3
Reached 5 on node 2
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4Reached 1.4 on node 3

Reached 2 on node 3
Reached 3 on node 3
Reached 1.4 on node 4Reached 3 on node 3

Reached 2 on node 4Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 5
Reached end on node 4
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 1 on node 3
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 4
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 3
Reached 1 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 04:50:55,700[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 3
Reached end on node 5
[[36m2023-11-29 04:50:57,262[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 04:50:57,720[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:50:57,721[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:50:57,721[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 04:50:57,728[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:50:57,730[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <261/2280>] - Data(s): 4.158 (5.921) - Batch(s): 12.253 
(12.052) - AE Loss: 227434.219 (561036.250) - AE Rec Loss: 1.542 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 3.439 (5.921) - Batch(s): 12.053 
(12.052) - AE Loss: 207343.203 (561036.250) - AE Rec Loss: 1.406 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 10.365 (5.921) - Batch(s): 11.833 
(12.052) - AE Loss: 99054.875 (561036.250) - AE Rec Loss: 0.672 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.504 (5.921) - Batch(s): 12.086 
(12.052) - AE Loss: 234823.766 (561036.250) - AE Rec Loss: 1.593 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 6.066 (5.921) - Batch(s): 11.974 
(12.052) - AE Loss: 135196.562 (561036.250) - AE Rec Loss: 0.917 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 8.293 (5.921) - Batch(s): 11.779 
(12.052) - AE Loss: 214312.672 (561036.250) - AE Rec Loss: 1.453 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.565 
(6.307) - AE Loss: 502461.562 (621049.562) - AE Rec Loss: 3.408 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.561 
(6.307) - AE Loss: 100405.328 (621049.562) - AE Rec Loss: 0.681 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.563 
(6.307) - AE Loss: 59230.484 (621049.562) - AE Rec Loss: 0.402 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.563 
(6.307) - AE Loss: 523954.031 (621049.562) - AE Rec Loss: 3.553 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.561 
(6.307) - AE Loss: 1295903.500 (621049.562) - AE Rec Loss: 8.788 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.559 
(6.307) - AE Loss: 3109366.250 (621049.562) - AE Rec Loss: 21.087 (4.212) - Disc
Loss: 0.000 (0.000) - 1.64 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <263/2280>] - Data(s): 0.001 (2.016) - Batch(s): 1.884 
(4.833) - AE Loss: 3242266.500 (617874.062) - AE Rec Loss: 21.988 (4.190) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.880 
(4.833) - AE Loss: 736576.438 (617874.062) - AE Rec Loss: 4.995 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.90 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.880 
(4.833) - AE Loss: 264967.531 (617874.062) - AE Rec Loss: 1.797 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.282 (2.016) - Batch(s): 1.883 
(4.833) - AE Loss: 228782.297 (617874.062) - AE Rec Loss: 1.552 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.883 
(4.833) - AE Loss: 118725.883 (617874.062) - AE Rec Loss: 0.805 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.89 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.001 (2.016) - Batch(s): 1.883 
(4.833) - AE Loss: 346686.375 (617874.062) - AE Rec Loss: 2.351 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.93 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.244 
(4.185) - AE Loss: 1628916.000 (676632.438) - AE Rec Loss: 11.047 (4.589) - Disc
Loss: 0.000 (0.000) - 2.25 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.241 
(4.185) - AE Loss: 129581.664 (676632.438) - AE Rec Loss: 0.879 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.241 
(4.185) - AE Loss: 2556007.000 (676632.438) - AE Rec Loss: 17.334 (4.589) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 1.681 (1.547) - Batch(s): 2.244 
(4.185) - AE Loss: 159769.344 (676632.438) - AE Rec Loss: 1.084 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.241 
(4.185) - AE Loss: 1454785.375 (676632.438) - AE Rec Loss: 9.866 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.239 
(4.185) - AE Loss: 147944.984 (676632.438) - AE Rec Loss: 1.003 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.561 
(3.460) - AE Loss: 73029.875 (732412.250) - AE Rec Loss: 0.495 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.564 
(3.460) - AE Loss: 1468160.500 (732412.250) - AE Rec Loss: 9.957 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.567 
(3.460) - AE Loss: 2660294.250 (732412.250) - AE Rec Loss: 18.041 (4.967) - Disc
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.563 
(3.460) - AE Loss: 1554880.750 (732412.250) - AE Rec Loss: 10.545 (4.967) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.565 
(3.460) - AE Loss: 253640.359 (732412.250) - AE Rec Loss: 1.720 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.31 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.562 
(3.460) - AE Loss: 1629609.375 (732412.250) - AE Rec Loss: 11.051 (4.967) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.736 
(3.006) - AE Loss: 1696716.250 (699626.562) - AE Rec Loss: 11.507 (4.745) - Disc
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.019 (1.033) - Batch(s): 0.735 
(3.006) - AE Loss: 153198.938 (699626.562) - AE Rec Loss: 1.039 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.735 
(3.006) - AE Loss: 151782.344 (699626.562) - AE Rec Loss: 1.029 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.736 
(3.006) - AE Loss: 87880.008 (699626.562) - AE Rec Loss: 0.596 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.736 
(3.006) - AE Loss: 257484.188 (699626.562) - AE Rec Loss: 1.746 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.41 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.736 
(3.006) - AE Loss: 2889758.000 (699626.562) - AE Rec Loss: 19.597 (4.745) - Disc
Loss: 0.000 (0.000) - 2.41 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.093 
(3.304) - AE Loss: 1452255.875 (671368.688) - AE Rec Loss: 9.849 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.090 
(3.304) - AE Loss: 162978.500 (671368.688) - AE Rec Loss: 1.105 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 4.524 (0.941) - Batch(s): 5.094 
(3.304) - AE Loss: 137488.875 (671368.688) - AE Rec Loss: 0.932 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.088 
(3.304) - AE Loss: 1490850.125 (671368.688) - AE Rec Loss: 10.110 (4.553) - Disc
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.113 (0.941) - Batch(s): 5.090 
(3.304) - AE Loss: 131646.047 (671368.688) - AE Rec Loss: 0.893 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.091 
(3.304) - AE Loss: 300714.875 (671368.688) - AE Rec Loss: 2.039 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.564 
(2.962) - AE Loss: 294564.594 (665912.688) - AE Rec Loss: 1.998 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.001 (0.823) - Batch(s): 0.561 
(2.962) - AE Loss: 319658.875 (665912.688) - AE Rec Loss: 2.168 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.10 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.564 
(2.962) - AE Loss: 1354408.000 (665912.688) - AE Rec Loss: 9.185 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.10 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.567 
(2.962) - AE Loss: 352367.938 (665912.688) - AE Rec Loss: 2.390 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.565 
(2.962) - AE Loss: 97359.805 (665912.688) - AE Rec Loss: 0.660 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.564 
(2.962) - AE Loss: 1335255.500 (665912.688) - AE Rec Loss: 9.055 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.826 
(2.724) - AE Loss: 518282.688 (681685.312) - AE Rec Loss: 3.515 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.823 
(2.724) - AE Loss: 1894952.500 (681685.312) - AE Rec Loss: 12.851 (4.623) - Disc
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.823 
(2.724) - AE Loss: 1570676.500 (681685.312) - AE Rec Loss: 10.652 (4.623) - Disc
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.146 (0.733) - Batch(s): 0.824 
(2.724) - AE Loss: 136752.688 (681685.312) - AE Rec Loss: 0.927 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.826 
(2.724) - AE Loss: 1514420.625 (681685.312) - AE Rec Loss: 10.270 (4.623) - Disc
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.825 
(2.724) - AE Loss: 132109.969 (681685.312) - AE Rec Loss: 0.896 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.001 (0.704) - Batch(s): 5.799 
(3.032) - AE Loss: 167478.609 (701574.562) - AE Rec Loss: 1.136 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.803 
(3.032) - AE Loss: 1548257.000 (701574.562) - AE Rec Loss: 10.500 (4.758) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.800 
(3.032) - AE Loss: 2009996.750 (701574.562) - AE Rec Loss: 13.631 (4.758) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 5.232 (0.704) - Batch(s): 5.805 
(3.032) - AE Loss: 77824.219 (701574.562) - AE Rec Loss: 0.528 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.798 
(3.032) - AE Loss: 1527429.500 (701574.562) - AE Rec Loss: 10.359 (4.758) - Disc
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.802 
(3.032) - AE Loss: 1557792.375 (701574.562) - AE Rec Loss: 10.564 (4.758) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.158 
(2.857) - AE Loss: 116939.133 (703098.312) - AE Rec Loss: 0.793 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.156 
(2.857) - AE Loss: 592668.500 (703098.312) - AE Rec Loss: 4.019 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.157 
(2.857) - AE Loss: 93221.672 (703098.312) - AE Rec Loss: 0.632 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.156 
(2.857) - AE Loss: 339833.844 (703098.312) - AE Rec Loss: 2.305 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.153 
(2.857) - AE Loss: 148756.188 (703098.312) - AE Rec Loss: 1.009 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.563 
(2.857) - AE Loss: 1792831.375 (703098.312) - AE Rec Loss: 12.158 (4.768) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.663 
(2.674) - AE Loss: 1340155.875 (689406.562) - AE Rec Loss: 9.089 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 157123.578 (689406.562) - AE Rec Loss: 1.066 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.664 
(2.674) - AE Loss: 1413434.250 (689406.562) - AE Rec Loss: 9.585 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.001 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 154247.062 (689406.562) - AE Rec Loss: 1.046 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 506822.250 (689406.562) - AE Rec Loss: 3.437 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 265271.812 (689406.562) - AE Rec Loss: 1.799 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.18 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.475 
(2.659) - AE Loss: 489488.812 (682977.125) - AE Rec Loss: 3.320 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.478 
(2.659) - AE Loss: 1740976.500 (682977.125) - AE Rec Loss: 11.807 (4.632) - Disc
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 1.907 (0.554) - Batch(s): 2.482 
(2.659) - AE Loss: 205641.734 (682977.125) - AE Rec Loss: 1.395 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.477 
(2.659) - AE Loss: 75705.828 (682977.125) - AE Rec Loss: 0.513 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.473 
(2.659) - AE Loss: 256795.578 (682977.125) - AE Rec Loss: 1.742 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.476 
(2.659) - AE Loss: 391548.500 (682977.125) - AE Rec Loss: 2.655 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.568 
(2.509) - AE Loss: 1753962.750 (692070.500) - AE Rec Loss: 11.895 (4.693) - Disc
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.563 
(2.509) - AE Loss: 159922.344 (692070.500) - AE Rec Loss: 1.085 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.001 (0.514) - Batch(s): 0.567 
(2.509) - AE Loss: 262708.250 (692070.500) - AE Rec Loss: 1.782 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.563 
(2.509) - AE Loss: 1525845.500 (692070.500) - AE Rec Loss: 10.348 (4.693) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.566 
(2.509) - AE Loss: 1540993.500 (692070.500) - AE Rec Loss: 10.451 (4.693) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.565 
(2.509) - AE Loss: 142968.094 (692070.500) - AE Rec Loss: 0.970 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.647 
(2.385) - AE Loss: 155779.375 (675185.312) - AE Rec Loss: 1.056 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.647 
(2.385) - AE Loss: 196825.797 (675185.312) - AE Rec Loss: 1.335 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.480) - Batch(s): 0.647 
(2.385) - AE Loss: 391486.750 (675185.312) - AE Rec Loss: 2.655 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.480) - Batch(s): 0.648 
(2.385) - AE Loss: 2933209.500 (675185.312) - AE Rec Loss: 19.892 (4.579) - Disc
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.649 
(2.385) - AE Loss: 68550.953 (675185.312) - AE Rec Loss: 0.465 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.648 
(2.385) - AE Loss: 103840.883 (675185.312) - AE Rec Loss: 0.704 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.007 
(2.424) - AE Loss: 325650.812 (670561.312) - AE Rec Loss: 2.208 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.03 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.006 
(2.424) - AE Loss: 1612199.750 (670561.312) - AE Rec Loss: 10.933 (4.548) - Disc
Loss: 0.000 (0.000) - 5.00 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.006 
(2.424) - AE Loss: 80649.984 (670561.312) - AE Rec Loss: 0.547 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.002 
(2.424) - AE Loss: 275946.469 (670561.312) - AE Rec Loss: 1.871 (4.548) - Disc 
Loss: 0.000 (0.000) - 4.98 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.006 
(2.424) - AE Loss: 77413.273 (670561.312) - AE Rec Loss: 0.525 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 2.435 (0.463) - Batch(s): 3.008 
(2.424) - AE Loss: 2773934.750 (670561.312) - AE Rec Loss: 18.812 (4.548) - Disc
Loss: 0.000 (0.000) - 4.98 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.569 
(2.315) - AE Loss: 448968.938 (670543.125) - AE Rec Loss: 3.045 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.566 
(2.315) - AE Loss: 3499631.000 (670543.125) - AE Rec Loss: 23.733 (4.547) - Disc
Loss: 0.000 (0.000) - 5.07 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.435) - Batch(s): 0.563 
(2.315) - AE Loss: 244940.891 (670543.125) - AE Rec Loss: 1.661 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.04 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.435) - Batch(s): 0.566 
(2.315) - AE Loss: 94223.750 (670543.125) - AE Rec Loss: 0.639 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.08 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.435) - Batch(s): 0.565 
(2.315) - AE Loss: 262509.969 (670543.125) - AE Rec Loss: 1.780 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.05 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.001 (0.435) - Batch(s): 0.565 
(2.315) - AE Loss: 100704.328 (670543.125) - AE Rec Loss: 0.683 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.08 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.327 
(2.316) - AE Loss: 87981.328 (660157.500) - AE Rec Loss: 0.597 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 261865.188 (660157.500) - AE Rec Loss: 1.776 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.34 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 1.663 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 340314.438 (660157.500) - AE Rec Loss: 2.308 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.134 (0.419) - Batch(s): 2.329 
(2.316) - AE Loss: 486208.125 (660157.500) - AE Rec Loss: 3.297 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 195976.375 (660157.500) - AE Rec Loss: 1.329 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 70396.398 (660157.500) - AE Rec Loss: 0.477 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.36 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.565 
(2.223) - AE Loss: 555830.125 (656595.500) - AE Rec Loss: 3.769 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.567 
(2.223) - AE Loss: 230968.875 (656595.500) - AE Rec Loss: 1.566 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.564 
(2.223) - AE Loss: 1542280.000 (656595.500) - AE Rec Loss: 10.459 (4.453) - Disc
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.564 
(2.223) - AE Loss: 350125.500 (656595.500) - AE Rec Loss: 2.374 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.569 
(2.223) - AE Loss: 1416764.500 (656595.500) - AE Rec Loss: 9.608 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.566 
(2.223) - AE Loss: 141996.438 (656595.500) - AE Rec Loss: 0.963 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.565 
(2.141) - AE Loss: 112110.539 (664869.188) - AE Rec Loss: 0.760 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.567 
(2.141) - AE Loss: 1340567.500 (664869.188) - AE Rec Loss: 9.091 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.001 (0.378) - Batch(s): 0.567 
(2.141) - AE Loss: 175989.281 (664869.188) - AE Rec Loss: 1.194 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.49 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.566 
(2.141) - AE Loss: 139443.609 (664869.188) - AE Rec Loss: 0.946 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.001 (0.378) - Batch(s): 0.569 
(2.141) - AE Loss: 1480335.000 (664869.188) - AE Rec Loss: 10.039 (4.509) - Disc
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.564 
(2.141) - AE Loss: 299652.062 (664869.188) - AE Rec Loss: 2.032 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

attempting to save
[[36m2023-11-29 04:51:44,555[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 04:51:45,720[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 04:51:46,109[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 04:51:46,115[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 04:51:46,120[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 04:51:46,124[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 04:51:46,128[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 04:51:46,133[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 04:51:46,141[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 04:51:46,146[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 04:51:46,699[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 04:51:48,371[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 04:51:58,826[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 04:51:58,831[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 04:52:02,232[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 04:52:02,232[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 04:52:02,232[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 04:52:02,246[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 70396.352 (649645.688) - AE Rec Loss: 0.477 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 67466.336 (649645.688) - AE Rec Loss: 0.458 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.001 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 218240.203 (649645.688) - AE Rec Loss: 1.480 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.71 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.001 (0.364) - Batch(s): 0.629 
(2.878) - AE Loss: 150860.875 (649645.688) - AE Rec Loss: 1.023 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.72 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 190179.609 (649645.688) - AE Rec Loss: 1.290 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.75 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 1.002 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 192447.797 (649645.688) - AE Rec Loss: 1.305 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.565 
(2.773) - AE Loss: 465300.812 (653407.062) - AE Rec Loss: 3.156 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.564 
(2.773) - AE Loss: 682892.375 (653407.062) - AE Rec Loss: 4.631 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.567 
(2.773) - AE Loss: 112328.992 (653407.062) - AE Rec Loss: 0.762 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.566 
(2.773) - AE Loss: 193428.547 (653407.062) - AE Rec Loss: 1.312 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.569 
(2.773) - AE Loss: 203049.594 (653407.062) - AE Rec Loss: 1.377 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.564 
(2.773) - AE Loss: 656261.188 (653407.062) - AE Rec Loss: 4.451 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.566 
(2.677) - AE Loss: 111627.016 (653220.500) - AE Rec Loss: 0.757 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.83 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.564 
(2.677) - AE Loss: 313716.250 (653220.500) - AE Rec Loss: 2.128 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.567 
(2.677) - AE Loss: 144734.359 (653220.500) - AE Rec Loss: 0.982 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.84 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.567 
(2.677) - AE Loss: 320288.312 (653220.500) - AE Rec Loss: 2.172 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.001 (0.332) - Batch(s): 0.570 
(2.677) - AE Loss: 1895342.750 (653220.500) - AE Rec Loss: 12.854 (4.430) - Disc
Loss: 0.000 (0.000) - 7.88 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.564 
(2.677) - AE Loss: 1357763.500 (653220.500) - AE Rec Loss: 9.208 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 138479.938 (652188.875) - AE Rec Loss: 0.939 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.90 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 126128.820 (652188.875) - AE Rec Loss: 0.855 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 1327900.500 (652188.875) - AE Rec Loss: 9.005 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 1885288.000 (652188.875) - AE Rec Loss: 12.785 (4.423) - Disc
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 91857.141 (652188.875) - AE Rec Loss: 0.623 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.634 
(2.592) - AE Loss: 1553938.000 (652188.875) - AE Rec Loss: 10.538 (4.423) - Disc
Loss: 0.000 (0.000) - 7.88 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 336045.656 (653049.750) - AE Rec Loss: 2.279 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 1500401.250 (653049.750) - AE Rec Loss: 10.175 (4.429) - Disc
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.565 
(2.511) - AE Loss: 87580.000 (653049.750) - AE Rec Loss: 0.594 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.570 
(2.511) - AE Loss: 1312988.375 (653049.750) - AE Rec Loss: 8.904 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 1633542.000 (653049.750) - AE Rec Loss: 11.078 (4.429) - Disc
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.564 
(2.511) - AE Loss: 127152.891 (653049.750) - AE Rec Loss: 0.862 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.93 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.294) - Batch(s): 0.568 
(2.436) - AE Loss: 1563316.750 (643148.625) - AE Rec Loss: 10.602 (4.362) - Disc
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.566 
(2.436) - AE Loss: 219156.281 (643148.625) - AE Rec Loss: 1.486 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.568 
(2.436) - AE Loss: 106654.617 (643148.625) - AE Rec Loss: 0.723 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.565 
(2.436) - AE Loss: 281092.812 (643148.625) - AE Rec Loss: 1.906 (4.362) - Disc 
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.294) - Batch(s): 0.568 
(2.436) - AE Loss: 77606.484 (643148.625) - AE Rec Loss: 0.526 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.294) - Batch(s): 0.569 
(2.436) - AE Loss: 71544.469 (643148.625) - AE Rec Loss: 0.485 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:52:24,650[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:24,690[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:24,835[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,007[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,013[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,097[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:52:26,856[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:26,995[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,144[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,185[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,214[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,240[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,340[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,574[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,766[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,858[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,870[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,884[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 04:52:28,140[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:52:28,141[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:52:28,141[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:52:28,142[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
[[36m2023-11-29 04:52:28,143[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:52:28,148[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Running in inference mode: False
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 5Reached 1.3 on node 3

Reached 1.4 on node 3Reached 1.4 on node 5

Reached 2 on node 5
Reached 2 on node 3
Reached 3 on node 5Reached 3 on node 3

Reached 5 on node 5
Reached 5 on node 3
Reached end on node 3Reached end on node 5

Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 3 on node 3Reached 3 on node 5

Reached 5 on node 5Reached 5 on node 3

Reached end on node 5
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.3 on node 2Reached 1.4 on node 1

Reached 1.4 on node 2
Reached 2 on node 1
Reached 2 on node 2
Reached 3 on node 1
Reached 3 on node 2
Reached 5 on node 1
Reached 5 on node 2
Reached 1.3 on node 0
Reached end on node 1Reached end on node 2Reached 1.4 on node 0


Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 1.3 on node 5Reached 2 on node 4Reached 3 on node 3


Reached 1.4 on node 5
Reached 5 on node 3Reached 2 on node 5

Reached 3 on node 4
Reached end on node 3
Reached 5 on node 4
Reached 3 on node 5
Reached end on node 4
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 1 on node 2Reached 3 on node 1

Reached 3 on node 1
Reached 5 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5Reached 1 on node 2Reached 1 on node 4


Reached 1.4 on node 2
Reached 1.4 on node 4
Reached 2 on node 2
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 1.4 on node 2
Reached 2 on node 4Reached 1 on node 5Reached 2 on node 2


Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2Reached 1.4 on node 5

Reached 1 on node 3Reached 3 on node 2

Reached 2 on node 5
Reached 5 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4Reached 1 on node 5

Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5Reached 1 on node 4

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 5
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 5
Reached end on node 0
Reached end on node 3
[[36m2023-11-29 04:52:29,855[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 04:52:32,173[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 04:52:33,382[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 04:52:33,383[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 04:52:33,383[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 04:52:33,385[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 04:52:33,386[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <281/2280>] - Data(s): 3.412 (5.253) - Batch(s): 12.519 
(12.091) - AE Loss: 218054.047 (345246.531) - AE Rec Loss: 1.479 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 4.053 (5.253) - Batch(s): 12.532 
(12.091) - AE Loss: 150958.531 (345246.531) - AE Rec Loss: 1.024 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.525 (5.253) - Batch(s): 12.527 
(12.091) - AE Loss: 69049.930 (345246.531) - AE Rec Loss: 0.468 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 3.175 (5.253) - Batch(s): 12.537 
(12.091) - AE Loss: 192040.078 (345246.531) - AE Rec Loss: 1.302 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 3.431 (5.253) - Batch(s): 12.518 
(12.091) - AE Loss: 189771.531 (345246.531) - AE Rec Loss: 1.287 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.320 (5.253) - Batch(s): 12.516 
(12.091) - AE Loss: 69981.898 (345246.531) - AE Rec Loss: 0.475 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.51 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.627) - Batch(s): 0.568 
(6.329) - AE Loss: 185633.109 (533329.250) - AE Rec Loss: 1.259 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.565 
(6.329) - AE Loss: 677653.750 (533329.250) - AE Rec Loss: 4.596 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.627) - Batch(s): 0.571 
(6.329) - AE Loss: 179495.406 (533329.250) - AE Rec Loss: 1.217 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.627) - Batch(s): 0.568 
(6.329) - AE Loss: 95741.500 (533329.250) - AE Rec Loss: 0.649 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.564 
(6.329) - AE Loss: 653476.312 (533329.250) - AE Rec Loss: 4.432 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.627) - Batch(s): 0.566 
(6.329) - AE Loss: 463393.500 (533329.250) - AE Rec Loss: 3.143 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.018 
(4.560) - AE Loss: 1897226.125 (568238.750) - AE Rec Loss: 12.866 (3.854) - Disc
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.022 
(4.560) - AE Loss: 300431.188 (568238.750) - AE Rec Loss: 2.037 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.023 
(4.560) - AE Loss: 1354754.375 (568238.750) - AE Rec Loss: 9.188 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.023 
(4.560) - AE Loss: 125401.094 (568238.750) - AE Rec Loss: 0.850 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.022 
(4.560) - AE Loss: 94736.039 (568238.750) - AE Rec Loss: 0.642 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.023 
(4.560) - AE Loss: 296308.188 (568238.750) - AE Rec Loss: 2.009 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.570 
(3.562) - AE Loss: 1882445.750 (581274.688) - AE Rec Loss: 12.766 (3.942) - Disc
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.567 
(3.562) - AE Loss: 80186.469 (581274.688) - AE Rec Loss: 0.544 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.566 
(3.562) - AE Loss: 115316.227 (581274.688) - AE Rec Loss: 0.782 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.567 
(3.562) - AE Loss: 1321471.000 (581274.688) - AE Rec Loss: 8.962 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.563 
(3.562) - AE Loss: 1549662.500 (581274.688) - AE Rec Loss: 10.509 (3.942) - Disc
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.321) - Batch(s): 0.567 
(3.562) - AE Loss: 129270.328 (581274.688) - AE Rec Loss: 0.877 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.063) - Batch(s): 0.571 
(3.010) - AE Loss: 340716.000 (600211.438) - AE Rec Loss: 2.311 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.063) - Batch(s): 0.571 
(3.010) - AE Loss: 1633718.125 (600211.438) - AE Rec Loss: 11.079 (4.070) - Disc
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.063) - Batch(s): 0.573 
(3.010) - AE Loss: 1313758.125 (600211.438) - AE Rec Loss: 8.909 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.063) - Batch(s): 0.570 
(3.010) - AE Loss: 103311.250 (600211.438) - AE Rec Loss: 0.701 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.360 (1.063) - Batch(s): 0.925 
(3.010) - AE Loss: 1497444.750 (600211.438) - AE Rec Loss: 10.155 (4.070) - Disc
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.063) - Batch(s): 0.920 
(3.010) - AE Loss: 135560.047 (600211.438) - AE Rec Loss: 0.919 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.372 
(2.904) - AE Loss: 110026.102 (566687.125) - AE Rec Loss: 0.746 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.372 
(2.904) - AE Loss: 84580.547 (566687.125) - AE Rec Loss: 0.574 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.374 
(2.904) - AE Loss: 219831.844 (566687.125) - AE Rec Loss: 1.491 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.373 
(2.904) - AE Loss: 1565092.000 (566687.125) - AE Rec Loss: 10.614 (3.843) - Disc
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 1.712 (0.909) - Batch(s): 2.374 
(2.904) - AE Loss: 92671.516 (566687.125) - AE Rec Loss: 0.628 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.373 
(2.904) - AE Loss: 277517.188 (566687.125) - AE Rec Loss: 1.882 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 0.948 
(2.638) - AE Loss: 67792.609 (567626.500) - AE Rec Loss: 0.460 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 0.948 
(2.638) - AE Loss: 188199.516 (567626.500) - AE Rec Loss: 1.276 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 2808479.000 (567626.500) - AE Rec Loss: 19.046 (3.849) - Disc
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 117243.008 (567626.500) - AE Rec Loss: 0.795 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.788) - Batch(s): 0.948 
(2.638) - AE Loss: 268795.312 (567626.500) - AE Rec Loss: 1.823 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 1516547.750 (567626.500) - AE Rec Loss: 10.285 (3.849) - Disc
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.001 (0.778) - Batch(s): 7.115 
(3.227) - AE Loss: 257276.922 (584087.562) - AE Rec Loss: 1.745 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.001 (0.778) - Batch(s): 7.115 
(3.227) - AE Loss: 215680.828 (584087.562) - AE Rec Loss: 1.463 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.001 (0.778) - Batch(s): 7.115 
(3.227) - AE Loss: 88149.867 (584087.562) - AE Rec Loss: 0.598 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 6.901 (0.778) - Batch(s): 7.474 
(3.227) - AE Loss: 1662557.250 (584087.562) - AE Rec Loss: 11.275 (3.961) - Disc
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.001 (0.778) - Batch(s): 7.115 
(3.227) - AE Loss: 68571.086 (584087.562) - AE Rec Loss: 0.465 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.001 (0.778) - Batch(s): 7.469 
(3.227) - AE Loss: 704651.625 (584087.562) - AE Rec Loss: 4.779 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 1620236.000 (612802.250) - AE Rec Loss: 10.988 (4.156) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 267217.562 (612802.250) - AE Rec Loss: 1.812 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 145981.516 (612802.250) - AE Rec Loss: 0.990 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 1502199.375 (612802.250) - AE Rec Loss: 10.187 (4.156) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 62522.559 (612802.250) - AE Rec Loss: 0.424 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.640 
(2.940) - AE Loss: 870429.625 (612802.250) - AE Rec Loss: 5.903 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.568 
(2.702) - AE Loss: 411905.000 (607850.562) - AE Rec Loss: 2.793 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.571 
(2.702) - AE Loss: 103007.867 (607850.562) - AE Rec Loss: 0.699 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.001 (0.623) - Batch(s): 0.568 
(2.702) - AE Loss: 51428.551 (607850.562) - AE Rec Loss: 0.349 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.568 
(2.702) - AE Loss: 442777.844 (607850.562) - AE Rec Loss: 3.003 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.001 (0.623) - Batch(s): 0.566 
(2.702) - AE Loss: 1626038.125 (607850.562) - AE Rec Loss: 11.027 (4.122) - Disc
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.563 
(2.702) - AE Loss: 215109.766 (607850.562) - AE Rec Loss: 1.459 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.264 
(2.920) - AE Loss: 228117.641 (583836.875) - AE Rec Loss: 1.547 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 4.912 
(2.920) - AE Loss: 130763.852 (583836.875) - AE Rec Loss: 0.887 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.001 (0.602) - Batch(s): 4.333 
(2.920) - AE Loss: 174049.875 (583836.875) - AE Rec Loss: 1.180 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 4.912 
(2.920) - AE Loss: 242145.219 (583836.875) - AE Rec Loss: 1.642 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 4.697 (0.602) - Batch(s): 5.269 
(2.920) - AE Loss: 213470.062 (583836.875) - AE Rec Loss: 1.448 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 4.912 
(2.920) - AE Loss: 305249.688 (583836.875) - AE Rec Loss: 2.070 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 261634.516 (577743.375) - AE Rec Loss: 1.774 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 222404.000 (577743.375) - AE Rec Loss: 1.508 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 147095.609 (577743.375) - AE Rec Loss: 0.998 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 96970.820 (577743.375) - AE Rec Loss: 0.658 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 91801.586 (577743.375) - AE Rec Loss: 0.623 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.637 
(2.730) - AE Loss: 1339832.875 (577743.375) - AE Rec Loss: 9.086 (3.918) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.072 
(2.616) - AE Loss: 255934.766 (570977.000) - AE Rec Loss: 1.736 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.072 
(2.616) - AE Loss: 221865.188 (570977.000) - AE Rec Loss: 1.505 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.073 
(2.616) - AE Loss: 329001.750 (570977.000) - AE Rec Loss: 2.231 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.072 
(2.616) - AE Loss: 196531.000 (570977.000) - AE Rec Loss: 1.333 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.515) - Batch(s): 1.073 
(2.616) - AE Loss: 124359.922 (570977.000) - AE Rec Loss: 0.843 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.072 
(2.616) - AE Loss: 326844.656 (570977.000) - AE Rec Loss: 2.217 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.306 
(3.443) - AE Loss: 247286.766 (571465.062) - AE Rec Loss: 1.677 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 13.741 (0.560) - Batch(s): 14.312 
(3.443) - AE Loss: 1944461.500 (571465.062) - AE Rec Loss: 13.187 (3.875) - Disc
Loss: 0.000 (0.000) - 5.83 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 13.954 
(3.443) - AE Loss: 119012.539 (571465.062) - AE Rec Loss: 0.807 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 13.954 
(3.443) - AE Loss: 108040.055 (571465.062) - AE Rec Loss: 0.733 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 13.954 
(3.443) - AE Loss: 458836.406 (571465.062) - AE Rec Loss: 3.112 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.83 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 13.954 
(3.443) - AE Loss: 116752.266 (571465.062) - AE Rec Loss: 0.792 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.83 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.001 (0.523) - Batch(s): 0.635 
(3.256) - AE Loss: 343049.875 (593207.625) - AE Rec Loss: 2.326 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.634 
(3.256) - AE Loss: 153788.891 (593207.625) - AE Rec Loss: 1.043 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.635 
(3.256) - AE Loss: 1455048.625 (593207.625) - AE Rec Loss: 9.868 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.637 
(3.256) - AE Loss: 228007.203 (593207.625) - AE Rec Loss: 1.546 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.001 (0.523) - Batch(s): 0.634 
(3.256) - AE Loss: 56920.559 (593207.625) - AE Rec Loss: 0.386 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.637 
(3.256) - AE Loss: 3004143.250 (593207.625) - AE Rec Loss: 20.373 (4.023) - Disc
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.569 
(3.088) - AE Loss: 1368037.750 (593370.562) - AE Rec Loss: 9.278 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.567 
(3.088) - AE Loss: 189402.984 (593370.562) - AE Rec Loss: 1.284 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.568 
(3.088) - AE Loss: 177615.328 (593370.562) - AE Rec Loss: 1.205 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.566 
(3.088) - AE Loss: 229109.734 (593370.562) - AE Rec Loss: 1.554 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.571 
(3.088) - AE Loss: 301156.375 (593370.562) - AE Rec Loss: 2.042 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.565 
(3.088) - AE Loss: 344054.812 (593370.562) - AE Rec Loss: 2.333 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 2.667 (0.474) - Batch(s): 3.241 
(3.090) - AE Loss: 132719.781 (580125.625) - AE Rec Loss: 0.900 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 2.882 
(3.090) - AE Loss: 72348.047 (580125.625) - AE Rec Loss: 0.491 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 2.882 
(3.090) - AE Loss: 84283.422 (580125.625) - AE Rec Loss: 0.572 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 2.882 
(3.090) - AE Loss: 151404.047 (580125.625) - AE Rec Loss: 1.027 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.234 
(3.090) - AE Loss: 140366.031 (580125.625) - AE Rec Loss: 0.952 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 2.882 
(3.090) - AE Loss: 70008.883 (580125.625) - AE Rec Loss: 0.475 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.638 
(2.953) - AE Loss: 90738.922 (589419.250) - AE Rec Loss: 0.615 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.638 
(2.953) - AE Loss: 162696.078 (589419.250) - AE Rec Loss: 1.103 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.638 
(2.953) - AE Loss: 149357.391 (589419.250) - AE Rec Loss: 1.013 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.638 
(2.953) - AE Loss: 212888.375 (589419.250) - AE Rec Loss: 1.444 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.639 
(2.953) - AE Loss: 257020.250 (589419.250) - AE Rec Loss: 1.743 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.638 
(2.953) - AE Loss: 2827752.500 (589419.250) - AE Rec Loss: 19.177 (3.997) - Disc
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.569 
(2.828) - AE Loss: 169814.938 (576836.438) - AE Rec Loss: 1.152 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.569 
(2.828) - AE Loss: 463069.625 (576836.438) - AE Rec Loss: 3.140 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.001 (0.424) - Batch(s): 0.565 
(2.828) - AE Loss: 588296.000 (576836.438) - AE Rec Loss: 3.990 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.566 
(2.828) - AE Loss: 240910.672 (576836.438) - AE Rec Loss: 1.634 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.572 
(2.828) - AE Loss: 239179.266 (576836.438) - AE Rec Loss: 1.622 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.569 
(2.828) - AE Loss: 93500.273 (576836.438) - AE Rec Loss: 0.634 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:03:05,942[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,072[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,143[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,143[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,159[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,278[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:03:08,086[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,256[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,264[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,278[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,329[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,424[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:08,635[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:08,963[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:08,983[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:08,989[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,025[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,088[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 05:03:09,547[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:03:09,548[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
[[36m2023-11-29 05:03:09,549[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
[[36m2023-11-29 05:03:09,549[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Running in inference mode: False
[[36m2023-11-29 05:03:09,551[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Running in inference mode: False
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 05:03:09,554[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Preparing opt_disc 
len(valid_dataset) = 4
=> Running in inference mode: False
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Preparing model 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:04:38,173[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,225[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,421[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,468[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,493[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,496[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:04:40,334[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:40,338[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:40,582[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:40,648[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:40,688[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:40,699[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:40,938[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:40,979[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,161[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,324[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,331[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,343[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
[[36m2023-11-29 05:04:42,161[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:04:42,164[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:04:42,164[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:04:42,164[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
[[36m2023-11-29 05:04:42,165[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:04:42,165[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2Reached 1.3 on node 4

Reached 1.4 on node 4
Reached 1.4 on node 2
Reached 2 on node 4Reached 2 on node 2

Reached 3 on node 4
Reached 3 on node 2
Reached 5 on node 4
Reached 5 on node 2
Reached end on node 4
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 0Reached 1.3 on node 1

Reached 1.4 on node 1Reached 1.4 on node 0

Reached 2 on node 1
Reached 2 on node 0
Reached 3 on node 1
Reached 3 on node 0
Reached 1.3 on node 3
Reached 5 on node 1
Reached 1.4 on node 3Reached 5 on node 0

Reached end on node 1
Reached end on node 0
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 2Reached 3 on node 4

Reached 5 on node 2Reached 5 on node 4

Reached end on node 2
Reached end on node 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1 on node 0
Reached 1.25 on node 4
Reached 1.2 on node 0
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1Reached 1.3 on node 0

Reached 1.4 on node 0Reached 1.4 on node 1

Reached 2 on node 1
Reached 2 on node 0
Reached 3 on node 1
Reached 3 on node 0
Reached 5 on node 1
Reached 5 on node 0
Reached end on node 1
Reached end on node 0
Reached 1.3 on node 4
Reached 1.3 on node 2Reached 1.4 on node 4

Reached 1.4 on node 2
Reached 2 on node 4
Reached 2 on node 2
Reached 3 on node 4
Reached 1.3 on node 5Reached 3 on node 2

Reached 5 on node 4
Reached 1.4 on node 5
Reached 1.3 on node 3
Reached end on node 4Reached 5 on node 2

Reached 1.4 on node 3Reached 2 on node 5

Reached end on node 2
Reached 2 on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached 3 on node 3
Reached end on node 5
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1Reached 3 on node 0

Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 1.4 on node 1
Reached 2 on node 2
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4Reached 1 on node 1

Reached 1 on node 3
Reached 1.4 on node 1Reached 1.4 on node 4

Reached 2 on node 4Reached 2 on node 1

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached end on node 0
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 5
Reached 1.4 on node 4Reached 2 on node 5

Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 1 on node 5Reached 2 on node 4

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 1.4 on node 5Reached 3 on node 3

Reached 2 on node 5Reached 3 on node 3

Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 1 on node 5Reached 3 on node 4

Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 1
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1 on node 4
Reached 1.4 on node 1
Reached 1.4 on node 4
Reached 2 on node 1
Reached 2 on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1 on node 4
Reached 1 on node 2
Reached 1 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 4
Reached 1 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 05:04:43,935[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 05:04:45,390[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:04:45,937[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:04:45,937[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:04:45,937[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 05:04:45,941[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:04:45,943[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <281/2280>] - Data(s): 3.586 (4.858) - Batch(s): 7.617 
(7.570) - AE Loss: 192284.406 (345289.750) - AE Rec Loss: 1.304 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 3.375 (4.858) - Batch(s): 7.547 
(7.570) - AE Loss: 190066.625 (345289.750) - AE Rec Loss: 1.289 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 3.404 (4.858) - Batch(s): 7.545 
(7.570) - AE Loss: 150958.531 (345289.750) - AE Rec Loss: 1.024 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.416 (4.858) - Batch(s): 7.425 
(7.570) - AE Loss: 69318.422 (345289.750) - AE Rec Loss: 0.470 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.814 (4.858) - Batch(s): 7.608 
(7.570) - AE Loss: 69330.891 (345289.750) - AE Rec Loss: 0.470 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 3.437 (4.858) - Batch(s): 7.333 
(7.570) - AE Loss: 218445.750 (345289.750) - AE Rec Loss: 1.481 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.561 
(4.066) - AE Loss: 463393.500 (533248.062) - AE Rec Loss: 3.143 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.01 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.562 
(4.066) - AE Loss: 96253.875 (533248.062) - AE Rec Loss: 0.653 (3.616) - Disc 
Loss: 0.000 (0.000) - 0.99 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.561 
(4.066) - AE Loss: 677134.375 (533248.062) - AE Rec Loss: 4.592 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.565 
(4.066) - AE Loss: 184851.656 (533248.062) - AE Rec Loss: 1.254 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.01 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.565 
(4.066) - AE Loss: 178686.219 (533248.062) - AE Rec Loss: 1.212 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.559 
(4.066) - AE Loss: 653285.125 (533248.062) - AE Rec Loss: 4.430 (3.616) - Disc 
Loss: 0.000 (0.000) - 0.98 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (2.057) - Batch(s): 4.512 
(4.214) - AE Loss: 94736.039 (568088.688) - AE Rec Loss: 0.642 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 2.498 (2.057) - Batch(s): 4.511 
(4.214) - AE Loss: 295350.312 (568088.688) - AE Rec Loss: 2.003 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 2.248 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 124889.250 (568088.688) - AE Rec Loss: 0.847 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.54 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 1.390 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 1354036.250 (568088.688) - AE Rec Loss: 9.183 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.950 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 1897357.250 (568088.688) - AE Rec Loss: 12.867 (3.853) - Disc
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 2.668 (2.057) - Batch(s): 4.512 
(4.214) - AE Loss: 299175.750 (568088.688) - AE Rec Loss: 2.029 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 0.910 
(3.432) - AE Loss: 1321500.750 (581251.938) - AE Rec Loss: 8.962 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 0.910 
(3.432) - AE Loss: 129207.773 (581251.938) - AE Rec Loss: 0.876 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 0.910 
(3.432) - AE Loss: 1549929.750 (581251.938) - AE Rec Loss: 10.511 (3.942) - Disc
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 0.910 
(3.432) - AE Loss: 80913.523 (581251.938) - AE Rec Loss: 0.549 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 0.909 
(3.432) - AE Loss: 115556.086 (581251.938) - AE Rec Loss: 0.784 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.320 (1.564) - Batch(s): 0.910 
(3.432) - AE Loss: 1882458.000 (581251.938) - AE Rec Loss: 12.766 (3.942) - Disc
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.564 
(2.859) - AE Loss: 102570.586 (600216.812) - AE Rec Loss: 0.696 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.251) - Batch(s): 0.568 
(2.859) - AE Loss: 1313675.500 (600216.812) - AE Rec Loss: 8.909 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.566 
(2.859) - AE Loss: 1496814.250 (600216.812) - AE Rec Loss: 10.151 (4.070) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.562 
(2.859) - AE Loss: 340394.312 (600216.812) - AE Rec Loss: 2.308 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.79 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.567 
(2.859) - AE Loss: 1633453.750 (600216.812) - AE Rec Loss: 11.078 (4.070) - Disc
Loss: 0.000 (0.000) - 1.79 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.563 
(2.859) - AE Loss: 136491.938 (600216.812) - AE Rec Loss: 0.926 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.170 
(3.244) - AE Loss: 219544.766 (566742.312) - AE Rec Loss: 1.489 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.41 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.169 
(3.244) - AE Loss: 278063.312 (566742.312) - AE Rec Loss: 1.886 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.170 
(3.244) - AE Loss: 86311.805 (566742.312) - AE Rec Loss: 0.585 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.41 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 4.471 (1.109) - Batch(s): 5.169 
(3.244) - AE Loss: 91594.812 (566742.312) - AE Rec Loss: 0.621 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.171 
(3.244) - AE Loss: 110246.961 (566742.312) - AE Rec Loss: 0.748 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.39 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.169 
(3.244) - AE Loss: 1565212.250 (566742.312) - AE Rec Loss: 10.615 (3.843) - Disc
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.563 
(2.861) - AE Loss: 269782.250 (567767.875) - AE Rec Loss: 1.830 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.567 
(2.861) - AE Loss: 188543.906 (567767.875) - AE Rec Loss: 1.279 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.565 
(2.861) - AE Loss: 67705.484 (567767.875) - AE Rec Loss: 0.459 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.563 
(2.861) - AE Loss: 1516630.250 (567767.875) - AE Rec Loss: 10.285 (3.850) - Disc
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.563 
(2.861) - AE Loss: 117717.000 (567767.875) - AE Rec Loss: 0.798 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.566 
(2.861) - AE Loss: 2808393.500 (567767.875) - AE Rec Loss: 19.046 (3.850) - Disc
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.564 
(2.574) - AE Loss: 88375.508 (584279.062) - AE Rec Loss: 0.599 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.567 
(2.574) - AE Loss: 258227.078 (584279.062) - AE Rec Loss: 1.751 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.565 
(2.574) - AE Loss: 215720.828 (584279.062) - AE Rec Loss: 1.463 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.563 
(2.574) - AE Loss: 705930.188 (584279.062) - AE Rec Loss: 4.787 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.567 
(2.574) - AE Loss: 67744.305 (584279.062) - AE Rec Loss: 0.459 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.566 
(2.574) - AE Loss: 1663405.250 (584279.062) - AE Rec Loss: 11.281 (3.962) - Disc
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.869 
(2.496) - AE Loss: 147510.625 (613009.875) - AE Rec Loss: 1.000 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.870 
(2.496) - AE Loss: 63690.199 (613009.875) - AE Rec Loss: 0.432 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 1.141 (0.759) - Batch(s): 1.869 
(2.496) - AE Loss: 1620314.000 (613009.875) - AE Rec Loss: 10.988 (4.157) - Disc
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.870 
(2.496) - AE Loss: 870742.000 (613009.875) - AE Rec Loss: 5.905 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.759) - Batch(s): 1.871 
(2.496) - AE Loss: 267431.000 (613009.875) - AE Rec Loss: 1.814 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.871 
(2.496) - AE Loss: 1502559.750 (613009.875) - AE Rec Loss: 10.190 (4.157) - Disc
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.811 
(2.345) - AE Loss: 51255.168 (608342.438) - AE Rec Loss: 0.348 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.811 
(2.345) - AE Loss: 445905.812 (608342.438) - AE Rec Loss: 3.024 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.812 
(2.345) - AE Loss: 215427.516 (608342.438) - AE Rec Loss: 1.461 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.812 
(2.345) - AE Loss: 412864.688 (608342.438) - AE Rec Loss: 2.800 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.811 
(2.345) - AE Loss: 107389.727 (608342.438) - AE Rec Loss: 0.728 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 0.812 
(2.345) - AE Loss: 1627125.500 (608342.438) - AE Rec Loss: 11.035 (4.126) - Disc
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.201 
(2.236) - AE Loss: 307342.875 (584593.500) - AE Rec Loss: 2.084 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.199 
(2.236) - AE Loss: 243630.594 (584593.500) - AE Rec Loss: 1.652 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.200 
(2.236) - AE Loss: 214843.391 (584593.500) - AE Rec Loss: 1.457 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.001 (0.626) - Batch(s): 0.566 
(2.236) - AE Loss: 175313.797 (584593.500) - AE Rec Loss: 1.189 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.197 
(2.236) - AE Loss: 229322.375 (584593.500) - AE Rec Loss: 1.555 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.201 
(2.236) - AE Loss: 138799.781 (584593.500) - AE Rec Loss: 0.941 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.576) - Batch(s): 1.078 
(2.140) - AE Loss: 100218.227 (578744.312) - AE Rec Loss: 0.680 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.079 
(2.140) - AE Loss: 1340064.000 (578744.312) - AE Rec Loss: 9.088 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 227941.047 (578744.312) - AE Rec Loss: 1.546 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.576) - Batch(s): 1.079 
(2.140) - AE Loss: 95876.367 (578744.312) - AE Rec Loss: 0.650 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.001 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 266466.562 (578744.312) - AE Rec Loss: 1.807 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.371 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 153296.656 (578744.312) - AE Rec Loss: 1.040 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.556 
(2.570) - AE Loss: 127008.977 (572109.875) - AE Rec Loss: 0.861 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.558 
(2.570) - AE Loss: 201595.500 (572109.875) - AE Rec Loss: 1.367 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.579) - Batch(s): 7.558 
(2.570) - AE Loss: 332830.906 (572109.875) - AE Rec Loss: 2.257 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.579) - Batch(s): 7.556 
(2.570) - AE Loss: 223566.078 (572109.875) - AE Rec Loss: 1.516 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.556 
(2.570) - AE Loss: 259715.000 (572109.875) - AE Rec Loss: 1.761 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.558 
(2.570) - AE Loss: 329346.000 (572109.875) - AE Rec Loss: 2.234 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.567 
(2.427) - AE Loss: 119512.773 (572737.625) - AE Rec Loss: 0.810 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.567 
(2.427) - AE Loss: 123342.492 (572737.625) - AE Rec Loss: 0.836 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.562 
(2.427) - AE Loss: 250536.000 (572737.625) - AE Rec Loss: 1.699 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.12 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.564 
(2.427) - AE Loss: 112960.359 (572737.625) - AE Rec Loss: 0.766 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.564 
(2.427) - AE Loss: 461257.594 (572737.625) - AE Rec Loss: 3.128 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.565 
(2.427) - AE Loss: 1945190.875 (572737.625) - AE Rec Loss: 13.192 (3.884) - Disc
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.722 
(2.313) - AE Loss: 59614.559 (594527.625) - AE Rec Loss: 0.404 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.722 
(2.313) - AE Loss: 1455394.000 (594527.625) - AE Rec Loss: 9.870 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.723 
(2.313) - AE Loss: 155875.297 (594527.625) - AE Rec Loss: 1.057 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.723 
(2.313) - AE Loss: 345437.469 (594527.625) - AE Rec Loss: 2.343 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.723 
(2.313) - AE Loss: 3004852.000 (594527.625) - AE Rec Loss: 20.378 (4.032) - Disc
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.724 
(2.313) - AE Loss: 231993.641 (594527.625) - AE Rec Loss: 1.573 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 303864.625 (594817.562) - AE Rec Loss: 2.061 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 199359.453 (594817.562) - AE Rec Loss: 1.352 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.001 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 345610.938 (594817.562) - AE Rec Loss: 2.344 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 188743.984 (594817.562) - AE Rec Loss: 1.280 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 1367906.875 (594817.562) - AE Rec Loss: 9.277 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 2.776 
(2.353) - AE Loss: 229773.734 (594817.562) - AE Rec Loss: 1.558 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.566 
(2.248) - AE Loss: 83930.320 (581634.250) - AE Rec Loss: 0.569 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.567 
(2.248) - AE Loss: 138544.469 (581634.250) - AE Rec Loss: 0.940 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.63 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.564 
(2.248) - AE Loss: 70184.883 (581634.250) - AE Rec Loss: 0.476 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.564 
(2.248) - AE Loss: 145634.578 (581634.250) - AE Rec Loss: 0.988 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.568 
(2.248) - AE Loss: 166573.859 (581634.250) - AE Rec Loss: 1.130 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.567 
(2.248) - AE Loss: 70710.516 (581634.250) - AE Rec Loss: 0.480 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.688 
(2.161) - AE Loss: 257248.328 (590970.312) - AE Rec Loss: 1.745 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.686 
(2.161) - AE Loss: 214959.031 (590970.312) - AE Rec Loss: 1.458 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 88428.297 (590970.312) - AE Rec Loss: 0.600 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 2827719.000 (590970.312) - AE Rec Loss: 19.177 (4.008) - Disc
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.686 
(2.161) - AE Loss: 158061.109 (590970.312) - AE Rec Loss: 1.072 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.71 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 173187.547 (590970.312) - AE Rec Loss: 1.175 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 469361.406 (578554.625) - AE Rec Loss: 3.183 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 597198.188 (578554.625) - AE Rec Loss: 4.050 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 178965.328 (578554.625) - AE Rec Loss: 1.214 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 97436.883 (578554.625) - AE Rec Loss: 0.661 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.001 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 246648.766 (578554.625) - AE Rec Loss: 1.673 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.769 
(2.097) - AE Loss: 244748.859 (578554.625) - AE Rec Loss: 1.660 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.565 
(2.023) - AE Loss: 112737.367 (589031.125) - AE Rec Loss: 0.765 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.613 
(2.023) - AE Loss: 332878.438 (589031.125) - AE Rec Loss: 2.257 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.051 (0.390) - Batch(s): 0.618 
(2.023) - AE Loss: 1431414.500 (589031.125) - AE Rec Loss: 9.707 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.615 
(2.023) - AE Loss: 262902.156 (589031.125) - AE Rec Loss: 1.783 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.90 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.565 
(2.023) - AE Loss: 100383.117 (589031.125) - AE Rec Loss: 0.681 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.570 
(2.023) - AE Loss: 97133.172 (589031.125) - AE Rec Loss: 0.659 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

attempting to save
[[36m2023-11-29 05:05:31,748[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 05:05:33,271[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:05:33,491[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:05:33,514[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:05:33,521[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:05:33,529[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:05:33,537[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:05:33,545[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:05:33,553[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:05:33,564[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:05:35,847[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:05:36,701[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:05:43,327[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:05:43,332[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 05:05:47,978[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:05:47,978[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 05:05:47,982[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 05:05:48,011[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.948 
(2.713) - AE Loss: 1669470.500 (590586.562) - AE Rec Loss: 11.322 (4.005) - Disc
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.676 
(2.713) - AE Loss: 51496.352 (590586.562) - AE Rec Loss: 0.349 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.87 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 163749.531 (590586.562) - AE Rec Loss: 1.110 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.85 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.948 
(2.713) - AE Loss: 257828.609 (590586.562) - AE Rec Loss: 1.749 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.86 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.948 
(2.713) - AE Loss: 211296.719 (590586.562) - AE Rec Loss: 1.433 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 1655724.750 (590586.562) - AE Rec Loss: 11.229 (4.005) - Disc
Loss: 0.000 (0.000) - 6.87 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.566 
(2.615) - AE Loss: 189681.984 (583897.688) - AE Rec Loss: 1.286 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.566 
(2.615) - AE Loss: 149513.094 (583897.688) - AE Rec Loss: 1.014 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.567 
(2.615) - AE Loss: 186110.594 (583897.688) - AE Rec Loss: 1.262 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.91 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.569 
(2.615) - AE Loss: 183576.031 (583897.688) - AE Rec Loss: 1.245 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.567 
(2.615) - AE Loss: 378782.062 (583897.688) - AE Rec Loss: 2.569 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.564 
(2.615) - AE Loss: 53541.176 (583897.688) - AE Rec Loss: 0.363 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.567 
(2.526) - AE Loss: 241638.984 (577881.188) - AE Rec Loss: 1.639 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.570 
(2.526) - AE Loss: 345808.062 (577881.188) - AE Rec Loss: 2.345 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.564 
(2.526) - AE Loss: 275728.000 (577881.188) - AE Rec Loss: 1.870 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.567 
(2.526) - AE Loss: 64646.148 (577881.188) - AE Rec Loss: 0.438 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.566 
(2.526) - AE Loss: 171138.203 (577881.188) - AE Rec Loss: 1.161 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.565 
(2.526) - AE Loss: 1542764.875 (577881.188) - AE Rec Loss: 10.463 (3.919) - Disc
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.691 
(2.449) - AE Loss: 1519841.125 (591933.875) - AE Rec Loss: 10.307 (4.014) - Disc
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.691 
(2.449) - AE Loss: 1382022.000 (591933.875) - AE Rec Loss: 9.372 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.692 
(2.449) - AE Loss: 98320.898 (591933.875) - AE Rec Loss: 0.667 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.03 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.692 
(2.449) - AE Loss: 243414.219 (591933.875) - AE Rec Loss: 1.651 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.692 
(2.449) - AE Loss: 2053407.375 (591933.875) - AE Rec Loss: 13.926 (4.014) - Disc
Loss: 0.000 (0.000) - 7.02 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.692 
(2.449) - AE Loss: 1807225.875 (591933.875) - AE Rec Loss: 12.256 (4.014) - Disc
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.568 
(2.374) - AE Loss: 616433.875 (593328.312) - AE Rec Loss: 4.180 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.08 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.567 
(2.374) - AE Loss: 1448854.750 (593328.312) - AE Rec Loss: 9.826 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.570 
(2.374) - AE Loss: 93873.727 (593328.312) - AE Rec Loss: 0.637 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.567 
(2.374) - AE Loss: 51557.895 (593328.312) - AE Rec Loss: 0.350 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.565 
(2.374) - AE Loss: 1432696.000 (593328.312) - AE Rec Loss: 9.716 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.565 
(2.374) - AE Loss: 96974.617 (593328.312) - AE Rec Loss: 0.658 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.305) - AE Loss: 1390352.750 (603193.000) - AE Rec Loss: 9.429 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.305) - AE Loss: 207569.000 (603193.000) - AE Rec Loss: 1.408 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.305) - AE Loss: 300010.500 (603193.000) - AE Rec Loss: 2.035 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.565 
(2.305) - AE Loss: 3664166.750 (603193.000) - AE Rec Loss: 24.849 (4.091) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.570 
(2.305) - AE Loss: 130578.383 (603193.000) - AE Rec Loss: 0.886 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.567 
(2.305) - AE Loss: 1639193.625 (603193.000) - AE Rec Loss: 11.116 (4.091) - Disc
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.781 
(2.359) - AE Loss: 91609.180 (600451.562) - AE Rec Loss: 0.621 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 153008.047 (600451.562) - AE Rec Loss: 1.038 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.783 
(2.359) - AE Loss: 167086.656 (600451.562) - AE Rec Loss: 1.133 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 1460410.500 (600451.562) - AE Rec Loss: 9.904 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 56857.707 (600451.562) - AE Rec Loss: 0.386 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 3.061 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 270698.625 (600451.562) - AE Rec Loss: 1.836 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:07:42,590[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:42,640[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:42,869[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:42,899[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:42,945[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,016[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:07:44,753[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:44,767[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:45,048[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:45,052[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:45,064[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:45,165[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,410[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,424[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,659[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,672[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,732[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:45,794[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 05:07:46,858[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:07:46,858[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:07:46,858[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 05:07:46,860[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:07:46,860[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataloader) = 1
[[36m2023-11-29 05:07:46,863[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
=> Instantiating valid dataloader 
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:09:15,113[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,133[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,461[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,463[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,469[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,475[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:09:17,259[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,269[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,611[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,628[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,647[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:17,740[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:17,838[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
[[36m2023-11-29 05:09:18,025[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,185[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,239[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,241[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,468[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 05:09:18,655[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:09:18,656[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 05:09:18,660[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 05:09:18,660[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:09:18,660[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:09:18,660[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3=> Preparing model 

Reached end on node 3
Reached 3 on node 4
Reached 3 on node 1Reached 5 on node 4

Reached 5 on node 1
Reached end on node 4
Reached end on node 1
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:16:51,733[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:51,735[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:51,863[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:51,954[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:51,989[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,114[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:16:53,870[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:53,871[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:53,987[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,100[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,147[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,267[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,534[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,558[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,594[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,751[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,758[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:54,850[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 05:16:55,517[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:16:55,518[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:16:55,518[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 05:16:55,519[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 05:16:55,520[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
[[36m2023-11-29 05:16:55,521[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
Reached 3 on node 3
=> Preparing opt_ae 
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 0
Reached 1.4 on node 0
=> Preparing criterion 
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing criterion 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 4
Reached 2 on node 1
Reached 3 on node 4
Reached 5 on node 4
Reached 3 on node 1
Reached 5 on node 1Reached end on node 4

Reached 1.3 on node 3
Reached 1.4 on node 3Reached end on node 1

Reached 2 on node 3
Reached 1.3 on node 2Reached 3 on node 3

Reached 1.3 on node 5
Reached 1.4 on node 2
Reached 1.4 on node 5Reached 1.3 on node 0
Reached 5 on node 3

Reached 1.4 on node 0
Reached 2 on node 2
Reached 2 on node 5
Reached end on node 3Reached 2 on node 0

Reached 3 on node 2Reached 3 on node 5

Reached 3 on node 0
Reached 5 on node 2Reached 5 on node 5

Reached 5 on node 0
Reached end on node 2Reached end on node 5

Reached end on node 0
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3
Reached 1.4 on node 2Reached 2 on node 3

Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2Reached 1.4 on node 4

Reached 2 on node 2
Reached 1.4 on node 3Reached 2 on node 4

Reached 2 on node 3
Reached 1 on node 2Reached end on node 1

Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3Reached 1.4 on node 4

Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 3
Reached 1 on node 4Reached 1.4 on node 2

Reached 2 on node 2
Reached 1.4 on node 3
Reached 3 on node 2
Reached 2 on node 3
Reached 1.4 on node 4Reached 3 on node 2

Reached 2 on node 4Reached 3 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 4
Reached 2 on node 4Reached 3 on node 3

Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 1
Reached 1 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 5
Reached end on node 0
[[36m2023-11-29 05:16:57,237[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 4
Reached 1 on node 1
Reached 1.4 on node 4
Reached 2 on node 4Reached 1.4 on node 1

Reached 2 on node 1
Reached 3 on node 4
Reached 3 on node 1
Reached 3 on node 4
Reached 3 on node 1
Reached 3 on node 4Reached 3 on node 1

Reached 3 on node 1Reached 3 on node 4

Reached 3 on node 1
Reached 3 on node 4
Reached 5 on node 1
Reached 5 on node 4
Reached end on node 1
Reached end on node 4
[[36m2023-11-29 05:16:59,754[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:17:00,891[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:17:00,891[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:17:00,891[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
[[36m2023-11-29 05:17:00,893[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:17:00,895[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <301/2280>] - Data(s): 5.754 (5.479) - Batch(s): 10.998 
(10.907) - AE Loss: 211175.344 (621691.438) - AE Rec Loss: 1.432 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.245 (5.479) - Batch(s): 11.000 
(10.907) - AE Loss: 257801.688 (621691.438) - AE Rec Loss: 1.748 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 6.529 (5.479) - Batch(s): 11.005 
(10.907) - AE Loss: 1656042.250 (621691.438) - AE Rec Loss: 11.231 (4.216) - 
Disc Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 4.024 (5.479) - Batch(s): 10.994 
(10.907) - AE Loss: 164412.047 (621691.438) - AE Rec Loss: 1.115 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.067 (5.479) - Batch(s): 11.009 
(10.907) - AE Loss: 51367.477 (621691.438) - AE Rec Loss: 0.348 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.961 (5.479) - Batch(s): 11.007 
(10.907) - AE Loss: 1669437.250 (621691.438) - AE Rec Loss: 11.322 (4.216) - 
Disc Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.562 
(5.735) - AE Loss: 196568.188 (535277.562) - AE Rec Loss: 1.333 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.567 
(5.735) - AE Loss: 393162.125 (535277.562) - AE Rec Loss: 2.666 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.567 
(5.735) - AE Loss: 184710.844 (535277.562) - AE Rec Loss: 1.253 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.563 
(5.735) - AE Loss: 56132.070 (535277.562) - AE Rec Loss: 0.381 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.564 
(5.735) - AE Loss: 156921.031 (535277.562) - AE Rec Loss: 1.064 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.568 
(5.735) - AE Loss: 189310.781 (535277.562) - AE Rec Loss: 1.284 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.30 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.437 
(4.636) - AE Loss: 1547697.250 (507055.000) - AE Rec Loss: 10.496 (3.439) - Disc
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 63665.086 (507055.000) - AE Rec Loss: 0.432 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 241865.062 (507055.000) - AE Rec Loss: 1.640 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 284464.688 (507055.000) - AE Rec Loss: 1.929 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.435 
(4.636) - AE Loss: 357358.375 (507055.000) - AE Rec Loss: 2.423 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 1.753 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 176299.094 (507055.000) - AE Rec Loss: 1.196 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.566 
(3.618) - AE Loss: 99905.227 (609140.188) - AE Rec Loss: 0.678 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.001 (1.429) - Batch(s): 0.567 
(3.618) - AE Loss: 242883.953 (609140.188) - AE Rec Loss: 1.647 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.563 
(3.618) - AE Loss: 1521108.000 (609140.188) - AE Rec Loss: 10.316 (4.131) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.001 (1.429) - Batch(s): 0.564 
(3.618) - AE Loss: 2053307.250 (609140.188) - AE Rec Loss: 13.925 (4.131) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.565 
(3.618) - AE Loss: 1382847.500 (609140.188) - AE Rec Loss: 9.378 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.568 
(3.618) - AE Loss: 1804548.000 (609140.188) - AE Rec Loss: 12.238 (4.131) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.170 
(3.193) - AE Loss: 1450080.625 (612980.938) - AE Rec Loss: 9.834 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.527 
(3.193) - AE Loss: 51125.359 (612980.938) - AE Rec Loss: 0.347 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.530 
(3.193) - AE Loss: 93559.742 (612980.938) - AE Rec Loss: 0.634 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.525 
(3.193) - AE Loss: 623094.625 (612980.938) - AE Rec Loss: 4.226 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.524 
(3.193) - AE Loss: 1436989.500 (612980.938) - AE Rec Loss: 9.745 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.964 (1.159) - Batch(s): 1.524 
(3.193) - AE Loss: 97606.297 (612980.938) - AE Rec Loss: 0.662 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.940 (0.993) - Batch(s): 1.661 
(2.938) - AE Loss: 207181.312 (652413.250) - AE Rec Loss: 1.405 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.661 
(2.938) - AE Loss: 298069.281 (652413.250) - AE Rec Loss: 2.021 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.661 
(2.938) - AE Loss: 3668985.000 (652413.250) - AE Rec Loss: 24.882 (4.424) - Disc
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.663 
(2.938) - AE Loss: 126220.344 (652413.250) - AE Rec Loss: 0.856 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.663 
(2.938) - AE Loss: 1391924.500 (652413.250) - AE Rec Loss: 9.440 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.001 (0.993) - Batch(s): 1.663 
(2.938) - AE Loss: 1638858.250 (652413.250) - AE Rec Loss: 11.114 (4.424) - Disc
Loss: 0.000 (0.000) - 2.02 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.001 (0.851) - Batch(s): 0.569 
(2.599) - AE Loss: 1460763.500 (635113.250) - AE Rec Loss: 9.906 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.562 
(2.599) - AE Loss: 171647.844 (635113.250) - AE Rec Loss: 1.164 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.567 
(2.599) - AE Loss: 152421.828 (635113.250) - AE Rec Loss: 1.034 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.565 
(2.599) - AE Loss: 275076.062 (635113.250) - AE Rec Loss: 1.865 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.568 
(2.599) - AE Loss: 94563.539 (635113.250) - AE Rec Loss: 0.641 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.564 
(2.599) - AE Loss: 66107.891 (635113.250) - AE Rec Loss: 0.448 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.09 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.566 
(2.345) - AE Loss: 1483679.750 (605287.188) - AE Rec Loss: 10.062 (4.105) - Disc
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.563 
(2.345) - AE Loss: 383040.438 (605287.188) - AE Rec Loss: 2.598 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.566 
(2.345) - AE Loss: 215117.000 (605287.188) - AE Rec Loss: 1.459 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.564 
(2.345) - AE Loss: 146807.234 (605287.188) - AE Rec Loss: 0.996 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.567 
(2.345) - AE Loss: 249045.297 (605287.188) - AE Rec Loss: 1.689 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.567 
(2.345) - AE Loss: 120681.906 (605287.188) - AE Rec Loss: 0.818 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 1.721 (0.752) - Batch(s): 5.212 
(2.664) - AE Loss: 184748.312 (555707.750) - AE Rec Loss: 1.253 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.001 (0.752) - Batch(s): 5.212 
(2.664) - AE Loss: 120584.727 (555707.750) - AE Rec Loss: 0.818 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 1.390 (0.752) - Batch(s): 5.214 
(2.664) - AE Loss: 124814.508 (555707.750) - AE Rec Loss: 0.846 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.000 (0.752) - Batch(s): 5.214 
(2.664) - AE Loss: 196375.859 (555707.750) - AE Rec Loss: 1.332 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 4.558 (0.752) - Batch(s): 5.214 
(2.664) - AE Loss: 92687.516 (555707.750) - AE Rec Loss: 0.629 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.000 (0.752) - Batch(s): 5.214 
(2.664) - AE Loss: 74450.938 (555707.750) - AE Rec Loss: 0.505 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.564 
(2.454) - AE Loss: 182467.859 (568244.688) - AE Rec Loss: 1.237 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.563 
(2.454) - AE Loss: 103025.367 (568244.688) - AE Rec Loss: 0.699 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.567 
(2.454) - AE Loss: 1617843.875 (568244.688) - AE Rec Loss: 10.972 (3.854) - Disc
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.565 
(2.454) - AE Loss: 113640.648 (568244.688) - AE Rec Loss: 0.771 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.001 (0.677) - Batch(s): 0.568 
(2.454) - AE Loss: 350807.156 (568244.688) - AE Rec Loss: 2.379 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.566 
(2.454) - AE Loss: 1582421.250 (568244.688) - AE Rec Loss: 10.731 (3.854) - Disc
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.326 
(2.345) - AE Loss: 405513.531 (561874.312) - AE Rec Loss: 2.750 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.328 
(2.345) - AE Loss: 62883.715 (561874.312) - AE Rec Loss: 0.426 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.329 
(2.345) - AE Loss: 415812.438 (561874.312) - AE Rec Loss: 2.820 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.001 (0.615) - Batch(s): 0.566 
(2.345) - AE Loss: 286229.938 (561874.312) - AE Rec Loss: 1.941 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.325 
(2.345) - AE Loss: 1540729.500 (561874.312) - AE Rec Loss: 10.449 (3.810) - Disc
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.325 
(2.345) - AE Loss: 247105.578 (561874.312) - AE Rec Loss: 1.676 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.001 (0.586) - Batch(s): 3.161 
(2.413) - AE Loss: 95920.992 (578382.688) - AE Rec Loss: 0.651 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.710 (0.586) - Batch(s): 3.161 
(2.413) - AE Loss: 1538655.750 (578382.688) - AE Rec Loss: 10.435 (3.922) - Disc
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.161 
(2.413) - AE Loss: 79824.133 (578382.688) - AE Rec Loss: 0.541 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.161 
(2.413) - AE Loss: 314757.594 (578382.688) - AE Rec Loss: 2.135 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.162 
(2.413) - AE Loss: 1970254.125 (578382.688) - AE Rec Loss: 13.362 (3.922) - Disc
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 2.480 (0.586) - Batch(s): 3.163 
(2.413) - AE Loss: 1439001.500 (578382.688) - AE Rec Loss: 9.759 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.563 
(2.271) - AE Loss: 1443856.500 (583027.375) - AE Rec Loss: 9.792 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.568 
(2.271) - AE Loss: 75919.938 (583027.375) - AE Rec Loss: 0.515 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.001 (0.541) - Batch(s): 0.567 
(2.271) - AE Loss: 274119.688 (583027.375) - AE Rec Loss: 1.859 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.566 
(2.271) - AE Loss: 856001.375 (583027.375) - AE Rec Loss: 5.805 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.563 
(2.271) - AE Loss: 1514840.375 (583027.375) - AE Rec Loss: 10.273 (3.954) - Disc
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.567 
(2.271) - AE Loss: 62124.609 (583027.375) - AE Rec Loss: 0.421 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.567 
(2.149) - AE Loss: 231741.594 (576240.125) - AE Rec Loss: 1.572 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.001 (0.502) - Batch(s): 0.567 
(2.149) - AE Loss: 399311.906 (576240.125) - AE Rec Loss: 2.708 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.567 
(2.149) - AE Loss: 1737359.750 (576240.125) - AE Rec Loss: 11.782 (3.908) - Disc
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.565 
(2.149) - AE Loss: 360927.750 (576240.125) - AE Rec Loss: 2.448 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.565 
(2.149) - AE Loss: 331175.406 (576240.125) - AE Rec Loss: 2.246 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.567 
(2.149) - AE Loss: 1622916.000 (576240.125) - AE Rec Loss: 11.006 (3.908) - Disc
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.862 
(2.130) - AE Loss: 2942845.750 (586880.938) - AE Rec Loss: 19.957 (3.980) - Disc
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.863 
(2.130) - AE Loss: 1891094.625 (586880.938) - AE Rec Loss: 12.825 (3.980) - Disc
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.864 
(2.130) - AE Loss: 214315.062 (586880.938) - AE Rec Loss: 1.453 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.864 
(2.130) - AE Loss: 121513.828 (586880.938) - AE Rec Loss: 0.824 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 1.203 (0.480) - Batch(s): 1.864 
(2.130) - AE Loss: 1444787.875 (586880.938) - AE Rec Loss: 9.798 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.726 (0.480) - Batch(s): 1.864 
(2.130) - AE Loss: 116821.398 (586880.938) - AE Rec Loss: 0.792 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.165 
(2.066) - AE Loss: 62887.852 (596921.000) - AE Rec Loss: 0.426 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.812 
(2.066) - AE Loss: 1416274.000 (596921.000) - AE Rec Loss: 9.605 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.286 (0.454) - Batch(s): 1.168 
(2.066) - AE Loss: 281971.625 (596921.000) - AE Rec Loss: 1.912 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.168 
(2.066) - AE Loss: 1467025.250 (596921.000) - AE Rec Loss: 9.949 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.811 
(2.066) - AE Loss: 157188.641 (596921.000) - AE Rec Loss: 1.066 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.602 (0.454) - Batch(s): 1.171 
(2.066) - AE Loss: 1518978.250 (596921.000) - AE Rec Loss: 10.301 (4.048) - Disc
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 239581.500 (594029.625) - AE Rec Loss: 1.625 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 1529787.625 (594029.625) - AE Rec Loss: 10.375 (4.029) - Disc
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 527587.438 (594029.625) - AE Rec Loss: 3.578 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 1354350.250 (594029.625) - AE Rec Loss: 9.185 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.538 (0.442) - Batch(s): 2.636 
(2.105) - AE Loss: 1456719.125 (594029.625) - AE Rec Loss: 9.879 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.001 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 268193.438 (594029.625) - AE Rec Loss: 1.819 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.676 
(2.026) - AE Loss: 1514100.000 (594256.688) - AE Rec Loss: 10.268 (4.030) - Disc
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.678 
(2.026) - AE Loss: 101069.172 (594256.688) - AE Rec Loss: 0.685 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.678 
(2.026) - AE Loss: 273634.625 (594256.688) - AE Rec Loss: 1.856 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.677 
(2.026) - AE Loss: 171407.438 (594256.688) - AE Rec Loss: 1.162 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.677 
(2.026) - AE Loss: 1373892.000 (594256.688) - AE Rec Loss: 9.317 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.678 
(2.026) - AE Loss: 135974.016 (594256.688) - AE Rec Loss: 0.922 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.001 (0.411) - Batch(s): 2.289 
(2.040) - AE Loss: 91260.648 (600663.875) - AE Rec Loss: 0.619 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 1.720 (0.411) - Batch(s): 2.295 
(2.040) - AE Loss: 109440.711 (600663.875) - AE Rec Loss: 0.742 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.291 
(2.040) - AE Loss: 2919562.750 (600663.875) - AE Rec Loss: 19.800 (4.074) - Disc
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.554 (0.411) - Batch(s): 2.292 
(2.040) - AE Loss: 2959716.000 (600663.875) - AE Rec Loss: 20.072 (4.074) - Disc
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 1.172 (0.411) - Batch(s): 2.294 
(2.040) - AE Loss: 66447.914 (600663.875) - AE Rec Loss: 0.451 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.291 
(2.040) - AE Loss: 204490.391 (600663.875) - AE Rec Loss: 1.387 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.569 
(1.966) - AE Loss: 143742.141 (600587.062) - AE Rec Loss: 0.975 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.563 
(1.966) - AE Loss: 207106.891 (600587.062) - AE Rec Loss: 1.405 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.568 
(1.966) - AE Loss: 2770449.000 (600587.062) - AE Rec Loss: 18.788 (4.073) - Disc
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.567 
(1.966) - AE Loss: 1546933.500 (600587.062) - AE Rec Loss: 10.491 (4.073) - Disc
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.566 
(1.966) - AE Loss: 70452.672 (600587.062) - AE Rec Loss: 0.478 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.570 
(1.966) - AE Loss: 131353.938 (600587.062) - AE Rec Loss: 0.891 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.39 m remaining

attempting to save
[[36m2023-11-29 05:17:44,968[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 05:17:45,526[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:17:45,669[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:17:45,671[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:17:45,673[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:17:45,674[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:17:45,676[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:17:45,677[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:17:45,679[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:17:45,680[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:17:45,921[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:17:46,397[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:17:49,833[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:17:49,862[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 05:17:55,399[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:17:55,399[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 05:17:55,400[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 05:17:55,430[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 337096.938 (614298.062) - AE Rec Loss: 2.286 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 96678.523 (614298.062) - AE Rec Loss: 0.656 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 105774.164 (614298.062) - AE Rec Loss: 0.717 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.060 
(2.401) - AE Loss: 853483.125 (614298.062) - AE Rec Loss: 5.788 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.001 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 1538011.250 (614298.062) - AE Rec Loss: 10.430 (4.166) - Disc
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.648 
(2.401) - AE Loss: 1553735.750 (614298.062) - AE Rec Loss: 10.537 (4.166) - Disc
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.567 
(2.318) - AE Loss: 200872.141 (602571.188) - AE Rec Loss: 1.362 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.568 
(2.318) - AE Loss: 134657.562 (602571.188) - AE Rec Loss: 0.913 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.564 
(2.318) - AE Loss: 73361.047 (602571.188) - AE Rec Loss: 0.498 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.565 
(2.318) - AE Loss: 319202.594 (602571.188) - AE Rec Loss: 2.165 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.568 
(2.318) - AE Loss: 238250.281 (602571.188) - AE Rec Loss: 1.616 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.568 
(2.318) - AE Loss: 170853.484 (602571.188) - AE Rec Loss: 1.159 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.570 
(2.242) - AE Loss: 580262.188 (608967.875) - AE Rec Loss: 3.935 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.001 (0.339) - Batch(s): 0.570 
(2.242) - AE Loss: 86819.594 (608967.875) - AE Rec Loss: 0.589 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.566 
(2.242) - AE Loss: 1426949.250 (608967.875) - AE Rec Loss: 9.677 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.570 
(2.242) - AE Loss: 1466970.750 (608967.875) - AE Rec Loss: 9.949 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.567 
(2.242) - AE Loss: 139581.094 (608967.875) - AE Rec Loss: 0.947 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.001 (0.339) - Batch(s): 0.566 
(2.242) - AE Loss: 189631.828 (608967.875) - AE Rec Loss: 1.286 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.672 
(2.177) - AE Loss: 156970.906 (600282.750) - AE Rec Loss: 1.065 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.001 (0.325) - Batch(s): 0.672 
(2.177) - AE Loss: 1476962.500 (600282.750) - AE Rec Loss: 10.016 (4.071) - Disc
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.672 
(2.177) - AE Loss: 150600.703 (600282.750) - AE Rec Loss: 1.021 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.674 
(2.177) - AE Loss: 81841.891 (600282.750) - AE Rec Loss: 0.555 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.674 
(2.177) - AE Loss: 48327.000 (600282.750) - AE Rec Loss: 0.328 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.673 
(2.177) - AE Loss: 203123.531 (600282.750) - AE Rec Loss: 1.378 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.566 
(2.112) - AE Loss: 134128.125 (592112.000) - AE Rec Loss: 0.910 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.569 
(2.112) - AE Loss: 203879.844 (592112.000) - AE Rec Loss: 1.383 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.568 
(2.112) - AE Loss: 60302.500 (592112.000) - AE Rec Loss: 0.409 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.565 
(2.112) - AE Loss: 68859.766 (592112.000) - AE Rec Loss: 0.467 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.568 
(2.112) - AE Loss: 1572910.250 (592112.000) - AE Rec Loss: 10.667 (4.016) - Disc
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.570 
(2.112) - AE Loss: 1611901.750 (592112.000) - AE Rec Loss: 10.931 (4.016) - Disc
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.566 
(2.053) - AE Loss: 184143.172 (610090.688) - AE Rec Loss: 1.249 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.569 
(2.053) - AE Loss: 1713634.000 (610090.688) - AE Rec Loss: 11.621 (4.137) - Disc
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.569 
(2.053) - AE Loss: 73396.406 (610090.688) - AE Rec Loss: 0.498 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.570 
(2.053) - AE Loss: 298518.062 (610090.688) - AE Rec Loss: 2.024 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.570 
(2.053) - AE Loss: 366044.062 (610090.688) - AE Rec Loss: 2.482 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.566 
(2.053) - AE Loss: 1837105.375 (610090.688) - AE Rec Loss: 12.459 (4.137) - Disc
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 1913690.625 (602579.438) - AE Rec Loss: 12.978 (4.087) - Disc
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.704 
(2.003) - AE Loss: 148634.000 (602579.438) - AE Rec Loss: 1.008 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 1314461.750 (602579.438) - AE Rec Loss: 8.914 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(2.003) - AE Loss: 331992.531 (602579.438) - AE Rec Loss: 2.251 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 120670.211 (602579.438) - AE Rec Loss: 0.818 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.704 
(2.003) - AE Loss: 229440.625 (602579.438) - AE Rec Loss: 1.556 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.96 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.578 
(2.021) - AE Loss: 227372.203 (597892.188) - AE Rec Loss: 1.542 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.846 (0.295) - Batch(s): 2.575 
(2.021) - AE Loss: 91789.977 (597892.188) - AE Rec Loss: 0.622 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.971 (0.295) - Batch(s): 2.578 
(2.021) - AE Loss: 122895.820 (597892.188) - AE Rec Loss: 0.833 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.222 
(2.021) - AE Loss: 204968.328 (597892.188) - AE Rec Loss: 1.390 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.223 
(2.021) - AE Loss: 1702381.250 (597892.188) - AE Rec Loss: 11.545 (4.055) - Disc
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 2.006 (0.295) - Batch(s): 2.584 
(2.021) - AE Loss: 1864715.250 (597892.188) - AE Rec Loss: 12.646 (4.055) - Disc
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 1.803 (0.299) - Batch(s): 2.376 
(2.034) - AE Loss: 91211.133 (593295.500) - AE Rec Loss: 0.619 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.372 
(2.034) - AE Loss: 96462.766 (593295.500) - AE Rec Loss: 0.654 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.493 (0.299) - Batch(s): 2.371 
(2.034) - AE Loss: 232454.797 (593295.500) - AE Rec Loss: 1.576 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.374 
(2.034) - AE Loss: 1809852.500 (593295.500) - AE Rec Loss: 12.274 (4.024) - Disc
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.374 
(2.034) - AE Loss: 329486.625 (593295.500) - AE Rec Loss: 2.234 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.374 
(2.034) - AE Loss: 58106.379 (593295.500) - AE Rec Loss: 0.394 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.44 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 241793.266 (600443.438) - AE Rec Loss: 1.640 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 301930.688 (600443.438) - AE Rec Loss: 2.048 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 1377525.750 (600443.438) - AE Rec Loss: 9.342 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.704 
(1.990) - AE Loss: 175497.516 (600443.438) - AE Rec Loss: 1.190 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(1.990) - AE Loss: 211686.562 (600443.438) - AE Rec Loss: 1.436 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(1.990) - AE Loss: 1445423.250 (600443.438) - AE Rec Loss: 9.802 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:18:25,811[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:25,952[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:25,973[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,044[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,098[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,112[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:18:28,108[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,118[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,177[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,199[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,237[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,268[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,691[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,840[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,892[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,969[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,982[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:28,989[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 05:18:29,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:18:29,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:18:29,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 05:18:29,580[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:18:29,581[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
[[36m2023-11-29 05:18:29,587[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing model 
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 3 on node 1Reached 2 on node 4

Reached 1.3 on node 5
Reached 5 on node 1Reached 1.4 on node 5

Reached 3 on node 4
Reached end on node 1
Reached 2 on node 5
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 2
=> Preparing opt_ae 
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 0=> Preparing criterion 

=> Preparing opt_ae 
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 4
Reached 1 on node 5
Reached 1.2 on node 4
Reached 1.2 on node 5
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 1.3 on node 5Reached 1.3 on node 0Reached 1.3 on node 3Reached 1.3 on node 2



Reached 2 on node 1
Reached 1.4 on node 5Reached 1.4 on node 3
Reached 1.4 on node 2Reached 1.4 on node 0


Reached 2 on node 5
Reached 2 on node 3Reached 2 on node 2

Reached 3 on node 1Reached 2 on node 0

Reached 1.3 on node 4
Reached 3 on node 5Reached 5 on node 1Reached 1.4 on node 4
Reached 3 on node 2Reached 3 on node 3


Reached 3 on node 0

Reached 5 on node 5Reached end on node 1

Reached 5 on node 2
Reached 5 on node 3Reached 2 on node 4

Reached end on node 5Reached 5 on node 0

Reached end on node 2
Reached end on node 3
Reached end on node 0
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached end on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1 on node 1
Reached 1.4 on node 2
Reached 1.4 on node 1Reached 2 on node 2

Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 3
Reached 1 on node 2
Reached 1.4 on node 3Reached 1.4 on node 2

Reached 2 on node 2Reached 2 on node 3

Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 1 on node 2Reached 2 on node 4

Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2Reached 1.4 on node 3

Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4Reached end on node 1

Reached 1.4 on node 4
Reached 1 on node 3Reached 1 on node 2Reached 2 on node 4


Reached 1.4 on node 3
Reached 1.4 on node 2
Reached 2 on node 3Reached 2 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4Reached 1 on node 3

Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 3
Reached 1 on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 3
Reached end on node 0
[[36m2023-11-29 05:18:31,323[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 05:18:33,810[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:18:34,900[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:18:34,901[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:18:34,901[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:18:34,903[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:18:34,904[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <321/2280>] - Data(s): 6.371 (5.836) - Batch(s): 10.500 
(10.296) - AE Loss: 105653.211 (888465.250) - AE Rec Loss: 0.717 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 4.592 (5.836) - Batch(s): 10.500 
(10.296) - AE Loss: 854336.125 (888465.250) - AE Rec Loss: 5.794 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 5.986 (5.836) - Batch(s): 10.505 
(10.296) - AE Loss: 1538171.500 (888465.250) - AE Rec Loss: 10.431 (6.025) - 
Disc Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 8.802 (5.836) - Batch(s): 10.499 
(10.296) - AE Loss: 1553285.750 (888465.250) - AE Rec Loss: 10.534 (6.025) - 
Disc Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 5.753 (5.836) - Batch(s): 10.497 
(10.296) - AE Loss: 336988.625 (888465.250) - AE Rec Loss: 2.285 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 2.865 (5.836) - Batch(s): 10.514 
(10.296) - AE Loss: 95405.969 (888465.250) - AE Rec Loss: 0.647 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.001 (2.918) - Batch(s): 0.566 
(5.431) - AE Loss: 238924.859 (622701.250) - AE Rec Loss: 1.620 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.564 
(5.431) - AE Loss: 318381.125 (622701.250) - AE Rec Loss: 2.159 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.001 (2.918) - Batch(s): 0.568 
(5.431) - AE Loss: 196209.391 (622701.250) - AE Rec Loss: 1.331 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.001 (2.918) - Batch(s): 0.570 
(5.431) - AE Loss: 137797.172 (622701.250) - AE Rec Loss: 0.934 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.001 (2.918) - Batch(s): 0.563 
(5.431) - AE Loss: 73373.875 (622701.250) - AE Rec Loss: 0.498 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.568 
(5.431) - AE Loss: 168552.234 (622701.250) - AE Rec Loss: 1.143 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.717 
(3.860) - AE Loss: 94761.938 (665745.812) - AE Rec Loss: 0.643 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 584048.000 (665745.812) - AE Rec Loss: 3.961 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.719 
(3.860) - AE Loss: 1428816.125 (665745.812) - AE Rec Loss: 9.690 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.001 (1.948) - Batch(s): 0.720 
(3.860) - AE Loss: 140459.344 (665745.812) - AE Rec Loss: 0.953 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 190049.797 (665745.812) - AE Rec Loss: 1.289 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.070 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 1469344.500 (665745.812) - AE Rec Loss: 9.965 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.571 
(3.037) - AE Loss: 84047.477 (600571.938) - AE Rec Loss: 0.570 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.001 (1.461) - Batch(s): 0.568 
(3.037) - AE Loss: 50183.422 (600571.938) - AE Rec Loss: 0.340 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.564 
(3.037) - AE Loss: 164075.516 (600571.938) - AE Rec Loss: 1.113 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.568 
(3.037) - AE Loss: 1485339.500 (600571.938) - AE Rec Loss: 10.073 (4.073) - Disc
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.001 (1.461) - Batch(s): 0.564 
(3.037) - AE Loss: 204870.500 (600571.938) - AE Rec Loss: 1.389 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.001 (1.461) - Batch(s): 0.568 
(3.037) - AE Loss: 155223.562 (600571.938) - AE Rec Loss: 1.053 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.343 
(2.728) - AE Loss: 59758.242 (559399.125) - AE Rec Loss: 0.405 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.344 
(2.728) - AE Loss: 135651.516 (559399.125) - AE Rec Loss: 0.920 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.343 
(2.728) - AE Loss: 43182.953 (559399.125) - AE Rec Loss: 0.293 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.343 
(2.728) - AE Loss: 213026.391 (559399.125) - AE Rec Loss: 1.445 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.348 
(2.728) - AE Loss: 1619047.500 (559399.125) - AE Rec Loss: 10.980 (3.794) - Disc
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (1.210) - Batch(s): 1.343 
(2.728) - AE Loss: 1574971.000 (559399.125) - AE Rec Loss: 10.681 (3.794) - Disc
Loss: 0.000 (0.000) - 1.50 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.443 
(2.514) - AE Loss: 1844509.000 (643439.750) - AE Rec Loss: 12.509 (4.364) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (1.021) - Batch(s): 1.443 
(2.514) - AE Loss: 367399.438 (643439.750) - AE Rec Loss: 2.492 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.443 
(2.514) - AE Loss: 302617.031 (643439.750) - AE Rec Loss: 2.052 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.087 (1.021) - Batch(s): 1.445 
(2.514) - AE Loss: 69444.312 (643439.750) - AE Rec Loss: 0.471 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.444 
(2.514) - AE Loss: 1715198.750 (643439.750) - AE Rec Loss: 11.632 (4.364) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (1.021) - Batch(s): 1.445 
(2.514) - AE Loss: 197289.766 (643439.750) - AE Rec Loss: 1.338 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.876) - Batch(s): 0.681 
(2.250) - AE Loss: 118632.828 (609344.312) - AE Rec Loss: 0.805 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.115 (0.876) - Batch(s): 0.680 
(2.250) - AE Loss: 350876.875 (609344.312) - AE Rec Loss: 2.380 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.876) - Batch(s): 0.678 
(2.250) - AE Loss: 1310758.750 (609344.312) - AE Rec Loss: 8.889 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.876) - Batch(s): 0.675 
(2.250) - AE Loss: 146607.203 (609344.312) - AE Rec Loss: 0.994 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.876) - Batch(s): 0.568 
(2.250) - AE Loss: 230598.047 (609344.312) - AE Rec Loss: 1.564 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.876) - Batch(s): 0.679 
(2.250) - AE Loss: 1915232.250 (609344.312) - AE Rec Loss: 12.988 (4.132) - Disc
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.569 
(2.058) - AE Loss: 205725.656 (591716.500) - AE Rec Loss: 1.395 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.173 (0.769) - Batch(s): 0.742 
(2.058) - AE Loss: 1863953.500 (591716.500) - AE Rec Loss: 12.641 (4.013) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.734 
(2.058) - AE Loss: 87830.930 (591716.500) - AE Rec Loss: 0.596 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.737 
(2.058) - AE Loss: 224648.766 (591716.500) - AE Rec Loss: 1.523 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.738 
(2.058) - AE Loss: 123526.594 (591716.500) - AE Rec Loss: 0.838 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.566 
(2.058) - AE Loss: 1704755.875 (591716.500) - AE Rec Loss: 11.561 (4.013) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.775) - Batch(s): 5.678 
(2.460) - AE Loss: 331265.500 (577525.812) - AE Rec Loss: 2.247 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.318 (0.775) - Batch(s): 5.680 
(2.460) - AE Loss: 60083.359 (577525.812) - AE Rec Loss: 0.407 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.775) - Batch(s): 5.679 
(2.460) - AE Loss: 1811542.250 (577525.812) - AE Rec Loss: 12.285 (3.917) - Disc
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.726 (0.775) - Batch(s): 5.680 
(2.460) - AE Loss: 223978.906 (577525.812) - AE Rec Loss: 1.519 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.775) - Batch(s): 5.680 
(2.460) - AE Loss: 95797.586 (577525.812) - AE Rec Loss: 0.650 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 5.043 (0.775) - Batch(s): 5.679 
(2.460) - AE Loss: 90397.086 (577525.812) - AE Rec Loss: 0.613 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.38 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.001 (0.698) - Batch(s): 0.570 
(2.271) - AE Loss: 212979.594 (600816.688) - AE Rec Loss: 1.444 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.001 (0.698) - Batch(s): 0.568 
(2.271) - AE Loss: 181064.578 (600816.688) - AE Rec Loss: 1.228 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.001 (0.698) - Batch(s): 0.569 
(2.271) - AE Loss: 241983.844 (600816.688) - AE Rec Loss: 1.641 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.570 
(2.271) - AE Loss: 1444848.500 (600816.688) - AE Rec Loss: 9.799 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.566 
(2.271) - AE Loss: 1379260.500 (600816.688) - AE Rec Loss: 9.354 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.001 (0.698) - Batch(s): 0.564 
(2.271) - AE Loss: 300751.500 (600816.688) - AE Rec Loss: 2.040 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.352 
(2.181) - AE Loss: 281641.000 (598338.188) - AE Rec Loss: 1.910 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.001 (0.634) - Batch(s): 1.350 
(2.181) - AE Loss: 312865.438 (598338.188) - AE Rec Loss: 2.122 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.346 
(2.181) - AE Loss: 329750.531 (598338.188) - AE Rec Loss: 2.236 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.349 
(2.181) - AE Loss: 46834.129 (598338.188) - AE Rec Loss: 0.318 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.350 
(2.181) - AE Loss: 153131.953 (598338.188) - AE Rec Loss: 1.038 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.001 (0.634) - Batch(s): 0.568 
(2.181) - AE Loss: 159868.719 (598338.188) - AE Rec Loss: 1.084 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.044 
(2.087) - AE Loss: 434055.375 (635582.750) - AE Rec Loss: 2.944 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.044 
(2.087) - AE Loss: 1441846.750 (635582.750) - AE Rec Loss: 9.778 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.001 (0.584) - Batch(s): 1.046 
(2.087) - AE Loss: 1881678.375 (635582.750) - AE Rec Loss: 12.761 (4.310) - Disc
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.045 
(2.087) - AE Loss: 326175.938 (635582.750) - AE Rec Loss: 2.212 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.045 
(2.087) - AE Loss: 1563668.875 (635582.750) - AE Rec Loss: 10.604 (4.310) - Disc
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.410 (0.584) - Batch(s): 1.045 
(2.087) - AE Loss: 2871277.500 (635582.750) - AE Rec Loss: 19.472 (4.310) - Disc
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.001 (0.539) - Batch(s): 0.569 
(1.970) - AE Loss: 221224.500 (613824.125) - AE Rec Loss: 1.500 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.567 
(1.970) - AE Loss: 1614871.250 (613824.125) - AE Rec Loss: 10.952 (4.163) - Disc
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.570 
(1.970) - AE Loss: 178181.984 (613824.125) - AE Rec Loss: 1.208 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.001 (0.539) - Batch(s): 0.571 
(1.970) - AE Loss: 195109.875 (613824.125) - AE Rec Loss: 1.323 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.568 
(1.970) - AE Loss: 139663.531 (613824.125) - AE Rec Loss: 0.947 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.565 
(1.970) - AE Loss: 234670.750 (613824.125) - AE Rec Loss: 1.591 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 2.335 (0.523) - Batch(s): 2.911 
(2.037) - AE Loss: 283786.344 (608413.500) - AE Rec Loss: 1.925 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.908 
(2.037) - AE Loss: 1742328.625 (608413.500) - AE Rec Loss: 11.816 (4.126) - Disc
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.906 
(2.037) - AE Loss: 1525252.500 (608413.500) - AE Rec Loss: 10.344 (4.126) - Disc
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.151 (0.523) - Batch(s): 2.903 
(2.037) - AE Loss: 94159.211 (608413.500) - AE Rec Loss: 0.639 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.530 (0.523) - Batch(s): 2.905 
(2.037) - AE Loss: 166553.594 (608413.500) - AE Rec Loss: 1.130 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.906 
(2.037) - AE Loss: 205142.859 (608413.500) - AE Rec Loss: 1.391 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 101947.258 (613318.625) - AE Rec Loss: 0.691 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.769 
(2.152) - AE Loss: 303091.438 (613318.625) - AE Rec Loss: 2.055 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 1523831.000 (613318.625) - AE Rec Loss: 10.334 (4.159) - Disc
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 1785616.000 (613318.625) - AE Rec Loss: 12.109 (4.159) - Disc
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.768 
(2.152) - AE Loss: 1518770.625 (613318.625) - AE Rec Loss: 10.300 (4.159) - Disc
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.771 
(2.152) - AE Loss: 1612786.500 (613318.625) - AE Rec Loss: 10.937 (4.159) - Disc
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.001 (0.474) - Batch(s): 0.569 
(2.053) - AE Loss: 79533.695 (641446.688) - AE Rec Loss: 0.539 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.001 (0.474) - Batch(s): 0.570 
(2.053) - AE Loss: 3023504.250 (641446.688) - AE Rec Loss: 20.504 (4.350) - Disc
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.565 
(2.053) - AE Loss: 53744.836 (641446.688) - AE Rec Loss: 0.364 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.568 
(2.053) - AE Loss: 1801588.000 (641446.688) - AE Rec Loss: 12.218 (4.350) - Disc
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.567 
(2.053) - AE Loss: 248565.266 (641446.688) - AE Rec Loss: 1.686 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.567 
(2.053) - AE Loss: 123261.781 (641446.688) - AE Rec Loss: 0.836 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.47 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.571 
(1.966) - AE Loss: 121984.422 (639905.312) - AE Rec Loss: 0.827 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.569 
(1.966) - AE Loss: 350542.062 (639905.312) - AE Rec Loss: 2.377 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.001 (0.447) - Batch(s): 0.567 
(1.966) - AE Loss: 286387.562 (639905.312) - AE Rec Loss: 1.942 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.570 
(1.966) - AE Loss: 1551606.500 (639905.312) - AE Rec Loss: 10.523 (4.340) - Disc
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.568 
(1.966) - AE Loss: 131008.086 (639905.312) - AE Rec Loss: 0.888 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.565 
(1.966) - AE Loss: 136818.453 (639905.312) - AE Rec Loss: 0.928 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.190 
(2.089) - AE Loss: 238647.422 (633713.938) - AE Rec Loss: 1.618 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.190 
(2.089) - AE Loss: 1413743.000 (633713.938) - AE Rec Loss: 9.588 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 175791.766 (633713.938) - AE Rec Loss: 1.192 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.001 (0.440) - Batch(s): 4.190 
(2.089) - AE Loss: 243014.125 (633713.938) - AE Rec Loss: 1.648 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.190 
(2.089) - AE Loss: 257178.344 (633713.938) - AE Rec Loss: 1.744 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.001 (0.440) - Batch(s): 4.190 
(2.089) - AE Loss: 114713.602 (633713.938) - AE Rec Loss: 0.778 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.568 
(2.009) - AE Loss: 167330.125 (627740.562) - AE Rec Loss: 1.135 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.570 
(2.009) - AE Loss: 1597802.500 (627740.562) - AE Rec Loss: 10.836 (4.257) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.570 
(2.009) - AE Loss: 164038.859 (627740.562) - AE Rec Loss: 1.112 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.566 
(2.009) - AE Loss: 278061.812 (627740.562) - AE Rec Loss: 1.886 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.001 (0.417) - Batch(s): 0.568 
(2.009) - AE Loss: 104256.297 (627740.562) - AE Rec Loss: 0.707 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.565 
(2.009) - AE Loss: 50747.781 (627740.562) - AE Rec Loss: 0.344 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.244 
(2.031) - AE Loss: 161148.312 (630035.438) - AE Rec Loss: 1.093 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.001 (0.404) - Batch(s): 2.244 
(2.031) - AE Loss: 1531361.625 (630035.438) - AE Rec Loss: 10.385 (4.273) - Disc
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.244 
(2.031) - AE Loss: 99068.078 (630035.438) - AE Rec Loss: 0.672 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.001 (0.404) - Batch(s): 2.244 
(2.031) - AE Loss: 1661193.750 (630035.438) - AE Rec Loss: 11.266 (4.273) - Disc
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.244 
(2.031) - AE Loss: 101370.672 (630035.438) - AE Rec Loss: 0.687 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 2.030 (0.404) - Batch(s): 2.599 
(2.031) - AE Loss: 603969.938 (630035.438) - AE Rec Loss: 4.096 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

attempting to save
[[36m2023-11-29 05:19:20,277[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 05:19:21,035[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:19:21,506[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:19:21,514[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:19:21,519[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:19:21,524[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:19:21,529[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:19:21,534[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:19:21,539[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:19:21,543[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:19:21,995[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:19:25,061[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:19:29,550[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:19:29,566[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 05:19:37,752[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:19:37,752[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 05:19:37,752[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 05:19:37,760[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.836 
(2.759) - AE Loss: 1395346.500 (635335.750) - AE Rec Loss: 9.463 (4.309) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.627 
(2.759) - AE Loss: 252626.641 (635335.750) - AE Rec Loss: 1.713 (4.309) - Disc 
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.836 
(2.759) - AE Loss: 102935.805 (635335.750) - AE Rec Loss: 0.698 (4.309) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.836 
(2.759) - AE Loss: 1527503.625 (635335.750) - AE Rec Loss: 10.359 (4.309) - Disc
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.836 
(2.759) - AE Loss: 2865384.000 (635335.750) - AE Rec Loss: 19.432 (4.309) - Disc
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.836 
(2.759) - AE Loss: 119386.273 (635335.750) - AE Rec Loss: 0.810 (4.309) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.567 
(2.660) - AE Loss: 2018151.375 (633998.562) - AE Rec Loss: 13.686 (4.300) - Disc
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.569 
(2.660) - AE Loss: 180660.375 (633998.562) - AE Rec Loss: 1.225 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.571 
(2.660) - AE Loss: 1373974.750 (633998.562) - AE Rec Loss: 9.318 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (0.379) - Batch(s): 0.571 
(2.660) - AE Loss: 182704.891 (633998.562) - AE Rec Loss: 1.239 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.565 
(2.660) - AE Loss: 52939.797 (633998.562) - AE Rec Loss: 0.359 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.568 
(2.660) - AE Loss: 61942.469 (633998.562) - AE Rec Loss: 0.420 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.570 
(2.569) - AE Loss: 177045.406 (629817.812) - AE Rec Loss: 1.201 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.001 (0.362) - Batch(s): 0.569 
(2.569) - AE Loss: 298296.312 (629817.812) - AE Rec Loss: 2.023 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.001 (0.362) - Batch(s): 0.574 
(2.569) - AE Loss: 71137.203 (629817.812) - AE Rec Loss: 0.482 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.566 
(2.569) - AE Loss: 1622251.500 (629817.812) - AE Rec Loss: 11.002 (4.271) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.001 (0.362) - Batch(s): 0.571 
(2.569) - AE Loss: 1487537.500 (629817.812) - AE Rec Loss: 10.088 (4.271) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.001 (0.362) - Batch(s): 0.567 
(2.569) - AE Loss: 258026.062 (629817.812) - AE Rec Loss: 1.750 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.644 
(2.489) - AE Loss: 183412.812 (619628.125) - AE Rec Loss: 1.244 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.642 
(2.489) - AE Loss: 128750.602 (619628.125) - AE Rec Loss: 0.873 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.643 
(2.489) - AE Loss: 103022.719 (619628.125) - AE Rec Loss: 0.699 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.644 
(2.489) - AE Loss: 137258.469 (619628.125) - AE Rec Loss: 0.931 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.644 
(2.489) - AE Loss: 109995.070 (619628.125) - AE Rec Loss: 0.746 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.644 
(2.489) - AE Loss: 104160.836 (619628.125) - AE Rec Loss: 0.706 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.571 
(2.412) - AE Loss: 1353385.625 (611424.625) - AE Rec Loss: 9.178 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.566 
(2.412) - AE Loss: 245736.391 (611424.625) - AE Rec Loss: 1.667 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.571 
(2.412) - AE Loss: 221497.953 (611424.625) - AE Rec Loss: 1.502 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.567 
(2.412) - AE Loss: 245980.328 (611424.625) - AE Rec Loss: 1.668 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.570 
(2.412) - AE Loss: 1604145.500 (611424.625) - AE Rec Loss: 10.879 (4.146) - Disc
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (0.333) - Batch(s): 0.574 
(2.412) - AE Loss: 84780.719 (611424.625) - AE Rec Loss: 0.575 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.570 
(2.341) - AE Loss: 2853132.500 (619839.875) - AE Rec Loss: 19.349 (4.204) - Disc
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.573 
(2.341) - AE Loss: 152255.625 (619839.875) - AE Rec Loss: 1.033 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.566 
(2.341) - AE Loss: 78186.414 (619839.875) - AE Rec Loss: 0.530 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.567 
(2.341) - AE Loss: 1466643.500 (619839.875) - AE Rec Loss: 9.946 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.569 
(2.341) - AE Loss: 265974.875 (619839.875) - AE Rec Loss: 1.804 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (0.320) - Batch(s): 0.570 
(2.341) - AE Loss: 84132.141 (619839.875) - AE Rec Loss: 0.571 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.26 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.662 
(2.279) - AE Loss: 137223.750 (616913.250) - AE Rec Loss: 0.931 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.663 
(2.279) - AE Loss: 80941.414 (616913.250) - AE Rec Loss: 0.549 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.662 
(2.279) - AE Loss: 1530171.750 (616913.250) - AE Rec Loss: 10.377 (4.184) - Disc
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.663 
(2.279) - AE Loss: 76826.062 (616913.250) - AE Rec Loss: 0.521 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.664 
(2.279) - AE Loss: 305349.062 (616913.250) - AE Rec Loss: 2.071 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.663 
(2.279) - AE Loss: 107567.250 (616913.250) - AE Rec Loss: 0.729 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.31 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:19:59,464[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,533[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,548[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,703[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,712[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,725[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:20:01,665[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:01,669[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:01,733[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:01,874[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:01,878[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:01,882[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,271[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,293[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,404[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,588[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,602[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,612[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 05:20:03,032[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,033[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,033[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:20:03,034[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating the optimizer 
[[36m2023-11-29 05:20:03,036[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,036[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Mixed precision: no
=> Mixed precision: no
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataset) = 4
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Preparing model 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
=> Preparing opt_ae 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 1
Reached 3 on node 0
Reached 5 on node 1
Reached end on node 1
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 1
Reached 3 on node 0
Reached 5 on node 1
Reached 5 on node 0
Reached end on node 1
Reached end on node 0
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1 on node 4
Reached 1.2 on node 1
Reached 1.2 on node 4
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 0Reached 1.3 on node 2Reached 1.3 on node 1


Reached 1.4 on node 2Reached 1.4 on node 1Reached 1.4 on node 0


Reached 2 on node 0Reached 2 on node 1
Reached 2 on node 2

Reached 3 on node 1Reached 3 on node 0
Reached 3 on node 2

Reached 5 on node 1
Reached 5 on node 0
Reached 5 on node 2
Reached end on node 1Reached end on node 0

Reached end on node 2Reached 1.3 on node 5
Reached 1.3 on node 4

Reached 1.4 on node 5Reached 1.4 on node 4

Reached 2 on node 5Reached 2 on node 4
Reached 1.3 on node 3

Reached 1.4 on node 3
Reached 3 on node 5
Reached 3 on node 4Reached 2 on node 3

Reached 5 on node 5
Reached 5 on node 4
Reached end on node 5
Reached end on node 4
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2Reached 1 on node 4

Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2Reached 1 on node 4

Reached 2 on node 2
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 4
Reached 3 on node 2Reached 2 on node 4

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 3
Reached end on node 2
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1 on node 4Reached 1.4 on node 5

Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 5
Reached 1.4 on node 5Reached 1 on node 4

Reached 2 on node 5
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 1
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 0
Reached end on node 4
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
[[36m2023-11-29 05:20:04,749[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Reached end on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
[[36m2023-11-29 05:20:07,607[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 05:20:08,772[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:20:08,772[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:20:08,772[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
[[36m2023-11-29 05:20:08,776[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
=> Starting model training 
[[36m2023-11-29 05:20:08,779[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <341/2280>] - Data(s): 5.613 (6.141) - Batch(s): 10.802 
(10.663) - AE Loss: 1528077.375 (741355.500) - AE Rec Loss: 10.363 (5.028) - 
Disc Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 7.090 (6.141) - Batch(s): 10.828 
(10.663) - AE Loss: 1395947.375 (741355.500) - AE Rec Loss: 9.467 (5.028) - Disc
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 6.993 (6.141) - Batch(s): 10.816 
(10.663) - AE Loss: 102706.641 (741355.500) - AE Rec Loss: 0.697 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 5.941 (6.141) - Batch(s): 10.802 
(10.663) - AE Loss: 252340.875 (741355.500) - AE Rec Loss: 1.711 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 6.903 (6.141) - Batch(s): 10.816 
(10.663) - AE Loss: 119053.453 (741355.500) - AE Rec Loss: 0.807 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 9.380 (6.141) - Batch(s): 10.812 
(10.663) - AE Loss: 2865382.250 (741355.500) - AE Rec Loss: 19.432 (5.028) - 
Disc Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.570 
(5.614) - AE Loss: 149925.172 (669225.938) - AE Rec Loss: 1.017 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.567 
(5.614) - AE Loss: 57013.328 (669225.938) - AE Rec Loss: 0.387 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.565 
(5.614) - AE Loss: 2021350.875 (669225.938) - AE Rec Loss: 13.708 (4.538) - Disc
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.563 
(5.614) - AE Loss: 47824.430 (669225.938) - AE Rec Loss: 0.324 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.568 
(5.614) - AE Loss: 1371345.250 (669225.938) - AE Rec Loss: 9.300 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.568 
(5.614) - AE Loss: 157114.812 (669225.938) - AE Rec Loss: 1.066 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.670 
(4.633) - AE Loss: 170806.031 (621787.000) - AE Rec Loss: 1.158 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.671 
(4.633) - AE Loss: 1475360.750 (621787.000) - AE Rec Loss: 10.005 (4.217) - Disc
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.671 
(4.633) - AE Loss: 251876.375 (621787.000) - AE Rec Loss: 1.708 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.671 
(4.633) - AE Loss: 1625978.250 (621787.000) - AE Rec Loss: 11.027 (4.217) - Disc
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.671 
(4.633) - AE Loss: 63800.133 (621787.000) - AE Rec Loss: 0.433 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 2.021 (2.108) - Batch(s): 2.672 
(4.633) - AE Loss: 279165.938 (621787.000) - AE Rec Loss: 1.893 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.38 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.568 
(3.617) - AE Loss: 108473.711 (562594.562) - AE Rec Loss: 0.736 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.570 
(3.617) - AE Loss: 127251.688 (562594.562) - AE Rec Loss: 0.863 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (1.581) - Batch(s): 0.566 
(3.617) - AE Loss: 136822.750 (562594.562) - AE Rec Loss: 0.928 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.568 
(3.617) - AE Loss: 186728.500 (562594.562) - AE Rec Loss: 1.266 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.564 
(3.617) - AE Loss: 99998.477 (562594.562) - AE Rec Loss: 0.678 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.570 
(3.617) - AE Loss: 99461.539 (562594.562) - AE Rec Loss: 0.675 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.44 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.087 
(3.329) - AE Loss: 76927.375 (531338.312) - AE Rec Loss: 0.522 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.087 
(3.329) - AE Loss: 236165.406 (531338.312) - AE Rec Loss: 1.602 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (1.296) - Batch(s): 2.088 
(3.329) - AE Loss: 1340689.000 (531338.312) - AE Rec Loss: 9.092 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (1.296) - Batch(s): 2.089 
(3.329) - AE Loss: 247878.797 (531338.312) - AE Rec Loss: 1.681 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.088 
(3.329) - AE Loss: 1599309.750 (531338.312) - AE Rec Loss: 10.846 (3.603) - Disc
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.087 
(3.329) - AE Loss: 219261.609 (531338.312) - AE Rec Loss: 1.487 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (1.080) - Batch(s): 0.657 
(2.884) - AE Loss: 275138.812 (579936.812) - AE Rec Loss: 1.866 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 74665.188 (579936.812) - AE Rec Loss: 0.506 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 1446760.500 (579936.812) - AE Rec Loss: 9.811 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 2851897.000 (579936.812) - AE Rec Loss: 19.341 (3.933) - Disc
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.659 
(2.884) - AE Loss: 143282.438 (579936.812) - AE Rec Loss: 0.972 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 62061.512 (579936.812) - AE Rec Loss: 0.421 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.568 
(2.553) - AE Loss: 76190.484 (573376.688) - AE Rec Loss: 0.517 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.001 (0.926) - Batch(s): 0.568 
(2.553) - AE Loss: 99716.672 (573376.688) - AE Rec Loss: 0.676 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.001 (0.926) - Batch(s): 0.569 
(2.553) - AE Loss: 1527805.375 (573376.688) - AE Rec Loss: 10.361 (3.888) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.001 (0.926) - Batch(s): 0.571 
(2.553) - AE Loss: 127836.414 (573376.688) - AE Rec Loss: 0.867 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.566 
(2.553) - AE Loss: 79485.562 (573376.688) - AE Rec Loss: 0.539 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.571 
(2.553) - AE Loss: 287717.094 (573376.688) - AE Rec Loss: 1.951 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 359115.375 (589204.188) - AE Rec Loss: 2.435 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 110964.070 (589204.188) - AE Rec Loss: 0.753 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 1466979.250 (589204.188) - AE Rec Loss: 9.949 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 1484196.250 (589204.188) - AE Rec Loss: 10.065 (3.996) - Disc
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.352 
(2.414) - AE Loss: 1526303.250 (589204.188) - AE Rec Loss: 10.351 (3.996) - Disc
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.353 
(2.414) - AE Loss: 1513452.750 (589204.188) - AE Rec Loss: 10.264 (3.996) - Disc
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.988 
(2.478) - AE Loss: 303393.219 (569764.688) - AE Rec Loss: 2.058 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 1624455.625 (569764.688) - AE Rec Loss: 11.017 (3.864) - Disc
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 91668.492 (569764.688) - AE Rec Loss: 0.622 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 73507.000 (569764.688) - AE Rec Loss: 0.499 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.988 
(2.478) - AE Loss: 72245.680 (569764.688) - AE Rec Loss: 0.490 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 2.338 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 148159.641 (569764.688) - AE Rec Loss: 1.005 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.568 
(2.287) - AE Loss: 161289.031 (577734.938) - AE Rec Loss: 1.094 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.001 (0.678) - Batch(s): 0.571 
(2.287) - AE Loss: 189681.000 (577734.938) - AE Rec Loss: 1.286 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.001 (0.678) - Batch(s): 0.567 
(2.287) - AE Loss: 54351.094 (577734.938) - AE Rec Loss: 0.369 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.001 (0.678) - Batch(s): 0.571 
(2.287) - AE Loss: 210019.797 (577734.938) - AE Rec Loss: 1.424 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.565 
(2.287) - AE Loss: 1308298.500 (577734.938) - AE Rec Loss: 8.872 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.001 (0.678) - Batch(s): 0.568 
(2.287) - AE Loss: 322505.344 (577734.938) - AE Rec Loss: 2.187 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.347 
(2.195) - AE Loss: 55215.297 (576499.688) - AE Rec Loss: 0.374 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.001 (0.616) - Batch(s): 0.569 
(2.195) - AE Loss: 126602.711 (576499.688) - AE Rec Loss: 0.859 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.001 (0.616) - Batch(s): 1.348 
(2.195) - AE Loss: 155608.875 (576499.688) - AE Rec Loss: 1.055 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.347 
(2.195) - AE Loss: 58677.031 (576499.688) - AE Rec Loss: 0.398 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.344 
(2.195) - AE Loss: 1792064.125 (576499.688) - AE Rec Loss: 12.153 (3.910) - Disc
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.351 
(2.195) - AE Loss: 675142.188 (576499.688) - AE Rec Loss: 4.579 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.45 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.066 
(2.101) - AE Loss: 242061.969 (594303.375) - AE Rec Loss: 1.642 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.067 
(2.101) - AE Loss: 66089.859 (594303.375) - AE Rec Loss: 0.448 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.418 (0.568) - Batch(s): 1.067 
(2.101) - AE Loss: 1545931.000 (594303.375) - AE Rec Loss: 10.484 (4.030) - Disc
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.067 
(2.101) - AE Loss: 1808403.250 (594303.375) - AE Rec Loss: 12.264 (4.030) - Disc
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.068 
(2.101) - AE Loss: 106550.633 (594303.375) - AE Rec Loss: 0.723 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.068 
(2.101) - AE Loss: 1450880.250 (594303.375) - AE Rec Loss: 9.839 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 160879.766 (589624.562) - AE Rec Loss: 1.091 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 203808.609 (589624.562) - AE Rec Loss: 1.382 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 109281.117 (589624.562) - AE Rec Loss: 0.741 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 260778.453 (589624.562) - AE Rec Loss: 1.769 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 118426.977 (589624.562) - AE Rec Loss: 0.803 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.001 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 369305.688 (589624.562) - AE Rec Loss: 2.505 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.480 
(2.071) - AE Loss: 137934.016 (567723.062) - AE Rec Loss: 0.935 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.95 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.481 
(2.071) - AE Loss: 209609.719 (567723.062) - AE Rec Loss: 1.422 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.481 
(2.071) - AE Loss: 280847.625 (567723.062) - AE Rec Loss: 1.905 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.481 
(2.071) - AE Loss: 117934.359 (567723.062) - AE Rec Loss: 0.800 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.481 
(2.071) - AE Loss: 235919.234 (567723.062) - AE Rec Loss: 1.600 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.482 
(2.071) - AE Loss: 84731.445 (567723.062) - AE Rec Loss: 0.575 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.651 
(1.976) - AE Loss: 451995.312 (576101.375) - AE Rec Loss: 3.065 (3.907) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.001 (0.474) - Batch(s): 0.651 
(1.976) - AE Loss: 156703.156 (576101.375) - AE Rec Loss: 1.063 (3.907) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.001 (0.474) - Batch(s): 0.652 
(1.976) - AE Loss: 101030.758 (576101.375) - AE Rec Loss: 0.685 (3.907) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.652 
(1.976) - AE Loss: 1590645.750 (576101.375) - AE Rec Loss: 10.787 (3.907) - Disc
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.652 
(1.976) - AE Loss: 218002.953 (576101.375) - AE Rec Loss: 1.478 (3.907) - Disc 
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 1556083.500 (576101.375) - AE Rec Loss: 10.553 (3.907) - Disc
Loss: 0.000 (0.000) - 3.02 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.000 (0.445) - Batch(s): 0.569 
(1.891) - AE Loss: 1632516.000 (574163.875) - AE Rec Loss: 11.071 (3.894) - Disc
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.570 
(1.891) - AE Loss: 269757.188 (574163.875) - AE Rec Loss: 1.829 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.572 
(1.891) - AE Loss: 1577131.250 (574163.875) - AE Rec Loss: 10.696 (3.894) - Disc
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.000 (0.445) - Batch(s): 0.571 
(1.891) - AE Loss: 54180.789 (574163.875) - AE Rec Loss: 0.367 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.000 (0.445) - Batch(s): 0.578 
(1.891) - AE Loss: 342586.719 (574163.875) - AE Rec Loss: 2.323 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.000 (0.445) - Batch(s): 0.567 
(1.891) - AE Loss: 122980.617 (574163.875) - AE Rec Loss: 0.834 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.09 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 97993.305 (582683.812) - AE Rec Loss: 0.665 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 63781.609 (582683.812) - AE Rec Loss: 0.433 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 666802.750 (582683.812) - AE Rec Loss: 4.522 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.001 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 62126.422 (582683.812) - AE Rec Loss: 0.421 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 213767.141 (582683.812) - AE Rec Loss: 1.450 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 1570104.000 (582683.812) - AE Rec Loss: 10.648 (3.952) - Disc
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 130127.570 (582704.688) - AE Rec Loss: 0.882 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 385758.062 (582704.688) - AE Rec Loss: 2.616 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 254372.891 (582704.688) - AE Rec Loss: 1.725 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 317379.375 (582704.688) - AE Rec Loss: 2.152 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 1.102 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 54885.371 (582704.688) - AE Rec Loss: 0.372 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.001 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 113301.125 (582704.688) - AE Rec Loss: 0.768 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.87 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 159438.141 (589840.625) - AE Rec Loss: 1.081 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.001 (0.427) - Batch(s): 0.573 
(2.060) - AE Loss: 246540.672 (589840.625) - AE Rec Loss: 1.672 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.566 
(2.060) - AE Loss: 208549.016 (589840.625) - AE Rec Loss: 1.414 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.568 
(2.060) - AE Loss: 214230.188 (589840.625) - AE Rec Loss: 1.453 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.571 
(2.060) - AE Loss: 1354283.250 (589840.625) - AE Rec Loss: 9.184 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 220100.438 (589840.625) - AE Rec Loss: 1.493 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.568 
(1.986) - AE Loss: 1639987.250 (604717.188) - AE Rec Loss: 11.122 (4.101) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.001 (0.406) - Batch(s): 0.570 
(1.986) - AE Loss: 74459.031 (604717.188) - AE Rec Loss: 0.505 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.001 (0.406) - Batch(s): 0.570 
(1.986) - AE Loss: 325424.562 (604717.188) - AE Rec Loss: 2.207 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.001 (0.406) - Batch(s): 0.567 
(1.986) - AE Loss: 1506073.500 (604717.188) - AE Rec Loss: 10.214 (4.101) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.001 (0.406) - Batch(s): 0.574 
(1.986) - AE Loss: 1545960.875 (604717.188) - AE Rec Loss: 10.484 (4.101) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.001 (0.406) - Batch(s): 0.572 
(1.986) - AE Loss: 239152.516 (604717.188) - AE Rec Loss: 1.622 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

attempting to save
[[36m2023-11-29 05:20:54,508[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 05:20:55,190[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:20:55,399[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:20:55,406[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:20:55,412[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:20:55,435[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:20:55,442[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:20:55,449[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:20:55,456[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:20:55,462[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:20:56,255[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:20:58,067[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:21:05,048[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:21:05,065[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 05:21:06,811[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:21:06,812[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 05:21:06,815[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 05:21:06,827[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <361/2280>] - Data(s): 0.000 (0.392) - Batch(s): 13.914 
(2.501) - AE Loss: 121464.422 (619681.250) - AE Rec Loss: 0.824 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.911 
(2.501) - AE Loss: 238284.797 (619681.250) - AE Rec Loss: 1.616 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.635 
(2.501) - AE Loss: 534013.000 (619681.250) - AE Rec Loss: 3.622 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.911 
(2.501) - AE Loss: 1654081.750 (619681.250) - AE Rec Loss: 11.217 (4.202) - Disc
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 113436.586 (619681.250) - AE Rec Loss: 0.769 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.000 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 1499980.750 (619681.250) - AE Rec Loss: 10.172 (4.202) - Disc
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.568 
(2.413) - AE Loss: 173693.109 (632520.312) - AE Rec Loss: 1.178 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.571 
(2.413) - AE Loss: 190386.359 (632520.312) - AE Rec Loss: 1.291 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.573 
(2.413) - AE Loss: 93803.305 (632520.312) - AE Rec Loss: 0.636 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.569 
(2.413) - AE Loss: 2241436.500 (632520.312) - AE Rec Loss: 15.201 (4.290) - Disc
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.570 
(2.413) - AE Loss: 1748311.500 (632520.312) - AE Rec Loss: 11.856 (4.290) - Disc
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.566 
(2.413) - AE Loss: 1428272.500 (632520.312) - AE Rec Loss: 9.686 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (0.358) - Batch(s): 0.568 
(2.333) - AE Loss: 113095.062 (635260.062) - AE Rec Loss: 0.767 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (0.358) - Batch(s): 0.571 
(2.333) - AE Loss: 154728.109 (635260.062) - AE Rec Loss: 1.049 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.572 
(2.333) - AE Loss: 114402.273 (635260.062) - AE Rec Loss: 0.776 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (0.358) - Batch(s): 0.568 
(2.333) - AE Loss: 2013870.250 (635260.062) - AE Rec Loss: 13.657 (4.308) - Disc
Loss: 0.000 (0.000) - 5.30 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.575 
(2.333) - AE Loss: 1454123.125 (635260.062) - AE Rec Loss: 9.861 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.570 
(2.333) - AE Loss: 1411066.000 (635260.062) - AE Rec Loss: 9.569 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 307663.312 (627962.875) - AE Rec Loss: 2.086 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.654 
(2.263) - AE Loss: 104106.602 (627962.875) - AE Rec Loss: 0.706 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 458659.562 (627962.875) - AE Rec Loss: 3.110 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 442665.531 (627962.875) - AE Rec Loss: 3.002 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 1450855.125 (627962.875) - AE Rec Loss: 9.839 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 119346.898 (627962.875) - AE Rec Loss: 0.809 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.570 
(2.195) - AE Loss: 153336.938 (628186.875) - AE Rec Loss: 1.040 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.567 
(2.195) - AE Loss: 100505.805 (628186.875) - AE Rec Loss: 0.682 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.570 
(2.195) - AE Loss: 470034.312 (628186.875) - AE Rec Loss: 3.188 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.572 
(2.195) - AE Loss: 1513431.375 (628186.875) - AE Rec Loss: 10.264 (4.260) - Disc
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.568 
(2.195) - AE Loss: 105339.398 (628186.875) - AE Rec Loss: 0.714 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.575 
(2.195) - AE Loss: 1509432.500 (628186.875) - AE Rec Loss: 10.236 (4.260) - Disc
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.568 
(2.133) - AE Loss: 194329.141 (622504.312) - AE Rec Loss: 1.318 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.574 
(2.133) - AE Loss: 61888.242 (622504.312) - AE Rec Loss: 0.420 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.572 
(2.133) - AE Loss: 212296.234 (622504.312) - AE Rec Loss: 1.440 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (0.317) - Batch(s): 0.570 
(2.133) - AE Loss: 1531442.250 (622504.312) - AE Rec Loss: 10.386 (4.222) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (0.317) - Batch(s): 0.571 
(2.133) - AE Loss: 171566.344 (622504.312) - AE Rec Loss: 1.164 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.568 
(2.133) - AE Loss: 170978.297 (622504.312) - AE Rec Loss: 1.160 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 1472029.250 (633364.812) - AE Rec Loss: 9.983 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.001 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 2854459.000 (633364.812) - AE Rec Loss: 19.358 (4.295) - Disc
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.355 
(2.141) - AE Loss: 375073.312 (633364.812) - AE Rec Loss: 2.544 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.356 
(2.141) - AE Loss: 1633718.000 (633364.812) - AE Rec Loss: 11.079 (4.295) - Disc
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.356 
(2.141) - AE Loss: 393886.625 (633364.812) - AE Rec Loss: 2.671 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 1.674 (0.310) - Batch(s): 2.356 
(2.141) - AE Loss: 301853.188 (633364.812) - AE Rec Loss: 2.047 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.162 
(2.188) - AE Loss: 1723880.750 (635869.375) - AE Rec Loss: 11.691 (4.312) - Disc
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 2.949 (0.309) - Batch(s): 3.525 
(2.188) - AE Loss: 178571.562 (635869.375) - AE Rec Loss: 1.211 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.519 
(2.188) - AE Loss: 562204.312 (635869.375) - AE Rec Loss: 3.813 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.384 (0.309) - Batch(s): 3.163 
(2.188) - AE Loss: 71522.094 (635869.375) - AE Rec Loss: 0.485 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.520 
(2.188) - AE Loss: 1809341.125 (635869.375) - AE Rec Loss: 12.270 (4.312) - Disc
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.517 
(2.188) - AE Loss: 88007.977 (635869.375) - AE Rec Loss: 0.597 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:23:04,941[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,046[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,072[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,089[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,174[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,196[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:23:07,100[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,176[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,266[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,341[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,341[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,625[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:07,835[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:07,883[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:07,887[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:07,942[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,037[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,193[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
[[36m2023-11-29 05:23:08,245[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:23:08,248[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
[[36m2023-11-29 05:23:08,249[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
[[36m2023-11-29 05:23:08,251[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(train_dataloader) = 2279
[[36m2023-11-29 05:23:08,253[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
[[36m2023-11-29 05:23:08,254[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating the optimizer 
=> Preparing model 
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing model 
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(train_dataset) = 54706
len(valid_dataloader) = 1
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing opt_ae 
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 1.3 on node 5
Reached 1.4 on node 5Reached 5 on node 3

Reached end on node 3
Reached 2 on node 5
=> Preparing criterion 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing criterion 
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1 on node 3
Reached 1.2 on node 5
Reached 1.2 on node 3
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 3Reached 1.3 on node 0

Reached 1.4 on node 0Reached 1.4 on node 3

Reached 2 on node 3Reached 2 on node 0

Reached 3 on node 3
Reached 3 on node 0
Reached 1.3 on node 2Reached 5 on node 3Reached 1.3 on node 5
Reached 5 on node 0


Reached 1.4 on node 2
Reached 1.4 on node 5Reached 1.3 on node 1

Reached 1.4 on node 1
Reached 2 on node 2Reached end on node 0Reached end on node 3


Reached 2 on node 5
Reached 2 on node 1
Reached 3 on node 2
Reached 3 on node 5
Reached 3 on node 1
Reached 5 on node 2
Reached 5 on node 5
Reached end on node 2
Reached 5 on node 1Reached end on node 5

Reached end on node 1
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1 on node 4Reached end on node 1

Reached 1 on node 3
Reached 1.4 on node 5Reached 1.4 on node 4

Reached 1.4 on node 3
Reached 2 on node 4Reached 2 on node 3

Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 1.4 on node 3
Reached 2 on node 4
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1 on node 3
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3Reached 1 on node 5

Reached 3 on node 3
Reached 5 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 4
Reached 1.4 on node 2
Reached 2 on node 2Reached 1.4 on node 4

Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5Reached 1.4 on node 2

Reached 2 on node 2
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 2Reached 3 on node 5

Reached 3 on node 5
Reached 3 on node 2
Reached 5 on node 5Reached 3 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached end on node 2
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4Reached 1 on node 2

Reached 2 on node 4
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 0
Reached 1 on node 5
Reached 1 on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1 on node 1
Reached 1 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached 1 on node 1
Reached end on node 5
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 0
Reached end on node 3
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
[[36m2023-11-29 05:23:10,034[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 05:23:12,602[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:23:13,849[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:23:13,849[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:23:13,849[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 05:23:13,851[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:23:13,853[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <361/2280>] - Data(s): 3.456 (6.891) - Batch(s): 12.629 
(12.415) - AE Loss: 534482.000 (919133.000) - AE Rec Loss: 3.625 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 7.181 (6.891) - Batch(s): 12.628 
(12.415) - AE Loss: 1653277.500 (919133.000) - AE Rec Loss: 11.212 (6.233) - 
Disc Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 5.803 (6.891) - Batch(s): 12.649 
(12.415) - AE Loss: 114147.875 (919133.000) - AE Rec Loss: 0.774 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 11.364 (6.891) - Batch(s): 12.632 
(12.415) - AE Loss: 1500022.125 (919133.000) - AE Rec Loss: 10.173 (6.233) - 
Disc Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 6.352 (6.891) - Batch(s): 12.626 
(12.415) - AE Loss: 238595.766 (919133.000) - AE Rec Loss: 1.618 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 6.267 (6.891) - Batch(s): 12.647 
(12.415) - AE Loss: 122525.773 (919133.000) - AE Rec Loss: 0.831 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.14 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.559 
(6.490) - AE Loss: 1430936.250 (915964.000) - AE Rec Loss: 9.704 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.563 
(6.490) - AE Loss: 1769158.750 (915964.000) - AE Rec Loss: 11.998 (6.212) - Disc
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.566 
(6.490) - AE Loss: 101065.602 (915964.000) - AE Rec Loss: 0.685 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.001 (3.446) - Batch(s): 0.567 
(6.490) - AE Loss: 2247598.500 (915964.000) - AE Rec Loss: 15.243 (6.212) - Disc
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.001 (3.446) - Batch(s): 0.565 
(6.490) - AE Loss: 217442.312 (915964.000) - AE Rec Loss: 1.475 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.001 (3.446) - Batch(s): 0.562 
(6.490) - AE Loss: 180998.500 (915964.000) - AE Rec Loss: 1.227 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.732 
(4.571) - AE Loss: 141662.094 (845812.000) - AE Rec Loss: 0.961 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.732 
(4.571) - AE Loss: 1458274.000 (845812.000) - AE Rec Loss: 9.890 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.734 
(4.571) - AE Loss: 164987.609 (845812.000) - AE Rec Loss: 1.119 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.735 
(4.571) - AE Loss: 128908.062 (845812.000) - AE Rec Loss: 0.874 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.735 
(4.571) - AE Loss: 1413214.250 (845812.000) - AE Rec Loss: 9.584 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.735 
(4.571) - AE Loss: 2022362.125 (845812.000) - AE Rec Loss: 13.715 (5.736) - Disc
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 306650.250 (749269.312) - AE Rec Loss: 2.080 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 1448270.750 (749269.312) - AE Rec Loss: 9.822 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 460947.000 (749269.312) - AE Rec Loss: 3.126 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 443144.812 (749269.312) - AE Rec Loss: 3.005 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.382 
(4.032) - AE Loss: 102785.570 (749269.312) - AE Rec Loss: 0.697 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (1.768) - Batch(s): 2.382 
(4.032) - AE Loss: 118478.750 (749269.312) - AE Rec Loss: 0.803 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.566 
(3.338) - AE Loss: 460255.844 (724108.750) - AE Rec Loss: 3.121 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.565 
(3.338) - AE Loss: 149929.000 (724108.750) - AE Rec Loss: 1.017 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.567 
(3.338) - AE Loss: 1500051.250 (724108.750) - AE Rec Loss: 10.173 (4.911) - Disc
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.561 
(3.338) - AE Loss: 89009.266 (724108.750) - AE Rec Loss: 0.604 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.565 
(3.338) - AE Loss: 1506758.500 (724108.750) - AE Rec Loss: 10.218 (4.911) - Disc
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.562 
(3.338) - AE Loss: 91476.305 (724108.750) - AE Rec Loss: 0.620 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.689 
(2.897) - AE Loss: 167100.781 (682492.625) - AE Rec Loss: 1.133 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.689 
(2.897) - AE Loss: 188865.875 (682492.625) - AE Rec Loss: 1.281 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.690 
(2.897) - AE Loss: 148784.297 (682492.625) - AE Rec Loss: 1.009 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.690 
(2.897) - AE Loss: 201705.406 (682492.625) - AE Rec Loss: 1.368 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.691 
(2.897) - AE Loss: 1528920.250 (682492.625) - AE Rec Loss: 10.369 (4.628) - Disc
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.691 
(2.897) - AE Loss: 61651.117 (682492.625) - AE Rec Loss: 0.418 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.001 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 1632261.125 (715171.250) - AE Rec Loss: 11.069 (4.850) - Disc
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 368315.531 (715171.250) - AE Rec Loss: 2.498 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.376 
(2.684) - AE Loss: 386079.656 (715171.250) - AE Rec Loss: 2.618 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 298764.562 (715171.250) - AE Rec Loss: 2.026 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.377 
(2.684) - AE Loss: 2852380.000 (715171.250) - AE Rec Loss: 19.344 (4.850) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.376 
(2.684) - AE Loss: 1471869.625 (715171.250) - AE Rec Loss: 9.982 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.392 
(2.640) - AE Loss: 1822400.000 (713271.750) - AE Rec Loss: 12.359 (4.837) - Disc
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 1.825 (0.916) - Batch(s): 2.400 
(2.640) - AE Loss: 166397.969 (713271.750) - AE Rec Loss: 1.128 (4.837) - Disc 
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.394 
(2.640) - AE Loss: 554555.250 (713271.750) - AE Rec Loss: 3.761 (4.837) - Disc 
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.916) - Batch(s): 2.041 
(2.640) - AE Loss: 62403.137 (713271.750) - AE Rec Loss: 0.423 (4.837) - Disc 
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.389 
(2.640) - AE Loss: 82607.211 (713271.750) - AE Rec Loss: 0.560 (4.837) - Disc 
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.916) - Batch(s): 2.041 
(2.640) - AE Loss: 1727266.750 (713271.750) - AE Rec Loss: 11.714 (4.837) - Disc
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.722 
(2.427) - AE Loss: 95452.148 (739378.375) - AE Rec Loss: 0.647 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.723 
(2.427) - AE Loss: 2835527.000 (739378.375) - AE Rec Loss: 19.230 (5.014) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.725 
(2.427) - AE Loss: 1887340.750 (739378.375) - AE Rec Loss: 12.799 (5.014) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.724 
(2.427) - AE Loss: 1502002.000 (739378.375) - AE Rec Loss: 10.186 (5.014) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.001 (0.814) - Batch(s): 0.724 
(2.427) - AE Loss: 156495.031 (739378.375) - AE Rec Loss: 1.061 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.724 
(2.427) - AE Loss: 174884.250 (739378.375) - AE Rec Loss: 1.186 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 88083.633 (688241.188) - AE Rec Loss: 0.597 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 120833.648 (688241.188) - AE Rec Loss: 0.819 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.997 
(2.287) - AE Loss: 47023.047 (688241.188) - AE Rec Loss: 0.319 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 230036.438 (688241.188) - AE Rec Loss: 1.560 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 99111.664 (688241.188) - AE Rec Loss: 0.672 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 1.006 
(2.287) - AE Loss: 217557.500 (688241.188) - AE Rec Loss: 1.475 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 1.857 (0.707) - Batch(s): 2.880 
(2.357) - AE Loss: 155972.828 (686884.625) - AE Rec Loss: 1.058 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 2.663 (0.707) - Batch(s): 3.236 
(2.357) - AE Loss: 106480.055 (686884.625) - AE Rec Loss: 0.722 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.001 (0.707) - Batch(s): 2.880 
(2.357) - AE Loss: 128723.148 (686884.625) - AE Rec Loss: 0.873 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.066 (0.707) - Batch(s): 2.880 
(2.357) - AE Loss: 393917.656 (686884.625) - AE Rec Loss: 2.671 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.001 (0.707) - Batch(s): 3.232 
(2.357) - AE Loss: 69380.305 (686884.625) - AE Rec Loss: 0.471 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.001 (0.707) - Batch(s): 2.082 
(2.357) - AE Loss: 118897.086 (686884.625) - AE Rec Loss: 0.806 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.51 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.712 
(2.220) - AE Loss: 1561349.125 (698287.688) - AE Rec Loss: 10.589 (4.736) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.714 
(2.220) - AE Loss: 1592122.875 (698287.688) - AE Rec Loss: 10.797 (4.736) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.714 
(2.220) - AE Loss: 554681.375 (698287.688) - AE Rec Loss: 3.762 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.715 
(2.220) - AE Loss: 2906696.000 (698287.688) - AE Rec Loss: 19.712 (4.736) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.715 
(2.220) - AE Loss: 428704.281 (698287.688) - AE Rec Loss: 2.907 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.715 
(2.220) - AE Loss: 110926.859 (698287.688) - AE Rec Loss: 0.752 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.565 
(2.092) - AE Loss: 150729.438 (676618.688) - AE Rec Loss: 1.022 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.000 (0.598) - Batch(s): 0.564 
(2.092) - AE Loss: 1476329.500 (676618.688) - AE Rec Loss: 10.012 (4.589) - Disc
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.000 (0.598) - Batch(s): 0.567 
(2.092) - AE Loss: 248628.172 (676618.688) - AE Rec Loss: 1.686 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.000 (0.598) - Batch(s): 0.568 
(2.092) - AE Loss: 1529623.500 (676618.688) - AE Rec Loss: 10.373 (4.589) - Disc
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.000 (0.598) - Batch(s): 0.565 
(2.092) - AE Loss: 223498.328 (676618.688) - AE Rec Loss: 1.516 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.567 
(2.092) - AE Loss: 160899.312 (676618.688) - AE Rec Loss: 1.091 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 0.978 
(2.030) - AE Loss: 368172.812 (663598.125) - AE Rec Loss: 2.497 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.770 (0.562) - Batch(s): 1.333 
(2.030) - AE Loss: 274699.750 (663598.125) - AE Rec Loss: 1.863 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.358 (0.562) - Batch(s): 0.977 
(2.030) - AE Loss: 1669119.625 (663598.125) - AE Rec Loss: 11.319 (4.500) - Disc
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.331 
(2.030) - AE Loss: 76232.125 (663598.125) - AE Rec Loss: 0.517 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 0.978 
(2.030) - AE Loss: 748029.812 (663598.125) - AE Rec Loss: 5.073 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 0.978 
(2.030) - AE Loss: 195851.266 (663598.125) - AE Rec Loss: 1.328 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.718 
(1.942) - AE Loss: 301786.000 (661895.438) - AE Rec Loss: 2.047 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.719 
(1.942) - AE Loss: 256405.859 (661895.438) - AE Rec Loss: 1.739 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.720 
(1.942) - AE Loss: 1455602.000 (661895.438) - AE Rec Loss: 9.871 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.001 (0.525) - Batch(s): 0.720 
(1.942) - AE Loss: 493480.438 (661895.438) - AE Rec Loss: 3.347 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.721 
(1.942) - AE Loss: 129530.227 (661895.438) - AE Rec Loss: 0.878 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.721 
(1.942) - AE Loss: 2644875.000 (661895.438) - AE Rec Loss: 17.937 (4.489) - Disc
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 174637.031 (653874.625) - AE Rec Loss: 1.184 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.599 
(2.050) - AE Loss: 147973.562 (653874.625) - AE Rec Loss: 1.004 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.599 
(2.050) - AE Loss: 113164.156 (653874.625) - AE Rec Loss: 0.767 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 257253.547 (653874.625) - AE Rec Loss: 1.745 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 139616.266 (653874.625) - AE Rec Loss: 0.947 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 89946.695 (653874.625) - AE Rec Loss: 0.610 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.766 
(2.031) - AE Loss: 103386.461 (638174.125) - AE Rec Loss: 0.701 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 1.205 (0.488) - Batch(s): 1.769 
(2.031) - AE Loss: 152031.438 (638174.125) - AE Rec Loss: 1.031 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.765 
(2.031) - AE Loss: 62246.344 (638174.125) - AE Rec Loss: 0.422 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.001 (0.488) - Batch(s): 1.413 
(2.031) - AE Loss: 270579.625 (638174.125) - AE Rec Loss: 1.835 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.001 (0.488) - Batch(s): 1.769 
(2.031) - AE Loss: 152036.672 (638174.125) - AE Rec Loss: 1.031 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.001 (0.488) - Batch(s): 1.772 
(2.031) - AE Loss: 210890.781 (638174.125) - AE Rec Loss: 1.430 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.709 
(1.958) - AE Loss: 1611120.250 (636598.875) - AE Rec Loss: 10.926 (4.317) - Disc
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.709 
(1.958) - AE Loss: 1489169.250 (636598.875) - AE Rec Loss: 10.099 (4.317) - Disc
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.711 
(1.958) - AE Loss: 142144.688 (636598.875) - AE Rec Loss: 0.964 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.710 
(1.958) - AE Loss: 239691.188 (636598.875) - AE Rec Loss: 1.626 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.712 
(1.958) - AE Loss: 1494466.750 (636598.875) - AE Rec Loss: 10.135 (4.317) - Disc
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.712 
(1.958) - AE Loss: 58095.102 (636598.875) - AE Rec Loss: 0.394 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.461 
(1.936) - AE Loss: 98683.812 (642890.438) - AE Rec Loss: 0.669 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.461 
(1.936) - AE Loss: 66625.438 (642890.438) - AE Rec Loss: 0.452 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.001 (0.449) - Batch(s): 1.461 
(1.936) - AE Loss: 70041.586 (642890.438) - AE Rec Loss: 0.475 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 312371.188 (642890.438) - AE Rec Loss: 2.118 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 107602.023 (642890.438) - AE Rec Loss: 0.730 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 320563.688 (642890.438) - AE Rec Loss: 2.174 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.564 
(1.867) - AE Loss: 162875.828 (631807.000) - AE Rec Loss: 1.105 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.000 (0.426) - Batch(s): 0.568 
(1.867) - AE Loss: 117867.898 (631807.000) - AE Rec Loss: 0.799 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.000 (0.426) - Batch(s): 0.568 
(1.867) - AE Loss: 61152.953 (631807.000) - AE Rec Loss: 0.415 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.000 (0.426) - Batch(s): 0.565 
(1.867) - AE Loss: 72314.859 (631807.000) - AE Rec Loss: 0.490 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.565 
(1.867) - AE Loss: 89216.297 (631807.000) - AE Rec Loss: 0.605 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.566 
(1.867) - AE Loss: 1336544.625 (631807.000) - AE Rec Loss: 9.064 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

attempting to save
[[36m2023-11-29 05:23:57,535[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 05:23:58,649[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:23:58,870[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:23:58,878[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:23:58,888[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:23:58,893[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:23:58,898[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:23:58,902[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:23:58,908[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:23:58,918[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:23:59,772[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:24:02,226[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:24:05,713[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:24:05,726[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 05:24:18,320[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:24:18,320[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 05:24:18,322[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 05:24:18,334[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.237 
(2.752) - AE Loss: 164225.688 (626334.875) - AE Rec Loss: 1.114 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.237 
(2.752) - AE Loss: 609737.938 (626334.875) - AE Rec Loss: 4.135 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.001 (0.410) - Batch(s): 22.237 
(2.752) - AE Loss: 257240.578 (626334.875) - AE Rec Loss: 1.745 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.237 
(2.752) - AE Loss: 523616.250 (626334.875) - AE Rec Loss: 3.551 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.237 
(2.752) - AE Loss: 326697.188 (626334.875) - AE Rec Loss: 2.216 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 0.686 
(2.752) - AE Loss: 216123.109 (626334.875) - AE Rec Loss: 1.466 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.564 
(2.653) - AE Loss: 297197.875 (628039.250) - AE Rec Loss: 2.016 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.570 
(2.653) - AE Loss: 271351.000 (628039.250) - AE Rec Loss: 1.840 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.568 
(2.653) - AE Loss: 106093.492 (628039.250) - AE Rec Loss: 0.719 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.565 
(2.653) - AE Loss: 362886.219 (628039.250) - AE Rec Loss: 2.461 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.566 
(2.653) - AE Loss: 296352.938 (628039.250) - AE Rec Loss: 2.010 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.567 
(2.653) - AE Loss: 1387753.750 (628039.250) - AE Rec Loss: 9.411 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.565 
(2.562) - AE Loss: 243177.422 (620808.625) - AE Rec Loss: 1.649 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.568 
(2.562) - AE Loss: 306948.375 (620808.625) - AE Rec Loss: 2.082 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (0.374) - Batch(s): 0.571 
(2.562) - AE Loss: 137179.641 (620808.625) - AE Rec Loss: 0.930 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (0.374) - Batch(s): 0.566 
(2.562) - AE Loss: 1651822.250 (620808.625) - AE Rec Loss: 11.202 (4.210) - Disc
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (0.374) - Batch(s): 0.568 
(2.562) - AE Loss: 140123.250 (620808.625) - AE Rec Loss: 0.950 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.567 
(2.562) - AE Loss: 424634.344 (620808.625) - AE Rec Loss: 2.880 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.001 (0.359) - Batch(s): 0.717 
(2.485) - AE Loss: 68061.031 (621870.688) - AE Rec Loss: 0.462 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.001 (0.359) - Batch(s): 0.717 
(2.485) - AE Loss: 49431.078 (621870.688) - AE Rec Loss: 0.335 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.718 
(2.485) - AE Loss: 1351665.500 (621870.688) - AE Rec Loss: 9.167 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.001 (0.359) - Batch(s): 0.717 
(2.485) - AE Loss: 1460358.500 (621870.688) - AE Rec Loss: 9.904 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.001 (0.359) - Batch(s): 0.718 
(2.485) - AE Loss: 1460656.000 (621870.688) - AE Rec Loss: 9.906 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.718 
(2.485) - AE Loss: 112483.805 (621870.688) - AE Rec Loss: 0.763 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.571 
(2.408) - AE Loss: 1728547.625 (631919.562) - AE Rec Loss: 11.722 (4.285) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.568 
(2.408) - AE Loss: 2765079.000 (631919.562) - AE Rec Loss: 18.752 (4.285) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.564 
(2.408) - AE Loss: 156739.219 (631919.562) - AE Rec Loss: 1.063 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.568 
(2.408) - AE Loss: 270793.688 (631919.562) - AE Rec Loss: 1.836 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.565 
(2.408) - AE Loss: 1439268.250 (631919.562) - AE Rec Loss: 9.761 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.566 
(2.408) - AE Loss: 1682478.000 (631919.562) - AE Rec Loss: 11.410 (4.285) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:27:40,471[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:40,529[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:40,541[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:40,544[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:40,610[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:40,610[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:27:42,641[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:42,707[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:42,731[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:42,737[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:42,769[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:42,803[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,334[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,480[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,487[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,504[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,519[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:43,534[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
[[36m2023-11-29 05:27:44,259[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:27:44,259[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 05:27:44,262[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:27:44,262[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
[[36m2023-11-29 05:27:44,264[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
[[36m2023-11-29 05:27:44,268[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Preparing model 
=> Preparing model 
len(valid_dataset) = 4
=> Mixed precision: no
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 2
Reached 5 on node 2
batch_size = 2, learning rate = 4.5e-06
Reached end on node 2
len(train_dataloader) = 2279
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing model 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
=> Preparing model 
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
Reached 1.3 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
=> Preparing opt_ae 
Reached 1.3 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1.3 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
=> Preparing opt_ae 
Reached 5 on node 4
Reached end on node 4
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Preparing criterion 
Reached 1.3 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 2
Reached 5 on node 2
Reached 1.3 on node 0
Reached end on node 2
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 0
Reached 1.2 on node 0
Reached 1 on node 2
Reached 1.2 on node 2
Reached 1.25 on node 0
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 2
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 4
Reached 1.2 on node 4
Reached 1.25 on node 4
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 1
Reached 1.2 on node 1
Reached 1.25 on node 1
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 3
Reached 1.2 on node 3
Reached 1.25 on node 3
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 5
Reached 1.2 on node 5
Reached 1.25 on node 5
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 2
Reached 1.3 on node 1Reached 1.4 on node 2Reached 1.3 on node 3


Reached 1.4 on node 1Reached 1.4 on node 3

Reached 2 on node 2
Reached 2 on node 1Reached 2 on node 3

Reached 3 on node 2
Reached 3 on node 1Reached 3 on node 3

Reached 1.3 on node 4
Reached 5 on node 1Reached 1.4 on node 4
Reached 5 on node 3Reached 5 on node 2


Reached end on node 1
Reached 2 on node 4Reached end on node 2

Reached end on node 3
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1.3 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached end on node 0
Reached 1.3 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 5
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached end on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached end on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4Reached 1 on node 5

Reached 1 on node 3
Reached 1.4 on node 4
Reached 1.4 on node 3Reached 2 on node 4

Reached 2 on node 3
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 4Reached 1 on node 3

Reached 1.4 on node 3
Reached 1.4 on node 4
Reached 2 on node 3
Reached 2 on node 4
Reached 1 on node 5
Reached 1 on node 2
Reached 1.4 on node 5Reached 1.4 on node 2

Reached 2 on node 5Reached 2 on node 2

Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached 1 on node 3
Reached 1 on node 4
Reached 1.4 on node 3
Reached 1.4 on node 4Reached 2 on node 3

Reached 2 on node 4
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 2
Reached end on node 3
Reached end on node 4
Reached end on node 5
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 1
Reached 1 on node 4
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1.4 on node 4
Reached 2 on node 4
Reached 1 on node 2
Reached 1 on node 3
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 2
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1.4 on node 2
Reached 2 on node 2
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 1 on node 0
Reached 1.4 on node 0
Reached 2 on node 0
Reached 1 on node 5
Reached 1.4 on node 5
Reached 2 on node 5
Reached 1 on node 4
Reached 1.4 on node 4
Reached 2 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 3 on node 4
Reached 5 on node 4
Reached end on node 4
Reached 1 on node 1
Reached 1.4 on node 1
Reached 2 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 3 on node 1
Reached 5 on node 1
Reached end on node 1
Reached 1 on node 3
Reached 1.4 on node 3
Reached 2 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 3 on node 3
Reached 5 on node 3
Reached end on node 3
Reached 1 on node 2
Reached 1.4 on node 2
Reached 2 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 3 on node 2
Reached 5 on node 2
Reached end on node 2
Reached 1 on node 0
Reached 1 on node 5
Reached 1.4 on node 0
Reached 2 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 3 on node 0
Reached 5 on node 0
Reached 1.4 on node 5
Reached 2 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 3 on node 5
Reached 5 on node 5
Reached end on node 0
Reached end on node 5
[[36m2023-11-29 05:27:46,010[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 05:27:48,690[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 05:27:49,888[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:27:49,888[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:27:49,888[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 05:27:49,904[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:27:49,905[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <381/2280>] - Data(s): 9.325 (5.365) - Batch(s): 10.603 
(10.597) - AE Loss: 216367.828 (516901.969) - AE Rec Loss: 1.467 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 3.430 (5.365) - Batch(s): 10.636 
(10.597) - AE Loss: 326946.594 (516901.969) - AE Rec Loss: 2.217 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 2.902 (5.365) - Batch(s): 10.649 
(10.597) - AE Loss: 523594.375 (516901.969) - AE Rec Loss: 3.551 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 3.033 (5.365) - Batch(s): 10.617 
(10.597) - AE Loss: 257388.562 (516901.969) - AE Rec Loss: 1.746 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 5.204 (5.365) - Batch(s): 10.634 
(10.597) - AE Loss: 609315.625 (516901.969) - AE Rec Loss: 4.132 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 5.924 (5.365) - Batch(s): 10.653 
(10.597) - AE Loss: 164398.625 (516901.969) - AE Rec Loss: 1.115 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.561 
(5.579) - AE Loss: 1388117.000 (588137.062) - AE Rec Loss: 9.414 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.001 (2.683) - Batch(s): 0.560 
(5.579) - AE Loss: 358407.906 (588137.062) - AE Rec Loss: 2.431 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.565 
(5.579) - AE Loss: 301183.594 (588137.062) - AE Rec Loss: 2.043 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.566 
(5.579) - AE Loss: 101092.477 (588137.062) - AE Rec Loss: 0.686 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.564 
(5.579) - AE Loss: 263735.594 (588137.062) - AE Rec Loss: 1.789 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.562 
(5.579) - AE Loss: 293757.125 (588137.062) - AE Rec Loss: 1.992 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.797 
(4.653) - AE Loss: 136471.656 (544804.250) - AE Rec Loss: 0.926 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.014 (1.847) - Batch(s): 2.796 
(4.653) - AE Loss: 235484.234 (544804.250) - AE Rec Loss: 1.597 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.798 
(4.653) - AE Loss: 423431.594 (544804.250) - AE Rec Loss: 2.872 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.799 
(4.653) - AE Loss: 1650921.125 (544804.250) - AE Rec Loss: 11.196 (3.695) - Disc
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (1.847) - Batch(s): 2.798 
(4.653) - AE Loss: 298667.562 (544804.250) - AE Rec Loss: 2.025 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (1.847) - Batch(s): 2.797 
(4.653) - AE Loss: 131304.594 (544804.250) - AE Rec Loss: 0.890 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.356 
(3.895) - AE Loss: 1460808.000 (569826.750) - AE Rec Loss: 9.907 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.356 
(3.895) - AE Loss: 1460923.750 (569826.750) - AE Rec Loss: 9.908 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.709 
(3.895) - AE Loss: 1354345.875 (569826.750) - AE Rec Loss: 9.185 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.356 
(3.895) - AE Loss: 70593.688 (569826.750) - AE Rec Loss: 0.479 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.711 
(3.895) - AE Loss: 107373.789 (569826.750) - AE Rec Loss: 0.728 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 1.149 (1.410) - Batch(s): 1.713 
(3.895) - AE Loss: 41975.781 (569826.750) - AE Rec Loss: 0.285 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.564 
(3.228) - AE Loss: 269487.000 (630892.062) - AE Rec Loss: 1.828 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.564 
(3.228) - AE Loss: 152721.391 (630892.062) - AE Rec Loss: 1.036 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.566 
(3.228) - AE Loss: 1726794.750 (630892.062) - AE Rec Loss: 11.711 (4.279) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.567 
(3.228) - AE Loss: 1680942.750 (630892.062) - AE Rec Loss: 11.400 (4.279) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.567 
(3.228) - AE Loss: 2767190.500 (630892.062) - AE Rec Loss: 18.766 (4.279) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.563 
(3.228) - AE Loss: 1440881.875 (630892.062) - AE Rec Loss: 9.772 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.001 (0.940) - Batch(s): 0.689 
(2.805) - AE Loss: 53686.859 (566632.125) - AE Rec Loss: 0.364 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 205898.141 (566632.125) - AE Rec Loss: 1.396 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 45952.504 (566632.125) - AE Rec Loss: 0.312 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.001 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 1431835.500 (566632.125) - AE Rec Loss: 9.710 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.691 
(2.805) - AE Loss: 216322.719 (566632.125) - AE Rec Loss: 1.467 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 57083.406 (566632.125) - AE Rec Loss: 0.387 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.660 
(2.776) - AE Loss: 128225.914 (586097.125) - AE Rec Loss: 0.870 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.001 (0.845) - Batch(s): 2.305 
(2.776) - AE Loss: 96819.875 (586097.125) - AE Rec Loss: 0.657 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.001 (0.845) - Batch(s): 2.305 
(2.776) - AE Loss: 229928.781 (586097.125) - AE Rec Loss: 1.559 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.657 
(2.776) - AE Loss: 184948.922 (586097.125) - AE Rec Loss: 1.254 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 1.228 (0.845) - Batch(s): 2.661 
(2.776) - AE Loss: 1702895.000 (586097.125) - AE Rec Loss: 11.548 (3.975) - Disc
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 2.090 (0.845) - Batch(s): 2.663 
(2.776) - AE Loss: 1737313.250 (586097.125) - AE Rec Loss: 11.782 (3.975) - Disc
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.567 
(2.499) - AE Loss: 1572479.000 (604359.938) - AE Rec Loss: 10.664 (4.099) - Disc
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.563 
(2.499) - AE Loss: 77950.133 (604359.938) - AE Rec Loss: 0.529 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.001 (0.740) - Batch(s): 0.563 
(2.499) - AE Loss: 1445865.750 (604359.938) - AE Rec Loss: 9.805 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.561 
(2.499) - AE Loss: 67800.992 (604359.938) - AE Rec Loss: 0.460 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.565 
(2.499) - AE Loss: 1578698.750 (604359.938) - AE Rec Loss: 10.706 (4.099) - Disc
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.568 
(2.499) - AE Loss: 176275.844 (604359.938) - AE Rec Loss: 1.195 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.712 
(2.301) - AE Loss: 1409190.125 (567768.250) - AE Rec Loss: 9.557 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.713 
(2.301) - AE Loss: 321873.969 (567768.250) - AE Rec Loss: 2.183 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.712 
(2.301) - AE Loss: 105504.633 (567768.250) - AE Rec Loss: 0.715 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.711 
(2.301) - AE Loss: 148291.734 (567768.250) - AE Rec Loss: 1.006 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.712 
(2.301) - AE Loss: 147327.406 (567768.250) - AE Rec Loss: 0.999 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.714 
(2.301) - AE Loss: 269388.500 (567768.250) - AE Rec Loss: 1.827 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 2.108 (0.633) - Batch(s): 3.112 
(2.409) - AE Loss: 362632.125 (577613.188) - AE Rec Loss: 2.459 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.001 (0.633) - Batch(s): 3.112 
(2.409) - AE Loss: 470854.688 (577613.188) - AE Rec Loss: 3.193 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.001 (0.633) - Batch(s): 3.466 
(2.409) - AE Loss: 1363432.750 (577613.188) - AE Rec Loss: 9.246 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.000 (0.633) - Batch(s): 3.111 
(2.409) - AE Loss: 61539.062 (577613.188) - AE Rec Loss: 0.417 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 2.895 (0.633) - Batch(s): 3.470 
(2.409) - AE Loss: 101796.102 (577613.188) - AE Rec Loss: 0.690 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.001 (0.633) - Batch(s): 3.464 
(2.409) - AE Loss: 332916.562 (577613.188) - AE Rec Loss: 2.258 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.272 
(2.300) - AE Loss: 1489444.000 (578191.250) - AE Rec Loss: 10.101 (3.921) - Disc
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.272 
(2.300) - AE Loss: 320810.531 (578191.250) - AE Rec Loss: 2.176 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.001 (0.576) - Batch(s): 0.565 
(2.300) - AE Loss: 708487.750 (578191.250) - AE Rec Loss: 4.805 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.268 
(2.300) - AE Loss: 156080.031 (578191.250) - AE Rec Loss: 1.058 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.268 
(2.300) - AE Loss: 102544.023 (578191.250) - AE Rec Loss: 0.695 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.272 
(2.300) - AE Loss: 1896193.250 (578191.250) - AE Rec Loss: 12.859 (3.921) - Disc
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 143247.359 (586092.750) - AE Rec Loss: 0.971 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.000 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 81419.062 (586092.750) - AE Rec Loss: 0.552 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 252646.812 (586092.750) - AE Rec Loss: 1.713 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 1389104.875 (586092.750) - AE Rec Loss: 9.420 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 1430811.500 (586092.750) - AE Rec Loss: 9.703 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 447788.906 (586092.750) - AE Rec Loss: 3.037 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.000 (0.524) - Batch(s): 3.332 
(2.274) - AE Loss: 183529.562 (590293.438) - AE Rec Loss: 1.245 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.000 (0.524) - Batch(s): 3.685 
(2.274) - AE Loss: 1459774.000 (590293.438) - AE Rec Loss: 9.900 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.000 (0.524) - Batch(s): 3.332 
(2.274) - AE Loss: 141827.141 (590293.438) - AE Rec Loss: 0.962 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.993 (0.524) - Batch(s): 3.332 
(2.274) - AE Loss: 177514.594 (590293.438) - AE Rec Loss: 1.204 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 3.118 (0.524) - Batch(s): 3.689 
(2.274) - AE Loss: 139249.000 (590293.438) - AE Rec Loss: 0.944 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.000 (0.524) - Batch(s): 3.332 
(2.274) - AE Loss: 1465028.625 (590293.438) - AE Rec Loss: 9.935 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.231 
(2.206) - AE Loss: 149580.531 (602629.250) - AE Rec Loss: 1.014 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.231 
(2.206) - AE Loss: 144682.766 (602629.250) - AE Rec Loss: 0.981 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.231 
(2.206) - AE Loss: 239962.188 (602629.250) - AE Rec Loss: 1.627 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.231 
(2.206) - AE Loss: 2894280.000 (602629.250) - AE Rec Loss: 19.628 (4.087) - Disc
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.230 
(2.206) - AE Loss: 261632.484 (602629.250) - AE Rec Loss: 1.774 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.231 
(2.206) - AE Loss: 442026.531 (602629.250) - AE Rec Loss: 2.998 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.703 
(2.106) - AE Loss: 1392526.250 (640502.688) - AE Rec Loss: 9.444 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.703 
(2.106) - AE Loss: 1419436.500 (640502.688) - AE Rec Loss: 9.626 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.702 
(2.106) - AE Loss: 216188.109 (640502.688) - AE Rec Loss: 1.466 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.704 
(2.106) - AE Loss: 1465733.875 (640502.688) - AE Rec Loss: 9.940 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.704 
(2.106) - AE Loss: 162979.484 (640502.688) - AE Rec Loss: 1.105 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.703 
(2.106) - AE Loss: 1758699.000 (640502.688) - AE Rec Loss: 11.927 (4.344) - Disc
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.544 
(2.398) - AE Loss: 306301.812 (637554.812) - AE Rec Loss: 2.077 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.545 
(2.398) - AE Loss: 2837755.500 (637554.812) - AE Rec Loss: 19.245 (4.324) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 6.327 (0.469) - Batch(s): 6.902 
(2.398) - AE Loss: 163522.047 (637554.812) - AE Rec Loss: 1.109 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.544 
(2.398) - AE Loss: 101960.297 (637554.812) - AE Rec Loss: 0.691 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.626 (0.469) - Batch(s): 6.544 
(2.398) - AE Loss: 232452.234 (637554.812) - AE Rec Loss: 1.576 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.895 
(2.398) - AE Loss: 210060.031 (637554.812) - AE Rec Loss: 1.425 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 1367877.750 (666015.500) - AE Rec Loss: 9.277 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 1369603.375 (666015.500) - AE Rec Loss: 9.288 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 1219135.875 (666015.500) - AE Rec Loss: 8.268 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 2858785.000 (666015.500) - AE Rec Loss: 19.387 (4.517) - Disc
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 1475278.250 (666015.500) - AE Rec Loss: 10.005 (4.517) - Disc
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 1625761.500 (666015.500) - AE Rec Loss: 11.025 (4.517) - Disc
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.001 (0.419) - Batch(s): 0.703 
(2.213) - AE Loss: 208726.172 (659795.875) - AE Rec Loss: 1.416 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.703 
(2.213) - AE Loss: 540010.812 (659795.875) - AE Rec Loss: 3.662 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.001 (0.419) - Batch(s): 0.705 
(2.213) - AE Loss: 1621172.625 (659795.875) - AE Rec Loss: 10.994 (4.475) - Disc
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.705 
(2.213) - AE Loss: 80554.531 (659795.875) - AE Rec Loss: 0.546 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.001 (0.419) - Batch(s): 0.703 
(2.213) - AE Loss: 129728.102 (659795.875) - AE Rec Loss: 0.880 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.705 
(2.213) - AE Loss: 129368.203 (659795.875) - AE Rec Loss: 0.877 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.568 
(2.126) - AE Loss: 123673.430 (651952.500) - AE Rec Loss: 0.839 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.567 
(2.126) - AE Loss: 55072.430 (651952.500) - AE Rec Loss: 0.373 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.563 
(2.126) - AE Loss: 168296.734 (651952.500) - AE Rec Loss: 1.141 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.567 
(2.126) - AE Loss: 1503559.250 (651952.500) - AE Rec Loss: 10.197 (4.421) - Disc
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.568 
(2.126) - AE Loss: 161142.281 (651952.500) - AE Rec Loss: 1.093 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.564 
(2.126) - AE Loss: 118177.953 (651952.500) - AE Rec Loss: 0.801 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.262 
(2.341) - AE Loss: 928587.375 (657132.875) - AE Rec Loss: 6.297 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.262 
(2.341) - AE Loss: 48598.980 (657132.875) - AE Rec Loss: 0.330 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.262 
(2.341) - AE Loss: 139291.812 (657132.875) - AE Rec Loss: 0.945 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.262 
(2.341) - AE Loss: 161506.656 (657132.875) - AE Rec Loss: 1.095 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.261 
(2.341) - AE Loss: 273276.500 (657132.875) - AE Rec Loss: 1.853 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.02 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.262 
(2.341) - AE Loss: 1734075.000 (657132.875) - AE Rec Loss: 11.760 (4.456) - Disc
Loss: 0.000 (0.000) - 4.02 m remaining

attempting to save
[[36m2023-11-29 05:28:42,154[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt[0m
[[36m2023-11-29 05:28:44,179[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:28:44,812[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:28:44,817[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:28:44,822[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:28:44,827[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:28:44,832[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:28:44,837[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:28:44,842[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:28:44,847[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:28:45,573[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:28:51,030[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:28:55,221[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:28:55,228[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer.bin[0m
[[36m2023-11-29 05:28:57,253[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:28:57,254[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler.bin[0m
[[36m2023-11-29 05:28:57,254[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/sampler_1.bin[0m
[[36m2023-11-29 05:28:57,272[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_2.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <401/2280>] - Data(s): 0.001 (0.383) - Batch(s): 16.611 
(2.957) - AE Loss: 1684413.000 (652401.750) - AE Rec Loss: 11.423 (4.424) - Disc
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.611 
(2.957) - AE Loss: 249399.797 (652401.750) - AE Rec Loss: 1.691 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.611 
(2.957) - AE Loss: 118883.141 (652401.750) - AE Rec Loss: 0.806 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.001 (0.383) - Batch(s): 16.611 
(2.957) - AE Loss: 221315.750 (652401.750) - AE Rec Loss: 1.501 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.611 
(2.957) - AE Loss: 230255.734 (652401.750) - AE Rec Loss: 1.562 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.001 (0.383) - Batch(s): 0.654 
(2.957) - AE Loss: 196225.766 (652401.750) - AE Rec Loss: 1.331 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.567 
(2.848) - AE Loss: 173067.484 (666141.000) - AE Rec Loss: 1.174 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.563 
(2.848) - AE Loss: 177221.547 (666141.000) - AE Rec Loss: 1.202 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.563 
(2.848) - AE Loss: 1461823.500 (666141.000) - AE Rec Loss: 9.914 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.567 
(2.848) - AE Loss: 3235513.750 (666141.000) - AE Rec Loss: 21.942 (4.518) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.566 
(2.848) - AE Loss: 212918.297 (666141.000) - AE Rec Loss: 1.444 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.566 
(2.848) - AE Loss: 361086.312 (666141.000) - AE Rec Loss: 2.449 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:36:48,708[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:48,740[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:48,755[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:48,852[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:48,859[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:48,872[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:36:50,872[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:50,909[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:50,963[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:50,985[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:51,000[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:51,279[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,398[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,532[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,654[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,697[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,702[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:51,870[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 05:36:53,039[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:36:53,039[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:36:53,040[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:36:53,040[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 05:36:53,042[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Running in inference mode: False
[[36m2023-11-29 05:36:53,044[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing model 
=> Mixed precision: no
=> Preparing opt_disc 
=> Running in inference mode: False
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
[[36m2023-11-29 05:36:54,737[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 05:36:57,432[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 05:36:58,516[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:36:58,517[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
[[36m2023-11-29 05:36:58,520[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
[[36m2023-11-29 05:36:58,522[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:36:58,523[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 3.123 (5.614) - Batch(s): 11.837 
(11.536) - AE Loss: 196291.297 (557930.312) - AE Rec Loss: 1.331 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 7.478 (5.614) - Batch(s): 11.838 
(11.536) - AE Loss: 118580.773 (557930.312) - AE Rec Loss: 0.804 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 6.295 (5.614) - Batch(s): 11.842 
(11.536) - AE Loss: 1684374.000 (557930.312) - AE Rec Loss: 11.423 (3.784) - 
Disc Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 10.427 (5.614) - Batch(s): 11.854 
(11.536) - AE Loss: 222143.562 (557930.312) - AE Rec Loss: 1.507 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 4.237 (5.614) - Batch(s): 11.837 
(11.536) - AE Loss: 250509.891 (557930.312) - AE Rec Loss: 1.699 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.113 (5.614) - Batch(s): 11.848 
(11.536) - AE Loss: 229318.328 (557930.312) - AE Rec Loss: 1.555 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.197 
(6.470) - AE Loss: 389816.656 (762580.312) - AE Rec Loss: 2.644 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.07 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.849) - Batch(s): 1.198 
(6.470) - AE Loss: 1470107.875 (762580.312) - AE Rec Loss: 9.970 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.07 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.198 
(6.470) - AE Loss: 190829.641 (762580.312) - AE Rec Loss: 1.294 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.07 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.849) - Batch(s): 1.198 
(6.470) - AE Loss: 210770.516 (762580.312) - AE Rec Loss: 1.429 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.07 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.993 (2.849) - Batch(s): 1.552 
(6.470) - AE Loss: 189228.266 (762580.312) - AE Rec Loss: 1.283 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.07 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.198 
(6.470) - AE Loss: 3239651.750 (762580.312) - AE Rec Loss: 21.970 (5.172) - Disc
Loss: 0.000 (0.000) - 1.07 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.002 
(5.315) - AE Loss: 1449953.500 (836624.250) - AE Rec Loss: 9.833 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.965) - Batch(s): 3.002 
(5.315) - AE Loss: 135107.734 (836624.250) - AE Rec Loss: 0.916 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.004 
(5.315) - AE Loss: 319305.969 (836624.250) - AE Rec Loss: 2.165 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.004 
(5.315) - AE Loss: 172040.719 (836624.250) - AE Rec Loss: 1.167 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.003 
(5.315) - AE Loss: 1408394.500 (836624.250) - AE Rec Loss: 9.551 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.003 
(5.315) - AE Loss: 2679413.000 (836624.250) - AE Rec Loss: 18.171 (5.674) - Disc
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.566 
(4.127) - AE Loss: 1287454.125 (813387.312) - AE Rec Loss: 8.731 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.562 
(4.127) - AE Loss: 1767000.750 (813387.312) - AE Rec Loss: 11.983 (5.516) - Disc
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.474) - Batch(s): 0.565 
(4.127) - AE Loss: 48290.328 (813387.312) - AE Rec Loss: 0.327 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.474) - Batch(s): 0.565 
(4.127) - AE Loss: 1620939.250 (813387.312) - AE Rec Loss: 10.993 (5.516) - Disc
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.563 
(4.127) - AE Loss: 1520107.875 (813387.312) - AE Rec Loss: 10.309 (5.516) - Disc
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.561 
(4.127) - AE Loss: 55032.195 (813387.312) - AE Rec Loss: 0.373 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.565 
(3.414) - AE Loss: 209406.094 (763805.375) - AE Rec Loss: 1.420 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.566 
(3.414) - AE Loss: 119289.336 (763805.375) - AE Rec Loss: 0.809 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.561 
(3.414) - AE Loss: 96533.352 (763805.375) - AE Rec Loss: 0.655 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.566 
(3.414) - AE Loss: 1417436.000 (763805.375) - AE Rec Loss: 9.613 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.563 
(3.414) - AE Loss: 95281.852 (763805.375) - AE Rec Loss: 0.646 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.564 
(3.414) - AE Loss: 95687.062 (763805.375) - AE Rec Loss: 0.649 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.42 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 1370579.125 (726684.875) - AE Rec Loss: 9.295 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 193194.547 (726684.875) - AE Rec Loss: 1.310 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 1.091 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 183356.062 (726684.875) - AE Rec Loss: 1.243 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 118168.039 (726684.875) - AE Rec Loss: 0.801 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 1519629.750 (726684.875) - AE Rec Loss: 10.306 (4.928) - Disc
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.966 
(3.506) - AE Loss: 228191.781 (726684.875) - AE Rec Loss: 1.548 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.564 
(3.086) - AE Loss: 1689974.000 (706232.188) - AE Rec Loss: 11.461 (4.789) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.561 
(3.086) - AE Loss: 1551729.500 (706232.188) - AE Rec Loss: 10.523 (4.789) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.565 
(3.086) - AE Loss: 630980.438 (706232.188) - AE Rec Loss: 4.279 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.566 
(3.086) - AE Loss: 133039.953 (706232.188) - AE Rec Loss: 0.902 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.563 
(3.086) - AE Loss: 1778852.750 (706232.188) - AE Rec Loss: 12.064 (4.789) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.562 
(3.086) - AE Loss: 106171.258 (706232.188) - AE Rec Loss: 0.720 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.562 
(2.770) - AE Loss: 179328.125 (655757.688) - AE Rec Loss: 1.216 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.783) - Batch(s): 0.566 
(2.770) - AE Loss: 125221.008 (655757.688) - AE Rec Loss: 0.849 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.567 
(2.770) - AE Loss: 66830.203 (655757.688) - AE Rec Loss: 0.453 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.565 
(2.770) - AE Loss: 1699159.750 (655757.688) - AE Rec Loss: 11.523 (4.447) - Disc
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.783) - Batch(s): 0.564 
(2.770) - AE Loss: 188806.859 (655757.688) - AE Rec Loss: 1.280 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.563 
(2.770) - AE Loss: 352672.562 (655757.688) - AE Rec Loss: 2.392 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.83 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 10.132 (1.122) - Batch(s): 20.049 
(4.690) - AE Loss: 116904.445 (626139.688) - AE Rec Loss: 0.793 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.051 
(4.690) - AE Loss: 323439.125 (626139.688) - AE Rec Loss: 2.193 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 19.404 (1.122) - Batch(s): 20.049 
(4.690) - AE Loss: 61084.391 (626139.688) - AE Rec Loss: 0.414 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 15.355 (1.122) - Batch(s): 20.051 
(4.690) - AE Loss: 103225.242 (626139.688) - AE Rec Loss: 0.700 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 1.113 (1.122) - Batch(s): 20.050 
(4.690) - AE Loss: 1590249.000 (626139.688) - AE Rec Loss: 10.785 (4.246) - Disc
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.050 
(4.690) - AE Loss: 108402.078 (626139.688) - AE Rec Loss: 0.735 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (1.019) - Batch(s): 1.325 
(4.377) - AE Loss: 281897.625 (599013.562) - AE Rec Loss: 1.912 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (1.019) - Batch(s): 1.325 
(4.377) - AE Loss: 379389.375 (599013.562) - AE Rec Loss: 2.573 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.325 
(4.377) - AE Loss: 482020.219 (599013.562) - AE Rec Loss: 3.269 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 1.119 (1.019) - Batch(s): 1.683 
(4.377) - AE Loss: 224708.469 (599013.562) - AE Rec Loss: 1.524 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.678 
(4.377) - AE Loss: 211563.547 (599013.562) - AE Rec Loss: 1.435 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.325 
(4.377) - AE Loss: 170266.562 (599013.562) - AE Rec Loss: 1.155 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.319 
(4.641) - AE Loss: 296089.125 (595574.938) - AE Rec Loss: 2.008 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.786 (0.980) - Batch(s): 7.323 
(4.641) - AE Loss: 216583.828 (595574.938) - AE Rec Loss: 1.469 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.319 
(4.641) - AE Loss: 324605.125 (595574.938) - AE Rec Loss: 2.201 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 6.244 (0.980) - Batch(s): 6.813 
(4.641) - AE Loss: 358854.656 (595574.938) - AE Rec Loss: 2.434 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.322 
(4.641) - AE Loss: 1439260.625 (595574.938) - AE Rec Loss: 9.761 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.323 
(4.641) - AE Loss: 425245.375 (595574.938) - AE Rec Loss: 2.884 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.05 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:39:54,248[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,264[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,448[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,502[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,512[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,517[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:39:56,383[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,390[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,590[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,629[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,671[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,689[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,077[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,083[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,205[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,302[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,311[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,348[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 05:39:57,719[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,719[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 05:39:57,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
[[36m2023-11-29 05:39:57,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
[[36m2023-11-29 05:39:57,722[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Running in inference mode: False
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 05:39:57,725[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing model 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
[[36m2023-11-29 05:39:59,403[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:40:00,773[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:40:01,331[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:40:01,332[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:40:01,334[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
Loaded from checkpoint
=> Starting model training 
[[36m2023-11-29 05:40:01,337[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:40:01,340[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 3.020 (5.421) - Batch(s): 10.507 
(10.632) - AE Loss: 196291.297 (558156.438) - AE Rec Loss: 1.331 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 6.223 (5.421) - Batch(s): 11.131 
(10.632) - AE Loss: 1684632.875 (558156.438) - AE Rec Loss: 11.425 (3.785) - 
Disc Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 7.535 (5.421) - Batch(s): 10.496 
(10.632) - AE Loss: 118953.281 (558156.438) - AE Rec Loss: 0.807 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.137 (5.421) - Batch(s): 10.513 
(10.632) - AE Loss: 231432.469 (558156.438) - AE Rec Loss: 1.570 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.564 (5.421) - Batch(s): 10.712 
(10.632) - AE Loss: 249798.484 (558156.438) - AE Rec Loss: 1.694 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.86 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 8.937 (5.421) - Batch(s): 10.503 
(10.632) - AE Loss: 222232.922 (558156.438) - AE Rec Loss: 1.507 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.711) - Batch(s): 0.565 
(5.597) - AE Loss: 389745.156 (762760.312) - AE Rec Loss: 2.643 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.561 
(5.597) - AE Loss: 210770.516 (762760.312) - AE Rec Loss: 1.429 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.559 
(5.597) - AE Loss: 1470089.000 (762760.312) - AE Rec Loss: 9.970 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.711) - Batch(s): 0.564 
(5.597) - AE Loss: 3239769.250 (762760.312) - AE Rec Loss: 21.971 (5.173) - Disc
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.711) - Batch(s): 0.565 
(5.597) - AE Loss: 192667.922 (762760.312) - AE Rec Loss: 1.307 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.561 
(5.597) - AE Loss: 189933.484 (762760.312) - AE Rec Loss: 1.288 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.91 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.878 
(5.024) - AE Loss: 134760.828 (836722.125) - AE Rec Loss: 0.914 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.877 
(5.024) - AE Loss: 1449856.375 (836722.125) - AE Rec Loss: 9.832 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.878 
(5.024) - AE Loss: 1408394.500 (836722.125) - AE Rec Loss: 9.551 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.878 
(5.024) - AE Loss: 319989.094 (836722.125) - AE Rec Loss: 2.170 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.878 
(5.024) - AE Loss: 171371.547 (836722.125) - AE Rec Loss: 1.162 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.878 
(5.024) - AE Loss: 2679808.500 (836722.125) - AE Rec Loss: 18.174 (5.674) - Disc
Loss: 0.000 (0.000) - 1.22 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.565 
(3.909) - AE Loss: 1287768.500 (813430.000) - AE Rec Loss: 8.733 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.564 
(3.909) - AE Loss: 48097.555 (813430.000) - AE Rec Loss: 0.326 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.562 
(3.909) - AE Loss: 1520023.500 (813430.000) - AE Rec Loss: 10.308 (5.516) - Disc
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.560 
(3.909) - AE Loss: 1766923.750 (813430.000) - AE Rec Loss: 11.983 (5.516) - Disc
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.560 
(3.909) - AE Loss: 55050.508 (813430.000) - AE Rec Loss: 0.373 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.422) - Batch(s): 0.564 
(3.909) - AE Loss: 1620821.000 (813430.000) - AE Rec Loss: 10.992 (5.516) - Disc
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.564 
(3.240) - AE Loss: 1417684.000 (763855.188) - AE Rec Loss: 9.614 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.565 
(3.240) - AE Loss: 209385.203 (763855.188) - AE Rec Loss: 1.420 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.563 
(3.240) - AE Loss: 95614.805 (763855.188) - AE Rec Loss: 0.648 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.564 
(3.240) - AE Loss: 118852.109 (763855.188) - AE Rec Loss: 0.806 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.36 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.560 
(3.240) - AE Loss: 95311.805 (763855.188) - AE Rec Loss: 0.646 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.561 
(3.240) - AE Loss: 96036.664 (763855.188) - AE Rec Loss: 0.651 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.018) - Batch(s): 3.504 
(3.284) - AE Loss: 1519731.000 (726732.125) - AE Rec Loss: 10.306 (4.928) - Disc
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.018) - Batch(s): 3.505 
(3.284) - AE Loss: 193729.594 (726732.125) - AE Rec Loss: 1.314 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.018) - Batch(s): 3.503 
(3.284) - AE Loss: 1370384.375 (726732.125) - AE Rec Loss: 9.294 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.504 
(3.284) - AE Loss: 117672.930 (726732.125) - AE Rec Loss: 0.798 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.018) - Batch(s): 3.505 
(3.284) - AE Loss: 228035.734 (726732.125) - AE Rec Loss: 1.546 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 2.819 (1.018) - Batch(s): 3.504 
(3.284) - AE Loss: 183183.906 (726732.125) - AE Rec Loss: 1.242 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.566 
(2.895) - AE Loss: 1690345.125 (706248.500) - AE Rec Loss: 11.463 (4.790) - Disc
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.561 
(2.895) - AE Loss: 1551803.875 (706248.500) - AE Rec Loss: 10.524 (4.790) - Disc
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.563 
(2.895) - AE Loss: 1778831.500 (706248.500) - AE Rec Loss: 12.063 (4.790) - Disc
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.566 
(2.895) - AE Loss: 631263.688 (706248.500) - AE Rec Loss: 4.281 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.564 
(2.895) - AE Loss: 132148.438 (706248.500) - AE Rec Loss: 0.896 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.560 
(2.895) - AE Loss: 105330.898 (706248.500) - AE Rec Loss: 0.714 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.764) - Batch(s): 0.565 
(2.604) - AE Loss: 125664.023 (655752.750) - AE Rec Loss: 0.852 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.565 
(2.604) - AE Loss: 1699315.125 (655752.750) - AE Rec Loss: 11.524 (4.447) - Disc
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.563 
(2.604) - AE Loss: 188555.719 (655752.750) - AE Rec Loss: 1.279 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.562 
(2.604) - AE Loss: 179358.344 (655752.750) - AE Rec Loss: 1.216 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.565 
(2.604) - AE Loss: 66791.352 (655752.750) - AE Rec Loss: 0.453 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.74 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.764) - Batch(s): 0.561 
(2.604) - AE Loss: 351254.062 (655752.750) - AE Rec Loss: 2.382 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 3.163 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 61062.863 (626104.125) - AE Rec Loss: 0.414 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 116063.430 (626104.125) - AE Rec Loss: 0.787 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 323706.844 (626104.125) - AE Rec Loss: 2.195 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 1590078.250 (626104.125) - AE Rec Loss: 10.783 (4.246) - Disc
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 102704.727 (626104.125) - AE Rec Loss: 0.697 (4.246) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 107665.461 (626104.125) - AE Rec Loss: 0.730 (4.246) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.562 
(2.524) - AE Loss: 211119.844 (598961.438) - AE Rec Loss: 1.432 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.05 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.566 
(2.524) - AE Loss: 224418.016 (598961.438) - AE Rec Loss: 1.522 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.08 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.562 
(2.524) - AE Loss: 480872.594 (598961.438) - AE Rec Loss: 3.261 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (0.640) - Batch(s): 0.564 
(2.524) - AE Loss: 169966.484 (598961.438) - AE Rec Loss: 1.153 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.565 
(2.524) - AE Loss: 281246.438 (598961.438) - AE Rec Loss: 1.907 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.566 
(2.524) - AE Loss: 379756.844 (598961.438) - AE Rec Loss: 2.575 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.959 (0.590) - Batch(s): 1.523 
(2.420) - AE Loss: 218257.500 (595524.625) - AE Rec Loss: 1.480 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.590) - Batch(s): 1.518 
(2.420) - AE Loss: 324392.812 (595524.625) - AE Rec Loss: 2.200 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.590) - Batch(s): 1.186 
(2.420) - AE Loss: 295151.062 (595524.625) - AE Rec Loss: 2.002 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.590) - Batch(s): 1.521 
(2.420) - AE Loss: 1439869.000 (595524.625) - AE Rec Loss: 9.765 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.20 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.103 (0.590) - Batch(s): 1.188 
(2.420) - AE Loss: 425340.938 (595524.625) - AE Rec Loss: 2.885 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.590) - Batch(s): 0.566 
(2.420) - AE Loss: 358966.656 (595524.625) - AE Rec Loss: 2.434 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.059 
(2.390) - AE Loss: 2975591.750 (656665.875) - AE Rec Loss: 20.180 (4.453) - Disc
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.057 
(2.390) - AE Loss: 3125800.500 (656665.875) - AE Rec Loss: 21.198 (4.453) - Disc
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 1.402 (0.558) - Batch(s): 2.057 
(2.390) - AE Loss: 1722581.750 (656665.875) - AE Rec Loss: 11.682 (4.453) - Disc
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.057 
(2.390) - AE Loss: 318665.500 (656665.875) - AE Rec Loss: 2.161 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.37 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.059 
(2.390) - AE Loss: 1608260.875 (656665.875) - AE Rec Loss: 10.907 (4.453) - Disc
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.057 
(2.390) - AE Loss: 1544558.625 (656665.875) - AE Rec Loss: 10.475 (4.453) - Disc
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 3.716 
(2.510) - AE Loss: 192603.438 (639855.188) - AE Rec Loss: 1.306 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 3.716 
(2.510) - AE Loss: 191065.969 (639855.188) - AE Rec Loss: 1.296 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 3.503 (0.537) - Batch(s): 4.074 
(2.510) - AE Loss: 294100.469 (639855.188) - AE Rec Loss: 1.994 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 3.716 
(2.510) - AE Loss: 429466.469 (639855.188) - AE Rec Loss: 2.913 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 3.716 
(2.510) - AE Loss: 76308.492 (639855.188) - AE Rec Loss: 0.518 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 4.067 
(2.510) - AE Loss: 100592.273 (639855.188) - AE Rec Loss: 0.682 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.565 
(2.371) - AE Loss: 388116.031 (651381.812) - AE Rec Loss: 2.632 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.562 
(2.371) - AE Loss: 1747156.750 (651381.812) - AE Rec Loss: 11.849 (4.417) - Disc
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.565 
(2.371) - AE Loss: 1463447.125 (651381.812) - AE Rec Loss: 9.925 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.562 
(2.371) - AE Loss: 148148.172 (651381.812) - AE Rec Loss: 1.005 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.563 
(2.371) - AE Loss: 1587640.625 (651381.812) - AE Rec Loss: 10.767 (4.417) - Disc
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.566 
(2.371) - AE Loss: 3159378.500 (651381.812) - AE Rec Loss: 21.426 (4.417) - Disc
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.652 
(2.257) - AE Loss: 160452.656 (657828.125) - AE Rec Loss: 1.088 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.651 
(2.257) - AE Loss: 1377488.750 (657828.125) - AE Rec Loss: 9.342 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.466) - Batch(s): 0.651 
(2.257) - AE Loss: 78106.805 (657828.125) - AE Rec Loss: 0.530 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.466) - Batch(s): 0.651 
(2.257) - AE Loss: 1376167.375 (657828.125) - AE Rec Loss: 9.333 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.651 
(2.257) - AE Loss: 197930.547 (657828.125) - AE Rec Loss: 1.342 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.651 
(2.257) - AE Loss: 1633678.875 (657828.125) - AE Rec Loss: 11.079 (4.461) - Disc
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 20.959 
(3.440) - AE Loss: 276559.719 (669995.312) - AE Rec Loss: 1.876 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.412 (0.603) - Batch(s): 20.959 
(3.440) - AE Loss: 361303.438 (669995.312) - AE Rec Loss: 2.450 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 20.959 
(3.440) - AE Loss: 1703739.250 (669995.312) - AE Rec Loss: 11.554 (4.544) - Disc
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.310 
(3.440) - AE Loss: 1534702.125 (669995.312) - AE Rec Loss: 10.408 (4.544) - Disc
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 10.793 (0.603) - Batch(s): 20.959 
(3.440) - AE Loss: 639946.188 (669995.312) - AE Rec Loss: 4.340 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 20.740 (0.603) - Batch(s): 21.318 
(3.440) - AE Loss: 231280.359 (669995.312) - AE Rec Loss: 1.568 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.001 (0.568) - Batch(s): 0.567 
(3.271) - AE Loss: 87579.742 (672973.312) - AE Rec Loss: 0.594 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.566 
(3.271) - AE Loss: 101776.414 (672973.312) - AE Rec Loss: 0.690 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.562 
(3.271) - AE Loss: 154568.984 (672973.312) - AE Rec Loss: 1.048 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.564 
(3.271) - AE Loss: 1576555.250 (672973.312) - AE Rec Loss: 10.692 (4.564) - Disc
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.001 (0.568) - Batch(s): 0.565 
(3.271) - AE Loss: 174408.328 (672973.312) - AE Rec Loss: 1.183 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.562 
(3.271) - AE Loss: 212701.953 (672973.312) - AE Rec Loss: 1.442 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.656 
(3.126) - AE Loss: 264204.688 (671468.812) - AE Rec Loss: 1.792 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.656 
(3.126) - AE Loss: 1592055.500 (671468.812) - AE Rec Loss: 10.797 (4.554) - Disc
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.656 
(3.126) - AE Loss: 44138.742 (671468.812) - AE Rec Loss: 0.299 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.657 
(3.126) - AE Loss: 151069.438 (671468.812) - AE Rec Loss: 1.025 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.657 
(3.126) - AE Loss: 287825.156 (671468.812) - AE Rec Loss: 1.952 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.657 
(3.126) - AE Loss: 1412047.250 (671468.812) - AE Rec Loss: 9.576 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.001 (0.531) - Batch(s): 5.370 
(3.256) - AE Loss: 239413.266 (671042.938) - AE Rec Loss: 1.624 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.370 
(3.256) - AE Loss: 58246.664 (671042.938) - AE Rec Loss: 0.395 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.370 
(3.256) - AE Loss: 129332.445 (671042.938) - AE Rec Loss: 0.877 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.722 
(3.256) - AE Loss: 1623380.375 (671042.938) - AE Rec Loss: 11.009 (4.551) - Disc
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 5.158 (0.531) - Batch(s): 5.728 
(3.256) - AE Loss: 376037.500 (671042.938) - AE Rec Loss: 2.550 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.001 (0.531) - Batch(s): 5.370 
(3.256) - AE Loss: 65547.805 (671042.938) - AE Rec Loss: 0.445 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.567 
(3.122) - AE Loss: 595396.750 (667590.875) - AE Rec Loss: 4.038 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.563 
(3.122) - AE Loss: 144821.797 (667590.875) - AE Rec Loss: 0.982 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.568 
(3.122) - AE Loss: 165071.609 (667590.875) - AE Rec Loss: 1.119 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.565 
(3.122) - AE Loss: 197390.438 (667590.875) - AE Rec Loss: 1.339 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.001 (0.504) - Batch(s): 0.562 
(3.122) - AE Loss: 1565725.750 (667590.875) - AE Rec Loss: 10.618 (4.527) - Disc
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.565 
(3.122) - AE Loss: 1405382.000 (667590.875) - AE Rec Loss: 9.531 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

attempting to save
[[36m2023-11-29 05:41:08,279[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 05:41:11,049[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:41:11,398[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:41:11,438[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:41:11,467[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:41:11,487[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:41:11,505[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:41:11,519[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:41:11,536[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:41:11,549[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:41:12,354[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:41:27,775[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:27,795[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:27,933[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,039[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,080[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,471[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:41:29,936[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:29,947[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,184[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,222[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,226[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:30,471[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 5[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:30,493[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2023-11-29 05:41:30,652[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:30,786[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 2[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:30,844[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 1[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:30,847[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 3[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:31,079[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 4[0m
[[36m2023-11-29 05:41:31,696[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:41:31,696[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:41:31,697[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:41:31,697[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
[[36m2023-11-29 05:41:31,700[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating the optimizer 
[[36m2023-11-29 05:41:31,703[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Preparing model 
=> Preparing opt_disc 
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
[[36m2023-11-29 05:41:33,354[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading states from /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/latest.pt[0m
[[36m2023-11-29 05:41:34,298[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All model weights loaded successfully[0m
[[36m2023-11-29 05:41:34,695[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All optimizer states loaded successfully[0m
[[36m2023-11-29 05:41:34,696[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All scheduler states loaded successfully[0m
[[36m2023-11-29 05:41:34,696[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All dataloader sampler states loaded successfully[0m
[[36m2023-11-29 05:41:34,698[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - All random states loaded successfully[0m
[[36m2023-11-29 05:41:34,701[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Loading in 0 custom states[0m
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 3.870 (5.543) - Batch(s): 11.516 
(11.648) - AE Loss: 229218.578 (557868.688) - AE Rec Loss: 1.554 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 5.766 (5.543) - Batch(s): 11.546 
(11.648) - AE Loss: 117945.211 (557868.688) - AE Rec Loss: 0.800 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 7.736 (5.543) - Batch(s): 11.651 
(11.648) - AE Loss: 1684431.750 (557868.688) - AE Rec Loss: 11.423 (3.783) - 
Disc Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.453 (5.543) - Batch(s): 12.087 
(11.648) - AE Loss: 196291.297 (557868.688) - AE Rec Loss: 1.331 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 9.093 (5.543) - Batch(s): 11.829 
(11.648) - AE Loss: 221327.734 (557868.688) - AE Rec Loss: 1.501 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.94 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.813 (5.543) - Batch(s): 11.511 
(11.648) - AE Loss: 250072.406 (557868.688) - AE Rec Loss: 1.696 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.565 
(6.106) - AE Loss: 210770.516 (762433.250) - AE Rec Loss: 1.429 (5.171) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.566 
(6.106) - AE Loss: 388296.625 (762433.250) - AE Rec Loss: 2.633 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.97 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.563 
(6.106) - AE Loss: 1469847.000 (762433.250) - AE Rec Loss: 9.968 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.97 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.561 
(6.106) - AE Loss: 189671.297 (762433.250) - AE Rec Loss: 1.286 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.97 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.565 
(6.106) - AE Loss: 191671.047 (762433.250) - AE Rec Loss: 1.300 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.98 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.566 
(6.106) - AE Loss: 3239467.500 (762433.250) - AE Rec Loss: 21.969 (5.171) - Disc
Loss: 0.000 (0.000) - 1.00 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.951) - Batch(s): 2.887 
(5.034) - AE Loss: 1408394.500 (836485.750) - AE Rec Loss: 9.551 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.25 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.888 
(5.034) - AE Loss: 134800.062 (836485.750) - AE Rec Loss: 0.914 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.888 
(5.034) - AE Loss: 1449753.500 (836485.750) - AE Rec Loss: 9.832 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.888 
(5.034) - AE Loss: 319326.469 (836485.750) - AE Rec Loss: 2.166 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.888 
(5.034) - AE Loss: 2679632.500 (836485.750) - AE Rec Loss: 18.172 (5.673) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 1.483 (1.951) - Batch(s): 2.889 
(5.034) - AE Loss: 172268.391 (836485.750) - AE Rec Loss: 1.168 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.22 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.464) - Batch(s): 0.568 
(3.917) - AE Loss: 47944.062 (813251.188) - AE Rec Loss: 0.325 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.563 
(3.917) - AE Loss: 54368.215 (813251.188) - AE Rec Loss: 0.369 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.464) - Batch(s): 0.562 
(3.917) - AE Loss: 1767098.625 (813251.188) - AE Rec Loss: 11.984 (5.515) - Disc
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.464) - Batch(s): 0.566 
(3.917) - AE Loss: 1287818.125 (813251.188) - AE Rec Loss: 8.734 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.565 
(3.917) - AE Loss: 1519976.000 (813251.188) - AE Rec Loss: 10.308 (5.515) - Disc
Loss: 0.000 (0.000) - 1.30 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.566 
(3.917) - AE Loss: 1620483.625 (813251.188) - AE Rec Loss: 10.990 (5.515) - Disc
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.565 
(3.246) - AE Loss: 1417171.500 (763759.312) - AE Rec Loss: 9.611 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.001 (1.171) - Batch(s): 0.567 
(3.246) - AE Loss: 95563.969 (763759.312) - AE Rec Loss: 0.648 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.564 
(3.246) - AE Loss: 119080.875 (763759.312) - AE Rec Loss: 0.808 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.564 
(3.246) - AE Loss: 96802.273 (763759.312) - AE Rec Loss: 0.656 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.568 
(3.246) - AE Loss: 209020.219 (763759.312) - AE Rec Loss: 1.418 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.33 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.563 
(3.246) - AE Loss: 95761.430 (763759.312) - AE Rec Loss: 0.649 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.666 
(3.316) - AE Loss: 227907.109 (726589.438) - AE Rec Loss: 1.546 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 3.025 (1.076) - Batch(s): 3.665 
(3.316) - AE Loss: 182454.594 (726589.438) - AE Rec Loss: 1.237 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.076) - Batch(s): 3.665 
(3.316) - AE Loss: 1519158.375 (726589.438) - AE Rec Loss: 10.302 (4.927) - Disc
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.667 
(3.316) - AE Loss: 193089.953 (726589.438) - AE Rec Loss: 1.309 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.076) - Batch(s): 3.668 
(3.316) - AE Loss: 117743.555 (726589.438) - AE Rec Loss: 0.798 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 1.738 (1.076) - Batch(s): 3.670 
(3.316) - AE Loss: 1369776.625 (726589.438) - AE Rec Loss: 9.289 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.565 
(2.923) - AE Loss: 1778834.000 (706129.312) - AE Rec Loss: 12.063 (4.789) - Disc
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.001 (0.922) - Batch(s): 0.564 
(2.923) - AE Loss: 1551777.875 (706129.312) - AE Rec Loss: 10.524 (4.789) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.562 
(2.923) - AE Loss: 105584.398 (706129.312) - AE Rec Loss: 0.716 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.567 
(2.923) - AE Loss: 631549.750 (706129.312) - AE Rec Loss: 4.283 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.565 
(2.923) - AE Loss: 1690475.875 (706129.312) - AE Rec Loss: 11.464 (4.789) - Disc
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.565 
(2.923) - AE Loss: 132942.516 (706129.312) - AE Rec Loss: 0.902 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.566 
(2.628) - AE Loss: 188651.359 (655652.688) - AE Rec Loss: 1.279 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.74 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.564 
(2.628) - AE Loss: 179274.641 (655652.688) - AE Rec Loss: 1.216 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.568 
(2.628) - AE Loss: 1699522.625 (655652.688) - AE Rec Loss: 11.526 (4.446) - Disc
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.562 
(2.628) - AE Loss: 352119.500 (655652.688) - AE Rec Loss: 2.388 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.565 
(2.628) - AE Loss: 125052.234 (655652.688) - AE Rec Loss: 0.848 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.807) - Batch(s): 0.566 
(2.628) - AE Loss: 67218.031 (655652.688) - AE Rec Loss: 0.456 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 2.003 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 60831.020 (626007.500) - AE Rec Loss: 0.413 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 1590160.500 (626007.500) - AE Rec Loss: 10.784 (4.245) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.642 
(2.630) - AE Loss: 102759.047 (626007.500) - AE Rec Loss: 0.697 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.001 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 116529.234 (626007.500) - AE Rec Loss: 0.790 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 108111.656 (626007.500) - AE Rec Loss: 0.733 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.647 
(2.630) - AE Loss: 323080.906 (626007.500) - AE Rec Loss: 2.191 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.93 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.563 
(2.424) - AE Loss: 169849.281 (598853.688) - AE Rec Loss: 1.152 (4.061) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.566 
(2.424) - AE Loss: 224238.188 (598853.688) - AE Rec Loss: 1.521 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.566 
(2.424) - AE Loss: 280971.750 (598853.688) - AE Rec Loss: 1.905 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.563 
(2.424) - AE Loss: 211641.172 (598853.688) - AE Rec Loss: 1.435 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.563 
(2.424) - AE Loss: 480729.781 (598853.688) - AE Rec Loss: 3.260 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.568 
(2.424) - AE Loss: 379275.406 (598853.688) - AE Rec Loss: 2.572 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 1.768 (0.616) - Batch(s): 2.341 
(2.404) - AE Loss: 216379.609 (595402.688) - AE Rec Loss: 1.467 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.337 
(2.404) - AE Loss: 1439551.000 (595402.688) - AE Rec Loss: 9.763 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.616) - Batch(s): 1.429 
(2.404) - AE Loss: 358492.438 (595402.688) - AE Rec Loss: 2.431 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.616) - Batch(s): 1.982 
(2.404) - AE Loss: 424915.625 (595402.688) - AE Rec Loss: 2.882 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.983 
(2.404) - AE Loss: 295394.688 (595402.688) - AE Rec Loss: 2.003 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.335 
(2.404) - AE Loss: 324409.594 (595402.688) - AE Rec Loss: 2.200 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.618 
(2.338) - AE Loss: 1608229.500 (656528.812) - AE Rec Loss: 10.907 (4.452) - Disc
Loss: 0.000 (0.000) - 2.31 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.617 
(2.338) - AE Loss: 3126197.250 (656528.812) - AE Rec Loss: 21.201 (4.452) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.618 
(2.338) - AE Loss: 318205.000 (656528.812) - AE Rec Loss: 2.158 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.617 
(2.338) - AE Loss: 2975813.500 (656528.812) - AE Rec Loss: 20.181 (4.452) - Disc
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.618 
(2.338) - AE Loss: 1544409.750 (656528.812) - AE Rec Loss: 10.474 (4.452) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.619 
(2.338) - AE Loss: 1721912.500 (656528.812) - AE Rec Loss: 11.677 (4.452) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.175 
(2.421) - AE Loss: 428824.281 (639690.062) - AE Rec Loss: 2.908 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.526 
(2.421) - AE Loss: 99584.508 (639690.062) - AE Rec Loss: 0.675 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.448 (0.549) - Batch(s): 3.175 
(2.421) - AE Loss: 76376.461 (639690.062) - AE Rec Loss: 0.518 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 2.961 (0.549) - Batch(s): 3.532 
(2.421) - AE Loss: 293038.594 (639690.062) - AE Rec Loss: 1.987 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.174 
(2.421) - AE Loss: 190248.781 (639690.062) - AE Rec Loss: 1.290 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.175 
(2.421) - AE Loss: 193717.859 (639690.062) - AE Rec Loss: 1.314 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.563 
(2.288) - AE Loss: 147586.469 (651182.688) - AE Rec Loss: 1.001 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.565 
(2.288) - AE Loss: 1587441.125 (651182.688) - AE Rec Loss: 10.766 (4.416) - Disc
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.568 
(2.288) - AE Loss: 3158977.000 (651182.688) - AE Rec Loss: 21.423 (4.416) - Disc
Loss: 0.000 (0.000) - 2.61 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.564 
(2.288) - AE Loss: 1747046.625 (651182.688) - AE Rec Loss: 11.848 (4.416) - Disc
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.566 
(2.288) - AE Loss: 387707.094 (651182.688) - AE Rec Loss: 2.629 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.565 
(2.288) - AE Loss: 1463015.000 (651182.688) - AE Rec Loss: 9.922 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.644 
(2.179) - AE Loss: 1633660.750 (657620.250) - AE Rec Loss: 11.079 (4.460) - Disc
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.644 
(2.179) - AE Loss: 77542.195 (657620.250) - AE Rec Loss: 0.526 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.645 
(2.179) - AE Loss: 197697.766 (657620.250) - AE Rec Loss: 1.341 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.646 
(2.179) - AE Loss: 1377258.500 (657620.250) - AE Rec Loss: 9.340 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.645 
(2.179) - AE Loss: 160320.578 (657620.250) - AE Rec Loss: 1.087 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.645 
(2.179) - AE Loss: 1376021.500 (657620.250) - AE Rec Loss: 9.332 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.457 
(2.211) - AE Loss: 276515.750 (669812.938) - AE Rec Loss: 1.875 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.808 
(2.211) - AE Loss: 1534382.750 (669812.938) - AE Rec Loss: 10.406 (4.542) - Disc
Loss: 0.000 (0.000) - 2.85 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.457 
(2.211) - AE Loss: 640222.938 (669812.938) - AE Rec Loss: 4.342 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 2.241 (0.458) - Batch(s): 2.815 
(2.211) - AE Loss: 231769.578 (669812.938) - AE Rec Loss: 1.572 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.457 
(2.211) - AE Loss: 1704340.500 (669812.938) - AE Rec Loss: 11.558 (4.542) - Disc
Loss: 0.000 (0.000) - 2.88 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.457 
(2.211) - AE Loss: 361382.219 (669812.938) - AE Rec Loss: 2.451 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.563 
(2.114) - AE Loss: 213530.266 (672827.375) - AE Rec Loss: 1.448 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.001 (0.431) - Batch(s): 0.567 
(2.114) - AE Loss: 102252.617 (672827.375) - AE Rec Loss: 0.693 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.565 
(2.114) - AE Loss: 1577239.250 (672827.375) - AE Rec Loss: 10.696 (4.563) - Disc
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.566 
(2.114) - AE Loss: 174691.328 (672827.375) - AE Rec Loss: 1.185 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.568 
(2.114) - AE Loss: 87576.117 (672827.375) - AE Rec Loss: 0.594 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.564 
(2.114) - AE Loss: 155106.328 (672827.375) - AE Rec Loss: 1.052 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 1412558.750 (671362.812) - AE Rec Loss: 9.580 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 45515.023 (671362.812) - AE Rec Loss: 0.309 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 1592794.625 (671362.812) - AE Rec Loss: 10.802 (4.553) - Disc
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.412) - Batch(s): 1.682 
(2.090) - AE Loss: 264371.281 (671362.812) - AE Rec Loss: 1.793 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 151794.766 (671362.812) - AE Rec Loss: 1.029 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.683 
(2.090) - AE Loss: 287724.812 (671362.812) - AE Rec Loss: 1.951 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 66033.047 (670969.938) - AE Rec Loss: 0.448 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 239112.438 (670969.938) - AE Rec Loss: 1.622 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.859 
(2.027) - AE Loss: 377361.188 (670969.938) - AE Rec Loss: 2.559 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 129674.273 (670969.938) - AE Rec Loss: 0.879 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 58503.273 (670969.938) - AE Rec Loss: 0.397 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 1623383.250 (670969.938) - AE Rec Loss: 11.009 (4.550) - Disc
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.929 
(1.980) - AE Loss: 1566720.250 (667535.562) - AE Rec Loss: 10.625 (4.527) - Disc
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.930 
(1.980) - AE Loss: 1405438.750 (667535.562) - AE Rec Loss: 9.531 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.930 
(1.980) - AE Loss: 199072.484 (667535.562) - AE Rec Loss: 1.350 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.930 
(1.980) - AE Loss: 166135.641 (667535.562) - AE Rec Loss: 1.127 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.929 
(1.980) - AE Loss: 145788.812 (667535.562) - AE Rec Loss: 0.989 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.930 
(1.980) - AE Loss: 595741.375 (667535.562) - AE Rec Loss: 4.040 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

attempting to save
[[36m2023-11-29 05:42:19,827[0m][[34maccelerate.accelerator[0m][[32mINFO[0m] - Saving current state to /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt[0m
[[36m2023-11-29 05:42:20,661[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model.bin[0m
[[36m2023-11-29 05:42:21,060[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_1.bin[0m
[[36m2023-11-29 05:42:21,067[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_2.bin[0m
[[36m2023-11-29 05:42:21,078[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_3.bin[0m
[[36m2023-11-29 05:42:21,084[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_4.bin[0m
[[36m2023-11-29 05:42:21,095[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_5.bin[0m
[[36m2023-11-29 05:42:21,106[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_6.bin[0m
[[36m2023-11-29 05:42:21,117[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_7.bin[0m
[[36m2023-11-29 05:42:21,127[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_8.bin[0m
[[36m2023-11-29 05:42:23,138[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_9.bin[0m
[[36m2023-11-29 05:42:26,499[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_10.bin[0m
[[36m2023-11-29 05:42:31,299[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Model weights saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/pytorch_model_11.bin[0m
[[36m2023-11-29 05:42:31,317[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer.bin[0m
[[36m2023-11-29 05:42:33,827[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Optimizer state saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/optimizer_1.bin[0m
[[36m2023-11-29 05:42:33,827[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 0 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler.bin[0m
[[36m2023-11-29 05:42:33,827[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Sampler state for dataloader 1 saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/sampler_1.bin[0m
[[36m2023-11-29 05:42:33,837[0m][[34maccelerate.checkpointing[0m][[32mINFO[0m] - Random states saved in /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/checkpoints/state_1.pt/random_states_0.pkl[0m
done saving state
[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.481 
(2.564) - AE Loss: 314627.062 (656640.125) - AE Rec Loss: 2.134 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.001 (0.360) - Batch(s): 0.633 
(2.564) - AE Loss: 1475928.250 (656640.125) - AE Rec Loss: 10.009 (4.453) - Disc
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.481 
(2.564) - AE Loss: 430758.125 (656640.125) - AE Rec Loss: 2.921 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.481 
(2.564) - AE Loss: 102707.633 (656640.125) - AE Rec Loss: 0.697 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.243 (0.360) - Batch(s): 15.481 
(2.564) - AE Loss: 102810.297 (656640.125) - AE Rec Loss: 0.697 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.481 
(2.564) - AE Loss: 305334.000 (656640.125) - AE Rec Loss: 2.071 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.566 
(2.473) - AE Loss: 56277.516 (642935.500) - AE Rec Loss: 0.382 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.563 
(2.473) - AE Loss: 64416.645 (642935.500) - AE Rec Loss: 0.437 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.567 
(2.473) - AE Loss: 210150.422 (642935.500) - AE Rec Loss: 1.425 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.564 
(2.473) - AE Loss: 142863.141 (642935.500) - AE Rec Loss: 0.969 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.570 
(2.473) - AE Loss: 49187.250 (642935.500) - AE Rec Loss: 0.334 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.566 
(2.473) - AE Loss: 198422.047 (642935.500) - AE Rec Loss: 1.346 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.567 
(2.390) - AE Loss: 586333.938 (640218.062) - AE Rec Loss: 3.976 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.569 
(2.390) - AE Loss: 402404.094 (640218.062) - AE Rec Loss: 2.729 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.567 
(2.390) - AE Loss: 181409.797 (640218.062) - AE Rec Loss: 1.230 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.567 
(2.390) - AE Loss: 176180.609 (640218.062) - AE Rec Loss: 1.195 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.563 
(2.390) - AE Loss: 120687.359 (640218.062) - AE Rec Loss: 0.818 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.001 (0.328) - Batch(s): 0.564 
(2.390) - AE Loss: 58854.641 (640218.062) - AE Rec Loss: 0.399 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.642 
(2.317) - AE Loss: 365214.719 (631876.125) - AE Rec Loss: 2.477 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.642 
(2.317) - AE Loss: 445101.250 (631876.125) - AE Rec Loss: 3.019 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.642 
(2.317) - AE Loss: 1467378.500 (631876.125) - AE Rec Loss: 9.951 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.642 
(2.317) - AE Loss: 72380.445 (631876.125) - AE Rec Loss: 0.491 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.643 
(2.317) - AE Loss: 52768.992 (631876.125) - AE Rec Loss: 0.358 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.001 (0.315) - Batch(s): 0.643 
(2.317) - AE Loss: 159394.609 (631876.125) - AE Rec Loss: 1.081 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.566 
(2.247) - AE Loss: 68272.359 (625146.500) - AE Rec Loss: 0.463 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.570 
(2.247) - AE Loss: 97423.438 (625146.500) - AE Rec Loss: 0.661 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.55 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.001 (0.302) - Batch(s): 0.564 
(2.247) - AE Loss: 51186.461 (625146.500) - AE Rec Loss: 0.347 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.001 (0.302) - Batch(s): 0.568 
(2.247) - AE Loss: 56062.578 (625146.500) - AE Rec Loss: 0.380 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.563 
(2.247) - AE Loss: 160808.562 (625146.500) - AE Rec Loss: 1.091 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.247) - AE Loss: 1706574.250 (625146.500) - AE Rec Loss: 11.573 (4.240) - Disc
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.567 
(2.182) - AE Loss: 614488.188 (628714.688) - AE Rec Loss: 4.167 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.571 
(2.182) - AE Loss: 1906427.250 (628714.688) - AE Rec Loss: 12.929 (4.264) - Disc
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.570 
(2.182) - AE Loss: 1449419.750 (628714.688) - AE Rec Loss: 9.830 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.564 
(2.182) - AE Loss: 329533.938 (628714.688) - AE Rec Loss: 2.235 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.569 
(2.182) - AE Loss: 98769.617 (628714.688) - AE Rec Loss: 0.670 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.567 
(2.182) - AE Loss: 112581.203 (628714.688) - AE Rec Loss: 0.763 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 496390.688 (626028.000) - AE Rec Loss: 3.366 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.001 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 1408508.250 (626028.000) - AE Rec Loss: 9.552 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.001 (0.280) - Batch(s): 0.647 
(2.126) - AE Loss: 466813.562 (626028.000) - AE Rec Loss: 3.166 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.65 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.001 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 1442332.500 (626028.000) - AE Rec Loss: 9.781 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.647 
(2.126) - AE Loss: 396219.062 (626028.000) - AE Rec Loss: 2.687 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.001 (0.280) - Batch(s): 0.647 
(2.126) - AE Loss: 112554.367 (626028.000) - AE Rec Loss: 0.763 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.63 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 2.148 (0.304) - Batch(s): 2.907 
(2.154) - AE Loss: 62250.328 (624615.312) - AE Rec Loss: 0.422 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 2.337 (0.304) - Batch(s): 2.911 
(2.154) - AE Loss: 49634.555 (624615.312) - AE Rec Loss: 0.337 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 2.013 (0.304) - Batch(s): 2.911 
(2.154) - AE Loss: 63582.312 (624615.312) - AE Rec Loss: 0.431 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 2.367 (0.304) - Batch(s): 2.937 
(2.154) - AE Loss: 1407689.500 (624615.312) - AE Rec Loss: 9.547 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 1.248 (0.304) - Batch(s): 2.908 
(2.154) - AE Loss: 184487.453 (624615.312) - AE Rec Loss: 1.251 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.547 (0.304) - Batch(s): 2.907 
(2.154) - AE Loss: 1628805.125 (624615.312) - AE Rec Loss: 11.046 (4.236) - Disc
Loss: 0.000 (0.000) - 4.82 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
