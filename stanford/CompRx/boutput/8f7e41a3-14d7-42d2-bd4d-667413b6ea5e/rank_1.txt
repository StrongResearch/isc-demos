WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:47:23,829[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:23,840[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:24,051[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:24,239[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:24,255[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:47:24,260[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:47:26,033[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:26,093[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:26,267[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:26,457[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,483[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,512[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 02:47:26,519[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:47:26,567[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,731[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:26,897[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:27,006[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:47:27,048[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 02:47:27,051[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 02:47:27,055[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Running in inference mode: False
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 02:47:27,060[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:47:27,060[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:47:27,060[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 02:47:27,061[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1 on node 9
Reached 1.2 on node 9
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:51:58,824[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,937[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,964[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,981[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:58,994[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:51:59,000[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:52:01,028[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:01,102[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:01,211[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:01,219[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:01,234[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:52:01,235[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,485[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,641[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,771[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 02:52:01,781[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:52:01,803[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 02:52:01,806[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 02:52:01,808[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 02:52:01,810[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
[[36m2023-11-29 02:52:01,812[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
[[36m2023-11-29 02:52:01,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:52:01,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Running in inference mode: False
len(train_dataset) = 54706
=> Preparing model 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
[[36m2023-11-29 02:52:01,819[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.3 on node 6Reached end on node 10

Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 5 on node 6
Reached end on node 6
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
=> Preparing criterion 
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 9=> Preparing opt_ae 
=> Preparing opt_ae 

Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6Reached 3 on node 7

Reached 5 on node 6Reached 5 on node 7

Reached end on node 6Reached end on node 7

=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 9
Reached 1 on node 10
Reached 1.2 on node 9
Reached 1.2 on node 10
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11Reached 1.3 on node 8

Reached 1.4 on node 8Reached 1.4 on node 11

Reached 2 on node 8Reached 2 on node 11

Reached 3 on node 11
Reached 3 on node 8
Reached 1.3 on node 9Reached 5 on node 11
Reached 5 on node 8

Reached 1.4 on node 9
Reached end on node 8Reached end on node 11

Reached 1.3 on node 7Reached 2 on node 9Reached 1.3 on node 6


Reached 1.4 on node 7
Reached 1.4 on node 6
Reached 2 on node 7
Reached 2 on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached 3 on node 7Reached 3 on node 6

Reached end on node 9Reached 1.3 on node 10Reached 5 on node 6Reached 5 on node 7



Reached 1.4 on node 10
Reached end on node 7Reached end on node 6

Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
Loaded checkpoint at epoch 0 and step 21
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 6
Reached 2 on node 7
Reached 2 on node 6
Reached 1 on node 8Reached 1 on node 6

Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7Reached 1.4 on node 8

Reached 2 on node 7Reached 2 on node 8

Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6Reached 1 on node 7

Reached 1 on node 8Reached 2 on node 6

Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 6

Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 11
Reached 3 on node 6Reached 1 on node 8Reached 1.4 on node 7
Reached 2 on node 11


Reached 3 on node 6Reached 2 on node 7

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1.4 on node 8
Reached 5 on node 6
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 7

Reached 1 on node 8
Reached 1.4 on node 7
Reached 1.4 on node 11
Reached 2 on node 7
Reached 2 on node 11
Reached 1.4 on node 8Reached 3 on node 7

Reached 2 on node 8Reached 3 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 10Reached 5 on node 7

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10Reached 3 on node 8

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached end on node 6Reached 3 on node 10

Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 1 on node 11Reached 2 on node 6

Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 11
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <021/2280>] - Data(s): 8.716 (5.497) - Batch(s): 11.588 
(11.363) - AE Loss: 651059.375 (564913.250) - AE Rec Loss: 4.415 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.30 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 5.604 (5.497) - Batch(s): 11.226 
(11.363) - AE Loss: 134120.875 (564913.250) - AE Rec Loss: 0.910 (3.831) - Disc 
Loss: 0.000 (0.000) - 19.65 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 4.660 (5.497) - Batch(s): 11.544 
(11.363) - AE Loss: 324857.281 (564913.250) - AE Rec Loss: 2.203 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.21 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 6.469 (5.497) - Batch(s): 11.515 
(11.363) - AE Loss: 132367.781 (564913.250) - AE Rec Loss: 0.898 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.19 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 6.129 (5.497) - Batch(s): 11.460 
(11.363) - AE Loss: 428477.250 (564913.250) - AE Rec Loss: 2.906 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.10 m remaining

[Epoch <000/100>: Step <021/2280>] - Data(s): 4.238 (5.497) - Batch(s): 11.490 
(11.363) - AE Loss: 253465.109 (564913.250) - AE Rec Loss: 1.719 (3.831) - Disc 
Loss: 0.000 (0.000) - 20.14 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.565 
(5.963) - AE Loss: 242428.375 (705908.938) - AE Rec Loss: 1.644 (4.787) - Disc 
Loss: 0.000 (0.000) - 20.52 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.552 
(5.963) - AE Loss: 1897770.250 (705908.938) - AE Rec Loss: 12.870 (4.787) - Disc
Loss: 0.000 (0.000) - 20.50 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.569 
(5.963) - AE Loss: 1785958.750 (705908.938) - AE Rec Loss: 12.112 (4.787) - Disc
Loss: 0.000 (0.000) - 20.61 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.001 (2.749) - Batch(s): 0.564 
(5.963) - AE Loss: 193490.719 (705908.938) - AE Rec Loss: 1.312 (4.787) - Disc 
Loss: 0.000 (0.000) - 19.98 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.563 
(5.963) - AE Loss: 129308.797 (705908.938) - AE Rec Loss: 0.877 (4.787) - Disc 
Loss: 0.000 (0.000) - 20.45 m remaining

[Epoch <000/100>: Step <022/2280>] - Data(s): 0.000 (2.749) - Batch(s): 0.562 
(5.963) - AE Loss: 1711564.750 (705908.938) - AE Rec Loss: 11.607 (4.787) - Disc
Loss: 0.000 (0.000) - 20.41 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.971 
(5.632) - AE Loss: 385513.812 (705409.875) - AE Rec Loss: 2.614 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.58 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.972 
(5.632) - AE Loss: 137696.594 (705409.875) - AE Rec Loss: 0.934 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.67 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.971 
(5.632) - AE Loss: 307414.531 (705409.875) - AE Rec Loss: 2.085 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.68 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.972 
(5.632) - AE Loss: 1812530.750 (705409.875) - AE Rec Loss: 12.292 (4.784) - Disc
Loss: 0.000 (0.000) - 27.77 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.971 
(5.632) - AE Loss: 280505.062 (705409.875) - AE Rec Loss: 1.902 (4.784) - Disc 
Loss: 0.000 (0.000) - 27.62 m remaining

[Epoch <000/100>: Step <023/2280>] - Data(s): 0.000 (1.996) - Batch(s): 4.971 
(5.632) - AE Loss: 2047927.750 (705409.875) - AE Rec Loss: 13.888 (4.784) - Disc
Loss: 0.000 (0.000) - 27.17 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.566 
(4.366) - AE Loss: 245470.594 (712598.250) - AE Rec Loss: 1.665 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.66 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.554 
(4.366) - AE Loss: 243153.781 (712598.250) - AE Rec Loss: 1.649 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.64 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.571 
(4.366) - AE Loss: 569170.625 (712598.250) - AE Rec Loss: 3.860 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.74 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.565 
(4.366) - AE Loss: 444683.625 (712598.250) - AE Rec Loss: 3.016 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.59 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.564 
(4.366) - AE Loss: 424118.781 (712598.250) - AE Rec Loss: 2.876 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.56 m remaining

[Epoch <000/100>: Step <024/2280>] - Data(s): 0.000 (1.497) - Batch(s): 0.565 
(4.366) - AE Loss: 346235.500 (712598.250) - AE Rec Loss: 2.348 (4.833) - Disc 
Loss: 0.000 (0.000) - 27.17 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.565 
(3.605) - AE Loss: 1782002.500 (733957.312) - AE Rec Loss: 12.085 (4.977) - Disc
Loss: 0.000 (0.000) - 27.58 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.554 
(3.605) - AE Loss: 422659.125 (733957.312) - AE Rec Loss: 2.866 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.63 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.565 
(3.605) - AE Loss: 231123.000 (733957.312) - AE Rec Loss: 1.567 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.17 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.564 
(3.605) - AE Loss: 1744149.250 (733957.312) - AE Rec Loss: 11.828 (4.977) - Disc
Loss: 0.000 (0.000) - 27.55 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.566 
(3.605) - AE Loss: 2053355.500 (733957.312) - AE Rec Loss: 13.925 (4.977) - Disc
Loss: 0.000 (0.000) - 27.64 m remaining

[Epoch <000/100>: Step <025/2280>] - Data(s): 0.000 (1.198) - Batch(s): 0.571 
(3.605) - AE Loss: 233822.500 (733957.312) - AE Rec Loss: 1.586 (4.977) - Disc 
Loss: 0.000 (0.000) - 27.72 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.818 
(3.141) - AE Loss: 729780.250 (795993.688) - AE Rec Loss: 4.949 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.818 
(3.141) - AE Loss: 853812.000 (795993.688) - AE Rec Loss: 5.790 (5.398) - Disc 
Loss: 0.000 (0.000) - 28.05 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.817 
(3.141) - AE Loss: 2022262.625 (795993.688) - AE Rec Loss: 13.714 (5.398) - Disc
Loss: 0.000 (0.000) - 27.97 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.001 (1.001) - Batch(s): 0.818 
(3.141) - AE Loss: 338948.250 (795993.688) - AE Rec Loss: 2.299 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.52 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.820 
(3.141) - AE Loss: 499381.656 (795993.688) - AE Rec Loss: 3.387 (5.398) - Disc 
Loss: 0.000 (0.000) - 27.88 m remaining

[Epoch <000/100>: Step <026/2280>] - Data(s): 0.000 (1.001) - Batch(s): 0.820 
(3.141) - AE Loss: 3095392.750 (795993.688) - AE Rec Loss: 20.992 (5.398) - Disc
Loss: 0.000 (0.000) - 27.96 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.566 
(2.773) - AE Loss: 905736.125 (813414.375) - AE Rec Loss: 6.142 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.94 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.552 
(2.773) - AE Loss: 513095.875 (813414.375) - AE Rec Loss: 3.480 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.93 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.566 
(2.773) - AE Loss: 2204069.750 (813414.375) - AE Rec Loss: 14.947 (5.516) - Disc
Loss: 0.000 (0.000) - 27.50 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.564 
(2.773) - AE Loss: 418310.469 (813414.375) - AE Rec Loss: 2.837 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.85 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.571 
(2.773) - AE Loss: 413187.219 (813414.375) - AE Rec Loss: 2.802 (5.516) - Disc 
Loss: 0.000 (0.000) - 28.01 m remaining

[Epoch <000/100>: Step <027/2280>] - Data(s): 0.000 (0.858) - Batch(s): 0.564 
(2.773) - AE Loss: 133240.281 (813414.375) - AE Rec Loss: 0.904 (5.516) - Disc 
Loss: 0.000 (0.000) - 27.88 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.952 
(2.534) - AE Loss: 281682.688 (836026.812) - AE Rec Loss: 1.910 (5.670) - Disc 
Loss: 0.000 (0.000) - 27.99 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.950 
(2.534) - AE Loss: 2131385.250 (836026.812) - AE Rec Loss: 14.454 (5.670) - Disc
Loss: 0.000 (0.000) - 28.35 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.940 
(2.534) - AE Loss: 265044.781 (836026.812) - AE Rec Loss: 1.797 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.39 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.949 
(2.534) - AE Loss: 351755.250 (836026.812) - AE Rec Loss: 2.385 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.954 
(2.534) - AE Loss: 1730022.250 (836026.812) - AE Rec Loss: 11.732 (5.670) - Disc
Loss: 0.000 (0.000) - 28.41 m remaining

[Epoch <000/100>: Step <028/2280>] - Data(s): 0.000 (0.755) - Batch(s): 0.955 
(2.534) - AE Loss: 759110.250 (836026.812) - AE Rec Loss: 5.148 (5.670) - Disc 
Loss: 0.000 (0.000) - 28.48 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.010 
(2.365) - AE Loss: 383564.125 (821621.312) - AE Rec Loss: 2.601 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.91 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 316753.125 (821621.312) - AE Rec Loss: 2.148 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.90 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 562847.438 (821621.312) - AE Rec Loss: 3.817 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.86 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 259020.625 (821621.312) - AE Rec Loss: 1.757 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.83 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.138 (0.675) - Batch(s): 1.011 
(2.365) - AE Loss: 667712.375 (821621.312) - AE Rec Loss: 4.528 (5.572) - Disc 
Loss: 0.000 (0.000) - 28.51 m remaining

[Epoch <000/100>: Step <029/2280>] - Data(s): 0.000 (0.675) - Batch(s): 1.010 
(2.365) - AE Loss: 1638957.250 (821621.312) - AE Rec Loss: 11.115 (5.572) - Disc
Loss: 0.000 (0.000) - 28.98 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.117 
(3.037) - AE Loss: 725570.750 (810392.875) - AE Rec Loss: 4.921 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.14 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.120 
(3.037) - AE Loss: 1622367.375 (810392.875) - AE Rec Loss: 11.002 (5.496) - Disc
Loss: 0.000 (0.000) - 39.19 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.116 
(3.037) - AE Loss: 234808.750 (810392.875) - AE Rec Loss: 1.592 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.11 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 4.899 (0.722) - Batch(s): 9.121 
(3.037) - AE Loss: 324484.750 (810392.875) - AE Rec Loss: 2.201 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.26 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.000 (0.722) - Batch(s): 9.106 
(3.037) - AE Loss: 334851.188 (810392.875) - AE Rec Loss: 2.271 (5.496) - Disc 
Loss: 0.000 (0.000) - 39.18 m remaining

[Epoch <000/100>: Step <030/2280>] - Data(s): 0.215 (0.722) - Batch(s): 9.118 
(3.037) - AE Loss: 289936.562 (810392.875) - AE Rec Loss: 1.966 (5.496) - Disc 
Loss: 0.000 (0.000) - 38.80 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.648 
(3.171) - AE Loss: 119584.586 (777911.062) - AE Rec Loss: 0.811 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.58 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.659 
(3.171) - AE Loss: 375045.500 (777911.062) - AE Rec Loss: 2.543 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.55 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.662 
(3.171) - AE Loss: 810907.000 (777911.062) - AE Rec Loss: 5.499 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.60 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.659 
(3.171) - AE Loss: 356473.625 (777911.062) - AE Rec Loss: 2.417 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.52 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.659 
(3.171) - AE Loss: 359037.812 (777911.062) - AE Rec Loss: 2.435 (5.276) - Disc 
Loss: 0.000 (0.000) - 43.21 m remaining

[Epoch <000/100>: Step <031/2280>] - Data(s): 0.000 (0.687) - Batch(s): 4.664 
(3.171) - AE Loss: 1678346.500 (777911.062) - AE Rec Loss: 11.382 (5.276) - Disc
Loss: 0.000 (0.000) - 43.66 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.674 
(2.963) - AE Loss: 319303.000 (789665.562) - AE Rec Loss: 2.165 (5.355) - Disc 
Loss: 0.000 (0.000) - 43.15 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.675 
(2.963) - AE Loss: 572306.125 (789665.562) - AE Rec Loss: 3.881 (5.355) - Disc 
Loss: 0.000 (0.000) - 43.19 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.677 
(2.963) - AE Loss: 394718.000 (789665.562) - AE Rec Loss: 2.677 (5.355) - Disc 
Loss: 0.000 (0.000) - 43.20 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.674 
(2.963) - AE Loss: 1690142.625 (789665.562) - AE Rec Loss: 11.462 (5.355) - Disc
Loss: 0.000 (0.000) - 43.27 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.674 
(2.963) - AE Loss: 127575.453 (789665.562) - AE Rec Loss: 0.865 (5.355) - Disc 
Loss: 0.000 (0.000) - 42.83 m remaining

[Epoch <000/100>: Step <032/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.674 
(2.963) - AE Loss: 470840.812 (789665.562) - AE Rec Loss: 3.193 (5.355) - Disc 
Loss: 0.000 (0.000) - 43.13 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.304 
(2.833) - AE Loss: 466681.688 (788930.750) - AE Rec Loss: 3.165 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.48 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.304 
(2.833) - AE Loss: 104947.102 (788930.750) - AE Rec Loss: 0.712 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.17 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.302 
(2.833) - AE Loss: 253612.797 (788930.750) - AE Rec Loss: 1.720 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.45 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.308 
(2.833) - AE Loss: 223933.031 (788930.750) - AE Rec Loss: 1.519 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.59 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.292 
(2.833) - AE Loss: 1476442.000 (788930.750) - AE Rec Loss: 10.013 (5.350) - Disc
Loss: 0.000 (0.000) - 43.52 m remaining

[Epoch <000/100>: Step <033/2280>] - Data(s): 0.000 (0.586) - Batch(s): 1.305 
(2.833) - AE Loss: 303112.281 (788930.750) - AE Rec Loss: 2.056 (5.350) - Disc 
Loss: 0.000 (0.000) - 43.53 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.240 
(2.856) - AE Loss: 263644.031 (764211.062) - AE Rec Loss: 1.788 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.83 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.241 
(2.856) - AE Loss: 247298.453 (764211.062) - AE Rec Loss: 1.677 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.86 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.229 
(2.856) - AE Loss: 512886.844 (764211.062) - AE Rec Loss: 3.478 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.89 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.241 
(2.856) - AE Loss: 313419.750 (764211.062) - AE Rec Loss: 2.126 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.56 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.243 
(2.856) - AE Loss: 327337.812 (764211.062) - AE Rec Loss: 2.220 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.90 m remaining

[Epoch <000/100>: Step <034/2280>] - Data(s): 0.000 (0.560) - Batch(s): 3.246 
(2.856) - AE Loss: 364415.625 (764211.062) - AE Rec Loss: 2.471 (5.183) - Disc 
Loss: 0.000 (0.000) - 45.96 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 262552.562 (756271.625) - AE Rec Loss: 1.781 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.42 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.666 
(2.710) - AE Loss: 457943.656 (756271.625) - AE Rec Loss: 3.106 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.45 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 1943349.375 (756271.625) - AE Rec Loss: 13.179 (5.129) - Disc
Loss: 0.000 (0.000) - 45.46 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.666 
(2.710) - AE Loss: 436090.562 (756271.625) - AE Rec Loss: 2.957 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.39 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 193633.078 (756271.625) - AE Rec Loss: 1.313 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.12 m remaining

[Epoch <000/100>: Step <035/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.665 
(2.710) - AE Loss: 100408.367 (756271.625) - AE Rec Loss: 0.681 (5.129) - Disc 
Loss: 0.000 (0.000) - 45.52 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.491 
(2.695) - AE Loss: 225330.109 (767917.438) - AE Rec Loss: 1.528 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.90 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.504 
(2.695) - AE Loss: 105905.664 (767917.438) - AE Rec Loss: 0.718 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.91 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.502 
(2.695) - AE Loss: 3116095.000 (767917.438) - AE Rec Loss: 21.132 (5.208) - Disc
Loss: 0.000 (0.000) - 46.58 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.504 
(2.695) - AE Loss: 112709.180 (767917.438) - AE Rec Loss: 0.764 (5.208) - Disc 
Loss: 0.000 (0.000) - 46.87 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.001 (0.500) - Batch(s): 2.507 
(2.695) - AE Loss: 1789603.250 (767917.438) - AE Rec Loss: 12.137 (5.208) - Disc
Loss: 0.000 (0.000) - 46.97 m remaining

[Epoch <000/100>: Step <036/2280>] - Data(s): 0.000 (0.500) - Batch(s): 2.501 
(2.695) - AE Loss: 1676440.500 (767917.438) - AE Rec Loss: 11.369 (5.208) - Disc
Loss: 0.000 (0.000) - 46.84 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 3.282 
(2.722) - AE Loss: 177947.188 (758948.062) - AE Rec Loss: 1.207 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.00 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 3.268 
(2.722) - AE Loss: 109598.367 (758948.062) - AE Rec Loss: 0.743 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.03 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.001 (0.486) - Batch(s): 3.280 
(2.722) - AE Loss: 413891.688 (758948.062) - AE Rec Loss: 2.807 (5.147) - Disc 
Loss: 0.000 (0.000) - 48.72 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.001 (0.486) - Batch(s): 3.285 
(2.722) - AE Loss: 418538.062 (758948.062) - AE Rec Loss: 2.838 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.09 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.000 (0.486) - Batch(s): 3.282 
(2.722) - AE Loss: 583186.375 (758948.062) - AE Rec Loss: 3.955 (5.147) - Disc 
Loss: 0.000 (0.000) - 49.04 m remaining

[Epoch <000/100>: Step <037/2280>] - Data(s): 0.001 (0.486) - Batch(s): 3.279 
(2.722) - AE Loss: 1641124.250 (758948.062) - AE Rec Loss: 11.130 (5.147) - Disc
Loss: 0.000 (0.000) - 48.98 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.654 
(2.607) - AE Loss: 297286.750 (761127.125) - AE Rec Loss: 2.016 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.53 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.653 
(2.607) - AE Loss: 522172.000 (761127.125) - AE Rec Loss: 3.541 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.50 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.654 
(2.607) - AE Loss: 1890142.875 (761127.125) - AE Rec Loss: 12.818 (5.162) - Disc
Loss: 0.000 (0.000) - 48.23 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.654 
(2.607) - AE Loss: 272377.938 (761127.125) - AE Rec Loss: 1.847 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.54 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.654 
(2.607) - AE Loss: 428089.000 (761127.125) - AE Rec Loss: 2.903 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.47 m remaining

[Epoch <000/100>: Step <038/2280>] - Data(s): 0.000 (0.459) - Batch(s): 0.655 
(2.607) - AE Loss: 316550.156 (761127.125) - AE Rec Loss: 2.147 (5.162) - Disc 
Loss: 0.000 (0.000) - 48.59 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.198 
(2.531) - AE Loss: 382111.500 (743328.562) - AE Rec Loss: 2.591 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.27 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.200 
(2.531) - AE Loss: 98957.289 (743328.562) - AE Rec Loss: 0.671 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.53 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.186 
(2.531) - AE Loss: 162724.062 (743328.562) - AE Rec Loss: 1.104 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.56 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.197 
(2.531) - AE Loss: 95214.070 (743328.562) - AE Rec Loss: 0.646 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.51 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.203 
(2.531) - AE Loss: 173829.438 (743328.562) - AE Rec Loss: 1.179 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.62 m remaining

[Epoch <000/100>: Step <039/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.200 
(2.531) - AE Loss: 331783.875 (743328.562) - AE Rec Loss: 2.250 (5.041) - Disc 
Loss: 0.000 (0.000) - 48.57 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.590 
(2.578) - AE Loss: 421541.656 (745824.375) - AE Rec Loss: 2.859 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.48 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.577 
(2.578) - AE Loss: 363632.812 (745824.375) - AE Rec Loss: 2.466 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.77 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.001 (0.428) - Batch(s): 3.592 
(2.578) - AE Loss: 1752247.125 (745824.375) - AE Rec Loss: 11.883 (5.058) - Disc
Loss: 0.000 (0.000) - 50.74 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.589 
(2.578) - AE Loss: 263728.062 (745824.375) - AE Rec Loss: 1.789 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.72 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.591 
(2.578) - AE Loss: 2072863.750 (745824.375) - AE Rec Loss: 14.058 (5.058) - Disc
Loss: 0.000 (0.000) - 50.78 m remaining

[Epoch <000/100>: Step <040/2280>] - Data(s): 0.000 (0.428) - Batch(s): 3.595 
(2.578) - AE Loss: 204361.078 (745824.375) - AE Rec Loss: 1.386 (5.058) - Disc 
Loss: 0.000 (0.000) - 50.83 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 261514.562 (727184.375) - AE Rec Loss: 1.774 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.28 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 263498.312 (727184.375) - AE Rec Loss: 1.787 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.54 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 903520.375 (727184.375) - AE Rec Loss: 6.127 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.56 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 246827.312 (727184.375) - AE Rec Loss: 1.674 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.51 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 602938.750 (727184.375) - AE Rec Loss: 4.089 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.62 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 0.000 (0.408) - Batch(s): 11.130 
(2.944) - AE Loss: 310489.688 (727184.375) - AE Rec Loss: 2.106 (4.932) - Disc 
Loss: 0.000 (0.000) - 59.57 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.566 
(2.836) - AE Loss: 198302.125 (728193.562) - AE Rec Loss: 1.345 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.76 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.555 
(2.836) - AE Loss: 1972038.000 (728193.562) - AE Rec Loss: 13.374 (4.938) - Disc
Loss: 0.000 (0.000) - 58.79 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.566 
(2.836) - AE Loss: 288242.125 (728193.562) - AE Rec Loss: 1.955 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.51 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.569 
(2.836) - AE Loss: 318274.250 (728193.562) - AE Rec Loss: 2.158 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.80 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.566 
(2.836) - AE Loss: 416942.938 (728193.562) - AE Rec Loss: 2.828 (4.938) - Disc 
Loss: 0.000 (0.000) - 58.74 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (0.389) - Batch(s): 0.575 
(2.836) - AE Loss: 1759707.500 (728193.562) - AE Rec Loss: 11.934 (4.938) - Disc
Loss: 0.000 (0.000) - 58.84 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.555 
(2.737) - AE Loss: 95139.078 (720012.188) - AE Rec Loss: 0.645 (4.883) - Disc 
Loss: 0.000 (0.000) - 58.04 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.567 
(2.737) - AE Loss: 1583684.375 (720012.188) - AE Rec Loss: 10.740 (4.883) - Disc
Loss: 0.000 (0.000) - 58.01 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.575 
(2.737) - AE Loss: 273699.062 (720012.188) - AE Rec Loss: 1.856 (4.883) - Disc 
Loss: 0.000 (0.000) - 58.10 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.569 
(2.737) - AE Loss: 251840.547 (720012.188) - AE Rec Loss: 1.708 (4.883) - Disc 
Loss: 0.000 (0.000) - 58.05 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.566 
(2.737) - AE Loss: 346365.969 (720012.188) - AE Rec Loss: 2.349 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.99 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (0.372) - Batch(s): 0.567 
(2.737) - AE Loss: 201502.562 (720012.188) - AE Rec Loss: 1.367 (4.883) - Disc 
Loss: 0.000 (0.000) - 57.78 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 172626.312 (705130.312) - AE Rec Loss: 1.171 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.38 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 530284.250 (705130.312) - AE Rec Loss: 3.596 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.41 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 168720.219 (705130.312) - AE Rec Loss: 1.144 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.41 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 95425.461 (705130.312) - AE Rec Loss: 0.647 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.36 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 1616854.500 (705130.312) - AE Rec Loss: 10.965 (4.782) - Disc
Loss: 0.000 (0.000) - 57.14 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.659 
(2.651) - AE Loss: 300809.250 (705130.312) - AE Rec Loss: 2.040 (4.782) - Disc 
Loss: 0.000 (0.000) - 57.46 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.568 
(2.567) - AE Loss: 292177.375 (707230.625) - AE Rec Loss: 1.981 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.47 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.555 
(2.567) - AE Loss: 119475.812 (707230.625) - AE Rec Loss: 0.810 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.72 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.568 
(2.567) - AE Loss: 473008.406 (707230.625) - AE Rec Loss: 3.208 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.70 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.567 
(2.567) - AE Loss: 258082.094 (707230.625) - AE Rec Loss: 1.750 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.68 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.569 
(2.567) - AE Loss: 1803397.000 (707230.625) - AE Rec Loss: 12.230 (4.796) - Disc
Loss: 0.000 (0.000) - 56.73 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (0.342) - Batch(s): 0.576 
(2.567) - AE Loss: 330969.500 (707230.625) - AE Rec Loss: 2.245 (4.796) - Disc 
Loss: 0.000 (0.000) - 56.78 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.568 
(2.491) - AE Loss: 1883637.250 (708197.750) - AE Rec Loss: 12.774 (4.803) - Disc
Loss: 0.000 (0.000) - 56.08 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.568 
(2.491) - AE Loss: 162605.156 (708197.750) - AE Rec Loss: 1.103 (4.803) - Disc 
Loss: 0.000 (0.000) - 55.82 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.567 
(2.491) - AE Loss: 1440411.625 (708197.750) - AE Rec Loss: 9.768 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.03 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.555 
(2.491) - AE Loss: 567903.438 (708197.750) - AE Rec Loss: 3.851 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.07 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.567 
(2.491) - AE Loss: 122865.438 (708197.750) - AE Rec Loss: 0.833 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.05 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (0.329) - Batch(s): 0.577 
(2.491) - AE Loss: 125764.906 (708197.750) - AE Rec Loss: 0.853 (4.803) - Disc 
Loss: 0.000 (0.000) - 56.12 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:53:32,724[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,757[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,760[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,826[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,844[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:53:32,870[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:53:34,947[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,004[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,029[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,043[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,082[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:53:35,108[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,447[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,586[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 02:53:35,593[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,627[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,659[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:53:35,699[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 02:53:35,778[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 02:53:35,780[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:53:35,780[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
[[36m2023-11-29 02:53:35,780[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 02:53:35,784[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Running in inference mode: False
[[36m2023-11-29 02:53:35,785[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
len(train_dataloader) = 2279
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 10
Reached 1.3 on node 7Reached 1.4 on node 10

Reached 1.4 on node 7
Reached 2 on node 10
Reached 2 on node 7
Reached 3 on node 10
Reached 3 on node 7
Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10
Reached end on node 7
Reached 3 on node 8
Reached 3 on node 9Reached 5 on node 8

Reached 5 on node 9
Reached end on node 8
Reached end on node 9
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 7Reached 3 on node 10

Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10Reached end on node 7

=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 8

Reached 1.4 on node 8Reached 1.4 on node 9

Reached 2 on node 8Reached 2 on node 9

Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 3 on node 9Reached 3 on node 8

Reached 2 on node 11Reached 5 on node 9
Reached 5 on node 8

Reached end on node 8Reached end on node 9

Reached 1.3 on node 10
Reached 3 on node 11Reached 1.4 on node 10

Reached 1.3 on node 7
Reached 1.4 on node 7Reached 5 on node 11

Reached 2 on node 10
Reached end on node 11Reached 2 on node 7Reached 1.3 on node 6


Reached 1.4 on node 6
Reached 3 on node 10
Reached 2 on node 6Reached 3 on node 7

Reached 5 on node 10
Reached end on node 10
Reached 5 on node 7
Reached 3 on node 6
Reached end on node 7
Reached 5 on node 6
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6Reached 1 on node 8

Reached 1.4 on node 6
Reached 2 on node 6Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7Reached 1 on node 11

Reached 1 on node 6
Reached 1.4 on node 7Reached 1 on node 8

Reached 2 on node 7Reached 1.4 on node 11

Reached 1.4 on node 6
Reached 2 on node 6Reached 2 on node 11

Reached 1.4 on node 8
Reached 2 on node 8Reached 3 on node 6

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7Reached 1 on node 11

Reached 1 on node 8Reached 2 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 11
Reached 3 on node 7Reached 1.4 on node 8
Reached 2 on node 11
Reached 3 on node 7

Reached 2 on node 8
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1 on node 6
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <041/2280>] - Data(s): 5.644 (5.979) - Batch(s): 10.029 
(10.088) - AE Loss: 263434.406 (354775.531) - AE Rec Loss: 1.787 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 3.849 (5.979) - Batch(s): 10.039 
(10.088) - AE Loss: 247300.844 (354775.531) - AE Rec Loss: 1.677 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 4.996 (5.979) - Batch(s): 10.053 
(10.088) - AE Loss: 312051.969 (354775.531) - AE Rec Loss: 2.116 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 6.231 (5.979) - Batch(s): 10.025 
(10.088) - AE Loss: 261518.031 (354775.531) - AE Rec Loss: 1.774 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 8.528 (5.979) - Batch(s): 10.053 
(10.088) - AE Loss: 604384.188 (354775.531) - AE Rec Loss: 4.099 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 6.962 (5.979) - Batch(s): 10.039 
(10.088) - AE Loss: 903520.000 (354775.531) - AE Rec Loss: 6.127 (2.406) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.941 
(5.470) - AE Loss: 190633.906 (552625.312) - AE Rec Loss: 1.293 (3.748) - Disc 
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.929 
(5.470) - AE Loss: 1971518.750 (552625.312) - AE Rec Loss: 13.370 (3.748) - Disc
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.944 
(5.470) - AE Loss: 322702.438 (552625.312) - AE Rec Loss: 2.188 (3.748) - Disc 
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.945 
(5.470) - AE Loss: 1761988.125 (552625.312) - AE Rec Loss: 11.949 (3.748) - Disc
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.001 (3.005) - Batch(s): 0.941 
(5.470) - AE Loss: 422578.594 (552625.312) - AE Rec Loss: 2.866 (3.748) - Disc 
Loss: 0.000 (0.000) - 9.91 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (3.005) - Batch(s): 0.941 
(5.470) - AE Loss: 274505.625 (552625.312) - AE Rec Loss: 1.862 (3.748) - Disc 
Loss: 0.000 (0.000) - 9.91 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.686 
(3.876) - AE Loss: 1587271.375 (545897.938) - AE Rec Loss: 10.764 (3.702) - Disc
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.691 
(3.876) - AE Loss: 242279.875 (545897.938) - AE Rec Loss: 1.643 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (2.004) - Batch(s): 0.692 
(3.876) - AE Loss: 98653.070 (545897.938) - AE Rec Loss: 0.669 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.691 
(3.876) - AE Loss: 324867.281 (545897.938) - AE Rec Loss: 2.203 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.691 
(3.876) - AE Loss: 201397.766 (545897.938) - AE Rec Loss: 1.366 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (2.004) - Batch(s): 0.692 
(3.876) - AE Loss: 248161.625 (545897.938) - AE Rec Loss: 1.683 (3.702) - Disc 
Loss: 0.000 (0.000) - 10.40 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.556 
(3.274) - AE Loss: 513281.781 (496945.500) - AE Rec Loss: 3.481 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.570 
(3.274) - AE Loss: 156234.438 (496945.500) - AE Rec Loss: 1.060 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.572 
(3.274) - AE Loss: 290635.562 (496945.500) - AE Rec Loss: 1.971 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.568 
(3.274) - AE Loss: 1613886.750 (496945.500) - AE Rec Loss: 10.945 (3.370) - Disc
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.567 
(3.274) - AE Loss: 91513.289 (496945.500) - AE Rec Loss: 0.621 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.539) - Batch(s): 1.568 
(3.274) - AE Loss: 157655.766 (496945.500) - AE Rec Loss: 1.069 (3.370) - Disc 
Loss: 0.000 (0.000) - 11.59 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (1.233) - Batch(s): 0.666 
(2.749) - AE Loss: 91790.930 (547931.812) - AE Rec Loss: 0.622 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.682 
(2.749) - AE Loss: 338937.250 (547931.812) - AE Rec Loss: 2.299 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.678 
(2.749) - AE Loss: 300170.188 (547931.812) - AE Rec Loss: 2.036 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.677 
(2.749) - AE Loss: 458007.500 (547931.812) - AE Rec Loss: 3.106 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.233) - Batch(s): 0.678 
(2.749) - AE Loss: 240224.312 (547931.812) - AE Rec Loss: 1.629 (3.716) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (1.233) - Batch(s): 0.681 
(2.749) - AE Loss: 1806719.250 (547931.812) - AE Rec Loss: 12.253 (3.716) - Disc
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.006 
(2.792) - AE Loss: 577370.000 (577584.938) - AE Rec Loss: 3.916 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.006 
(2.792) - AE Loss: 94130.180 (577584.938) - AE Rec Loss: 0.638 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.005 
(2.792) - AE Loss: 95724.547 (577584.938) - AE Rec Loss: 0.649 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.005 
(2.792) - AE Loss: 1445925.750 (577584.938) - AE Rec Loss: 9.806 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.006 
(2.792) - AE Loss: 158310.719 (577584.938) - AE Rec Loss: 1.074 (3.917) - Disc 
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.060) - Batch(s): 3.005 
(2.792) - AE Loss: 1890195.500 (577584.938) - AE Rec Loss: 12.819 (3.917) - Disc
Loss: 0.000 (0.000) - 14.27 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.685 
(2.772) - AE Loss: 2576143.000 (618374.750) - AE Rec Loss: 17.471 (4.194) - Disc
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.681 
(2.772) - AE Loss: 117130.609 (618374.750) - AE Rec Loss: 0.794 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.683 
(2.772) - AE Loss: 402189.688 (618374.750) - AE Rec Loss: 2.728 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.669 
(2.772) - AE Loss: 1682342.000 (618374.750) - AE Rec Loss: 11.409 (4.194) - Disc
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.680 
(2.772) - AE Loss: 194203.734 (618374.750) - AE Rec Loss: 1.317 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.934) - Batch(s): 2.682 
(2.772) - AE Loss: 250232.859 (618374.750) - AE Rec Loss: 1.697 (4.194) - Disc 
Loss: 0.000 (0.000) - 16.17 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.573 
(2.496) - AE Loss: 106115.312 (625452.438) - AE Rec Loss: 0.720 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.567 
(2.496) - AE Loss: 108988.680 (625452.438) - AE Rec Loss: 0.739 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.570 
(2.496) - AE Loss: 115339.836 (625452.438) - AE Rec Loss: 0.782 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.556 
(2.496) - AE Loss: 264374.969 (625452.438) - AE Rec Loss: 1.793 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.568 
(2.496) - AE Loss: 439669.062 (625452.438) - AE Rec Loss: 2.982 (4.242) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.817) - Batch(s): 0.568 
(2.496) - AE Loss: 1927744.750 (625452.438) - AE Rec Loss: 13.073 (4.242) - Disc
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.151 
(2.569) - AE Loss: 180150.500 (601630.125) - AE Rec Loss: 1.222 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 1.440 (0.763) - Batch(s): 3.152 
(2.569) - AE Loss: 183548.500 (601630.125) - AE Rec Loss: 1.245 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.151 
(2.569) - AE Loss: 692686.062 (601630.125) - AE Rec Loss: 4.698 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.151 
(2.569) - AE Loss: 327673.625 (601630.125) - AE Rec Loss: 2.222 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.151 
(2.569) - AE Loss: 429708.281 (601630.125) - AE Rec Loss: 2.914 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.763) - Batch(s): 3.151 
(2.569) - AE Loss: 418165.250 (601630.125) - AE Rec Loss: 2.836 (4.080) - Disc 
Loss: 0.000 (0.000) - 18.51 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.896) - Batch(s): 13.257 
(3.637) - AE Loss: 422518.562 (610211.000) - AE Rec Loss: 2.865 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.896) - Batch(s): 13.254 
(3.637) - AE Loss: 1866506.125 (610211.000) - AE Rec Loss: 12.658 (4.138) - Disc
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.896) - Batch(s): 13.252 
(3.637) - AE Loss: 373760.938 (610211.000) - AE Rec Loss: 2.535 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.896) - Batch(s): 13.252 
(3.637) - AE Loss: 280262.656 (610211.000) - AE Rec Loss: 1.901 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.896) - Batch(s): 13.254 
(3.637) - AE Loss: 93378.594 (610211.000) - AE Rec Loss: 0.633 (4.138) - Disc 
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.896) - Batch(s): 13.239 
(3.637) - AE Loss: 1879954.125 (610211.000) - AE Rec Loss: 12.749 (4.138) - Disc
Loss: 0.000 (0.000) - 27.91 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.183 
(3.409) - AE Loss: 223521.438 (610047.562) - AE Rec Loss: 1.516 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.186 
(3.409) - AE Loss: 251376.938 (610047.562) - AE Rec Loss: 1.705 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.180 
(3.409) - AE Loss: 414982.656 (610047.562) - AE Rec Loss: 2.814 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.182 
(3.409) - AE Loss: 93412.844 (610047.562) - AE Rec Loss: 0.633 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.168 
(3.409) - AE Loss: 312122.812 (610047.562) - AE Rec Loss: 2.117 (4.137) - Disc 
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.815) - Batch(s): 1.179 
(3.409) - AE Loss: 1607389.250 (610047.562) - AE Rec Loss: 10.901 (4.137) - Disc
Loss: 0.000 (0.000) - 28.32 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 182787.219 (614117.875) - AE Rec Loss: 1.240 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 981359.250 (614117.875) - AE Rec Loss: 6.655 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 350677.875 (614117.875) - AE Rec Loss: 2.378 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 1984177.500 (614117.875) - AE Rec Loss: 13.456 (4.165) - Disc
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 955330.125 (614117.875) - AE Rec Loss: 6.479 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.765) - Batch(s): 3.317 
(3.402) - AE Loss: 391495.500 (614117.875) - AE Rec Loss: 2.655 (4.165) - Disc 
Loss: 0.000 (0.000) - 30.21 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.566 
(3.184) - AE Loss: 149874.656 (624953.438) - AE Rec Loss: 1.016 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.568 
(3.184) - AE Loss: 221783.844 (624953.438) - AE Rec Loss: 1.504 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.569 
(3.184) - AE Loss: 1760560.250 (624953.438) - AE Rec Loss: 11.940 (4.238) - Disc
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.567 
(3.184) - AE Loss: 580652.250 (624953.438) - AE Rec Loss: 3.938 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.555 
(3.184) - AE Loss: 1514522.500 (624953.438) - AE Rec Loss: 10.271 (4.238) - Disc
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.706) - Batch(s): 0.575 
(3.184) - AE Loss: 96257.586 (624953.438) - AE Rec Loss: 0.653 (4.238) - Disc 
Loss: 0.000 (0.000) - 30.14 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.567 
(2.997) - AE Loss: 170150.703 (649675.875) - AE Rec Loss: 1.154 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.576 
(2.997) - AE Loss: 1913737.750 (649675.875) - AE Rec Loss: 12.978 (4.406) - Disc
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.569 
(2.997) - AE Loss: 513271.219 (649675.875) - AE Rec Loss: 3.481 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.567 
(2.997) - AE Loss: 391438.688 (649675.875) - AE Rec Loss: 2.655 (4.406) - Disc 
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.556 
(2.997) - AE Loss: 1611225.375 (649675.875) - AE Rec Loss: 10.927 (4.406) - Disc
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.656) - Batch(s): 0.568 
(2.997) - AE Loss: 1671201.500 (649675.875) - AE Rec Loss: 11.334 (4.406) - Disc
Loss: 0.000 (0.000) - 30.07 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.576 
(3.236) - AE Loss: 988267.062 (644607.750) - AE Rec Loss: 6.702 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.576 
(3.236) - AE Loss: 508812.219 (644607.750) - AE Rec Loss: 3.451 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.578 
(3.236) - AE Loss: 200768.125 (644607.750) - AE Rec Loss: 1.362 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.578 
(3.236) - AE Loss: 255653.078 (644607.750) - AE Rec Loss: 1.734 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.579 
(3.236) - AE Loss: 324531.062 (644607.750) - AE Rec Loss: 2.201 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.646) - Batch(s): 6.578 
(3.236) - AE Loss: 398538.688 (644607.750) - AE Rec Loss: 2.703 (4.372) - Disc 
Loss: 0.000 (0.000) - 33.98 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.576 
(3.069) - AE Loss: 331778.312 (663976.812) - AE Rec Loss: 2.250 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.568 
(3.069) - AE Loss: 1650254.250 (663976.812) - AE Rec Loss: 11.192 (4.503) - Disc
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.569 
(3.069) - AE Loss: 223003.484 (663976.812) - AE Rec Loss: 1.512 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.555 
(3.069) - AE Loss: 1610982.250 (663976.812) - AE Rec Loss: 10.925 (4.503) - Disc
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.568 
(3.069) - AE Loss: 1670977.250 (663976.812) - AE Rec Loss: 11.332 (4.503) - Disc
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.606) - Batch(s): 0.565 
(3.069) - AE Loss: 412640.750 (663976.812) - AE Rec Loss: 2.798 (4.503) - Disc 
Loss: 0.000 (0.000) - 33.85 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 1.168 
(2.943) - AE Loss: 1667945.875 (681705.250) - AE Rec Loss: 11.311 (4.623) - Disc
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 1.160 
(2.943) - AE Loss: 1432709.125 (681705.250) - AE Rec Loss: 9.716 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 1.163 
(2.943) - AE Loss: 249507.594 (681705.250) - AE Rec Loss: 1.692 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 2204019.500 (681705.250) - AE Rec Loss: 14.947 (4.623) - Disc
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.573) - Batch(s): 0.804 
(2.943) - AE Loss: 158480.812 (681705.250) - AE Rec Loss: 1.075 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.596 (0.573) - Batch(s): 1.164 
(2.943) - AE Loss: 671374.500 (681705.250) - AE Rec Loss: 4.553 (4.623) - Disc 
Loss: 0.000 (0.000) - 34.09 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 312671.906 (686901.750) - AE Rec Loss: 2.120 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.597) - Batch(s): 9.117 
(3.286) - AE Loss: 1974187.375 (686901.750) - AE Rec Loss: 13.388 (4.658) - Disc
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 3.516 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 324546.750 (686901.750) - AE Rec Loss: 2.201 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 401160.500 (686901.750) - AE Rec Loss: 2.721 (4.658) - Disc 
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 1731335.000 (686901.750) - AE Rec Loss: 11.741 (4.658) - Disc
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.597) - Batch(s): 9.116 
(3.286) - AE Loss: 1861750.000 (686901.750) - AE Rec Loss: 12.626 (4.658) - Disc
Loss: 0.000 (0.000) - 39.32 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.577 
(3.143) - AE Loss: 1330416.875 (694935.000) - AE Rec Loss: 9.022 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.568 
(3.143) - AE Loss: 1693145.500 (694935.000) - AE Rec Loss: 11.482 (4.713) - Disc
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.568 
(3.143) - AE Loss: 182948.094 (694935.000) - AE Rec Loss: 1.241 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.570 
(3.143) - AE Loss: 95116.094 (694935.000) - AE Rec Loss: 0.645 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.565) - Batch(s): 0.555 
(3.143) - AE Loss: 280178.562 (694935.000) - AE Rec Loss: 1.900 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.001 (0.565) - Batch(s): 0.569 
(3.143) - AE Loss: 825599.250 (694935.000) - AE Rec Loss: 5.599 (4.713) - Disc 
Loss: 0.000 (0.000) - 39.10 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.568 
(3.014) - AE Loss: 272598.125 (691524.375) - AE Rec Loss: 1.849 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.88 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.570 
(3.014) - AE Loss: 247775.891 (691524.375) - AE Rec Loss: 1.680 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.88 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.570 
(3.014) - AE Loss: 1514253.750 (691524.375) - AE Rec Loss: 10.269 (4.690) - Disc
Loss: 0.000 (0.000) - 38.88 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.576 
(3.014) - AE Loss: 1770903.250 (691524.375) - AE Rec Loss: 12.010 (4.690) - Disc
Loss: 0.000 (0.000) - 38.88 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.557 
(3.014) - AE Loss: 97300.391 (691524.375) - AE Rec Loss: 0.660 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.88 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.537) - Batch(s): 0.571 
(3.014) - AE Loss: 110267.781 (691524.375) - AE Rec Loss: 0.748 (4.690) - Disc 
Loss: 0.000 (0.000) - 38.88 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:55:06,639[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,743[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,775[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,798[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,801[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:55:06,813[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:55:08,844[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:09,000[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:09,061[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:09,061[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:09,068[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:55:09,087[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,381[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,622[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:55:09,700[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 02:55:09,709[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 02:55:09,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 02:55:09,716[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
[[36m2023-11-29 02:55:09,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:55:09,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:55:09,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:55:09,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10Reached 3 on node 6

Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.3 on node 10
Reached 3 on node 7Reached 1.4 on node 10

Reached 2 on node 10
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 8
Reached 5 on node 8Reached 3 on node 10

Reached end on node 8Reached 5 on node 10

Reached end on node 10
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6Reached 1.3 on node 9

Reached 1.4 on node 6Reached 1.4 on node 9

Reached 2 on node 9Reached 2 on node 6

Reached 3 on node 6Reached 3 on node 9

Reached 5 on node 6Reached 1.3 on node 11Reached 5 on node 9


Reached 1.4 on node 11
Reached end on node 6Reached end on node 9

Reached 2 on node 11
Reached 1.3 on node 7
Reached 1.3 on node 8
Reached 1.4 on node 7
Reached 1.4 on node 8Reached 3 on node 11

Reached 2 on node 7
Reached 2 on node 8Reached 5 on node 11

Reached 3 on node 7
Reached end on node 11
Reached 5 on node 7Reached 3 on node 8
Reached 1.3 on node 10

Reached end on node 7Reached 1.4 on node 10
Reached 5 on node 8

Reached 2 on node 10Reached end on node 8

Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
Loaded checkpoint at epoch 0 and step 41
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 8Reached 1 on node 10

Reached 2 on node 8Reached 1.4 on node 6

Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 1 on node 6Reached 1.4 on node 8Reached 2 on node 7


Reached 2 on node 8
Reached 1.4 on node 6Reached 1 on node 10

Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1.4 on node 10
Reached 3 on node 6
Reached 2 on node 10
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6Reached 1 on node 11

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8Reached 1 on node 7

Reached 1.4 on node 7Reached 1.4 on node 8

Reached 2 on node 7Reached 2 on node 8

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 10Reached 3 on node 7

Reached 5 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1 on node 11Reached 1.4 on node 10

Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 1.4 on node 11Reached 3 on node 10

Reached 2 on node 11Reached 3 on node 10

Reached 3 on node 10
Reached 3 on node 11
Reached 5 on node 10
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached end on node 6
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 8Reached 1.4 on node 9

Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11Reached 1 on node 10

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <041/2280>] - Data(s): 3.914 (5.637) - Batch(s): 10.145 
(10.136) - AE Loss: 310554.438 (354579.156) - AE Rec Loss: 2.106 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 4.010 (5.637) - Batch(s): 10.126 
(10.136) - AE Loss: 264042.719 (354579.156) - AE Rec Loss: 1.791 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 9.023 (5.637) - Batch(s): 10.374 
(10.136) - AE Loss: 603502.375 (354579.156) - AE Rec Loss: 4.093 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.46 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 6.069 (5.637) - Batch(s): 10.128 
(10.136) - AE Loss: 903861.750 (354579.156) - AE Rec Loss: 6.130 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.27 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 7.095 (5.637) - Batch(s): 10.179 
(10.136) - AE Loss: 260646.078 (354579.156) - AE Rec Loss: 1.768 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.29 m remaining

[Epoch <000/100>: Step <041/2280>] - Data(s): 3.781 (5.637) - Batch(s): 10.106 
(10.136) - AE Loss: 247335.734 (354579.156) - AE Rec Loss: 1.677 (2.405) - Disc 
Loss: 0.000 (0.000) - 9.24 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.513 (2.840) - Batch(s): 1.078 
(5.472) - AE Loss: 190562.594 (552517.875) - AE Rec Loss: 1.292 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.12 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.001 (2.840) - Batch(s): 1.075 
(5.472) - AE Loss: 422312.812 (552517.875) - AE Rec Loss: 2.864 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.10 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.081 
(5.472) - AE Loss: 1762685.750 (552517.875) - AE Rec Loss: 11.954 (3.747) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.719 
(5.472) - AE Loss: 1971489.625 (552517.875) - AE Rec Loss: 13.370 (3.747) - Disc
Loss: 0.000 (0.000) - 10.13 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.719 
(5.472) - AE Loss: 274972.469 (552517.875) - AE Rec Loss: 1.865 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.15 m remaining

[Epoch <000/100>: Step <042/2280>] - Data(s): 0.000 (2.840) - Batch(s): 0.720 
(5.472) - AE Loss: 323227.062 (552517.875) - AE Rec Loss: 2.192 (3.747) - Disc 
Loss: 0.000 (0.000) - 10.12 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.812 
(3.918) - AE Loss: 325330.594 (545726.000) - AE Rec Loss: 2.206 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.69 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (1.895) - Batch(s): 0.805 
(3.918) - AE Loss: 248955.734 (545726.000) - AE Rec Loss: 1.688 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.71 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.001 (1.895) - Batch(s): 0.811 
(3.918) - AE Loss: 97961.609 (545726.000) - AE Rec Loss: 0.664 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.72 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.811 
(3.918) - AE Loss: 1587071.375 (545726.000) - AE Rec Loss: 10.763 (3.701) - Disc
Loss: 0.000 (0.000) - 10.71 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.000 (1.895) - Batch(s): 0.811 
(3.918) - AE Loss: 241888.875 (545726.000) - AE Rec Loss: 1.640 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.90 m remaining

[Epoch <000/100>: Step <043/2280>] - Data(s): 0.070 (1.895) - Batch(s): 0.811 
(3.918) - AE Loss: 200725.578 (545726.000) - AE Rec Loss: 1.361 (3.701) - Disc 
Loss: 0.000 (0.000) - 10.74 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.708 
(4.089) - AE Loss: 513836.312 (496894.125) - AE Rec Loss: 3.485 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.52 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.719 
(4.089) - AE Loss: 157913.078 (496894.125) - AE Rec Loss: 1.071 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.51 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.720 
(4.089) - AE Loss: 90314.141 (496894.125) - AE Rec Loss: 0.612 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.49 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.721 
(4.089) - AE Loss: 157791.406 (496894.125) - AE Rec Loss: 1.070 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.51 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.001 (1.514) - Batch(s): 4.721 
(4.089) - AE Loss: 1614863.375 (496894.125) - AE Rec Loss: 10.951 (3.370) - Disc
Loss: 0.000 (0.000) - 14.54 m remaining

[Epoch <000/100>: Step <044/2280>] - Data(s): 0.000 (1.514) - Batch(s): 4.725 
(4.089) - AE Loss: 290277.562 (496894.125) - AE Rec Loss: 1.969 (3.370) - Disc 
Loss: 0.000 (0.000) - 14.70 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.556 
(3.384) - AE Loss: 91895.711 (547952.562) - AE Rec Loss: 0.623 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.79 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.568 
(3.384) - AE Loss: 457132.188 (547952.562) - AE Rec Loss: 3.100 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.78 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.568 
(3.384) - AE Loss: 301494.969 (547952.562) - AE Rec Loss: 2.045 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.001 (1.211) - Batch(s): 0.569 
(3.384) - AE Loss: 1806589.000 (547952.562) - AE Rec Loss: 12.252 (3.716) - Disc
Loss: 0.000 (0.000) - 14.78 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.575 
(3.384) - AE Loss: 338816.406 (547952.562) - AE Rec Loss: 2.298 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.96 m remaining

[Epoch <000/100>: Step <045/2280>] - Data(s): 0.000 (1.211) - Batch(s): 0.568 
(3.384) - AE Loss: 239148.672 (547952.562) - AE Rec Loss: 1.622 (3.716) - Disc 
Loss: 0.000 (0.000) - 14.76 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.740 
(2.944) - AE Loss: 159496.844 (577704.750) - AE Rec Loss: 1.082 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.20 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.739 
(2.944) - AE Loss: 579823.875 (577704.750) - AE Rec Loss: 3.932 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.18 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.739 
(2.944) - AE Loss: 93198.805 (577704.750) - AE Rec Loss: 0.632 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.35 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.741 
(2.944) - AE Loss: 94754.570 (577704.750) - AE Rec Loss: 0.643 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.17 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.000 (1.010) - Batch(s): 0.741 
(2.944) - AE Loss: 1890807.875 (577704.750) - AE Rec Loss: 12.823 (3.918) - Disc
Loss: 0.000 (0.000) - 15.18 m remaining

[Epoch <000/100>: Step <046/2280>] - Data(s): 0.001 (1.010) - Batch(s): 0.742 
(2.944) - AE Loss: 1447041.625 (577704.750) - AE Rec Loss: 9.813 (3.918) - Disc 
Loss: 0.000 (0.000) - 15.16 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.270 
(2.688) - AE Loss: 401493.625 (618207.062) - AE Rec Loss: 2.723 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.97 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.275 
(2.688) - AE Loss: 2576806.000 (618207.062) - AE Rec Loss: 17.475 (4.192) - Disc
Loss: 0.000 (0.000) - 16.14 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.270 
(2.688) - AE Loss: 112548.039 (618207.062) - AE Rec Loss: 0.763 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.97 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.258 
(2.688) - AE Loss: 1681873.000 (618207.062) - AE Rec Loss: 11.406 (4.192) - Disc
Loss: 0.000 (0.000) - 15.98 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.269 
(2.688) - AE Loss: 190791.719 (618207.062) - AE Rec Loss: 1.294 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.95 m remaining

[Epoch <000/100>: Step <047/2280>] - Data(s): 0.000 (0.875) - Batch(s): 1.272 
(2.688) - AE Loss: 244094.312 (618207.062) - AE Rec Loss: 1.655 (4.192) - Disc 
Loss: 0.000 (0.000) - 15.99 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.568 
(2.423) - AE Loss: 1929618.625 (624856.000) - AE Rec Loss: 13.086 (4.238) - Disc
Loss: 0.000 (0.000) - 16.19 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.570 
(2.423) - AE Loss: 108040.656 (624856.000) - AE Rec Loss: 0.733 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.19 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.576 
(2.423) - AE Loss: 99663.070 (624856.000) - AE Rec Loss: 0.676 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.36 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.001 (0.766) - Batch(s): 0.556 
(2.423) - AE Loss: 264709.500 (624856.000) - AE Rec Loss: 1.795 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.20 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.567 
(2.423) - AE Loss: 102654.227 (624856.000) - AE Rec Loss: 0.696 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.18 m remaining

[Epoch <000/100>: Step <048/2280>] - Data(s): 0.000 (0.766) - Batch(s): 0.569 
(2.423) - AE Loss: 439987.219 (624856.000) - AE Rec Loss: 2.984 (4.238) - Disc 
Loss: 0.000 (0.000) - 16.22 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.219 
(2.622) - AE Loss: 327602.625 (600989.625) - AE Rec Loss: 2.222 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.12 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.001 (0.714) - Batch(s): 4.220 
(2.622) - AE Loss: 693230.250 (600989.625) - AE Rec Loss: 4.701 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.13 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.219 
(2.622) - AE Loss: 182616.375 (600989.625) - AE Rec Loss: 1.238 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.12 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.219 
(2.622) - AE Loss: 174108.688 (600989.625) - AE Rec Loss: 1.181 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.28 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.218 
(2.622) - AE Loss: 419240.031 (600989.625) - AE Rec Loss: 2.843 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.10 m remaining

[Epoch <000/100>: Step <049/2280>] - Data(s): 0.000 (0.714) - Batch(s): 4.220 
(2.622) - AE Loss: 429126.656 (600989.625) - AE Rec Loss: 2.910 (4.076) - Disc 
Loss: 0.000 (0.000) - 19.14 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.830 
(2.531) - AE Loss: 370488.125 (609591.000) - AE Rec Loss: 2.513 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.21 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.828 
(2.531) - AE Loss: 279650.469 (609591.000) - AE Rec Loss: 1.897 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.17 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.831 
(2.531) - AE Loss: 1866987.500 (609591.000) - AE Rec Loss: 12.661 (4.134) - Disc
Loss: 0.000 (0.000) - 20.18 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.001 (0.653) - Batch(s): 1.830 
(2.531) - AE Loss: 93068.562 (609591.000) - AE Rec Loss: 0.631 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.19 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.835 
(2.531) - AE Loss: 424319.312 (609591.000) - AE Rec Loss: 2.878 (4.134) - Disc 
Loss: 0.000 (0.000) - 20.35 m remaining

[Epoch <000/100>: Step <050/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.816 
(2.531) - AE Loss: 1881261.250 (609591.000) - AE Rec Loss: 12.758 (4.134) - Disc
Loss: 0.000 (0.000) - 20.19 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.001 (0.593) - Batch(s): 1.409 
(2.423) - AE Loss: 413284.375 (609393.938) - AE Rec Loss: 2.803 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.94 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.407 
(2.423) - AE Loss: 1607650.125 (609393.938) - AE Rec Loss: 10.903 (4.133) - Disc
Loss: 0.000 (0.000) - 20.90 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.409 
(2.423) - AE Loss: 222991.703 (609393.938) - AE Rec Loss: 1.512 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.91 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.413 
(2.423) - AE Loss: 250620.125 (609393.938) - AE Rec Loss: 1.700 (4.133) - Disc 
Loss: 0.000 (0.000) - 21.08 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.395 
(2.423) - AE Loss: 310516.688 (609393.938) - AE Rec Loss: 2.106 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.92 m remaining

[Epoch <000/100>: Step <051/2280>] - Data(s): 0.000 (0.593) - Batch(s): 1.409 
(2.423) - AE Loss: 91394.117 (609393.938) - AE Rec Loss: 0.620 (4.133) - Disc 
Loss: 0.000 (0.000) - 20.92 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.001 (0.570) - Batch(s): 4.381 
(2.586) - AE Loss: 980729.938 (613470.000) - AE Rec Loss: 6.651 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.69 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 955069.250 (613470.000) - AE Rec Loss: 6.477 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.70 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.380 
(2.586) - AE Loss: 349336.281 (613470.000) - AE Rec Loss: 2.369 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.69 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.381 
(2.586) - AE Loss: 1983675.750 (613470.000) - AE Rec Loss: 13.453 (4.160) - Disc
Loss: 0.000 (0.000) - 23.67 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.382 
(2.586) - AE Loss: 392580.062 (613470.000) - AE Rec Loss: 2.662 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.71 m remaining

[Epoch <000/100>: Step <052/2280>] - Data(s): 0.000 (0.570) - Batch(s): 4.381 
(2.586) - AE Loss: 181811.938 (613470.000) - AE Rec Loss: 1.233 (4.160) - Disc 
Loss: 0.000 (0.000) - 23.85 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.571 
(2.431) - AE Loss: 1759170.000 (624265.625) - AE Rec Loss: 11.930 (4.234) - Disc
Loss: 0.000 (0.000) - 23.75 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.569 
(2.431) - AE Loss: 220506.656 (624265.625) - AE Rec Loss: 1.495 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.75 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.556 
(2.431) - AE Loss: 1512787.000 (624265.625) - AE Rec Loss: 10.259 (4.234) - Disc
Loss: 0.000 (0.000) - 23.75 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.569 
(2.431) - AE Loss: 149079.031 (624265.625) - AE Rec Loss: 1.011 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.73 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.569 
(2.431) - AE Loss: 580950.500 (624265.625) - AE Rec Loss: 3.940 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.77 m remaining

[Epoch <000/100>: Step <053/2280>] - Data(s): 0.000 (0.526) - Batch(s): 0.577 
(2.431) - AE Loss: 96752.023 (624265.625) - AE Rec Loss: 0.656 (4.234) - Disc 
Loss: 0.000 (0.000) - 23.90 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.571 
(2.298) - AE Loss: 1671090.000 (648929.625) - AE Rec Loss: 11.333 (4.401) - Disc
Loss: 0.000 (0.000) - 23.80 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.570 
(2.298) - AE Loss: 168049.688 (648929.625) - AE Rec Loss: 1.140 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.78 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.576 
(2.298) - AE Loss: 1912675.000 (648929.625) - AE Rec Loss: 12.971 (4.401) - Disc
Loss: 0.000 (0.000) - 23.95 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.557 
(2.298) - AE Loss: 1610467.000 (648929.625) - AE Rec Loss: 10.922 (4.401) - Disc
Loss: 0.000 (0.000) - 23.81 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.570 
(2.298) - AE Loss: 511400.781 (648929.625) - AE Rec Loss: 3.468 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.82 m remaining

[Epoch <000/100>: Step <054/2280>] - Data(s): 0.000 (0.488) - Batch(s): 0.570 
(2.298) - AE Loss: 389717.938 (648929.625) - AE Rec Loss: 2.643 (4.401) - Disc 
Loss: 0.000 (0.000) - 23.80 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.296 
(2.431) - AE Loss: 320739.812 (643791.312) - AE Rec Loss: 2.175 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.30 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 988054.312 (643791.312) - AE Rec Loss: 6.701 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.34 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.296 
(2.431) - AE Loss: 504384.562 (643791.312) - AE Rec Loss: 3.421 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.31 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.295 
(2.431) - AE Loss: 398117.344 (643791.312) - AE Rec Loss: 2.700 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.31 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.296 
(2.431) - AE Loss: 197284.141 (643791.312) - AE Rec Loss: 1.338 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.46 m remaining

[Epoch <000/100>: Step <055/2280>] - Data(s): 0.000 (0.476) - Batch(s): 4.296 
(2.431) - AE Loss: 253658.438 (643791.312) - AE Rec Loss: 1.720 (4.366) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.572 
(2.315) - AE Loss: 226614.156 (663304.875) - AE Rec Loss: 1.537 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.001 (0.446) - Batch(s): 0.570 
(2.315) - AE Loss: 1672423.500 (663304.875) - AE Rec Loss: 11.342 (4.498) - Disc
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.446) - Batch(s): 0.577 
(2.315) - AE Loss: 334881.750 (663304.875) - AE Rec Loss: 2.271 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.46 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.446) - Batch(s): 0.569 
(2.315) - AE Loss: 419132.938 (663304.875) - AE Rec Loss: 2.842 (4.498) - Disc 
Loss: 0.000 (0.000) - 26.30 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.446) - Batch(s): 0.570 
(2.315) - AE Loss: 1650903.625 (663304.875) - AE Rec Loss: 11.196 (4.498) - Disc
Loss: 0.000 (0.000) - 26.34 m remaining

[Epoch <000/100>: Step <056/2280>] - Data(s): 0.000 (0.446) - Batch(s): 0.559 
(2.315) - AE Loss: 1609664.875 (663304.875) - AE Rec Loss: 10.916 (4.498) - Disc
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.571 
(2.212) - AE Loss: 156254.094 (681181.000) - AE Rec Loss: 1.060 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.577 
(2.212) - AE Loss: 1670448.000 (681181.000) - AE Rec Loss: 11.328 (4.620) - Disc
Loss: 0.000 (0.000) - 26.46 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.559 
(2.212) - AE Loss: 2206852.000 (681181.000) - AE Rec Loss: 14.966 (4.620) - Disc
Loss: 0.000 (0.000) - 26.33 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.001 (0.420) - Batch(s): 0.570 
(2.212) - AE Loss: 252241.281 (681181.000) - AE Rec Loss: 1.711 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.32 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.000 (0.420) - Batch(s): 0.570 
(2.212) - AE Loss: 1428106.250 (681181.000) - AE Rec Loss: 9.685 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.31 m remaining

[Epoch <000/100>: Step <057/2280>] - Data(s): 0.001 (0.420) - Batch(s): 0.570 
(2.212) - AE Loss: 673338.750 (681181.000) - AE Rec Loss: 4.566 (4.620) - Disc 
Loss: 0.000 (0.000) - 26.34 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.513 
(2.340) - AE Loss: 1976106.875 (686529.750) - AE Rec Loss: 13.401 (4.656) - Disc
Loss: 0.000 (0.000) - 28.80 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 1733743.750 (686529.750) - AE Rec Loss: 11.758 (4.656) - Disc
Loss: 0.000 (0.000) - 28.80 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 1861095.875 (686529.750) - AE Rec Loss: 12.621 (4.656) - Disc
Loss: 0.000 (0.000) - 28.82 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 403170.406 (686529.750) - AE Rec Loss: 2.734 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.80 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.001 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 313721.375 (686529.750) - AE Rec Loss: 2.128 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.78 m remaining

[Epoch <000/100>: Step <058/2280>] - Data(s): 0.000 (0.414) - Batch(s): 4.514 
(2.340) - AE Loss: 325861.688 (686529.750) - AE Rec Loss: 2.210 (4.656) - Disc 
Loss: 0.000 (0.000) - 28.94 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.569 
(2.247) - AE Loss: 1692365.750 (694349.812) - AE Rec Loss: 11.477 (4.709) - Disc
Loss: 0.000 (0.000) - 28.76 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.001 (0.392) - Batch(s): 0.578 
(2.247) - AE Loss: 1330643.625 (694349.812) - AE Rec Loss: 9.024 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.90 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.570 
(2.247) - AE Loss: 180514.344 (694349.812) - AE Rec Loss: 1.224 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.74 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.557 
(2.247) - AE Loss: 272177.688 (694349.812) - AE Rec Loss: 1.846 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.76 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.000 (0.392) - Batch(s): 0.571 
(2.247) - AE Loss: 93540.734 (694349.812) - AE Rec Loss: 0.634 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.76 m remaining

[Epoch <000/100>: Step <059/2280>] - Data(s): 0.001 (0.392) - Batch(s): 0.570 
(2.247) - AE Loss: 817172.625 (694349.812) - AE Rec Loss: 5.542 (4.709) - Disc 
Loss: 0.000 (0.000) - 28.78 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.001 (0.373) - Batch(s): 0.572 
(2.163) - AE Loss: 112961.195 (690796.000) - AE Rec Loss: 0.766 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.72 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.570 
(2.163) - AE Loss: 237529.172 (690796.000) - AE Rec Loss: 1.611 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.74 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.571 
(2.163) - AE Loss: 1514364.250 (690796.000) - AE Rec Loss: 10.270 (4.685) - Disc
Loss: 0.000 (0.000) - 28.72 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.558 
(2.163) - AE Loss: 97740.719 (690796.000) - AE Rec Loss: 0.663 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.73 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.571 
(2.163) - AE Loss: 262849.312 (690796.000) - AE Rec Loss: 1.783 (4.685) - Disc 
Loss: 0.000 (0.000) - 28.70 m remaining

[Epoch <000/100>: Step <060/2280>] - Data(s): 0.000 (0.373) - Batch(s): 0.577 
(2.163) - AE Loss: 1769436.750 (690796.000) - AE Rec Loss: 12.000 (4.685) - Disc
Loss: 0.000 (0.000) - 28.85 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 102552.086 (690581.562) - AE Rec Loss: 0.695 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.36 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.001 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 89301.844 (690581.562) - AE Rec Loss: 0.606 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.22 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.001 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 240067.812 (690581.562) - AE Rec Loss: 1.628 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.24 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 778897.562 (690581.562) - AE Rec Loss: 5.282 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.21 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.001 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 1581325.750 (690581.562) - AE Rec Loss: 10.724 (4.683) - Disc
Loss: 0.000 (0.000) - 36.22 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 0.000 (0.358) - Batch(s): 13.223 
(2.640) - AE Loss: 318148.469 (690581.562) - AE Rec Loss: 2.158 (4.683) - Disc 
Loss: 0.000 (0.000) - 36.23 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.569 
(2.546) - AE Loss: 111997.484 (686442.438) - AE Rec Loss: 0.760 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.06 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.570 
(2.546) - AE Loss: 214891.500 (686442.438) - AE Rec Loss: 1.457 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.08 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.571 
(2.546) - AE Loss: 528941.625 (686442.438) - AE Rec Loss: 3.587 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.06 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.558 
(2.546) - AE Loss: 142071.438 (686442.438) - AE Rec Loss: 0.963 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.07 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.569 
(2.546) - AE Loss: 556600.625 (686442.438) - AE Rec Loss: 3.775 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.05 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.577 
(2.546) - AE Loss: 169447.000 (686442.438) - AE Rec Loss: 1.149 (4.655) - Disc 
Loss: 0.000 (0.000) - 36.19 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.570 
(2.460) - AE Loss: 142397.141 (678890.188) - AE Rec Loss: 0.966 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.92 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.569 
(2.460) - AE Loss: 157524.047 (678890.188) - AE Rec Loss: 1.068 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.90 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.569 
(2.460) - AE Loss: 300457.469 (678890.188) - AE Rec Loss: 2.038 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.89 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.558 
(2.460) - AE Loss: 98540.586 (678890.188) - AE Rec Loss: 0.668 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.91 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.571 
(2.460) - AE Loss: 823761.875 (678890.188) - AE Rec Loss: 5.586 (4.604) - Disc 
Loss: 0.000 (0.000) - 35.91 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.577 
(2.460) - AE Loss: 234696.844 (678890.188) - AE Rec Loss: 1.592 (4.604) - Disc 
Loss: 0.000 (0.000) - 36.03 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 322495.688 (681374.875) - AE Rec Loss: 2.187 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.95 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 1891459.375 (681374.875) - AE Rec Loss: 12.827 (4.621) - Disc
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 100844.609 (681374.875) - AE Rec Loss: 0.684 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.704 
(2.387) - AE Loss: 313229.094 (681374.875) - AE Rec Loss: 2.124 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.81 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.705 
(2.387) - AE Loss: 94269.914 (681374.875) - AE Rec Loss: 0.639 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.83 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (0.314) - Batch(s): 0.705 
(2.387) - AE Loss: 100177.016 (681374.875) - AE Rec Loss: 0.679 (4.621) - Disc 
Loss: 0.000 (0.000) - 35.85 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.571 
(2.314) - AE Loss: 121336.180 (685363.062) - AE Rec Loss: 0.823 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.68 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.557 
(2.314) - AE Loss: 1978711.000 (685363.062) - AE Rec Loss: 13.419 (4.648) - Disc
Loss: 0.000 (0.000) - 35.69 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.571 
(2.314) - AE Loss: 253022.594 (685363.062) - AE Rec Loss: 1.716 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.70 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.570 
(2.314) - AE Loss: 154796.969 (685363.062) - AE Rec Loss: 1.050 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.67 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.579 
(2.314) - AE Loss: 365027.438 (685363.062) - AE Rec Loss: 2.476 (4.648) - Disc 
Loss: 0.000 (0.000) - 35.80 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (0.301) - Batch(s): 0.570 
(2.314) - AE Loss: 1725173.125 (685363.062) - AE Rec Loss: 11.700 (4.648) - Disc
Loss: 0.000 (0.000) - 35.68 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.570 
(2.247) - AE Loss: 566563.250 (684622.562) - AE Rec Loss: 3.842 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.56 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.571 
(2.247) - AE Loss: 353285.844 (684622.562) - AE Rec Loss: 2.396 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.52 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.558 
(2.247) - AE Loss: 521644.031 (684622.562) - AE Rec Loss: 3.538 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.54 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.572 
(2.247) - AE Loss: 262186.500 (684622.562) - AE Rec Loss: 1.778 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.54 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.580 
(2.247) - AE Loss: 483684.219 (684622.562) - AE Rec Loss: 3.280 (4.643) - Disc 
Loss: 0.000 (0.000) - 35.66 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.570 
(2.247) - AE Loss: 1575987.500 (684622.562) - AE Rec Loss: 10.688 (4.643) - Disc
Loss: 0.000 (0.000) - 35.54 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:56:43,505[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,510[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,536[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,738[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,749[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:56:43,754[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:56:45,737[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,789[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,791[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:45,947[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:46,016[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:56:46,049[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,248[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,313[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,368[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,543[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,567[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:56:46,611[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 02:56:46,612[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 02:56:46,613[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
[[36m2023-11-29 02:56:46,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
[[36m2023-11-29 02:56:46,620[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:56:46,621[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:56:46,621[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 3 on node 7
Reached 5 on node 9
Reached 5 on node 7
Reached end on node 9
Reached end on node 7
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 1.3 on node 6Reached 1.3 on node 8

Reached 1.4 on node 8
Reached 1.4 on node 6
Reached 2 on node 8
Reached 2 on node 6
Reached 3 on node 8
Reached 3 on node 6
Reached 5 on node 6Reached 5 on node 8

Reached end on node 6Reached end on node 8

=> Preparing opt_ae 
Reached 1.3 on node 9Reached 1.3 on node 7

Reached 1.4 on node 9
Reached 1.4 on node 7
Reached 2 on node 9
Reached 2 on node 7
Reached 3 on node 9
Reached 3 on node 7
Reached 5 on node 9
Reached 5 on node 7
Reached end on node 9
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1 on node 11
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.3 on node 6Reached 1.3 on node 8Reached 1.4 on node 10


Reached 1.4 on node 6Reached 1.4 on node 8

Reached 1.3 on node 7Reached 1.3 on node 11
Reached 2 on node 6Reached 2 on node 8
Reached 1.3 on node 9Reached 1.4 on node 7Reached 2 on node 10



Reached 1.4 on node 11
Reached 1.4 on node 9
Reached 2 on node 7

Reached 3 on node 6Reached 3 on node 8
Reached 2 on node 11

Reached 2 on node 9
Reached 3 on node 10Reached 5 on node 6
Reached 3 on node 7
Reached 5 on node 8

Reached 5 on node 10Reached 3 on node 11Reached 5 on node 7
Reached end on node 6Reached 3 on node 9
Reached end on node 8



Reached end on node 10
Reached 5 on node 11Reached 5 on node 9Reached end on node 7


Reached end on node 11
Reached end on node 9
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 6
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7Reached 1 on node 8

Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 6
Reached 2 on node 7
Reached 2 on node 6Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 11Reached 1 on node 8

Reached 3 on node 6
Reached 1.4 on node 7Reached 3 on node 6

Reached 2 on node 7
Reached 3 on node 6
Reached 3 on node 6Reached 1.4 on node 8

Reached 3 on node 6Reached 1.4 on node 11Reached 2 on node 8


Reached 5 on node 6
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1 on node 8Reached 3 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7Reached 1.4 on node 11
Reached 1.4 on node 8Reached 3 on node 7


Reached 2 on node 11Reached 2 on node 8Reached 5 on node 7


Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 1.4 on node 8Reached 2 on node 11

Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8Reached 1 on node 10

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached end on node 6Reached 3 on node 10

Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 1 on node 9Reached 2 on node 10

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 10
Reached end on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 7
Reached end on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <061/2280>] - Data(s): 6.740 (5.597) - Batch(s): 8.644 
(9.018) - AE Loss: 1581623.875 (686166.625) - AE Rec Loss: 10.726 (4.653) - Disc
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 4.007 (5.597) - Batch(s): 8.645 
(9.018) - AE Loss: 89444.141 (686166.625) - AE Rec Loss: 0.607 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 7.176 (5.597) - Batch(s): 8.643 
(9.018) - AE Loss: 102368.289 (686166.625) - AE Rec Loss: 0.694 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 5.528 (5.597) - Batch(s): 8.648 
(9.018) - AE Loss: 241856.109 (686166.625) - AE Rec Loss: 1.640 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 3.457 (5.597) - Batch(s): 8.589 
(9.018) - AE Loss: 316411.844 (686166.625) - AE Rec Loss: 2.146 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 4.393 (5.597) - Batch(s): 8.642 
(9.018) - AE Loss: 777015.312 (686166.625) - AE Rec Loss: 5.269 (4.653) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.799) - Batch(s): 0.567 
(4.793) - AE Loss: 217996.938 (645467.188) - AE Rec Loss: 1.478 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.574 
(4.793) - AE Loss: 175140.344 (645467.188) - AE Rec Loss: 1.188 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.799) - Batch(s): 0.566 
(4.793) - AE Loss: 562579.250 (645467.188) - AE Rec Loss: 3.815 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.001 (2.799) - Batch(s): 0.556 
(4.793) - AE Loss: 154685.281 (645467.188) - AE Rec Loss: 1.049 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.571 
(4.793) - AE Loss: 541851.125 (645467.188) - AE Rec Loss: 3.675 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.799) - Batch(s): 0.570 
(4.793) - AE Loss: 120890.156 (645467.188) - AE Rec Loss: 0.820 (4.377) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <063/2280>] - Data(s): 1.252 (2.198) - Batch(s): 6.267 
(5.284) - AE Loss: 92235.648 (603111.750) - AE Rec Loss: 0.626 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.28 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.198) - Batch(s): 6.267 
(5.284) - AE Loss: 826044.812 (603111.750) - AE Rec Loss: 5.602 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.30 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.198) - Batch(s): 6.267 
(5.284) - AE Loss: 174042.000 (603111.750) - AE Rec Loss: 1.180 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.30 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.492 (2.198) - Batch(s): 6.268 
(5.284) - AE Loss: 156450.750 (603111.750) - AE Rec Loss: 1.061 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.30 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.198) - Batch(s): 6.268 
(5.284) - AE Loss: 238114.750 (603111.750) - AE Rec Loss: 1.615 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.30 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.198) - Batch(s): 6.268 
(5.284) - AE Loss: 300248.000 (603111.750) - AE Rec Loss: 2.036 (4.090) - Disc 
Loss: 0.000 (0.000) - 9.30 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.568 
(4.105) - AE Loss: 94071.367 (636837.625) - AE Rec Loss: 0.638 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.56 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.556 
(4.105) - AE Loss: 1893450.250 (636837.625) - AE Rec Loss: 12.841 (4.319) - Disc
Loss: 0.000 (0.000) - 9.55 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.569 
(4.105) - AE Loss: 94838.125 (636837.625) - AE Rec Loss: 0.643 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.56 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.567 
(4.105) - AE Loss: 90198.375 (636837.625) - AE Rec Loss: 0.612 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.56 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.575 
(4.105) - AE Loss: 321109.000 (636837.625) - AE Rec Loss: 2.178 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.56 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.648) - Batch(s): 0.567 
(4.105) - AE Loss: 318213.500 (636837.625) - AE Rec Loss: 2.158 (4.319) - Disc 
Loss: 0.000 (0.000) - 9.56 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (1.319) - Batch(s): 0.556 
(3.398) - AE Loss: 1974493.500 (665625.062) - AE Rec Loss: 13.390 (4.514) - Disc
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.575 
(3.398) - AE Loss: 378811.094 (665625.062) - AE Rec Loss: 2.569 (4.514) - Disc 
Loss: 0.000 (0.000) - 9.83 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.569 
(3.398) - AE Loss: 243370.031 (665625.062) - AE Rec Loss: 1.650 (4.514) - Disc 
Loss: 0.000 (0.000) - 9.83 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.567 
(3.398) - AE Loss: 140741.188 (665625.062) - AE Rec Loss: 0.954 (4.514) - Disc 
Loss: 0.000 (0.000) - 9.83 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.570 
(3.398) - AE Loss: 98047.258 (665625.062) - AE Rec Loss: 0.665 (4.514) - Disc 
Loss: 0.000 (0.000) - 9.83 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.319) - Batch(s): 0.569 
(3.398) - AE Loss: 1730751.750 (665625.062) - AE Rec Loss: 11.737 (4.514) - Disc
Loss: 0.000 (0.000) - 9.83 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.882 
(3.312) - AE Loss: 512293.500 (665944.188) - AE Rec Loss: 3.474 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 564255.625 (665944.188) - AE Rec Loss: 3.827 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 367158.000 (665944.188) - AE Rec Loss: 2.490 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.881 
(3.312) - AE Loss: 1563905.250 (665944.188) - AE Rec Loss: 10.606 (4.516) - Disc
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.882 
(3.312) - AE Loss: 274835.312 (665944.188) - AE Rec Loss: 1.864 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.132) - Batch(s): 2.883 
(3.312) - AE Loss: 485298.875 (665944.188) - AE Rec Loss: 3.291 (4.516) - Disc 
Loss: 0.000 (0.000) - 11.35 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.568 
(2.920) - AE Loss: 227516.438 (679314.188) - AE Rec Loss: 1.543 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.58 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.569 
(2.920) - AE Loss: 616023.625 (679314.188) - AE Rec Loss: 4.178 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.58 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.571 
(2.920) - AE Loss: 167841.391 (679314.188) - AE Rec Loss: 1.138 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.58 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.569 
(2.920) - AE Loss: 1602159.125 (679314.188) - AE Rec Loss: 10.865 (4.607) - Disc
Loss: 0.000 (0.000) - 11.58 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.557 
(2.920) - AE Loss: 283686.031 (679314.188) - AE Rec Loss: 1.924 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.57 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.970) - Batch(s): 0.577 
(2.920) - AE Loss: 2171322.750 (679314.188) - AE Rec Loss: 14.725 (4.607) - Disc
Loss: 0.000 (0.000) - 11.58 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.569 
(2.626) - AE Loss: 1065344.000 (681051.438) - AE Rec Loss: 7.225 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.80 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.576 
(2.626) - AE Loss: 1804722.625 (681051.438) - AE Rec Loss: 12.239 (4.619) - Disc
Loss: 0.000 (0.000) - 11.80 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.568 
(2.626) - AE Loss: 761459.750 (681051.438) - AE Rec Loss: 5.164 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.80 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.556 
(2.626) - AE Loss: 1535874.750 (681051.438) - AE Rec Loss: 10.416 (4.619) - Disc
Loss: 0.000 (0.000) - 11.79 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.570 
(2.626) - AE Loss: 320697.844 (681051.438) - AE Rec Loss: 2.175 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.80 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.849) - Batch(s): 0.568 
(2.626) - AE Loss: 299036.656 (681051.438) - AE Rec Loss: 2.028 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.80 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.975 
(2.554) - AE Loss: 318678.000 (700792.438) - AE Rec Loss: 2.161 (4.753) - Disc 
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 1933136.125 (700792.438) - AE Rec Loss: 13.110 (4.753) - Disc
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 1.300 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 1450918.750 (700792.438) - AE Rec Loss: 9.840 (4.753) - Disc 
Loss: 0.000 (0.000) - 12.74 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.976 
(2.554) - AE Loss: 144397.750 (700792.438) - AE Rec Loss: 0.979 (4.753) - Disc 
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 1506019.250 (700792.438) - AE Rec Loss: 10.213 (4.753) - Disc
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 1.974 
(2.554) - AE Loss: 1615592.000 (700792.438) - AE Rec Loss: 10.956 (4.753) - Disc
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.896 
(2.681) - AE Loss: 1609951.125 (717482.688) - AE Rec Loss: 10.918 (4.866) - Disc
Loss: 0.000 (0.000) - 14.66 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.879 
(2.681) - AE Loss: 1557308.250 (717482.688) - AE Rec Loss: 10.561 (4.866) - Disc
Loss: 0.000 (0.000) - 14.65 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.893 
(2.681) - AE Loss: 386240.375 (717482.688) - AE Rec Loss: 2.619 (4.866) - Disc 
Loss: 0.000 (0.000) - 14.66 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.892 
(2.681) - AE Loss: 270187.188 (717482.688) - AE Rec Loss: 1.832 (4.866) - Disc 
Loss: 0.000 (0.000) - 14.66 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.889 
(2.681) - AE Loss: 1596883.000 (717482.688) - AE Rec Loss: 10.830 (4.866) - Disc
Loss: 0.000 (0.000) - 14.66 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.732) - Batch(s): 3.892 
(2.681) - AE Loss: 90836.422 (717482.688) - AE Rec Loss: 0.616 (4.866) - Disc 
Loss: 0.000 (0.000) - 14.66 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.608 
(2.593) - AE Loss: 236126.672 (720890.375) - AE Rec Loss: 1.601 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.54 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 1.405 (0.676) - Batch(s): 1.954 
(2.593) - AE Loss: 156022.562 (720890.375) - AE Rec Loss: 1.058 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.53 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.971 
(2.593) - AE Loss: 150652.344 (720890.375) - AE Rec Loss: 1.022 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.54 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.964 
(2.593) - AE Loss: 302765.531 (720890.375) - AE Rec Loss: 2.053 (4.889) - Disc 
Loss: 0.000 (0.000) - 15.54 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.967 
(2.593) - AE Loss: 1730216.250 (720890.375) - AE Rec Loss: 11.734 (4.889) - Disc
Loss: 0.000 (0.000) - 15.54 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.676) - Batch(s): 1.968 
(2.593) - AE Loss: 1506841.000 (720890.375) - AE Rec Loss: 10.219 (4.889) - Disc
Loss: 0.000 (0.000) - 15.54 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 170420.562 (729916.500) - AE Rec Loss: 1.156 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.49 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 159105.391 (729916.500) - AE Rec Loss: 1.079 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.48 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 1.781 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 1847763.750 (729916.500) - AE Rec Loss: 12.531 (4.950) - Disc
Loss: 0.000 (0.000) - 18.47 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.116 
(2.886) - AE Loss: 1787868.500 (729916.500) - AE Rec Loss: 12.125 (4.950) - Disc
Loss: 0.000 (0.000) - 18.49 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.114 
(2.886) - AE Loss: 197597.328 (729916.500) - AE Rec Loss: 1.340 (4.950) - Disc 
Loss: 0.000 (0.000) - 18.48 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.691) - Batch(s): 6.116 
(2.886) - AE Loss: 1692193.000 (729916.500) - AE Rec Loss: 11.476 (4.950) - Disc
Loss: 0.000 (0.000) - 18.49 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.678) - Batch(s): 5.402 
(3.076) - AE Loss: 205114.500 (727115.875) - AE Rec Loss: 1.391 (4.931) - Disc 
Loss: 0.000 (0.000) - 20.99 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.678) - Batch(s): 5.419 
(3.076) - AE Loss: 260766.953 (727115.875) - AE Rec Loss: 1.768 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.00 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.241 (0.678) - Batch(s): 5.416 
(3.076) - AE Loss: 150930.562 (727115.875) - AE Rec Loss: 1.024 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.00 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.678) - Batch(s): 5.413 
(3.076) - AE Loss: 226711.422 (727115.875) - AE Rec Loss: 1.537 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.00 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.678) - Batch(s): 5.415 
(3.076) - AE Loss: 1562144.000 (727115.875) - AE Rec Loss: 10.594 (4.931) - Disc
Loss: 0.000 (0.000) - 21.00 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 1.174 (0.678) - Batch(s): 5.415 
(3.076) - AE Loss: 194422.766 (727115.875) - AE Rec Loss: 1.319 (4.931) - Disc 
Loss: 0.000 (0.000) - 21.00 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.557 
(2.897) - AE Loss: 1812666.000 (736156.625) - AE Rec Loss: 12.293 (4.992) - Disc
Loss: 0.000 (0.000) - 21.06 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.570 
(2.897) - AE Loss: 240488.453 (736156.625) - AE Rec Loss: 1.631 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.07 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.576 
(2.897) - AE Loss: 134495.781 (736156.625) - AE Rec Loss: 0.912 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.07 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.572 
(2.897) - AE Loss: 292954.062 (736156.625) - AE Rec Loss: 1.987 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.07 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.569 
(2.897) - AE Loss: 2994113.500 (736156.625) - AE Rec Loss: 20.305 (4.992) - Disc
Loss: 0.000 (0.000) - 21.07 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.630) - Batch(s): 0.570 
(2.897) - AE Loss: 221798.094 (736156.625) - AE Rec Loss: 1.504 (4.992) - Disc 
Loss: 0.000 (0.000) - 21.07 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.001 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 1864278.250 (725494.250) - AE Rec Loss: 12.643 (4.920) - Disc
Loss: 0.000 (0.000) - 21.46 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 594095.625 (725494.250) - AE Rec Loss: 4.029 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.46 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 165946.609 (725494.250) - AE Rec Loss: 1.125 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.46 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 1683704.000 (725494.250) - AE Rec Loss: 11.418 (4.920) - Disc
Loss: 0.000 (0.000) - 21.46 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.247 
(2.787) - AE Loss: 228116.297 (725494.250) - AE Rec Loss: 1.547 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.591) - Batch(s): 1.249 
(2.787) - AE Loss: 613148.062 (725494.250) - AE Rec Loss: 4.158 (4.920) - Disc 
Loss: 0.000 (0.000) - 21.46 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.569 
(2.649) - AE Loss: 88760.719 (714627.500) - AE Rec Loss: 0.602 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.52 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.554) - Batch(s): 0.570 
(2.649) - AE Loss: 211134.688 (714627.500) - AE Rec Loss: 1.432 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.52 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.556 
(2.649) - AE Loss: 1561359.750 (714627.500) - AE Rec Loss: 10.589 (4.846) - Disc
Loss: 0.000 (0.000) - 21.51 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.571 
(2.649) - AE Loss: 302632.250 (714627.500) - AE Rec Loss: 2.052 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.52 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.001 (0.554) - Batch(s): 0.569 
(2.649) - AE Loss: 263847.312 (714627.500) - AE Rec Loss: 1.789 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.554) - Batch(s): 0.578 
(2.649) - AE Loss: 154790.688 (714627.500) - AE Rec Loss: 1.050 (4.846) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.883 
(2.601) - AE Loss: 256860.625 (700045.188) - AE Rec Loss: 1.742 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.20 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.896 
(2.601) - AE Loss: 327946.438 (700045.188) - AE Rec Loss: 2.224 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.21 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.900 
(2.601) - AE Loss: 112128.102 (700045.188) - AE Rec Loss: 0.760 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.21 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.893 
(2.601) - AE Loss: 297885.000 (700045.188) - AE Rec Loss: 2.020 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.21 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.895 
(2.601) - AE Loss: 432388.719 (700045.188) - AE Rec Loss: 2.932 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.21 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.528) - Batch(s): 1.895 
(2.601) - AE Loss: 244934.000 (700045.188) - AE Rec Loss: 1.661 (4.747) - Disc 
Loss: 0.000 (0.000) - 22.21 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.997 
(2.734) - AE Loss: 292374.188 (693113.312) - AE Rec Loss: 1.983 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.31 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.997 
(2.734) - AE Loss: 348766.938 (693113.312) - AE Rec Loss: 2.365 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.31 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.997 
(2.734) - AE Loss: 524091.156 (693113.312) - AE Rec Loss: 3.554 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.31 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 5.000 
(2.734) - AE Loss: 1495713.375 (693113.312) - AE Rec Loss: 10.143 (4.700) - Disc
Loss: 0.000 (0.000) - 24.31 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.519) - Batch(s): 4.999 
(2.734) - AE Loss: 229771.312 (693113.312) - AE Rec Loss: 1.558 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.30 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.001 (0.519) - Batch(s): 4.999 
(2.734) - AE Loss: 813774.562 (693113.312) - AE Rec Loss: 5.519 (4.700) - Disc 
Loss: 0.000 (0.000) - 24.31 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.576 
(2.620) - AE Loss: 260457.094 (692458.438) - AE Rec Loss: 1.766 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.33 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.570 
(2.620) - AE Loss: 119844.141 (692458.438) - AE Rec Loss: 0.813 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.33 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.492) - Batch(s): 0.569 
(2.620) - AE Loss: 1599448.250 (692458.438) - AE Rec Loss: 10.847 (4.696) - Disc
Loss: 0.000 (0.000) - 24.33 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.569 
(2.620) - AE Loss: 230208.359 (692458.438) - AE Rec Loss: 1.561 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.33 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.492) - Batch(s): 0.556 
(2.620) - AE Loss: 315148.750 (692458.438) - AE Rec Loss: 2.137 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.32 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.492) - Batch(s): 0.571 
(2.620) - AE Loss: 1464397.500 (692458.438) - AE Rec Loss: 9.931 (4.696) - Disc 
Loss: 0.000 (0.000) - 24.33 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.859 
(2.583) - AE Loss: 80197.859 (687564.312) - AE Rec Loss: 0.544 (4.663) - Disc 
Loss: 0.000 (0.000) - 24.93 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.873 
(2.583) - AE Loss: 238794.812 (687564.312) - AE Rec Loss: 1.619 (4.663) - Disc 
Loss: 0.000 (0.000) - 24.94 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.870 
(2.583) - AE Loss: 222410.750 (687564.312) - AE Rec Loss: 1.508 (4.663) - Disc 
Loss: 0.000 (0.000) - 24.94 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.873 
(2.583) - AE Loss: 1682924.000 (687564.312) - AE Rec Loss: 11.413 (4.663) - Disc
Loss: 0.000 (0.000) - 24.94 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.248 (0.474) - Batch(s): 1.877 
(2.583) - AE Loss: 486814.781 (687564.312) - AE Rec Loss: 3.301 (4.663) - Disc 
Loss: 0.000 (0.000) - 24.94 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.474) - Batch(s): 1.873 
(2.583) - AE Loss: 494527.250 (687564.312) - AE Rec Loss: 3.354 (4.663) - Disc 
Loss: 0.000 (0.000) - 24.94 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channelsWorking with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:58:17,375[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,380[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,407[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,439[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,453[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:58:17,473[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:58:19,644[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:19,649[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:19,653[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:19,671[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:19,718[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:58:19,725[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:58:20,262[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 02:58:20,265[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:20,299[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 02:58:20,314[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 02:58:20,319[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:58:20,335[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 02:58:20,336[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 02:58:20,338[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 02:58:20,340[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Preparing opt_disc 
=> Instantiating train dataloader 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
=> Preparing model 
Reached end on node 6
=> Preparing model 
len(train_dataset) = 54706
[[36m2023-11-29 02:58:20,343[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:58:20,343[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 02:58:20,346[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 1.3 on node 6=> Preparing criterion 

Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1.3 on node 9Reached 1.3 on node 7

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 5 on node 6
Reached 2 on node 7
Reached end on node 6Reached 2 on node 9

Reached 3 on node 7
Reached 3 on node 9
Reached 5 on node 7
Reached 5 on node 9
Reached end on node 7
Reached end on node 9
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 3 on node 7Reached 3 on node 9

Reached 5 on node 9
Reached 5 on node 7
Reached end on node 9
Reached 3 on node 6Reached end on node 7

Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 1.3 on node 8
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 11
Reached 5 on node 11
Reached 3 on node 8
Reached 5 on node 8Reached 1.3 on node 10
Reached end on node 11

Reached 1.4 on node 10Reached end on node 8

Reached 1.3 on node 9
Reached 1.4 on node 9Reached 2 on node 10Reached 1.3 on node 7


Reached 1.4 on node 7
Reached 2 on node 9
Reached 2 on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached 3 on node 9
Reached 3 on node 7
Reached 5 on node 9Reached end on node 10
Reached 5 on node 7

Reached end on node 9
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
Loaded checkpoint at epoch 0 and step 61
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 61
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 1.4 on node 7
Reached 2 on node 8Reached 2 on node 7

Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 7
Reached 1.4 on node 8Reached 2 on node 7

Reached 1.4 on node 10
Reached 2 on node 8Reached 1 on node 6
Reached 2 on node 10

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11Reached 1 on node 7

Reached 1 on node 8
Reached 1 on node 10Reached 1.4 on node 7

Reached 1.4 on node 8
Reached 2 on node 7
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 7
Reached 1 on node 10Reached 1.4 on node 8

Reached 2 on node 8Reached 1.4 on node 7

Reached 2 on node 7
Reached 1.4 on node 10Reached 3 on node 7

Reached 2 on node 10
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 11
Reached 5 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 1.4 on node 10
Reached 3 on node 8
Reached 2 on node 10Reached 3 on node 8

Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11Reached 3 on node 9

Reached 3 on node 9Reached 2 on node 11

Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 7
Reached 1 on node 11Reached end on node 8

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9Reached 1.4 on node 10

Reached 2 on node 9Reached 2 on node 10

Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 7
Reached end on node 9
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 11
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <061/2280>] - Data(s): 5.453 (5.787) - Batch(s): 10.812 
(10.674) - AE Loss: 241951.594 (686665.875) - AE Rec Loss: 1.641 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.62 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 7.069 (5.787) - Batch(s): 10.453 
(10.674) - AE Loss: 1581619.750 (686665.875) - AE Rec Loss: 10.726 (4.657) - 
Disc Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 4.102 (5.787) - Batch(s): 10.765 
(10.674) - AE Loss: 90665.016 (686665.875) - AE Rec Loss: 0.615 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.60 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 7.315 (5.787) - Batch(s): 10.844 
(10.674) - AE Loss: 103407.406 (686665.875) - AE Rec Loss: 0.701 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.63 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 3.252 (5.787) - Batch(s): 10.532 
(10.674) - AE Loss: 777721.125 (686665.875) - AE Rec Loss: 5.274 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.45 m remaining

[Epoch <000/100>: Step <061/2280>] - Data(s): 3.708 (5.787) - Batch(s): 10.788 
(10.674) - AE Loss: 316773.000 (686665.875) - AE Rec Loss: 2.148 (4.657) - Disc 
Loss: 0.000 (0.000) - 6.61 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.568 
(5.621) - AE Loss: 217166.281 (645952.312) - AE Rec Loss: 1.473 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.568 
(5.621) - AE Loss: 541240.688 (645952.312) - AE Rec Loss: 3.671 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.574 
(5.621) - AE Loss: 175539.797 (645952.312) - AE Rec Loss: 1.190 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.567 
(5.621) - AE Loss: 564288.500 (645952.312) - AE Rec Loss: 3.827 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.77 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.554 
(5.621) - AE Loss: 155943.844 (645952.312) - AE Rec Loss: 1.058 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <062/2280>] - Data(s): 0.000 (2.894) - Batch(s): 0.566 
(5.621) - AE Loss: 121138.953 (645952.312) - AE Rec Loss: 0.822 (4.381) - Disc 
Loss: 0.000 (0.000) - 6.74 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.801 
(5.347) - AE Loss: 156874.531 (603362.250) - AE Rec Loss: 1.064 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.801 
(5.347) - AE Loss: 300131.250 (603362.250) - AE Rec Loss: 2.035 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.53 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.802 
(5.347) - AE Loss: 825058.875 (603362.250) - AE Rec Loss: 5.595 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.68 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.801 
(5.347) - AE Loss: 238862.703 (603362.250) - AE Rec Loss: 1.620 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.71 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.802 
(5.347) - AE Loss: 172624.594 (603362.250) - AE Rec Loss: 1.171 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.50 m remaining

[Epoch <000/100>: Step <063/2280>] - Data(s): 0.000 (2.131) - Batch(s): 4.801 
(5.347) - AE Loss: 91860.078 (603362.250) - AE Rec Loss: 0.623 (4.092) - Disc 
Loss: 0.000 (0.000) - 9.68 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.569 
(4.153) - AE Loss: 95793.359 (637045.688) - AE Rec Loss: 0.650 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.96 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.568 
(4.153) - AE Loss: 318224.562 (637045.688) - AE Rec Loss: 2.158 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.80 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.577 
(4.153) - AE Loss: 323558.688 (637045.688) - AE Rec Loss: 2.194 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.97 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.555 
(4.153) - AE Loss: 1892839.625 (637045.688) - AE Rec Loss: 12.837 (4.320) - Disc
Loss: 0.000 (0.000) - 9.95 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.568 
(4.153) - AE Loss: 90560.422 (637045.688) - AE Rec Loss: 0.614 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <064/2280>] - Data(s): 0.000 (1.598) - Batch(s): 0.570 
(4.153) - AE Loss: 95477.406 (637045.688) - AE Rec Loss: 0.647 (4.320) - Disc 
Loss: 0.000 (0.000) - 9.94 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.558 
(3.436) - AE Loss: 1977770.000 (665809.625) - AE Rec Loss: 13.413 (4.515) - Disc
Loss: 0.000 (0.000) - 10.21 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.568 
(3.436) - AE Loss: 142571.203 (665809.625) - AE Rec Loss: 0.967 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.06 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.001 (1.279) - Batch(s): 0.571 
(3.436) - AE Loss: 100346.891 (665809.625) - AE Rec Loss: 0.681 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.20 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.568 
(3.436) - AE Loss: 1729858.875 (665809.625) - AE Rec Loss: 11.731 (4.515) - Disc
Loss: 0.000 (0.000) - 10.03 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.570 
(3.436) - AE Loss: 243550.828 (665809.625) - AE Rec Loss: 1.652 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.22 m remaining

[Epoch <000/100>: Step <065/2280>] - Data(s): 0.000 (1.279) - Batch(s): 0.576 
(3.436) - AE Loss: 377819.156 (665809.625) - AE Rec Loss: 2.562 (4.515) - Disc 
Loss: 0.000 (0.000) - 10.24 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.435 
(3.269) - AE Loss: 513529.750 (666093.875) - AE Rec Loss: 3.483 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.48 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.434 
(3.269) - AE Loss: 484512.438 (666093.875) - AE Rec Loss: 3.286 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.51 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.001 (1.110) - Batch(s): 2.435 
(3.269) - AE Loss: 565736.250 (666093.875) - AE Rec Loss: 3.837 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.50 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.436 
(3.269) - AE Loss: 1564257.000 (666093.875) - AE Rec Loss: 10.608 (4.517) - Disc
Loss: 0.000 (0.000) - 11.31 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.437 
(3.269) - AE Loss: 366217.875 (666093.875) - AE Rec Loss: 2.484 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.34 m remaining

[Epoch <000/100>: Step <066/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.437 
(3.269) - AE Loss: 273595.219 (666093.875) - AE Rec Loss: 1.855 (4.517) - Disc 
Loss: 0.000 (0.000) - 11.48 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.575 
(2.883) - AE Loss: 2168103.500 (679391.188) - AE Rec Loss: 14.703 (4.607) - Disc
Loss: 0.000 (0.000) - 11.74 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.568 
(2.883) - AE Loss: 617334.062 (679391.188) - AE Rec Loss: 4.187 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.72 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.556 
(2.883) - AE Loss: 284534.500 (679391.188) - AE Rec Loss: 1.930 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.71 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.568 
(2.883) - AE Loss: 1601740.500 (679391.188) - AE Rec Loss: 10.862 (4.607) - Disc
Loss: 0.000 (0.000) - 11.54 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.570 
(2.883) - AE Loss: 167579.312 (679391.188) - AE Rec Loss: 1.136 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.70 m remaining

[Epoch <000/100>: Step <067/2280>] - Data(s): 0.000 (0.952) - Batch(s): 0.567 
(2.883) - AE Loss: 229164.531 (679391.188) - AE Rec Loss: 1.554 (4.607) - Disc 
Loss: 0.000 (0.000) - 11.57 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.557 
(2.594) - AE Loss: 1537247.500 (681123.375) - AE Rec Loss: 10.425 (4.619) - Disc
Loss: 0.000 (0.000) - 11.93 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.570 
(2.594) - AE Loss: 1064950.500 (681123.375) - AE Rec Loss: 7.222 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.94 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.576 
(2.594) - AE Loss: 1806089.000 (681123.375) - AE Rec Loss: 12.248 (4.619) - Disc
Loss: 0.000 (0.000) - 11.95 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.569 
(2.594) - AE Loss: 762111.688 (681123.375) - AE Rec Loss: 5.168 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.76 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.570 
(2.594) - AE Loss: 320485.562 (681123.375) - AE Rec Loss: 2.173 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.92 m remaining

[Epoch <000/100>: Step <068/2280>] - Data(s): 0.000 (0.833) - Batch(s): 0.569 
(2.594) - AE Loss: 297489.812 (681123.375) - AE Rec Loss: 2.017 (4.619) - Disc 
Loss: 0.000 (0.000) - 11.79 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.222 
(2.664) - AE Loss: 316064.094 (700779.938) - AE Rec Loss: 2.143 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.55 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.001 (0.782) - Batch(s): 3.223 
(2.664) - AE Loss: 1932328.375 (700779.938) - AE Rec Loss: 13.104 (4.752) - Disc
Loss: 0.000 (0.000) - 13.56 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.224 
(2.664) - AE Loss: 1451908.375 (700779.938) - AE Rec Loss: 9.846 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.54 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.223 
(2.664) - AE Loss: 1507611.000 (700779.938) - AE Rec Loss: 10.224 (4.752) - Disc
Loss: 0.000 (0.000) - 13.37 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.224 
(2.664) - AE Loss: 145257.969 (700779.938) - AE Rec Loss: 0.985 (4.752) - Disc 
Loss: 0.000 (0.000) - 13.40 m remaining

[Epoch <000/100>: Step <069/2280>] - Data(s): 0.000 (0.782) - Batch(s): 3.224 
(2.664) - AE Loss: 1616112.000 (700779.938) - AE Rec Loss: 10.960 (4.752) - Disc
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.435 
(2.635) - AE Loss: 1609749.750 (717431.562) - AE Rec Loss: 10.917 (4.865) - Disc
Loss: 0.000 (0.000) - 14.71 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.431 
(2.635) - AE Loss: 89958.531 (717431.562) - AE Rec Loss: 0.610 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.70 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.418 
(2.635) - AE Loss: 1556304.500 (717431.562) - AE Rec Loss: 10.554 (4.865) - Disc
Loss: 0.000 (0.000) - 14.69 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.430 
(2.635) - AE Loss: 387369.000 (717431.562) - AE Rec Loss: 2.627 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.52 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.430 
(2.635) - AE Loss: 269838.250 (717431.562) - AE Rec Loss: 1.830 (4.865) - Disc 
Loss: 0.000 (0.000) - 14.68 m remaining

[Epoch <000/100>: Step <070/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.429 
(2.635) - AE Loss: 1596369.500 (717431.562) - AE Rec Loss: 10.826 (4.865) - Disc
Loss: 0.000 (0.000) - 14.55 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.001 (0.654) - Batch(s): 1.316 
(2.509) - AE Loss: 234801.188 (720778.812) - AE Rec Loss: 1.592 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.23 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.320 
(2.509) - AE Loss: 150049.656 (720778.812) - AE Rec Loss: 1.018 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.26 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.316 
(2.509) - AE Loss: 1728890.750 (720778.812) - AE Rec Loss: 11.725 (4.888) - Disc
Loss: 0.000 (0.000) - 15.25 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.314 
(2.509) - AE Loss: 302119.344 (720778.812) - AE Rec Loss: 2.049 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.10 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.303 
(2.509) - AE Loss: 155428.047 (720778.812) - AE Rec Loss: 1.054 (4.888) - Disc 
Loss: 0.000 (0.000) - 15.24 m remaining

[Epoch <000/100>: Step <071/2280>] - Data(s): 0.000 (0.654) - Batch(s): 1.315 
(2.509) - AE Loss: 1505636.875 (720778.812) - AE Rec Loss: 10.211 (4.888) - Disc
Loss: 0.000 (0.000) - 15.07 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.255 
(2.488) - AE Loss: 159796.469 (729793.875) - AE Rec Loss: 1.084 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.001 (0.610) - Batch(s): 2.255 
(2.488) - AE Loss: 1787264.500 (729793.875) - AE Rec Loss: 12.121 (4.949) - Disc
Loss: 0.000 (0.000) - 16.26 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.001 (0.610) - Batch(s): 2.257 
(2.488) - AE Loss: 1690845.875 (729793.875) - AE Rec Loss: 11.467 (4.949) - Disc
Loss: 0.000 (0.000) - 16.23 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.257 
(2.488) - AE Loss: 1846676.375 (729793.875) - AE Rec Loss: 12.524 (4.949) - Disc
Loss: 0.000 (0.000) - 16.24 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.257 
(2.488) - AE Loss: 196270.781 (729793.875) - AE Rec Loss: 1.331 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <072/2280>] - Data(s): 0.000 (0.610) - Batch(s): 2.257 
(2.488) - AE Loss: 170255.922 (729793.875) - AE Rec Loss: 1.155 (4.949) - Disc 
Loss: 0.000 (0.000) - 16.08 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.557 
(2.342) - AE Loss: 206627.812 (727051.438) - AE Rec Loss: 1.401 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.41 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.001 (0.564) - Batch(s): 0.626 
(2.342) - AE Loss: 226664.062 (727051.438) - AE Rec Loss: 1.537 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.27 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.572 
(2.342) - AE Loss: 1563272.500 (727051.438) - AE Rec Loss: 10.602 (4.931) - Disc
Loss: 0.000 (0.000) - 16.40 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.060 (0.564) - Batch(s): 0.628 
(2.342) - AE Loss: 193819.984 (727051.438) - AE Rec Loss: 1.314 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.42 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.625 
(2.342) - AE Loss: 152307.594 (727051.438) - AE Rec Loss: 1.033 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.25 m remaining

[Epoch <000/100>: Step <073/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.631 
(2.342) - AE Loss: 261996.922 (727051.438) - AE Rec Loss: 1.777 (4.931) - Disc 
Loss: 0.000 (0.000) - 16.43 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.572 
(2.215) - AE Loss: 294351.531 (736152.750) - AE Rec Loss: 1.996 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.53 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.577 
(2.215) - AE Loss: 136181.625 (736152.750) - AE Rec Loss: 0.924 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.56 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.570 
(2.215) - AE Loss: 2993727.000 (736152.750) - AE Rec Loss: 20.303 (4.992) - Disc
Loss: 0.000 (0.000) - 16.55 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.571 
(2.215) - AE Loss: 222221.562 (736152.750) - AE Rec Loss: 1.507 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.41 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.559 
(2.215) - AE Loss: 1813179.500 (736152.750) - AE Rec Loss: 12.296 (4.992) - Disc
Loss: 0.000 (0.000) - 16.54 m remaining

[Epoch <000/100>: Step <074/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.570 
(2.215) - AE Loss: 241098.047 (736152.750) - AE Rec Loss: 1.635 (4.992) - Disc 
Loss: 0.000 (0.000) - 16.38 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.001 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 614528.938 (725531.562) - AE Rec Loss: 4.168 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.02 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 1862474.000 (725531.562) - AE Rec Loss: 12.631 (4.920) - Disc
Loss: 0.000 (0.000) - 17.16 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.558 
(2.171) - AE Loss: 1683771.750 (725531.562) - AE Rec Loss: 11.419 (4.920) - Disc
Loss: 0.000 (0.000) - 17.17 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 593855.875 (725531.562) - AE Rec Loss: 4.027 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.14 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 229442.141 (725531.562) - AE Rec Loss: 1.556 (4.920) - Disc 
Loss: 0.000 (0.000) - 17.15 m remaining

[Epoch <000/100>: Step <075/2280>] - Data(s): 0.000 (0.494) - Batch(s): 1.559 
(2.171) - AE Loss: 168851.734 (725531.562) - AE Rec Loss: 1.145 (4.920) - Disc 
Loss: 0.000 (0.000) - 16.99 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.659 
(2.073) - AE Loss: 154267.812 (714697.250) - AE Rec Loss: 1.046 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.33 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.652 
(2.073) - AE Loss: 266204.406 (714697.250) - AE Rec Loss: 1.805 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.16 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.087 (0.464) - Batch(s): 0.654 
(2.073) - AE Loss: 211415.531 (714697.250) - AE Rec Loss: 1.434 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.32 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.653 
(2.073) - AE Loss: 86894.344 (714697.250) - AE Rec Loss: 0.589 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.18 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.572 
(2.073) - AE Loss: 303246.000 (714697.250) - AE Rec Loss: 2.057 (4.847) - Disc 
Loss: 0.000 (0.000) - 17.30 m remaining

[Epoch <000/100>: Step <076/2280>] - Data(s): 0.000 (0.464) - Batch(s): 0.557 
(2.073) - AE Loss: 1560514.750 (714697.250) - AE Rec Loss: 10.583 (4.847) - Disc
Loss: 0.000 (0.000) - 17.31 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.001 (0.437) - Batch(s): 0.558 
(1.985) - AE Loss: 257464.328 (700115.000) - AE Rec Loss: 1.746 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.43 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.570 
(1.985) - AE Loss: 329826.688 (700115.000) - AE Rec Loss: 2.237 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.28 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.570 
(1.985) - AE Loss: 245924.000 (700115.000) - AE Rec Loss: 1.668 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.44 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.571 
(1.985) - AE Loss: 435930.562 (700115.000) - AE Rec Loss: 2.956 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.42 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.580 
(1.985) - AE Loss: 111124.078 (700115.000) - AE Rec Loss: 0.754 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.45 m remaining

[Epoch <000/100>: Step <077/2280>] - Data(s): 0.000 (0.437) - Batch(s): 0.570 
(1.985) - AE Loss: 296745.531 (700115.000) - AE Rec Loss: 2.012 (4.748) - Disc 
Loss: 0.000 (0.000) - 17.30 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.304 
(2.114) - AE Loss: 527013.062 (693217.938) - AE Rec Loss: 3.574 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.30 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.304 
(2.114) - AE Loss: 813739.250 (693217.938) - AE Rec Loss: 5.519 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.27 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.305 
(2.114) - AE Loss: 291946.250 (693217.938) - AE Rec Loss: 1.980 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.29 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.304 
(2.114) - AE Loss: 230234.875 (693217.938) - AE Rec Loss: 1.561 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.28 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.091 (0.429) - Batch(s): 4.304 
(2.114) - AE Loss: 1494851.250 (693217.938) - AE Rec Loss: 10.138 (4.701) - Disc
Loss: 0.000 (0.000) - 19.13 m remaining

[Epoch <000/100>: Step <078/2280>] - Data(s): 0.000 (0.429) - Batch(s): 4.305 
(2.114) - AE Loss: 350370.562 (693217.938) - AE Rec Loss: 2.376 (4.701) - Disc 
Loss: 0.000 (0.000) - 19.15 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.571 
(2.032) - AE Loss: 1463951.500 (692584.250) - AE Rec Loss: 9.928 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.36 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.557 
(2.032) - AE Loss: 316297.938 (692584.250) - AE Rec Loss: 2.145 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.407) - Batch(s): 0.569 
(2.032) - AE Loss: 228665.359 (692584.250) - AE Rec Loss: 1.551 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.24 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.000 (0.407) - Batch(s): 0.580 
(2.032) - AE Loss: 263415.812 (692584.250) - AE Rec Loss: 1.786 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.39 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.571 
(2.032) - AE Loss: 120385.375 (692584.250) - AE Rec Loss: 0.816 (4.697) - Disc 
Loss: 0.000 (0.000) - 19.38 m remaining

[Epoch <000/100>: Step <079/2280>] - Data(s): 0.001 (0.407) - Batch(s): 0.570 
(2.032) - AE Loss: 1598998.125 (692584.250) - AE Rec Loss: 10.844 (4.697) - Disc
Loss: 0.000 (0.000) - 19.22 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.571 
(1.959) - AE Loss: 494652.812 (687702.438) - AE Rec Loss: 3.355 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.47 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.572 
(1.959) - AE Loss: 234291.594 (687702.438) - AE Rec Loss: 1.589 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.580 
(1.959) - AE Loss: 487978.438 (687702.438) - AE Rec Loss: 3.309 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.47 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.001 (0.387) - Batch(s): 0.571 
(1.959) - AE Loss: 222417.359 (687702.438) - AE Rec Loss: 1.508 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.33 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.571 
(1.959) - AE Loss: 1685493.750 (687702.438) - AE Rec Loss: 11.430 (4.664) - Disc
Loss: 0.000 (0.000) - 19.31 m remaining

[Epoch <000/100>: Step <080/2280>] - Data(s): 0.000 (0.387) - Batch(s): 0.558 
(1.959) - AE Loss: 79578.695 (687702.438) - AE Rec Loss: 0.540 (4.664) - Disc 
Loss: 0.000 (0.000) - 19.45 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.001 (0.379) - Batch(s): 17.044 
(2.613) - AE Loss: 186919.938 (689631.250) - AE Rec Loss: 1.268 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.78 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.045 
(2.613) - AE Loss: 1837631.375 (689631.250) - AE Rec Loss: 12.462 (4.677) - Disc
Loss: 0.000 (0.000) - 26.92 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.045 
(2.613) - AE Loss: 448303.188 (689631.250) - AE Rec Loss: 3.040 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.91 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.045 
(2.613) - AE Loss: 528521.625 (689631.250) - AE Rec Loss: 3.584 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.89 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.282 (0.379) - Batch(s): 17.044 
(2.613) - AE Loss: 291739.062 (689631.250) - AE Rec Loss: 1.978 (4.677) - Disc 
Loss: 0.000 (0.000) - 26.75 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 0.000 (0.379) - Batch(s): 17.044 
(2.613) - AE Loss: 1535919.250 (689631.250) - AE Rec Loss: 10.416 (4.677) - Disc
Loss: 0.000 (0.000) - 26.90 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.569 
(2.520) - AE Loss: 260513.891 (691733.812) - AE Rec Loss: 1.767 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.77 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.571 
(2.520) - AE Loss: 409028.000 (691733.812) - AE Rec Loss: 2.774 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.88 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.570 
(2.520) - AE Loss: 268256.438 (691733.812) - AE Rec Loss: 1.819 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.90 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.577 
(2.520) - AE Loss: 206977.484 (691733.812) - AE Rec Loss: 1.404 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.90 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.569 
(2.520) - AE Loss: 226014.281 (691733.812) - AE Rec Loss: 1.533 (4.691) - Disc 
Loss: 0.000 (0.000) - 26.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.557 
(2.520) - AE Loss: 1598813.500 (691733.812) - AE Rec Loss: 10.843 (4.691) - Disc
Loss: 0.000 (0.000) - 26.88 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.570 
(2.435) - AE Loss: 395679.625 (692697.188) - AE Rec Loss: 2.683 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.76 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.572 
(2.435) - AE Loss: 77860.656 (692697.188) - AE Rec Loss: 0.528 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.87 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.577 
(2.435) - AE Loss: 161460.156 (692697.188) - AE Rec Loss: 1.095 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.89 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.570 
(2.435) - AE Loss: 78493.312 (692697.188) - AE Rec Loss: 0.532 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.73 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.558 
(2.435) - AE Loss: 5266150.000 (692697.188) - AE Rec Loss: 35.713 (4.698) - Disc
Loss: 0.000 (0.000) - 26.87 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.570 
(2.435) - AE Loss: 93180.312 (692697.188) - AE Rec Loss: 0.632 (4.698) - Disc 
Loss: 0.000 (0.000) - 26.88 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.731 
(2.364) - AE Loss: 209146.141 (689099.125) - AE Rec Loss: 1.418 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.94 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.731 
(2.364) - AE Loss: 1942631.000 (689099.125) - AE Rec Loss: 13.174 (4.673) - Disc
Loss: 0.000 (0.000) - 26.95 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 250831.578 (689099.125) - AE Rec Loss: 1.701 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.92 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.733 
(2.364) - AE Loss: 117804.203 (689099.125) - AE Rec Loss: 0.799 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 78344.031 (689099.125) - AE Rec Loss: 0.531 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.79 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.732 
(2.364) - AE Loss: 1394467.000 (689099.125) - AE Rec Loss: 9.457 (4.673) - Disc 
Loss: 0.000 (0.000) - 26.93 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.571 
(2.292) - AE Loss: 101893.305 (681847.188) - AE Rec Loss: 0.691 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.93 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.570 
(2.292) - AE Loss: 459864.125 (681847.188) - AE Rec Loss: 3.119 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.81 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.558 
(2.292) - AE Loss: 243597.672 (681847.188) - AE Rec Loss: 1.652 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.92 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.572 
(2.292) - AE Loss: 274354.250 (681847.188) - AE Rec Loss: 1.861 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.91 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.570 
(2.292) - AE Loss: 220386.844 (681847.188) - AE Rec Loss: 1.495 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.79 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (0.319) - Batch(s): 0.581 
(2.292) - AE Loss: 214460.875 (681847.188) - AE Rec Loss: 1.454 (4.624) - Disc 
Loss: 0.000 (0.000) - 26.94 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.570 
(2.226) - AE Loss: 1512373.250 (694412.938) - AE Rec Loss: 10.256 (4.709) - Disc
Loss: 0.000 (0.000) - 26.78 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.580 
(2.226) - AE Loss: 1606405.625 (694412.938) - AE Rec Loss: 10.894 (4.709) - Disc
Loss: 0.000 (0.000) - 26.93 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.570 
(2.226) - AE Loss: 1490631.375 (694412.938) - AE Rec Loss: 10.109 (4.709) - Disc
Loss: 0.000 (0.000) - 26.92 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.572 
(2.226) - AE Loss: 1422482.250 (694412.938) - AE Rec Loss: 9.647 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.91 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.559 
(2.226) - AE Loss: 134513.062 (694412.938) - AE Rec Loss: 0.912 (4.709) - Disc 
Loss: 0.000 (0.000) - 26.91 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (0.307) - Batch(s): 0.572 
(2.226) - AE Loss: 1769763.500 (694412.938) - AE Rec Loss: 12.002 (4.709) - Disc
Loss: 0.000 (0.000) - 26.80 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.723 
(2.171) - AE Loss: 555666.312 (694243.188) - AE Rec Loss: 3.768 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.85 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 225917.250 (694243.188) - AE Rec Loss: 1.532 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.96 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 111171.500 (694243.188) - AE Rec Loss: 0.754 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.98 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.726 
(2.171) - AE Loss: 1649369.000 (694243.188) - AE Rec Loss: 11.185 (4.708) - Disc
Loss: 0.000 (0.000) - 26.83 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.295) - Batch(s): 0.726 
(2.171) - AE Loss: 343378.938 (694243.188) - AE Rec Loss: 2.329 (4.708) - Disc 
Loss: 0.000 (0.000) - 26.97 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.001 (0.295) - Batch(s): 0.725 
(2.171) - AE Loss: 1683519.000 (694243.188) - AE Rec Loss: 11.417 (4.708) - Disc
Loss: 0.000 (0.000) - 26.96 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 02:59:50,732[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,758[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,769[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,947[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,968[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 02:59:50,974[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 02:59:52,908[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:52,997[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:53,022[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:53,169[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:53,184[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 02:59:53,241[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,350[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,595[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,645[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,796[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 02:59:53,829[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 02:59:53,832[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 02:59:53,837[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,837[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,837[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 02:59:53,837[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 02:59:53,838[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6Reached 3 on node 7

Reached 5 on node 7Reached 5 on node 6

Reached end on node 7
Reached end on node 6
=> Preparing model 
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 1.3 on node 8
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 11
Reached 5 on node 11
Reached 3 on node 8
Reached end on node 11
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8Reached 1.3 on node 9

Reached 1.4 on node 9
Reached 1.4 on node 8
Reached 2 on node 9
Reached 2 on node 8
Reached 3 on node 9Reached 3 on node 8

Reached 5 on node 8Reached 5 on node 9

Reached end on node 8Reached end on node 9

Reached 1.3 on node 6
Reached 1.3 on node 7Reached 1.3 on node 11
Reached 1.4 on node 6

Reached 1.4 on node 7
Reached 1.4 on node 11
Reached 2 on node 6Reached 2 on node 7

Reached 2 on node 11
Reached 3 on node 7Reached 3 on node 6

Reached 3 on node 11
Reached 1.3 on node 10Reached 5 on node 6Reached 5 on node 7


Reached 1.4 on node 10Reached 5 on node 11Reached end on node 6Reached end on node 7



Reached end on node 11Reached 2 on node 10

Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
Loaded checkpoint at epoch 0 and step 81
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 6Reached 2 on node 7

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 6Reached 2 on node 7

Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 1.4 on node 8
Reached 2 on node 11Reached 2 on node 8

Reached 1 on node 7Reached 1 on node 6

Reached 1.4 on node 7Reached 1.4 on node 6

Reached 2 on node 7Reached 2 on node 6

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 1.4 on node 8Reached 3 on node 7

Reached 3 on node 7Reached 2 on node 8

Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8Reached 1 on node 9

Reached 1.4 on node 9Reached 1 on node 11

Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11
Reached 3 on node 9
Reached 2 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached end on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8Reached 3 on node 11

Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 7
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <081/2280>] - Data(s): 3.037 (6.058) - Batch(s): 9.705 
(10.220) - AE Loss: 526519.625 (728560.500) - AE Rec Loss: 3.571 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 6.974 (6.058) - Batch(s): 9.728 
(10.220) - AE Loss: 1837050.125 (728560.500) - AE Rec Loss: 12.458 (4.941) - 
Disc Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 8.197 (6.058) - Batch(s): 9.706 
(10.220) - AE Loss: 1536105.500 (728560.500) - AE Rec Loss: 10.417 (4.941) - 
Disc Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 5.282 (6.058) - Batch(s): 9.695 
(10.220) - AE Loss: 188112.469 (728560.500) - AE Rec Loss: 1.276 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 6.662 (6.058) - Batch(s): 9.690 
(10.220) - AE Loss: 292311.031 (728560.500) - AE Rec Loss: 1.982 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <081/2280>] - Data(s): 3.400 (6.058) - Batch(s): 9.728 
(10.220) - AE Loss: 451565.188 (728560.500) - AE Rec Loss: 3.062 (4.941) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.570 
(5.394) - AE Loss: 431957.500 (737082.688) - AE Rec Loss: 2.929 (4.999) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.574 
(5.394) - AE Loss: 215164.016 (737082.688) - AE Rec Loss: 1.459 (4.999) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.556 
(5.394) - AE Loss: 1598512.625 (737082.688) - AE Rec Loss: 10.841 (4.999) - Disc
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.567 
(5.394) - AE Loss: 267879.625 (737082.688) - AE Rec Loss: 1.817 (4.999) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.001 (3.029) - Batch(s): 0.567 
(5.394) - AE Loss: 290932.938 (737082.688) - AE Rec Loss: 1.973 (4.999) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <082/2280>] - Data(s): 0.000 (3.029) - Batch(s): 0.567 
(5.394) - AE Loss: 230590.250 (737082.688) - AE Rec Loss: 1.564 (4.999) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.283 
(5.357) - AE Loss: 410936.250 (733088.125) - AE Rec Loss: 2.787 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.283 
(5.357) - AE Loss: 76465.398 (733088.125) - AE Rec Loss: 0.519 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 4.580 (2.243) - Batch(s): 5.281 
(5.357) - AE Loss: 169405.891 (733088.125) - AE Rec Loss: 1.149 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.282 
(5.357) - AE Loss: 95819.758 (733088.125) - AE Rec Loss: 0.650 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 0.000 (2.243) - Batch(s): 5.282 
(5.357) - AE Loss: 79766.852 (733088.125) - AE Rec Loss: 0.541 (4.972) - Disc 
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <083/2280>] - Data(s): 2.935 (2.243) - Batch(s): 5.284 
(5.357) - AE Loss: 5282284.000 (733088.125) - AE Rec Loss: 35.823 (4.972) - Disc
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.568 
(4.160) - AE Loss: 122214.312 (701973.562) - AE Rec Loss: 0.829 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.568 
(4.160) - AE Loss: 85451.391 (701973.562) - AE Rec Loss: 0.580 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.569 
(4.160) - AE Loss: 208807.203 (701973.562) - AE Rec Loss: 1.416 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.574 
(4.160) - AE Loss: 1948443.000 (701973.562) - AE Rec Loss: 13.214 (4.761) - Disc
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.571 
(4.160) - AE Loss: 249899.625 (701973.562) - AE Rec Loss: 1.695 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <084/2280>] - Data(s): 0.000 (1.682) - Batch(s): 0.555 
(4.160) - AE Loss: 1397699.125 (701973.562) - AE Rec Loss: 9.479 (4.761) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.570 
(3.442) - AE Loss: 94626.258 (663181.438) - AE Rec Loss: 0.642 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.569 
(3.442) - AE Loss: 461014.812 (663181.438) - AE Rec Loss: 3.126 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.575 
(3.442) - AE Loss: 216572.531 (663181.438) - AE Rec Loss: 1.469 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.569 
(3.442) - AE Loss: 217376.328 (663181.438) - AE Rec Loss: 1.474 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.556 
(3.442) - AE Loss: 250198.734 (663181.438) - AE Rec Loss: 1.697 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <085/2280>] - Data(s): 0.000 (1.346) - Batch(s): 0.572 
(3.442) - AE Loss: 280500.938 (663181.438) - AE Rec Loss: 1.902 (4.497) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.737 
(2.991) - AE Loss: 1773508.125 (720977.688) - AE Rec Loss: 12.027 (4.889) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.737 
(2.991) - AE Loss: 1511292.875 (720977.688) - AE Rec Loss: 10.249 (4.889) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.738 
(2.991) - AE Loss: 134440.750 (720977.688) - AE Rec Loss: 0.912 (4.889) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.738 
(2.991) - AE Loss: 1612066.125 (720977.688) - AE Rec Loss: 10.933 (4.889) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.001 (1.122) - Batch(s): 0.738 
(2.991) - AE Loss: 1432651.375 (720977.688) - AE Rec Loss: 9.716 (4.889) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <086/2280>] - Data(s): 0.000 (1.122) - Batch(s): 0.739 
(2.991) - AE Loss: 1487954.750 (720977.688) - AE Rec Loss: 10.091 (4.889) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.571 
(2.645) - AE Loss: 1685705.500 (717636.125) - AE Rec Loss: 11.432 (4.867) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.577 
(2.645) - AE Loss: 129587.664 (717636.125) - AE Rec Loss: 0.879 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.571 
(2.645) - AE Loss: 346908.562 (717636.125) - AE Rec Loss: 2.353 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.570 
(2.645) - AE Loss: 555580.875 (717636.125) - AE Rec Loss: 3.768 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.571 
(2.645) - AE Loss: 1652874.750 (717636.125) - AE Rec Loss: 11.209 (4.867) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <087/2280>] - Data(s): 0.000 (0.961) - Batch(s): 0.558 
(2.645) - AE Loss: 233954.156 (717636.125) - AE Rec Loss: 1.587 (4.867) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.820 
(3.012) - AE Loss: 1674259.875 (775261.500) - AE Rec Loss: 11.354 (5.258) - Disc
Loss: 0.000 (0.000) - 10.37 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.463 
(3.012) - AE Loss: 1676734.250 (775261.500) - AE Rec Loss: 11.371 (5.258) - Disc
Loss: 0.000 (0.000) - 10.38 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 5.243 (0.896) - Batch(s): 5.824 
(3.012) - AE Loss: 2979466.000 (775261.500) - AE Rec Loss: 20.206 (5.258) - Disc
Loss: 0.000 (0.000) - 10.38 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.464 
(3.012) - AE Loss: 269798.875 (775261.500) - AE Rec Loss: 1.830 (5.258) - Disc 
Loss: 0.000 (0.000) - 10.37 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.818 
(3.012) - AE Loss: 222348.250 (775261.500) - AE Rec Loss: 1.508 (5.258) - Disc 
Loss: 0.000 (0.000) - 10.37 m remaining

[Epoch <000/100>: Step <088/2280>] - Data(s): 0.000 (0.896) - Batch(s): 5.824 
(3.012) - AE Loss: 1771516.750 (775261.500) - AE Rec Loss: 12.014 (5.258) - Disc
Loss: 0.000 (0.000) - 10.38 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.411 
(2.834) - AE Loss: 247556.406 (793137.188) - AE Rec Loss: 1.679 (5.379) - Disc 
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.709 (0.803) - Batch(s): 1.410 
(2.834) - AE Loss: 218526.641 (793137.188) - AE Rec Loss: 1.482 (5.379) - Disc 
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.409 
(2.834) - AE Loss: 1481317.875 (793137.188) - AE Rec Loss: 10.046 (5.379) - Disc
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.408 
(2.834) - AE Loss: 536713.750 (793137.188) - AE Rec Loss: 3.640 (5.379) - Disc 
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.409 
(2.834) - AE Loss: 3009345.000 (793137.188) - AE Rec Loss: 20.408 (5.379) - Disc
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <089/2280>] - Data(s): 0.000 (0.803) - Batch(s): 1.410 
(2.834) - AE Loss: 1492229.875 (793137.188) - AE Rec Loss: 10.120 (5.379) - Disc
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.568 
(2.608) - AE Loss: 237652.812 (801428.000) - AE Rec Loss: 1.612 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.576 
(2.608) - AE Loss: 1384074.000 (801428.000) - AE Rec Loss: 9.386 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.569 
(2.608) - AE Loss: 411275.000 (801428.000) - AE Rec Loss: 2.789 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.570 
(2.608) - AE Loss: 710864.688 (801428.000) - AE Rec Loss: 4.821 (5.435) - Disc 
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.556 
(2.608) - AE Loss: 1511428.750 (801428.000) - AE Rec Loss: 10.250 (5.435) - Disc
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <090/2280>] - Data(s): 0.000 (0.723) - Batch(s): 0.568 
(2.608) - AE Loss: 1902653.500 (801428.000) - AE Rec Loss: 12.903 (5.435) - Disc
Loss: 0.000 (0.000) - 11.06 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.957 
(2.611) - AE Loss: 1603522.750 (782866.438) - AE Rec Loss: 10.875 (5.309) - Disc
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.953 
(2.611) - AE Loss: 86749.578 (782866.438) - AE Rec Loss: 0.588 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.596 
(2.611) - AE Loss: 343929.750 (782866.438) - AE Rec Loss: 2.332 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.596 
(2.611) - AE Loss: 72238.609 (782866.438) - AE Rec Loss: 0.490 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 2.375 (0.675) - Batch(s): 2.956 
(2.611) - AE Loss: 445939.500 (782866.438) - AE Rec Loss: 3.024 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <091/2280>] - Data(s): 0.000 (0.675) - Batch(s): 2.951 
(2.611) - AE Loss: 460506.719 (782866.438) - AE Rec Loss: 3.123 (5.309) - Disc 
Loss: 0.000 (0.000) - 12.17 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.707 
(2.453) - AE Loss: 1466487.500 (766855.562) - AE Rec Loss: 9.945 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 413800.969 (766855.562) - AE Rec Loss: 2.806 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 1397750.375 (766855.562) - AE Rec Loss: 9.479 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 330290.719 (766855.562) - AE Rec Loss: 2.240 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.708 
(2.453) - AE Loss: 78980.531 (766855.562) - AE Rec Loss: 0.536 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <092/2280>] - Data(s): 0.000 (0.619) - Batch(s): 0.709 
(2.453) - AE Loss: 217893.125 (766855.562) - AE Rec Loss: 1.478 (5.201) - Disc 
Loss: 0.000 (0.000) - 12.37 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.570 
(2.308) - AE Loss: 1400525.500 (742416.562) - AE Rec Loss: 9.498 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.570 
(2.308) - AE Loss: 238538.641 (742416.562) - AE Rec Loss: 1.618 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.576 
(2.308) - AE Loss: 219787.453 (742416.562) - AE Rec Loss: 1.491 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.557 
(2.308) - AE Loss: 174456.281 (742416.562) - AE Rec Loss: 1.183 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.000 (0.571) - Batch(s): 0.568 
(2.308) - AE Loss: 365240.219 (742416.562) - AE Rec Loss: 2.477 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <093/2280>] - Data(s): 0.001 (0.571) - Batch(s): 0.570 
(2.308) - AE Loss: 336456.062 (742416.562) - AE Rec Loss: 2.282 (5.035) - Disc 
Loss: 0.000 (0.000) - 12.52 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.764 
(2.252) - AE Loss: 1580004.000 (728715.312) - AE Rec Loss: 10.715 (4.942) - Disc
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 153529.031 (728715.312) - AE Rec Loss: 1.041 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.066 (0.538) - Batch(s): 1.402 
(2.252) - AE Loss: 424995.656 (728715.312) - AE Rec Loss: 2.882 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.001 (0.538) - Batch(s): 1.760 
(2.252) - AE Loss: 201766.781 (728715.312) - AE Rec Loss: 1.368 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 1.193 (0.538) - Batch(s): 1.761 
(2.252) - AE Loss: 887587.250 (728715.312) - AE Rec Loss: 6.019 (4.942) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <094/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.758 
(2.252) - AE Loss: 1841841.250 (728715.312) - AE Rec Loss: 12.491 (4.942) - Disc
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.070 
(2.240) - AE Loss: 2117442.000 (751182.750) - AE Rec Loss: 14.360 (5.094) - Disc
Loss: 0.000 (0.000) - 13.82 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.070 
(2.240) - AE Loss: 1841571.250 (751182.750) - AE Rec Loss: 12.489 (5.094) - Disc
Loss: 0.000 (0.000) - 13.83 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 1.359 (0.510) - Batch(s): 2.071 
(2.240) - AE Loss: 1655281.000 (751182.750) - AE Rec Loss: 11.226 (5.094) - Disc
Loss: 0.000 (0.000) - 13.83 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.071 
(2.240) - AE Loss: 2970617.500 (751182.750) - AE Rec Loss: 20.146 (5.094) - Disc
Loss: 0.000 (0.000) - 13.83 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.072 
(2.240) - AE Loss: 1700758.000 (751182.750) - AE Rec Loss: 11.534 (5.094) - Disc
Loss: 0.000 (0.000) - 13.82 m remaining

[Epoch <000/100>: Step <095/2280>] - Data(s): 0.000 (0.510) - Batch(s): 2.072 
(2.240) - AE Loss: 130786.320 (751182.750) - AE Rec Loss: 0.887 (5.094) - Disc 
Loss: 0.000 (0.000) - 13.83 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.557 
(2.135) - AE Loss: 1526520.500 (748906.188) - AE Rec Loss: 10.352 (5.079) - Disc
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.570 
(2.135) - AE Loss: 1629491.250 (748906.188) - AE Rec Loss: 11.051 (5.079) - Disc
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.570 
(2.135) - AE Loss: 429560.750 (748906.188) - AE Rec Loss: 2.913 (5.079) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.571 
(2.135) - AE Loss: 292695.812 (748906.188) - AE Rec Loss: 1.985 (5.079) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.571 
(2.135) - AE Loss: 1592369.500 (748906.188) - AE Rec Loss: 10.799 (5.079) - Disc
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <096/2280>] - Data(s): 0.000 (0.478) - Batch(s): 0.578 
(2.135) - AE Loss: 266657.188 (748906.188) - AE Rec Loss: 1.808 (5.079) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.507 
(2.084) - AE Loss: 233014.750 (731494.125) - AE Rec Loss: 1.580 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.42 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.299 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 201103.812 (731494.125) - AE Rec Loss: 1.364 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.43 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.939 (0.456) - Batch(s): 1.509 
(2.084) - AE Loss: 1721395.750 (731494.125) - AE Rec Loss: 11.674 (4.961) - Disc
Loss: 0.000 (0.000) - 14.43 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.149 
(2.084) - AE Loss: 1864653.000 (731494.125) - AE Rec Loss: 12.645 (4.961) - Disc
Loss: 0.000 (0.000) - 14.43 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.000 (0.456) - Batch(s): 1.510 
(2.084) - AE Loss: 288273.906 (731494.125) - AE Rec Loss: 1.955 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.43 m remaining

[Epoch <000/100>: Step <097/2280>] - Data(s): 0.001 (0.456) - Batch(s): 1.506 
(2.084) - AE Loss: 212589.719 (731494.125) - AE Rec Loss: 1.442 (4.961) - Disc 
Loss: 0.000 (0.000) - 14.42 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.192 
(2.201) - AE Loss: 350576.844 (730670.938) - AE Rec Loss: 2.378 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.192 
(2.201) - AE Loss: 102092.766 (730670.938) - AE Rec Loss: 0.692 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.192 
(2.201) - AE Loss: 100067.867 (730670.938) - AE Rec Loss: 0.679 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.000 (0.456) - Batch(s): 4.194 
(2.201) - AE Loss: 279962.344 (730670.938) - AE Rec Loss: 1.899 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 0.001 (0.456) - Batch(s): 4.193 
(2.201) - AE Loss: 204700.547 (730670.938) - AE Rec Loss: 1.388 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <098/2280>] - Data(s): 1.991 (0.456) - Batch(s): 4.193 
(2.201) - AE Loss: 337419.875 (730670.938) - AE Rec Loss: 2.288 (4.955) - Disc 
Loss: 0.000 (0.000) - 15.87 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.570 
(2.117) - AE Loss: 352330.719 (729270.875) - AE Rec Loss: 2.389 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.01 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.571 
(2.117) - AE Loss: 1619440.125 (729270.875) - AE Rec Loss: 10.983 (4.946) - Disc
Loss: 0.000 (0.000) - 16.01 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.573 
(2.117) - AE Loss: 185421.875 (729270.875) - AE Rec Loss: 1.257 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.01 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.690 
(2.117) - AE Loss: 136743.906 (729270.875) - AE Rec Loss: 0.927 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.02 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.000 (0.432) - Batch(s): 0.558 
(2.117) - AE Loss: 226243.812 (729270.875) - AE Rec Loss: 1.534 (4.946) - Disc 
Loss: 0.000 (0.000) - 16.01 m remaining

[Epoch <000/100>: Step <099/2280>] - Data(s): 0.120 (0.432) - Batch(s): 0.688 
(2.117) - AE Loss: 1928295.625 (729270.875) - AE Rec Loss: 13.077 (4.946) - Disc
Loss: 0.000 (0.000) - 16.01 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.570 
(2.039) - AE Loss: 454066.750 (726559.062) - AE Rec Loss: 3.079 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.571 
(2.039) - AE Loss: 1826219.375 (726559.062) - AE Rec Loss: 12.385 (4.927) - Disc
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.571 
(2.039) - AE Loss: 331741.781 (726559.062) - AE Rec Loss: 2.250 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.557 
(2.039) - AE Loss: 259499.625 (726559.062) - AE Rec Loss: 1.760 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.577 
(2.039) - AE Loss: 365445.188 (726559.062) - AE Rec Loss: 2.478 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.12 m remaining

[Epoch <000/100>: Step <100/2280>] - Data(s): 0.000 (0.411) - Batch(s): 0.571 
(2.039) - AE Loss: 454681.562 (726559.062) - AE Rec Loss: 3.084 (4.927) - Disc 
Loss: 0.000 (0.000) - 16.11 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.783 (0.413) - Batch(s): 15.292 
(2.612) - AE Loss: 107193.484 (728511.438) - AE Rec Loss: 0.727 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.001 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 262815.656 (728511.438) - AE Rec Loss: 1.782 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.463 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 391134.531 (728511.438) - AE Rec Loss: 2.653 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.001 (0.413) - Batch(s): 15.292 
(2.612) - AE Loss: 92330.742 (728511.438) - AE Rec Loss: 0.626 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.001 (0.413) - Batch(s): 15.291 
(2.612) - AE Loss: 211504.750 (728511.438) - AE Rec Loss: 1.434 (4.941) - Disc 
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 0.000 (0.413) - Batch(s): 15.292 
(2.612) - AE Loss: 2908426.750 (728511.438) - AE Rec Loss: 19.724 (4.941) - Disc
Loss: 0.000 (0.000) - 21.45 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.570 
(2.520) - AE Loss: 1534828.000 (738646.938) - AE Rec Loss: 10.409 (5.009) - Disc
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.556 
(2.520) - AE Loss: 723593.125 (738646.938) - AE Rec Loss: 4.907 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.576 
(2.520) - AE Loss: 1640882.375 (738646.938) - AE Rec Loss: 11.128 (5.009) - Disc
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.570 
(2.520) - AE Loss: 123272.719 (738646.938) - AE Rec Loss: 0.836 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.570 
(2.520) - AE Loss: 234268.672 (738646.938) - AE Rec Loss: 1.589 (5.009) - Disc 
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (0.394) - Batch(s): 0.569 
(2.520) - AE Loss: 1615505.000 (738646.938) - AE Rec Loss: 10.956 (5.009) - Disc
Loss: 0.000 (0.000) - 21.49 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.576 
(2.435) - AE Loss: 285242.750 (732324.500) - AE Rec Loss: 1.934 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.557 
(2.435) - AE Loss: 118497.422 (732324.500) - AE Rec Loss: 0.804 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.570 
(2.435) - AE Loss: 168569.062 (732324.500) - AE Rec Loss: 1.143 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.570 
(2.435) - AE Loss: 199249.234 (732324.500) - AE Rec Loss: 1.351 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.570 
(2.435) - AE Loss: 206491.281 (732324.500) - AE Rec Loss: 1.400 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (0.377) - Batch(s): 0.572 
(2.435) - AE Loss: 254050.875 (732324.500) - AE Rec Loss: 1.723 (4.966) - Disc 
Loss: 0.000 (0.000) - 21.53 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.746 
(2.364) - AE Loss: 376473.500 (722362.750) - AE Rec Loss: 2.553 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.748 
(2.364) - AE Loss: 561940.438 (722362.750) - AE Rec Loss: 3.811 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.747 
(2.364) - AE Loss: 100040.484 (722362.750) - AE Rec Loss: 0.678 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.748 
(2.364) - AE Loss: 1408132.000 (722362.750) - AE Rec Loss: 9.550 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (0.361) - Batch(s): 0.748 
(2.364) - AE Loss: 141045.188 (722362.750) - AE Rec Loss: 0.957 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (0.361) - Batch(s): 0.748 
(2.364) - AE Loss: 392289.562 (722362.750) - AE Rec Loss: 2.660 (4.899) - Disc 
Loss: 0.000 (0.000) - 21.63 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.571 
(2.293) - AE Loss: 437982.875 (732170.500) - AE Rec Loss: 2.970 (4.965) - Disc 
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.557 
(2.293) - AE Loss: 1692015.375 (732170.500) - AE Rec Loss: 11.475 (4.965) - Disc
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.571 
(2.293) - AE Loss: 723776.688 (732170.500) - AE Rec Loss: 4.908 (4.965) - Disc 
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.571 
(2.293) - AE Loss: 146411.484 (732170.500) - AE Rec Loss: 0.993 (4.965) - Disc 
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.578 
(2.293) - AE Loss: 1670767.000 (732170.500) - AE Rec Loss: 11.331 (4.965) - Disc
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.570 
(2.293) - AE Loss: 1598405.500 (732170.500) - AE Rec Loss: 10.840 (4.965) - Disc
Loss: 0.000 (0.000) - 21.67 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.575 
(2.227) - AE Loss: 129798.477 (718624.688) - AE Rec Loss: 0.880 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.581 
(2.227) - AE Loss: 307884.312 (718624.688) - AE Rec Loss: 2.088 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.574 
(2.227) - AE Loss: 329928.938 (718624.688) - AE Rec Loss: 2.237 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.573 
(2.227) - AE Loss: 145894.594 (718624.688) - AE Rec Loss: 0.989 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.563 
(2.227) - AE Loss: 146219.844 (718624.688) - AE Rec Loss: 0.992 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (0.334) - Batch(s): 0.575 
(2.227) - AE Loss: 179581.062 (718624.688) - AE Rec Loss: 1.218 (4.873) - Disc 
Loss: 0.000 (0.000) - 21.71 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.704 
(2.170) - AE Loss: 279146.438 (718917.750) - AE Rec Loss: 1.893 (4.875) - Disc 
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.704 
(2.170) - AE Loss: 253595.266 (718917.750) - AE Rec Loss: 1.720 (4.875) - Disc 
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.705 
(2.170) - AE Loss: 1558887.750 (718917.750) - AE Rec Loss: 10.572 (4.875) - Disc
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.705 
(2.170) - AE Loss: 403532.812 (718917.750) - AE Rec Loss: 2.737 (4.875) - Disc 
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.705 
(2.170) - AE Loss: 298184.500 (718917.750) - AE Rec Loss: 2.022 (4.875) - Disc 
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (0.321) - Batch(s): 0.705 
(2.170) - AE Loss: 251793.344 (718917.750) - AE Rec Loss: 1.708 (4.875) - Disc 
Loss: 0.000 (0.000) - 21.79 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.201 (0.341) - Batch(s): 3.729 
(2.218) - AE Loss: 158171.656 (711529.438) - AE Rec Loss: 1.073 (4.825) - Disc 
Loss: 0.000 (0.000) - 22.87 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 3.147 (0.341) - Batch(s): 3.709 
(2.218) - AE Loss: 220331.125 (711529.438) - AE Rec Loss: 1.494 (4.825) - Disc 
Loss: 0.000 (0.000) - 22.87 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.341) - Batch(s): 3.722 
(2.218) - AE Loss: 1630804.750 (711529.438) - AE Rec Loss: 11.060 (4.825) - Disc
Loss: 0.000 (0.000) - 22.87 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 1.654 (0.341) - Batch(s): 3.364 
(2.218) - AE Loss: 1625181.500 (711529.438) - AE Rec Loss: 11.021 (4.825) - Disc
Loss: 0.000 (0.000) - 22.87 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.001 (0.341) - Batch(s): 3.722 
(2.218) - AE Loss: 85436.562 (711529.438) - AE Rec Loss: 0.579 (4.825) - Disc 
Loss: 0.000 (0.000) - 22.87 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.001 (0.341) - Batch(s): 3.723 
(2.218) - AE Loss: 589598.562 (711529.438) - AE Rec Loss: 3.998 (4.825) - Disc 
Loss: 0.000 (0.000) - 22.87 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:01:24,927[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,937[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,946[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:24,991[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:25,087[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:01:25,479[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:01:27,178[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:27,183[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:27,189[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:27,200[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:27,274[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:01:27,707[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,788[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:01:27,788[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:01:27,879[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:01:27,879[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:01:27,889[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:01:28,189[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:01:28,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:01:28,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
[[36m2023-11-29 03:01:28,192[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 10
Reached 5 on node 10
=> Instantiating the optimizer 
Reached end on node 10
=> Instantiating the optimizer 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_disc 
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
        main()
main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
    result = tuple(  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(    
model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
      File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
        _verify_param_shape_across_processes(self.process_group, parameters)_verify_param_shape_across_processes(self.process_group, parameters)    

_verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
      File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
_verify_param_shape_across_processes(self.process_group, parameters)  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<49136>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<36366>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<57436>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer fdaa:1:b86:a7b:9076:0:a:2202<59754>
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:05:59,542[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,557[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,558[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,611[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,615[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:05:59,626[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:06:01,789[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,816[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,818[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,829[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,850[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:06:01,866[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:02,358[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:06:02,428[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:06:02,463[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:06:02,474[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:06:02,495[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:06:02,510[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:06:02,513[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:06:02,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:06:02,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:06:02,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:06:02,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 03:06:02,517[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Running in inference mode: False
=> Preparing model 
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6Reached 3 on node 7

Reached 5 on node 6Reached 5 on node 7

Reached end on node 7Reached end on node 6

=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:07:31,722[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,722[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:31,923[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:32,015[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:32,038[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:07:32,076[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:07:33,951[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:34,003[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:34,182[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:34,211[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:07:34,295[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,417[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,478[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:07:34,501[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,701[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,736[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,823[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:07:34,947[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:07:34,947[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:07:34,950[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Running in inference mode: False
[[36m2023-11-29 03:07:34,951[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:07:34,951[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 6
[[36m2023-11-29 03:07:34,952[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 5 on node 6
Reached end on node 6
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Preparing model 
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating train dataloader 
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:07:34,956[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:10:35,364[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,551[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,606[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,665[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,782[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:10:35,826[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:10:37,564[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,786[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:37,933[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:37,976[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:10:38,007[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:38,008[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:10:38,046[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:38,351[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:10:38,459[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:10:38,468[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:38,591[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:10:38,608[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:10:38,611[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:10:38,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
[[36m2023-11-29 03:10:38,615[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
[[36m2023-11-29 03:10:38,617[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:10:38,618[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Mixed precision: no
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Running in inference mode: False
[[36m2023-11-29 03:10:38,619[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
len(train_dataloader) = 2279
Reached end on node 7
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:12:08,185[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:08,233[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:08,247[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:08,301[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:08,302[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:12:08,420[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:12:10,405[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:10,466[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:10,483[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:10,512[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:10,523[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:12:10,603[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:10,864[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:11,014[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:11,082[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:12:11,104[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:12:11,109[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:12:11,179[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:12:11,183[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 03:12:11,185[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
[[36m2023-11-29 03:12:11,186[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:12:11,186[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Running in inference mode: False
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:12:11,190[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Mixed precision: no
[[36m2023-11-29 03:12:11,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(valid_dataset) = 4
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataset) = 4
=> Preparing model 
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.3 on node 6Reached end on node 11

Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1 on node 8Reached 1.25 on node 9

devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 8
Reached 2 on node 9Reached 1.3 on node 7

Reached 1.4 on node 7
Reached 3 on node 8
Reached 3 on node 9
Reached 2 on node 7Reached 5 on node 8

Reached 5 on node 9
Reached end on node 8
Reached end on node 9
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 1.3 on node 10
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached 3 on node 10
Reached 1.3 on node 11Reached end on node 6

Reached 5 on node 10
Reached 1.4 on node 11
Reached end on node 10Reached 2 on node 11

Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8Reached 1 on node 7

Reached 1.4 on node 7Reached 1 on node 6

Reached 2 on node 7Reached 1.4 on node 8

Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 8

Reached 1.4 on node 6
Reached 2 on node 8
Reached 2 on node 6
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 7
Reached 1.4 on node 11Reached 1 on node 8Reached 1 on node 6


Reached 2 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 6Reached 2 on node 8

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 7

Reached 1 on node 10Reached 1 on node 8

Reached 1.4 on node 7
Reached 1.4 on node 11
Reached 2 on node 7
Reached 2 on node 11Reached 1.4 on node 8

Reached 3 on node 7Reached 2 on node 8
Reached 1.4 on node 10
Reached 3 on node 7

Reached 3 on node 7Reached 2 on node 10

Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 1.4 on node 8
Reached 2 on node 11
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10Reached 1.4 on node 9

Reached 2 on node 10Reached 2 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 6
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10Reached end on node 8

Reached end on node 9
Reached end on node 11
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 8
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <101/2280>] - Data(s): 8.425 (6.839) - Batch(s): 10.948 
(11.012) - AE Loss: 2908527.000 (767528.188) - AE Rec Loss: 19.725 (5.205) - 
Disc Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 8.928 (6.839) - Batch(s): 10.962 
(11.012) - AE Loss: 107104.531 (767528.188) - AE Rec Loss: 0.726 (5.205) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 3.995 (6.839) - Batch(s): 10.939 
(11.012) - AE Loss: 261783.812 (767528.188) - AE Rec Loss: 1.775 (5.205) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 4.873 (6.839) - Batch(s): 10.953 
(11.012) - AE Loss: 91789.367 (767528.188) - AE Rec Loss: 0.622 (5.205) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 5.830 (6.839) - Batch(s): 10.954 
(11.012) - AE Loss: 390739.188 (767528.188) - AE Rec Loss: 2.650 (5.205) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 6.968 (6.839) - Batch(s): 10.946 
(11.012) - AE Loss: 210983.156 (767528.188) - AE Rec Loss: 1.431 (5.205) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.564 
(5.787) - AE Loss: 1539082.875 (863225.500) - AE Rec Loss: 10.438 (5.854) - Disc
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.551 
(5.787) - AE Loss: 721719.875 (863225.500) - AE Rec Loss: 4.894 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.564 
(5.787) - AE Loss: 133116.516 (863225.500) - AE Rec Loss: 0.903 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.562 
(5.787) - AE Loss: 1613399.375 (863225.500) - AE Rec Loss: 10.942 (5.854) - Disc
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.564 
(5.787) - AE Loss: 240898.703 (863225.500) - AE Rec Loss: 1.634 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.420) - Batch(s): 0.569 
(5.787) - AE Loss: 1651258.125 (863225.500) - AE Rec Loss: 11.198 (5.854) - Disc
Loss: 0.000 (0.000) - 4.21 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <103/2280>] - Data(s): 0.679 (2.299) - Batch(s): 1.350 
(4.308) - AE Loss: 178861.047 (776412.375) - AE Rec Loss: 1.213 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.299) - Batch(s): 1.350 
(4.308) - AE Loss: 130594.422 (776412.375) - AE Rec Loss: 0.886 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.299) - Batch(s): 1.349 
(4.308) - AE Loss: 252884.750 (776412.375) - AE Rec Loss: 1.715 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.299) - Batch(s): 1.351 
(4.308) - AE Loss: 219709.641 (776412.375) - AE Rec Loss: 1.490 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.299) - Batch(s): 1.350 
(4.308) - AE Loss: 288432.844 (776412.375) - AE Rec Loss: 1.956 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.299) - Batch(s): 1.350 
(4.308) - AE Loss: 227336.781 (776412.375) - AE Rec Loss: 1.542 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.198 
(4.258) - AE Loss: 1407475.750 (705747.188) - AE Rec Loss: 9.545 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.196 
(4.258) - AE Loss: 569921.062 (705747.188) - AE Rec Loss: 3.865 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.203 
(4.258) - AE Loss: 377320.000 (705747.188) - AE Rec Loss: 2.559 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.187 
(4.258) - AE Loss: 134103.672 (705747.188) - AE Rec Loss: 0.909 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.806) - Batch(s): 4.199 
(4.258) - AE Loss: 392276.281 (705747.188) - AE Rec Loss: 2.660 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.304 (1.806) - Batch(s): 4.197 
(4.258) - AE Loss: 104750.594 (705747.188) - AE Rec Loss: 0.710 (4.786) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.563 
(3.519) - AE Loss: 130736.711 (755522.812) - AE Rec Loss: 0.887 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.564 
(3.519) - AE Loss: 1584974.250 (755522.812) - AE Rec Loss: 10.749 (5.124) - Disc
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.572 
(3.519) - AE Loss: 1662953.875 (755522.812) - AE Rec Loss: 11.278 (5.124) - Disc
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.566 
(3.519) - AE Loss: 425326.625 (755522.812) - AE Rec Loss: 2.884 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.552 
(3.519) - AE Loss: 1685985.375 (755522.812) - AE Rec Loss: 11.434 (5.124) - Disc
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.445) - Batch(s): 0.564 
(3.519) - AE Loss: 689847.500 (755522.812) - AE Rec Loss: 4.678 (5.124) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.204) - Batch(s): 0.663 
(3.043) - AE Loss: 113473.211 (690263.000) - AE Rec Loss: 0.770 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.55 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.204) - Batch(s): 0.664 
(3.043) - AE Loss: 128168.781 (690263.000) - AE Rec Loss: 0.869 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.55 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.204) - Batch(s): 0.665 
(3.043) - AE Loss: 123199.836 (690263.000) - AE Rec Loss: 0.836 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.55 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.204) - Batch(s): 0.664 
(3.043) - AE Loss: 320627.625 (690263.000) - AE Rec Loss: 2.174 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.55 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.204) - Batch(s): 0.664 
(3.043) - AE Loss: 282686.281 (690263.000) - AE Rec Loss: 1.917 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.55 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.204) - Batch(s): 0.664 
(3.043) - AE Loss: 170030.562 (690263.000) - AE Rec Loss: 1.153 (4.681) - Disc 
Loss: 0.000 (0.000) - 6.56 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.145 
(2.759) - AE Loss: 300384.438 (695561.750) - AE Rec Loss: 2.037 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.133 
(2.759) - AE Loss: 249043.141 (695561.750) - AE Rec Loss: 1.689 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.144 
(2.759) - AE Loss: 1561403.250 (695561.750) - AE Rec Loss: 10.589 (4.717) - Disc
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.146 
(2.759) - AE Loss: 401300.500 (695561.750) - AE Rec Loss: 2.721 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.142 
(2.759) - AE Loss: 251057.125 (695561.750) - AE Rec Loss: 1.703 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.149 
(2.759) - AE Loss: 288466.312 (695561.750) - AE Rec Loss: 1.956 (4.717) - Disc 
Loss: 0.000 (0.000) - 6.93 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.001 (0.909) - Batch(s): 0.553 
(2.485) - AE Loss: 228687.547 (673984.438) - AE Rec Loss: 1.551 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.563 
(2.485) - AE Loss: 1644289.625 (673984.438) - AE Rec Loss: 11.151 (4.571) - Disc
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.566 
(2.485) - AE Loss: 1637010.875 (673984.438) - AE Rec Loss: 11.102 (4.571) - Disc
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.566 
(2.485) - AE Loss: 599653.500 (673984.438) - AE Rec Loss: 4.067 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.566 
(2.485) - AE Loss: 88140.969 (673984.438) - AE Rec Loss: 0.598 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.571 
(2.485) - AE Loss: 171052.359 (673984.438) - AE Rec Loss: 1.160 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.397 
(2.364) - AE Loss: 2068286.000 (681904.750) - AE Rec Loss: 14.026 (4.624) - Disc
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.399 
(2.364) - AE Loss: 161071.281 (681904.750) - AE Rec Loss: 1.092 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.399 
(2.364) - AE Loss: 222458.188 (681904.750) - AE Rec Loss: 1.509 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.031 (0.816) - Batch(s): 1.399 
(2.364) - AE Loss: 485381.438 (681904.750) - AE Rec Loss: 3.292 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.400 
(2.364) - AE Loss: 237362.844 (681904.750) - AE Rec Loss: 1.610 (4.624) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.816) - Batch(s): 1.399 
(2.364) - AE Loss: 1510223.250 (681904.750) - AE Rec Loss: 10.242 (4.624) - Disc
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.689 
(2.294) - AE Loss: 480302.719 (661720.375) - AE Rec Loss: 3.257 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.687 
(2.294) - AE Loss: 193194.188 (661720.375) - AE Rec Loss: 1.310 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.804 (0.757) - Batch(s): 1.678 
(2.294) - AE Loss: 191237.094 (661720.375) - AE Rec Loss: 1.297 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.692 
(2.294) - AE Loss: 138313.750 (661720.375) - AE Rec Loss: 0.938 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.694 
(2.294) - AE Loss: 1844950.250 (661720.375) - AE Rec Loss: 12.512 (4.488) - Disc
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.757) - Batch(s): 1.692 
(2.294) - AE Loss: 135058.234 (661720.375) - AE Rec Loss: 0.916 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 1.761 (0.719) - Batch(s): 2.335 
(2.274) - AE Loss: 244572.359 (654375.625) - AE Rec Loss: 1.659 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.129 
(2.274) - AE Loss: 127022.305 (654375.625) - AE Rec Loss: 0.861 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.126 
(2.274) - AE Loss: 188627.016 (654375.625) - AE Rec Loss: 1.279 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.646 (0.719) - Batch(s): 2.116 
(2.274) - AE Loss: 3034067.000 (654375.625) - AE Rec Loss: 20.576 (4.438) - Disc
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.336 
(2.274) - AE Loss: 178805.406 (654375.625) - AE Rec Loss: 1.213 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.719) - Batch(s): 2.129 
(2.274) - AE Loss: 97967.859 (654375.625) - AE Rec Loss: 0.664 (4.438) - Disc 
Loss: 0.000 (0.000) - 8.81 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 238360.625 (661263.688) - AE Rec Loss: 1.616 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.692 
(2.475) - AE Loss: 158739.094 (661263.688) - AE Rec Loss: 1.077 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.692 
(2.475) - AE Loss: 164367.656 (661263.688) - AE Rec Loss: 1.115 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 1599816.625 (661263.688) - AE Rec Loss: 10.849 (4.484) - Disc
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 4.042 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 1532579.750 (661263.688) - AE Rec Loss: 10.393 (4.484) - Disc
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.704) - Batch(s): 4.691 
(2.475) - AE Loss: 624276.625 (661263.688) - AE Rec Loss: 4.234 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.28 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.566 
(2.328) - AE Loss: 258340.766 (657788.062) - AE Rec Loss: 1.752 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.565 
(2.328) - AE Loss: 78801.820 (657788.062) - AE Rec Loss: 0.534 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.572 
(2.328) - AE Loss: 242716.625 (657788.062) - AE Rec Loss: 1.646 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.566 
(2.328) - AE Loss: 188056.125 (657788.062) - AE Rec Loss: 1.275 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.566 
(2.328) - AE Loss: 237662.609 (657788.062) - AE Rec Loss: 1.612 (4.461) - Disc 
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.650) - Batch(s): 0.553 
(2.328) - AE Loss: 1527032.875 (657788.062) - AE Rec Loss: 10.356 (4.461) - Disc
Loss: 0.000 (0.000) - 10.41 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.907 
(2.712) - AE Loss: 307087.188 (660829.375) - AE Rec Loss: 2.083 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.338 (0.676) - Batch(s): 7.903 
(2.712) - AE Loss: 1590301.875 (660829.375) - AE Rec Loss: 10.785 (4.482) - Disc
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.549 
(2.712) - AE Loss: 366753.625 (660829.375) - AE Rec Loss: 2.487 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 7.329 (0.676) - Batch(s): 7.901 
(2.712) - AE Loss: 1609941.875 (660829.375) - AE Rec Loss: 10.918 (4.482) - Disc
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.904 
(2.712) - AE Loss: 161924.203 (660829.375) - AE Rec Loss: 1.098 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.676) - Batch(s): 7.909 
(2.712) - AE Loss: 445738.312 (660829.375) - AE Rec Loss: 3.023 (4.482) - Disc 
Loss: 0.000 (0.000) - 12.85 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.538 
(2.967) - AE Loss: 243467.625 (654723.875) - AE Rec Loss: 1.651 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.538 
(2.967) - AE Loss: 148640.406 (654723.875) - AE Rec Loss: 1.008 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.539 
(2.967) - AE Loss: 1803257.000 (654723.875) - AE Rec Loss: 12.229 (4.440) - Disc
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 288636.875 (654723.875) - AE Rec Loss: 1.957 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.664) - Batch(s): 6.538 
(2.967) - AE Loss: 138758.719 (654723.875) - AE Rec Loss: 0.941 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 5.900 (0.664) - Batch(s): 6.537 
(2.967) - AE Loss: 143772.594 (654723.875) - AE Rec Loss: 0.975 (4.440) - Disc 
Loss: 0.000 (0.000) - 14.81 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 193138.844 (648743.500) - AE Rec Loss: 1.310 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 213626.984 (648743.500) - AE Rec Loss: 1.449 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.553 
(2.817) - AE Loss: 97734.852 (648743.500) - AE Rec Loss: 0.663 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 1974651.500 (648743.500) - AE Rec Loss: 13.391 (4.400) - Disc
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.566 
(2.817) - AE Loss: 1471271.750 (648743.500) - AE Rec Loss: 9.978 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.622) - Batch(s): 0.573 
(2.817) - AE Loss: 243251.000 (648743.500) - AE Rec Loss: 1.650 (4.400) - Disc 
Loss: 0.000 (0.000) - 14.90 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.566 
(2.684) - AE Loss: 372935.219 (651085.312) - AE Rec Loss: 2.529 (4.415) - Disc 
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.565 
(2.684) - AE Loss: 185307.875 (651085.312) - AE Rec Loss: 1.257 (4.415) - Disc 
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.553 
(2.684) - AE Loss: 125645.617 (651085.312) - AE Rec Loss: 0.852 (4.415) - Disc 
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(2.684) - AE Loss: 1551632.000 (651085.312) - AE Rec Loss: 10.523 (4.415) - Disc
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.573 
(2.684) - AE Loss: 137722.750 (651085.312) - AE Rec Loss: 0.934 (4.415) - Disc 
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.568 
(2.684) - AE Loss: 1682007.250 (651085.312) - AE Rec Loss: 11.407 (4.415) - Disc
Loss: 0.000 (0.000) - 14.99 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 328796.844 (635765.500) - AE Rec Loss: 2.230 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.743 
(3.354) - AE Loss: 218301.953 (635765.500) - AE Rec Loss: 1.480 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.743 
(3.354) - AE Loss: 163127.297 (635765.500) - AE Rec Loss: 1.106 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.742 
(3.354) - AE Loss: 97868.344 (635765.500) - AE Rec Loss: 0.664 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.619) - Batch(s): 14.743 
(3.354) - AE Loss: 180744.422 (635765.500) - AE Rec Loss: 1.226 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 14.106 (0.619) - Batch(s): 14.743 
(3.354) - AE Loss: 319174.938 (635765.500) - AE Rec Loss: 2.165 (4.312) - Disc 
Loss: 0.000 (0.000) - 19.37 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(3.207) - AE Loss: 134972.266 (648574.375) - AE Rec Loss: 0.915 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.567 
(3.207) - AE Loss: 1615775.375 (648574.375) - AE Rec Loss: 10.958 (4.398) - Disc
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.566 
(3.207) - AE Loss: 1529366.625 (648574.375) - AE Rec Loss: 10.372 (4.398) - Disc
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.566 
(3.207) - AE Loss: 93366.711 (648574.375) - AE Rec Loss: 0.633 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.574 
(3.207) - AE Loss: 538136.188 (648574.375) - AE Rec Loss: 3.649 (4.398) - Disc 
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.553 
(3.207) - AE Loss: 1819977.500 (648574.375) - AE Rec Loss: 12.343 (4.398) - Disc
Loss: 0.000 (0.000) - 19.42 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.566 
(3.075) - AE Loss: 1796999.375 (658991.438) - AE Rec Loss: 12.187 (4.469) - Disc
Loss: 0.000 (0.000) - 19.46 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.566 
(3.075) - AE Loss: 1626267.125 (658991.438) - AE Rec Loss: 11.029 (4.469) - Disc
Loss: 0.000 (0.000) - 19.46 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.566 
(3.075) - AE Loss: 342941.688 (658991.438) - AE Rec Loss: 2.326 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.46 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.574 
(3.075) - AE Loss: 1591485.750 (658991.438) - AE Rec Loss: 10.793 (4.469) - Disc
Loss: 0.000 (0.000) - 19.46 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.567 
(3.075) - AE Loss: 268192.781 (658991.438) - AE Rec Loss: 1.819 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.46 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.557) - Batch(s): 0.553 
(3.075) - AE Loss: 505004.719 (658991.438) - AE Rec Loss: 3.425 (4.469) - Disc 
Loss: 0.000 (0.000) - 19.46 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:13:41,584[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,788[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,802[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,820[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,872[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:13:41,936[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:13:43,838[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:44,011[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:44,011[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:44,037[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:13:44,147[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,364[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,496[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,509[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:13:44,529[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,601[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,709[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:13:44,960[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:13:44,964[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
[[36m2023-11-29 03:13:44,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:13:44,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:13:44,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:13:44,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:13:44,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pthloaded pretrained LPIPS loss from .cache/vgg.pth

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:16:45,673[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,739[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,779[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,781[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,818[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:16:45,826[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:16:47,898[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,941[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:47,954[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:48,019[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:48,040[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:16:48,043[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:16:48,453[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:16:48,493[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:16:48,499[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:16:48,616[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:16:48,619[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:16:48,625[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:16:48,626[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:16:48,626[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 03:16:48,628[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
[[36m2023-11-29 03:16:48,632[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:16:48,635[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:16:48,636[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
=> Preparing criterion 
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 1.3 on node 6
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 8
Reached 3 on node 6
Reached 5 on node 8
Reached end on node 8
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 1.3 on node 9=> Preparing opt_ae 

Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 8
Reached 3 on node 6
Reached 5 on node 8
Reached 5 on node 6
Reached end on node 8
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7Reached 1.3 on node 10

Reached 1.4 on node 7Reached 1.4 on node 10

Reached 2 on node 10Reached 2 on node 7

Reached 3 on node 7Reached 3 on node 10

Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10Reached end on node 7

Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8Reached 1.3 on node 6
Reached 1.3 on node 11

Reached 1.4 on node 6Reached 1.4 on node 11
Reached end on node 8

Reached 2 on node 6Reached 2 on node 11

Reached 3 on node 6Reached 3 on node 11

Reached 5 on node 11
Reached 5 on node 6
Reached end on node 11
Reached end on node 6
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
Loaded checkpoint at epoch 0 and step 101
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 6Reached 2 on node 7

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6Reached 1 on node 8

Reached 1 on node 7
Reached 1.4 on node 6
Reached 1.4 on node 8Reached 1.4 on node 7Reached 2 on node 6


Reached 2 on node 8Reached 2 on node 7

Reached 1 on node 6
Reached 1 on node 7
Reached 1 on node 8Reached 1.4 on node 6

Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 8Reached 2 on node 7Reached 3 on node 6


Reached 2 on node 8Reached 1.4 on node 11Reached 3 on node 6


Reached 2 on node 11
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7Reached 1 on node 11

Reached 2 on node 7
Reached 3 on node 7
Reached 1.4 on node 8
Reached 3 on node 7Reached 1.4 on node 11Reached 2 on node 8


Reached 3 on node 7Reached 2 on node 11

Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8Reached 1 on node 11

Reached 1.4 on node 8Reached 1.4 on node 11

Reached 1.4 on node 9Reached 2 on node 8Reached 2 on node 11


Reached 2 on node 9
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached end on node 6
Reached 3 on node 10
Reached 3 on node 10
Reached 1.4 on node 9
Reached 3 on node 10
Reached 2 on node 9Reached 3 on node 10

Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 8
Reached end on node 10
Reached end on node 11
Reached end on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 1.4 on node 10Reached 2 on node 8

Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 11
Reached end on node 6
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 7
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <101/2280>] - Data(s): 9.309 (6.633) - Batch(s): 10.876 
(10.709) - AE Loss: 2908459.250 (767327.188) - AE Rec Loss: 19.724 (5.204) - 
Disc Loss: 0.000 (0.000) - 3.98 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 5.362 (6.633) - Batch(s): 10.621 
(10.709) - AE Loss: 261324.328 (767327.188) - AE Rec Loss: 1.772 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 4.403 (6.633) - Batch(s): 10.654 
(10.709) - AE Loss: 92154.617 (767327.188) - AE Rec Loss: 0.625 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 6.936 (6.633) - Batch(s): 10.710 
(10.709) - AE Loss: 210771.625 (767327.188) - AE Rec Loss: 1.429 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.91 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 7.743 (6.633) - Batch(s): 11.062 
(10.709) - AE Loss: 106304.078 (767327.188) - AE Rec Loss: 0.721 (5.204) - Disc 
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <101/2280>] - Data(s): 6.543 (6.633) - Batch(s): 10.898 
(10.709) - AE Loss: 391264.000 (767327.188) - AE Rec Loss: 2.653 (5.204) - Disc 
Loss: 0.000 (0.000) - 3.98 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.552 
(5.636) - AE Loss: 722076.062 (863161.812) - AE Rec Loss: 4.897 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.566 
(5.636) - AE Loss: 240636.359 (863161.812) - AE Rec Loss: 1.632 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.569 
(5.636) - AE Loss: 1651371.625 (863161.812) - AE Rec Loss: 11.199 (5.854) - Disc
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.564 
(5.636) - AE Loss: 132891.812 (863161.812) - AE Rec Loss: 0.901 (5.854) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.562 
(5.636) - AE Loss: 1539113.000 (863161.812) - AE Rec Loss: 10.438 (5.854) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <102/2280>] - Data(s): 0.000 (3.317) - Batch(s): 0.562 
(5.636) - AE Loss: 1613852.750 (863161.812) - AE Rec Loss: 10.945 (5.854) - Disc
Loss: 0.000 (0.000) - 4.13 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.952 
(4.408) - AE Loss: 253094.281 (776363.312) - AE Rec Loss: 1.716 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.81 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.001 (2.292) - Batch(s): 1.956 
(4.408) - AE Loss: 130776.398 (776363.312) - AE Rec Loss: 0.887 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.80 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.292) - Batch(s): 1.952 
(4.408) - AE Loss: 287243.875 (776363.312) - AE Rec Loss: 1.948 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.292) - Batch(s): 1.955 
(4.408) - AE Loss: 219264.844 (776363.312) - AE Rec Loss: 1.487 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.000 (2.292) - Batch(s): 1.955 
(4.408) - AE Loss: 227142.906 (776363.312) - AE Rec Loss: 1.540 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <103/2280>] - Data(s): 0.561 (2.292) - Batch(s): 1.955 
(4.408) - AE Loss: 180385.422 (776363.312) - AE Rec Loss: 1.223 (5.265) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.639 
(4.443) - AE Loss: 1408350.250 (705540.312) - AE Rec Loss: 9.551 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.56 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.638 
(4.443) - AE Loss: 570114.875 (705540.312) - AE Rec Loss: 3.866 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.178 (1.807) - Batch(s): 4.644 
(4.443) - AE Loss: 377811.188 (705540.312) - AE Rec Loss: 2.562 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.000 (1.807) - Batch(s): 4.636 
(4.443) - AE Loss: 101692.539 (705540.312) - AE Rec Loss: 0.690 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.43 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (1.807) - Batch(s): 4.627 
(4.443) - AE Loss: 133439.188 (705540.312) - AE Rec Loss: 0.905 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.41 m remaining

[Epoch <000/100>: Step <104/2280>] - Data(s): 0.001 (1.807) - Batch(s): 4.638 
(4.443) - AE Loss: 391859.938 (705540.312) - AE Rec Loss: 2.657 (4.785) - Disc 
Loss: 0.000 (0.000) - 6.41 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.564 
(3.667) - AE Loss: 689841.750 (755310.188) - AE Rec Loss: 4.678 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.74 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.562 
(3.667) - AE Loss: 131073.578 (755310.188) - AE Rec Loss: 0.889 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.68 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.571 
(3.667) - AE Loss: 1661690.250 (755310.188) - AE Rec Loss: 11.269 (5.122) - Disc
Loss: 0.000 (0.000) - 6.69 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (1.446) - Batch(s): 0.563 
(3.667) - AE Loss: 1584988.250 (755310.188) - AE Rec Loss: 10.749 (5.122) - Disc
Loss: 0.000 (0.000) - 6.62 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.000 (1.446) - Batch(s): 0.552 
(3.667) - AE Loss: 1686330.750 (755310.188) - AE Rec Loss: 11.436 (5.122) - Disc
Loss: 0.000 (0.000) - 6.59 m remaining

[Epoch <000/100>: Step <105/2280>] - Data(s): 0.001 (1.446) - Batch(s): 0.565 
(3.667) - AE Loss: 428037.344 (755310.188) - AE Rec Loss: 2.903 (5.122) - Disc 
Loss: 0.000 (0.000) - 6.60 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.655 
(3.165) - AE Loss: 320448.938 (690040.562) - AE Rec Loss: 2.173 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.656 
(3.165) - AE Loss: 128709.898 (690040.562) - AE Rec Loss: 0.873 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.81 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.656 
(3.165) - AE Loss: 112507.227 (690040.562) - AE Rec Loss: 0.763 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.205) - Batch(s): 0.655 
(3.165) - AE Loss: 167090.203 (690040.562) - AE Rec Loss: 1.133 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.81 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.000 (1.205) - Batch(s): 0.656 
(3.165) - AE Loss: 283293.312 (690040.562) - AE Rec Loss: 1.921 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <106/2280>] - Data(s): 0.001 (1.205) - Batch(s): 0.656 
(3.165) - AE Loss: 125556.930 (690040.562) - AE Rec Loss: 0.851 (4.680) - Disc 
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.046 
(2.850) - AE Loss: 251141.469 (695518.000) - AE Rec Loss: 1.703 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.23 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (1.039) - Batch(s): 1.037 
(2.850) - AE Loss: 251976.109 (695518.000) - AE Rec Loss: 1.709 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.001 (1.039) - Batch(s): 1.048 
(2.850) - AE Loss: 303337.562 (695518.000) - AE Rec Loss: 2.057 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.047 
(2.850) - AE Loss: 403915.250 (695518.000) - AE Rec Loss: 2.739 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.052 
(2.850) - AE Loss: 288030.625 (695518.000) - AE Rec Loss: 1.953 (4.717) - Disc 
Loss: 0.000 (0.000) - 7.23 m remaining

[Epoch <000/100>: Step <107/2280>] - Data(s): 0.000 (1.039) - Batch(s): 1.046 
(2.850) - AE Loss: 1560882.000 (695518.000) - AE Rec Loss: 10.585 (4.717) - Disc
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.564 
(2.564) - AE Loss: 1643484.250 (674048.250) - AE Rec Loss: 11.146 (4.571) - Disc
Loss: 0.000 (0.000) - 7.40 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.001 (0.909) - Batch(s): 0.565 
(2.564) - AE Loss: 1637973.375 (674048.250) - AE Rec Loss: 11.108 (4.571) - Disc
Loss: 0.000 (0.000) - 7.32 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.575 
(2.564) - AE Loss: 173761.438 (674048.250) - AE Rec Loss: 1.178 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.41 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.564 
(2.564) - AE Loss: 600564.125 (674048.250) - AE Rec Loss: 4.073 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.46 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.563 
(2.564) - AE Loss: 90330.375 (674048.250) - AE Rec Loss: 0.613 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <108/2280>] - Data(s): 0.000 (0.909) - Batch(s): 0.552 
(2.564) - AE Loss: 229904.969 (674048.250) - AE Rec Loss: 1.559 (4.571) - Disc 
Loss: 0.000 (0.000) - 7.32 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.448 
(2.551) - AE Loss: 222801.938 (682014.938) - AE Rec Loss: 1.511 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.664 (0.832) - Batch(s): 2.448 
(2.551) - AE Loss: 487434.656 (682014.938) - AE Rec Loss: 3.306 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.001 (0.832) - Batch(s): 2.448 
(2.551) - AE Loss: 237704.812 (682014.938) - AE Rec Loss: 1.612 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.449 
(2.551) - AE Loss: 2069783.375 (682014.938) - AE Rec Loss: 14.037 (4.625) - Disc
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.449 
(2.551) - AE Loss: 159240.812 (682014.938) - AE Rec Loss: 1.080 (4.625) - Disc 
Loss: 0.000 (0.000) - 8.13 m remaining

[Epoch <000/100>: Step <109/2280>] - Data(s): 0.000 (0.832) - Batch(s): 2.449 
(2.551) - AE Loss: 1510880.500 (682014.938) - AE Rec Loss: 10.246 (4.625) - Disc
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.195 (0.750) - Batch(s): 0.743 
(2.361) - AE Loss: 190830.266 (661724.000) - AE Rec Loss: 1.294 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.33 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.754 
(2.361) - AE Loss: 133996.266 (661724.000) - AE Rec Loss: 0.909 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.47 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.753 
(2.361) - AE Loss: 478546.750 (661724.000) - AE Rec Loss: 3.245 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.35 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.753 
(2.361) - AE Loss: 192703.969 (661724.000) - AE Rec Loss: 1.307 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.41 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.767 
(2.361) - AE Loss: 1845468.750 (661724.000) - AE Rec Loss: 12.515 (4.488) - Disc
Loss: 0.000 (0.000) - 8.42 m remaining

[Epoch <000/100>: Step <110/2280>] - Data(s): 0.000 (0.750) - Batch(s): 0.565 
(2.361) - AE Loss: 136000.562 (661724.000) - AE Rec Loss: 0.922 (4.488) - Disc 
Loss: 0.000 (0.000) - 8.34 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.255 
(2.337) - AE Loss: 126138.805 (654334.062) - AE Rec Loss: 0.855 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.17 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.259 
(2.337) - AE Loss: 177313.219 (654334.062) - AE Rec Loss: 1.202 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 1.103 (0.712) - Batch(s): 2.245 
(2.337) - AE Loss: 3034299.000 (654334.062) - AE Rec Loss: 20.578 (4.437) - Disc
Loss: 0.000 (0.000) - 9.03 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.256 
(2.337) - AE Loss: 97442.797 (654334.062) - AE Rec Loss: 0.661 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.04 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 0.000 (0.712) - Batch(s): 2.255 
(2.337) - AE Loss: 186383.906 (654334.062) - AE Rec Loss: 1.264 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.05 m remaining

[Epoch <000/100>: Step <111/2280>] - Data(s): 1.168 (0.712) - Batch(s): 2.253 
(2.337) - AE Loss: 243673.688 (654334.062) - AE Rec Loss: 1.653 (4.437) - Disc 
Loss: 0.000 (0.000) - 9.11 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.083 
(2.399) - AE Loss: 1532409.875 (661161.750) - AE Rec Loss: 10.392 (4.484) - Disc
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.085 
(2.399) - AE Loss: 156736.469 (661161.750) - AE Rec Loss: 1.063 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.12 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.084 
(2.399) - AE Loss: 624238.000 (661161.750) - AE Rec Loss: 4.233 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.07 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.086 
(2.399) - AE Loss: 164341.906 (661161.750) - AE Rec Loss: 1.115 (4.484) - Disc 
Loss: 0.000 (0.000) - 9.99 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.086 
(2.399) - AE Loss: 1599565.625 (661161.750) - AE Rec Loss: 10.848 (4.484) - Disc
Loss: 0.000 (0.000) - 10.06 m remaining

[Epoch <000/100>: Step <112/2280>] - Data(s): 0.000 (0.689) - Batch(s): 3.085 
(2.399) - AE Loss: 236649.422 (661161.750) - AE Rec Loss: 1.605 (4.484) - Disc 
Loss: 0.000 (0.000) - 10.00 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.001 (0.636) - Batch(s): 0.563 
(2.258) - AE Loss: 77773.188 (657686.750) - AE Rec Loss: 0.527 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.20 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.552 
(2.258) - AE Loss: 1527196.000 (657686.750) - AE Rec Loss: 10.357 (4.460) - Disc
Loss: 0.000 (0.000) - 10.12 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.564 
(2.258) - AE Loss: 259152.328 (657686.750) - AE Rec Loss: 1.757 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.565 
(2.258) - AE Loss: 187760.328 (657686.750) - AE Rec Loss: 1.273 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.26 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.001 (0.636) - Batch(s): 0.571 
(2.258) - AE Loss: 242172.953 (657686.750) - AE Rec Loss: 1.642 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.21 m remaining

[Epoch <000/100>: Step <113/2280>] - Data(s): 0.000 (0.636) - Batch(s): 0.566 
(2.258) - AE Loss: 236955.797 (657686.750) - AE Rec Loss: 1.607 (4.460) - Disc 
Loss: 0.000 (0.000) - 10.13 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.006 
(2.233) - AE Loss: 307917.906 (660758.438) - AE Rec Loss: 2.088 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.84 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.006 
(2.233) - AE Loss: 161987.375 (660758.438) - AE Rec Loss: 1.099 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.73 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.010 
(2.233) - AE Loss: 446363.688 (660758.438) - AE Rec Loss: 3.027 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.79 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.000 (0.605) - Batch(s): 2.004 
(2.233) - AE Loss: 1589925.875 (660758.438) - AE Rec Loss: 10.782 (4.481) - Disc
Loss: 0.000 (0.000) - 10.79 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.840 (0.605) - Batch(s): 1.994 
(2.233) - AE Loss: 1609211.375 (660758.438) - AE Rec Loss: 10.913 (4.481) - Disc
Loss: 0.000 (0.000) - 10.71 m remaining

[Epoch <000/100>: Step <114/2280>] - Data(s): 0.001 (0.605) - Batch(s): 2.007 
(2.233) - AE Loss: 368243.750 (660758.438) - AE Rec Loss: 2.497 (4.481) - Disc 
Loss: 0.000 (0.000) - 10.71 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.663 
(2.129) - AE Loss: 139045.219 (654648.500) - AE Rec Loss: 0.943 (4.440) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.664 
(2.129) - AE Loss: 143344.734 (654648.500) - AE Rec Loss: 0.972 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.87 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.664 
(2.129) - AE Loss: 242399.859 (654648.500) - AE Rec Loss: 1.644 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.87 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.664 
(2.129) - AE Loss: 147597.469 (654648.500) - AE Rec Loss: 1.001 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.95 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.666 
(2.129) - AE Loss: 289651.344 (654648.500) - AE Rec Loss: 1.964 (4.440) - Disc 
Loss: 0.000 (0.000) - 10.95 m remaining

[Epoch <000/100>: Step <115/2280>] - Data(s): 0.000 (0.564) - Batch(s): 0.666 
(2.129) - AE Loss: 1803252.750 (654648.500) - AE Rec Loss: 12.229 (4.440) - Disc
Loss: 0.000 (0.000) - 10.89 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.001 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 1974525.750 (648665.062) - AE Rec Loss: 13.391 (4.399) - Disc
Loss: 0.000 (0.000) - 11.13 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.001 (0.529) - Batch(s): 0.563 
(2.031) - AE Loss: 213820.438 (648665.062) - AE Rec Loss: 1.450 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.554 
(2.031) - AE Loss: 98365.539 (648665.062) - AE Rec Loss: 0.667 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.001 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 1471181.500 (648665.062) - AE Rec Loss: 9.977 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.573 
(2.031) - AE Loss: 243255.750 (648665.062) - AE Rec Loss: 1.650 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.08 m remaining

[Epoch <000/100>: Step <116/2280>] - Data(s): 0.000 (0.529) - Batch(s): 0.566 
(2.031) - AE Loss: 191978.422 (648665.062) - AE Rec Loss: 1.302 (4.399) - Disc 
Loss: 0.000 (0.000) - 11.02 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.820 
(2.131) - AE Loss: 137479.969 (650948.000) - AE Rec Loss: 0.932 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.20 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.815 
(2.131) - AE Loss: 371993.625 (650948.000) - AE Rec Loss: 2.523 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.14 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 1.513 (0.521) - Batch(s): 3.805 
(2.131) - AE Loss: 125965.531 (650948.000) - AE Rec Loss: 0.854 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.12 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.818 
(2.131) - AE Loss: 1681606.000 (650948.000) - AE Rec Loss: 11.404 (4.415) - Disc
Loss: 0.000 (0.000) - 12.12 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.000 (0.521) - Batch(s): 3.817 
(2.131) - AE Loss: 1550156.500 (650948.000) - AE Rec Loss: 10.513 (4.415) - Disc
Loss: 0.000 (0.000) - 12.25 m remaining

[Epoch <000/100>: Step <117/2280>] - Data(s): 0.001 (0.521) - Batch(s): 3.815 
(2.131) - AE Loss: 184736.328 (650948.000) - AE Rec Loss: 1.253 (4.415) - Disc 
Loss: 0.000 (0.000) - 12.19 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.511 (0.499) - Batch(s): 1.632 
(2.103) - AE Loss: 317358.000 (635599.438) - AE Rec Loss: 2.152 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.55 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.001 (0.499) - Batch(s): 1.632 
(2.103) - AE Loss: 216822.891 (635599.438) - AE Rec Loss: 1.470 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.68 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.001 (0.499) - Batch(s): 1.633 
(2.103) - AE Loss: 326652.875 (635599.438) - AE Rec Loss: 2.215 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.57 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.633 
(2.103) - AE Loss: 98601.250 (635599.438) - AE Rec Loss: 0.669 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.63 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.001 (0.499) - Batch(s): 1.633 
(2.103) - AE Loss: 179690.609 (635599.438) - AE Rec Loss: 1.219 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.56 m remaining

[Epoch <000/100>: Step <118/2280>] - Data(s): 0.000 (0.499) - Batch(s): 1.633 
(2.103) - AE Loss: 162719.078 (635599.438) - AE Rec Loss: 1.104 (4.310) - Disc 
Loss: 0.000 (0.000) - 12.63 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.566 
(2.022) - AE Loss: 134980.516 (648384.188) - AE Rec Loss: 0.915 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.79 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.566 
(2.022) - AE Loss: 1529355.375 (648384.188) - AE Rec Loss: 10.372 (4.397) - Disc
Loss: 0.000 (0.000) - 12.68 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.572 
(2.022) - AE Loss: 536105.938 (648384.188) - AE Rec Loss: 3.636 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.74 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.555 
(2.022) - AE Loss: 1819667.750 (648384.188) - AE Rec Loss: 12.340 (4.397) - Disc
Loss: 0.000 (0.000) - 12.66 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.565 
(2.022) - AE Loss: 92561.203 (648384.188) - AE Rec Loss: 0.628 (4.397) - Disc 
Loss: 0.000 (0.000) - 12.74 m remaining

[Epoch <000/100>: Step <119/2280>] - Data(s): 0.000 (0.473) - Batch(s): 0.567 
(2.022) - AE Loss: 1616225.500 (648384.188) - AE Rec Loss: 10.961 (4.397) - Disc
Loss: 0.000 (0.000) - 12.67 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.737 
(1.998) - AE Loss: 1796710.250 (658773.375) - AE Rec Loss: 12.185 (4.468) - Disc
Loss: 0.000 (0.000) - 13.24 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.425 
(1.998) - AE Loss: 266252.812 (658773.375) - AE Rec Loss: 1.806 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 1.177 (0.458) - Batch(s): 1.725 
(1.998) - AE Loss: 502457.312 (658773.375) - AE Rec Loss: 3.408 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.12 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.736 
(1.998) - AE Loss: 341226.375 (658773.375) - AE Rec Loss: 2.314 (4.468) - Disc 
Loss: 0.000 (0.000) - 13.14 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.740 
(1.998) - AE Loss: 1590781.625 (658773.375) - AE Rec Loss: 10.788 (4.468) - Disc
Loss: 0.000 (0.000) - 13.20 m remaining

[Epoch <000/100>: Step <120/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.735 
(1.998) - AE Loss: 1625283.000 (658773.375) - AE Rec Loss: 11.022 (4.468) - Disc
Loss: 0.000 (0.000) - 13.19 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 1658631.500 (676453.562) - AE Rec Loss: 11.248 (4.587) - Disc
Loss: 0.000 (0.000) - 17.87 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 83935.805 (676453.562) - AE Rec Loss: 0.569 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.93 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 86295.938 (676453.562) - AE Rec Loss: 0.585 (4.587) - Disc 
Loss: 0.000 (0.000) - 17.86 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 1916466.000 (676453.562) - AE Rec Loss: 12.997 (4.587) - Disc
Loss: 0.000 (0.000) - 17.86 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 1518955.875 (676453.562) - AE Rec Loss: 10.301 (4.587) - Disc
Loss: 0.000 (0.000) - 17.93 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 0.000 (0.436) - Batch(s): 16.296 
(2.617) - AE Loss: 1756882.250 (676453.562) - AE Rec Loss: 11.915 (4.587) - Disc
Loss: 0.000 (0.000) - 17.98 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.566 
(2.524) - AE Loss: 279302.250 (665528.125) - AE Rec Loss: 1.894 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.93 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.565 
(2.524) - AE Loss: 1446683.500 (665528.125) - AE Rec Loss: 9.811 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.99 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.568 
(2.524) - AE Loss: 181029.422 (665528.125) - AE Rec Loss: 1.228 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.92 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.555 
(2.524) - AE Loss: 216629.250 (665528.125) - AE Rec Loss: 1.469 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.91 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.573 
(2.524) - AE Loss: 183727.188 (665528.125) - AE Rec Loss: 1.246 (4.513) - Disc 
Loss: 0.000 (0.000) - 17.99 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.566 
(2.524) - AE Loss: 1557644.750 (665528.125) - AE Rec Loss: 10.563 (4.513) - Disc
Loss: 0.000 (0.000) - 18.04 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.568 
(2.438) - AE Loss: 99779.711 (650271.625) - AE Rec Loss: 0.677 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.98 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.567 
(2.438) - AE Loss: 423192.062 (650271.625) - AE Rec Loss: 2.870 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.99 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.566 
(2.438) - AE Loss: 248405.688 (650271.625) - AE Rec Loss: 1.685 (4.410) - Disc 
Loss: 0.000 (0.000) - 18.10 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (0.399) - Batch(s): 0.555 
(2.438) - AE Loss: 70349.391 (650271.625) - AE Rec Loss: 0.477 (4.410) - Disc 
Loss: 0.000 (0.000) - 17.97 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.565 
(2.438) - AE Loss: 147642.391 (650271.625) - AE Rec Loss: 1.001 (4.410) - Disc 
Loss: 0.000 (0.000) - 18.05 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (0.399) - Batch(s): 0.573 
(2.438) - AE Loss: 1386079.125 (650271.625) - AE Rec Loss: 9.400 (4.410) - Disc 
Loss: 0.000 (0.000) - 18.05 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 1559111.250 (648486.250) - AE Rec Loss: 10.573 (4.398) - Disc
Loss: 0.000 (0.000) - 18.08 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 135810.750 (648486.250) - AE Rec Loss: 0.921 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.07 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (0.382) - Batch(s): 0.682 
(2.365) - AE Loss: 292065.625 (648486.250) - AE Rec Loss: 1.981 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.19 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 263715.000 (648486.250) - AE Rec Loss: 1.788 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.14 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (0.382) - Batch(s): 0.682 
(2.365) - AE Loss: 189013.953 (648486.250) - AE Rec Loss: 1.282 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.06 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (0.382) - Batch(s): 0.681 
(2.365) - AE Loss: 317083.062 (648486.250) - AE Rec Loss: 2.150 (4.398) - Disc 
Loss: 0.000 (0.000) - 18.14 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.566 
(2.293) - AE Loss: 138471.500 (645571.188) - AE Rec Loss: 0.939 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.19 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.568 
(2.293) - AE Loss: 165781.625 (645571.188) - AE Rec Loss: 1.124 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.14 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.573 
(2.293) - AE Loss: 70746.781 (645571.188) - AE Rec Loss: 0.480 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.20 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.556 
(2.293) - AE Loss: 114372.711 (645571.188) - AE Rec Loss: 0.776 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.12 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.568 
(2.293) - AE Loss: 77386.266 (645571.188) - AE Rec Loss: 0.525 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.24 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.570 
(2.293) - AE Loss: 203682.672 (645571.188) - AE Rec Loss: 1.381 (4.378) - Disc 
Loss: 0.000 (0.000) - 18.12 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.567 
(2.227) - AE Loss: 584085.375 (646239.062) - AE Rec Loss: 3.961 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.19 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.566 
(2.227) - AE Loss: 166039.000 (646239.062) - AE Rec Loss: 1.126 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.25 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.001 (0.353) - Batch(s): 0.568 
(2.227) - AE Loss: 618930.625 (646239.062) - AE Rec Loss: 4.197 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.18 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.566 
(2.227) - AE Loss: 1506263.250 (646239.062) - AE Rec Loss: 10.215 (4.383) - Disc
Loss: 0.000 (0.000) - 18.30 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.001 (0.353) - Batch(s): 0.575 
(2.227) - AE Loss: 128314.016 (646239.062) - AE Rec Loss: 0.870 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.25 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.555 
(2.227) - AE Loss: 586945.000 (646239.062) - AE Rec Loss: 3.980 (4.383) - Disc 
Loss: 0.000 (0.000) - 18.18 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 527569.688 (648069.312) - AE Rec Loss: 3.578 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.72 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 234988.812 (648069.312) - AE Rec Loss: 1.594 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.67 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 1622879.375 (648069.312) - AE Rec Loss: 11.006 (4.395) - Disc
Loss: 0.000 (0.000) - 18.67 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.878 
(2.214) - AE Loss: 230650.203 (648069.312) - AE Rec Loss: 1.564 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.61 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.877 
(2.214) - AE Loss: 106051.539 (648069.312) - AE Rec Loss: 0.719 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.60 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.343) - Batch(s): 1.880 
(2.214) - AE Loss: 183689.516 (648069.312) - AE Rec Loss: 1.246 (4.395) - Disc 
Loss: 0.000 (0.000) - 18.60 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:18:19,051[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:19,133[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:19,134[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:19,138[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:19,143[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:18:19,496[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:18:21,375[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:21,390[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:21,403[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:21,404[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:21,433[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:18:21,699[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,928[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:21,956[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:22,035[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:18:22,055[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:18:22,067[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:18:22,274[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:18:22,277[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,277[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,277[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:18:22,284[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,285[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:18:22,285[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 11
Reached 5 on node 11
=> Mixed precision: no
Reached end on node 11
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
=> Preparing opt_ae 
Reached 2 on node 10
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 3 on node 10
Reached 2 on node 7
Reached 5 on node 10
Reached 3 on node 7
Reached end on node 10
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 3 on node 9
Reached 2 on node 11Reached 5 on node 9

Reached end on node 9
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 7Reached 3 on node 10

Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10
Reached end on node 7
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6Reached 1.3 on node 9

Reached 1.4 on node 9Reached 1.4 on node 6Reached 1.3 on node 8


Reached 1.4 on node 8
Reached 2 on node 9
Reached 2 on node 6
Reached 2 on node 8
Reached 3 on node 6Reached 3 on node 9

Reached 3 on node 8Reached 5 on node 9Reached 5 on node 6


Reached 1.3 on node 10Reached 1.3 on node 7Reached end on node 6Reached end on node 9Reached 5 on node 8




Reached 1.4 on node 10Reached 1.4 on node 7

Reached end on node 8Reached 2 on node 10

Reached 2 on node 7
Reached 3 on node 10
Reached 3 on node 7
Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10
Reached end on node 7
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7Reached 1 on node 6

Reached 1.4 on node 6Reached 1.4 on node 7

Reached 2 on node 6Reached 2 on node 7

Reached 1 on node 8
Reached 3 on node 6
Reached 1 on node 11Reached 3 on node 6

Reached 3 on node 6Reached 1.4 on node 8

Reached 3 on node 6Reached 2 on node 8

Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8Reached 1.4 on node 7

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8Reached 3 on node 7

Reached 2 on node 8Reached 3 on node 7

Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10Reached 1 on node 11

Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 11Reached 1.4 on node 9

Reached 2 on node 9
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached end on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 7
Reached end on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8Reached 1.4 on node 9

Reached 2 on node 8Reached 2 on node 9

Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9Reached 1 on node 8

Reached 1.4 on node 8
Reached 1.4 on node 9
Reached 2 on node 8
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 1 on node 7Reached 2 on node 9

Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 9
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <121/2280>] - Data(s): 5.448 (6.198) - Batch(s): 10.519 
(10.670) - AE Loss: 1519087.875 (1030141.250) - AE Rec Loss: 10.302 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 8.358 (6.198) - Batch(s): 10.493 
(10.670) - AE Loss: 83895.719 (1030141.250) - AE Rec Loss: 0.569 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.284 (6.198) - Batch(s): 10.509 
(10.670) - AE Loss: 1916428.250 (1030141.250) - AE Rec Loss: 12.997 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.576 (6.198) - Batch(s): 10.507 
(10.670) - AE Loss: 86077.305 (1030141.250) - AE Rec Loss: 0.584 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 7.586 (6.198) - Batch(s): 10.512 
(10.670) - AE Loss: 1756613.250 (1030141.250) - AE Rec Loss: 11.913 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.706 (6.198) - Batch(s): 10.508 
(10.670) - AE Loss: 1659341.500 (1030141.250) - AE Rec Loss: 11.253 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.552 
(5.618) - AE Loss: 221352.609 (735981.500) - AE Rec Loss: 1.501 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.567 
(5.618) - AE Loss: 188934.281 (735981.500) - AE Rec Loss: 1.281 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.572 
(5.618) - AE Loss: 191913.422 (735981.500) - AE Rec Loss: 1.301 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.099) - Batch(s): 0.566 
(5.618) - AE Loss: 1562964.750 (735981.500) - AE Rec Loss: 10.600 (4.991) - Disc
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.565 
(5.618) - AE Loss: 1448409.750 (735981.500) - AE Rec Loss: 9.823 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.099) - Batch(s): 0.566 
(5.618) - AE Loss: 284925.844 (735981.500) - AE Rec Loss: 1.932 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.357 
(4.531) - AE Loss: 75977.961 (597390.625) - AE Rec Loss: 0.515 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.357 
(4.531) - AE Loss: 1390384.000 (597390.625) - AE Rec Loss: 9.429 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.358 
(4.531) - AE Loss: 102495.992 (597390.625) - AE Rec Loss: 0.695 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.357 
(4.531) - AE Loss: 427529.938 (597390.625) - AE Rec Loss: 2.899 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.358 
(4.531) - AE Loss: 151977.484 (597390.625) - AE Rec Loss: 1.031 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.111) - Batch(s): 2.358 
(4.531) - AE Loss: 253083.938 (597390.625) - AE Rec Loss: 1.716 (4.051) - Disc 
Loss: 0.000 (0.000) - 4.07 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (1.584) - Batch(s): 0.566 
(3.540) - AE Loss: 289582.000 (599354.625) - AE Rec Loss: 1.964 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.001 (1.584) - Batch(s): 0.566 
(3.540) - AE Loss: 315129.344 (599354.625) - AE Rec Loss: 2.137 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.554 
(3.540) - AE Loss: 186953.266 (599354.625) - AE Rec Loss: 1.268 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.574 
(3.540) - AE Loss: 261114.078 (599354.625) - AE Rec Loss: 1.771 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.568 
(3.540) - AE Loss: 132089.375 (599354.625) - AE Rec Loss: 0.896 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.584) - Batch(s): 0.566 
(3.540) - AE Loss: 1557576.000 (599354.625) - AE Rec Loss: 10.563 (4.065) - Disc
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.752 
(2.979) - AE Loss: 78404.594 (594055.250) - AE Rec Loss: 0.532 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.740 
(2.979) - AE Loss: 112697.156 (594055.250) - AE Rec Loss: 0.764 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.753 
(2.979) - AE Loss: 191818.688 (594055.250) - AE Rec Loss: 1.301 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.270) - Batch(s): 0.756 
(2.979) - AE Loss: 65901.922 (594055.250) - AE Rec Loss: 0.447 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.751 
(2.979) - AE Loss: 156307.844 (594055.250) - AE Rec Loss: 1.060 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.270) - Batch(s): 0.751 
(2.979) - AE Loss: 139112.031 (594055.250) - AE Rec Loss: 0.943 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 1512697.250 (605202.250) - AE Rec Loss: 10.259 (4.104) - Disc
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 614517.500 (605202.250) - AE Rec Loss: 4.167 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 589177.250 (605202.250) - AE Rec Loss: 3.996 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.098 (1.122) - Batch(s): 3.358 
(3.042) - AE Loss: 124775.211 (605202.250) - AE Rec Loss: 0.846 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.001 (1.122) - Batch(s): 3.360 
(3.042) - AE Loss: 588494.375 (605202.250) - AE Rec Loss: 3.991 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.122) - Batch(s): 3.359 
(3.042) - AE Loss: 162335.719 (605202.250) - AE Rec Loss: 1.101 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.976) - Batch(s): 1.767 
(2.843) - AE Loss: 539467.875 (618324.500) - AE Rec Loss: 3.659 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.771 
(2.843) - AE Loss: 1619191.500 (618324.500) - AE Rec Loss: 10.981 (4.193) - Disc
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.755 
(2.843) - AE Loss: 108234.359 (618324.500) - AE Rec Loss: 0.734 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.769 
(2.843) - AE Loss: 182511.312 (618324.500) - AE Rec Loss: 1.238 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.765 
(2.843) - AE Loss: 232812.031 (618324.500) - AE Rec Loss: 1.579 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.976) - Batch(s): 1.766 
(2.843) - AE Loss: 223872.859 (618324.500) - AE Rec Loss: 1.518 (4.193) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.565 
(2.558) - AE Loss: 294862.562 (614960.812) - AE Rec Loss: 2.000 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.554 
(2.558) - AE Loss: 588703.688 (614960.812) - AE Rec Loss: 3.992 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.566 
(2.558) - AE Loss: 115995.336 (614960.812) - AE Rec Loss: 0.787 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.566 
(2.558) - AE Loss: 529990.875 (614960.812) - AE Rec Loss: 3.594 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.573 
(2.558) - AE Loss: 1475295.125 (614960.812) - AE Rec Loss: 10.005 (4.170) - Disc
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.854) - Batch(s): 0.568 
(2.558) - AE Loss: 241876.656 (614960.812) - AE Rec Loss: 1.640 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.714 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 418002.688 (622506.375) - AE Rec Loss: 2.835 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 276903.750 (622506.375) - AE Rec Loss: 1.878 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 157078.031 (622506.375) - AE Rec Loss: 1.065 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.442 
(2.545) - AE Loss: 252793.844 (622506.375) - AE Rec Loss: 1.714 (4.222) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.782) - Batch(s): 2.441 
(2.545) - AE Loss: 1641012.250 (622506.375) - AE Rec Loss: 11.129 (4.222) - Disc
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.001 (0.782) - Batch(s): 2.442 
(2.545) - AE Loss: 1637233.250 (622506.375) - AE Rec Loss: 11.103 (4.222) - Disc
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.935 
(2.572) - AE Loss: 166052.750 (640037.875) - AE Rec Loss: 1.126 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.935 
(2.572) - AE Loss: 1798114.000 (640037.875) - AE Rec Loss: 12.194 (4.341) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.939 
(2.572) - AE Loss: 178232.438 (640037.875) - AE Rec Loss: 1.209 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.922 
(2.572) - AE Loss: 78740.406 (640037.875) - AE Rec Loss: 0.534 (4.341) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.935 
(2.572) - AE Loss: 1768046.125 (640037.875) - AE Rec Loss: 11.990 (4.341) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.723) - Batch(s): 2.936 
(2.572) - AE Loss: 1623105.750 (640037.875) - AE Rec Loss: 11.007 (4.341) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.657) - Batch(s): 1.234 
(2.446) - AE Loss: 1495619.500 (634236.438) - AE Rec Loss: 10.143 (4.301) - Disc
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.235 
(2.446) - AE Loss: 129211.352 (634236.438) - AE Rec Loss: 0.876 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.657) - Batch(s): 1.234 
(2.446) - AE Loss: 182466.391 (634236.438) - AE Rec Loss: 1.237 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.223 
(2.446) - AE Loss: 167569.750 (634236.438) - AE Rec Loss: 1.136 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.239 
(2.446) - AE Loss: 120079.555 (634236.438) - AE Rec Loss: 0.814 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.657) - Batch(s): 1.237 
(2.446) - AE Loss: 182200.828 (634236.438) - AE Rec Loss: 1.236 (4.301) - Disc 
Loss: 0.000 (0.000) - 7.86 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 1.043 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 533315.688 (608966.375) - AE Rec Loss: 3.617 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.760 
(2.389) - AE Loss: 146626.719 (608966.375) - AE Rec Loss: 0.994 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.760 
(2.389) - AE Loss: 162748.734 (608966.375) - AE Rec Loss: 1.104 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 101381.203 (608966.375) - AE Rec Loss: 0.688 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.759 
(2.389) - AE Loss: 1770409.750 (608966.375) - AE Rec Loss: 12.006 (4.130) - Disc
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.758 
(2.389) - AE Loss: 82723.812 (608966.375) - AE Rec Loss: 0.561 (4.130) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 77042.531 (609563.000) - AE Rec Loss: 0.522 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 139753.000 (609563.000) - AE Rec Loss: 0.948 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 7.854 (0.617) - Batch(s): 8.427 
(2.830) - AE Loss: 189647.641 (609563.000) - AE Rec Loss: 1.286 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 1613695.750 (609563.000) - AE Rec Loss: 10.944 (4.134) - Disc
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.431 
(2.830) - AE Loss: 242496.031 (609563.000) - AE Rec Loss: 1.645 (4.134) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.617) - Batch(s): 8.070 
(2.830) - AE Loss: 2036944.000 (609563.000) - AE Rec Loss: 13.814 (4.134) - Disc
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.874 
(2.747) - AE Loss: 407251.938 (634922.188) - AE Rec Loss: 2.762 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.875 
(2.747) - AE Loss: 296039.062 (634922.188) - AE Rec Loss: 2.008 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 1.315 (0.580) - Batch(s): 1.863 
(2.747) - AE Loss: 2884442.000 (634922.188) - AE Rec Loss: 19.561 (4.306) - Disc
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.875 
(2.747) - AE Loss: 1887163.750 (634922.188) - AE Rec Loss: 12.798 (4.306) - Disc
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.518 
(2.747) - AE Loss: 107422.148 (634922.188) - AE Rec Loss: 0.729 (4.306) - Disc 
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.580) - Batch(s): 1.879 
(2.747) - AE Loss: 1505031.875 (634922.188) - AE Rec Loss: 10.207 (4.306) - Disc
Loss: 0.000 (0.000) - 11.00 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 1325585.500 (661038.688) - AE Rec Loss: 8.990 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 1592871.000 (661038.688) - AE Rec Loss: 10.802 (4.483) - Disc
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 1673794.500 (661038.688) - AE Rec Loss: 11.351 (4.483) - Disc
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 441570.531 (661038.688) - AE Rec Loss: 2.995 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 1364303.250 (661038.688) - AE Rec Loss: 9.252 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.542) - Batch(s): 0.702 
(2.611) - AE Loss: 134400.344 (661038.688) - AE Rec Loss: 0.911 (4.483) - Disc 
Loss: 0.000 (0.000) - 11.14 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 76366.609 (683722.688) - AE Rec Loss: 0.518 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.514) - Batch(s): 1.285 
(2.532) - AE Loss: 99184.312 (683722.688) - AE Rec Loss: 0.673 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 1.078 (0.514) - Batch(s): 1.642 
(2.532) - AE Loss: 1655895.875 (683722.688) - AE Rec Loss: 11.230 (4.637) - Disc
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 207539.047 (683722.688) - AE Rec Loss: 1.407 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.286 
(2.532) - AE Loss: 1373125.625 (683722.688) - AE Rec Loss: 9.312 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.514) - Batch(s): 1.648 
(2.532) - AE Loss: 76196.336 (683722.688) - AE Rec Loss: 0.517 (4.637) - Disc 
Loss: 0.000 (0.000) - 11.52 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 1.472 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 96807.352 (664769.750) - AE Rec Loss: 0.657 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.75 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 144050.594 (664769.750) - AE Rec Loss: 0.977 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.76 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 8.241 (0.531) - Batch(s): 8.824 
(2.882) - AE Loss: 454150.844 (664769.750) - AE Rec Loss: 3.080 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.76 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 391520.250 (664769.750) - AE Rec Loss: 2.655 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.75 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.463 
(2.882) - AE Loss: 131924.500 (664769.750) - AE Rec Loss: 0.895 (4.508) - Disc 
Loss: 0.000 (0.000) - 13.75 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.531) - Batch(s): 8.461 
(2.882) - AE Loss: 1580460.375 (664769.750) - AE Rec Loss: 10.718 (4.508) - Disc
Loss: 0.000 (0.000) - 13.75 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.706 
(2.761) - AE Loss: 271869.000 (671219.875) - AE Rec Loss: 1.844 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.707 
(2.761) - AE Loss: 168883.875 (671219.875) - AE Rec Loss: 1.145 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.706 
(2.761) - AE Loss: 1362968.375 (671219.875) - AE Rec Loss: 9.243 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.706 
(2.761) - AE Loss: 186288.250 (671219.875) - AE Rec Loss: 1.263 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.706 
(2.761) - AE Loss: 1676148.500 (671219.875) - AE Rec Loss: 11.367 (4.552) - Disc
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.708 
(2.761) - AE Loss: 161022.531 (671219.875) - AE Rec Loss: 1.092 (4.552) - Disc 
Loss: 0.000 (0.000) - 13.87 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.568 
(2.646) - AE Loss: 118845.398 (656165.812) - AE Rec Loss: 0.806 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.567 
(2.646) - AE Loss: 78087.469 (656165.812) - AE Rec Loss: 0.530 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.569 
(2.646) - AE Loss: 77696.703 (656165.812) - AE Rec Loss: 0.527 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.567 
(2.646) - AE Loss: 84894.930 (656165.812) - AE Rec Loss: 0.576 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.556 
(2.646) - AE Loss: 190567.469 (656165.812) - AE Rec Loss: 1.292 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.475) - Batch(s): 0.575 
(2.646) - AE Loss: 69895.773 (656165.812) - AE Rec Loss: 0.474 (4.450) - Disc 
Loss: 0.000 (0.000) - 13.95 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.178 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 1899824.750 (641367.188) - AE Rec Loss: 12.884 (4.350) - Disc
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 155599.125 (641367.188) - AE Rec Loss: 1.055 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 1.333 (0.458) - Batch(s): 1.907 
(2.592) - AE Loss: 134198.438 (641367.188) - AE Rec Loss: 0.910 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 166697.406 (641367.188) - AE Rec Loss: 1.130 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 199370.281 (641367.188) - AE Rec Loss: 1.352 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.543 
(2.592) - AE Loss: 87710.734 (641367.188) - AE Rec Loss: 0.595 (4.350) - Disc 
Loss: 0.000 (0.000) - 14.37 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:21:28,101[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:28,111[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:28,155[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:28,369[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:28,372[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:21:28,406[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:21:30,337[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,346[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,363[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,621[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,632[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:21:30,649[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,884[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:21:30,960[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:21:30,966[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:31,146[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:31,240[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:21:31,258[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:21:31,260[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:21:31,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
[[36m2023-11-29 03:21:31,263[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
[[36m2023-11-29 03:21:31,265[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:21:31,265[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Preparing model 
len(train_dataset) = 54706
[[36m2023-11-29 03:21:31,268[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Preparing opt_disc 
len(train_dataloader) = 2279
=> Mixed precision: no
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
=> Preparing opt_ae 
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 1.3 on node 6Reached 5 on node 10

Reached 1.4 on node 6
Reached end on node 10
Reached 2 on node 6
Reached 1.3 on node 9Reached 3 on node 6

Reached 1.4 on node 9
Reached 2 on node 9Reached 5 on node 6

Reached end on node 6
Reached 3 on node 9
Reached 3 on node 8
Reached 5 on node 8
Reached 5 on node 9Reached end on node 8

Reached end on node 9
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
=> Preparing opt_ae 
Reached end on node 11
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 9
=> Preparing criterion 
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10Reached 1 on node 8

devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8Reached 1.3 on node 7Reached 1.3 on node 10Reached 1.3 on node 11



Reached 1.4 on node 7Reached 1.4 on node 8Reached 1.4 on node 10
Reached 1.4 on node 11


Reached 2 on node 7Reached 2 on node 10Reached 2 on node 8
Reached 2 on node 11


Reached 3 on node 7Reached 3 on node 10Reached 3 on node 8
Reached 3 on node 11


Reached 5 on node 10
Reached 5 on node 8Reached 5 on node 7

Reached 5 on node 11
Reached end on node 10Reached end on node 8

Reached end on node 7Reached end on node 11

Reached 1.3 on node 9Reached 1.3 on node 6
Reached 1.4 on node 6

Reached 1.4 on node 9
Reached 2 on node 6
Reached 2 on node 9
Reached 3 on node 6
Reached 3 on node 9
Reached 5 on node 6
Reached 5 on node 9
Reached end on node 6Reached end on node 9

=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
Loaded checkpoint at epoch 0 and step 121
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 1.4 on node 8Reached 2 on node 6

Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6Reached 1 on node 8

Reached 1.4 on node 6
Reached 1.4 on node 8
Reached 2 on node 6
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1 on node 7Reached 1.4 on node 9

Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6Reached 1 on node 10

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6Reached 1.4 on node 10

Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 1.4 on node 10Reached 2 on node 7

Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11Reached 1.4 on node 9

Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1 on node 10Reached 3 on node 8

Reached 5 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 7Reached 1.4 on node 11

Reached 1.4 on node 9
Reached 2 on node 11Reached 2 on node 7Reached 2 on node 9


Reached 3 on node 9Reached 3 on node 7

Reached 3 on node 9
Reached 3 on node 7
Reached 3 on node 9
Reached 3 on node 7
Reached 3 on node 9
Reached 3 on node 7
Reached 3 on node 9
Reached 3 on node 7
Reached 5 on node 9
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached end on node 6Reached 2 on node 11

Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7Reached 1.4 on node 8

Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 10
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <121/2280>] - Data(s): 6.828 (6.180) - Batch(s): 10.839 
(10.774) - AE Loss: 1756721.125 (1030179.500) - AE Rec Loss: 11.914 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 7.722 (6.180) - Batch(s): 10.790 
(10.774) - AE Loss: 83829.234 (1030179.500) - AE Rec Loss: 0.569 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.275 (6.180) - Batch(s): 10.913 
(10.774) - AE Loss: 1916272.625 (1030179.500) - AE Rec Loss: 12.996 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.682 (6.180) - Batch(s): 10.778 
(10.774) - AE Loss: 1659030.000 (1030179.500) - AE Rec Loss: 11.251 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 6.980 (6.180) - Batch(s): 11.027 
(10.774) - AE Loss: 1519138.750 (1030179.500) - AE Rec Loss: 10.302 (6.986) - 
Disc Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <121/2280>] - Data(s): 5.643 (6.180) - Batch(s): 10.766 
(10.774) - AE Loss: 86747.570 (1030179.500) - AE Rec Loss: 0.588 (6.986) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.563 
(5.669) - AE Loss: 284842.469 (736020.188) - AE Rec Loss: 1.932 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.569 
(5.669) - AE Loss: 192030.438 (736020.188) - AE Rec Loss: 1.302 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.552 
(5.669) - AE Loss: 222396.406 (736020.188) - AE Rec Loss: 1.508 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.564 
(5.669) - AE Loss: 1448215.625 (736020.188) - AE Rec Loss: 9.821 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.000 (3.090) - Batch(s): 0.564 
(5.669) - AE Loss: 189438.531 (736020.188) - AE Rec Loss: 1.285 (4.991) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <122/2280>] - Data(s): 0.001 (3.090) - Batch(s): 0.564 
(5.669) - AE Loss: 1562577.500 (736020.188) - AE Rec Loss: 10.597 (4.991) - Disc
Loss: 0.000 (0.000) - 3.46 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.661 
(4.999) - AE Loss: 152589.688 (597454.125) - AE Rec Loss: 1.035 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.661 
(4.999) - AE Loss: 253736.000 (597454.125) - AE Rec Loss: 1.721 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.661 
(4.999) - AE Loss: 101578.664 (597454.125) - AE Rec Loss: 0.689 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (2.179) - Batch(s): 3.661 
(4.999) - AE Loss: 427849.625 (597454.125) - AE Rec Loss: 2.902 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.001 (2.179) - Batch(s): 3.662 
(4.999) - AE Loss: 1390441.125 (597454.125) - AE Rec Loss: 9.430 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <123/2280>] - Data(s): 0.000 (2.179) - Batch(s): 3.660 
(4.999) - AE Loss: 76316.305 (597454.125) - AE Rec Loss: 0.518 (4.052) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.564 
(3.890) - AE Loss: 131603.922 (599375.688) - AE Rec Loss: 0.892 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.68 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.564 
(3.890) - AE Loss: 315615.094 (599375.688) - AE Rec Loss: 2.140 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.552 
(3.890) - AE Loss: 186507.000 (599375.688) - AE Rec Loss: 1.265 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.570 
(3.890) - AE Loss: 260476.328 (599375.688) - AE Rec Loss: 1.766 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.76 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.563 
(3.890) - AE Loss: 1558156.500 (599375.688) - AE Rec Loss: 10.567 (4.065) - Disc
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <124/2280>] - Data(s): 0.000 (1.634) - Batch(s): 0.564 
(3.890) - AE Loss: 289737.000 (599375.688) - AE Rec Loss: 1.965 (4.065) - Disc 
Loss: 0.000 (0.000) - 4.71 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.308) - Batch(s): 0.565 
(3.225) - AE Loss: 191959.969 (594076.562) - AE Rec Loss: 1.302 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.573 
(3.225) - AE Loss: 66205.539 (594076.562) - AE Rec Loss: 0.449 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.000 (1.308) - Batch(s): 0.564 
(3.225) - AE Loss: 138495.844 (594076.562) - AE Rec Loss: 0.939 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.563 
(3.225) - AE Loss: 156617.219 (594076.562) - AE Rec Loss: 1.062 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.552 
(3.225) - AE Loss: 111520.719 (594076.562) - AE Rec Loss: 0.756 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <125/2280>] - Data(s): 0.001 (1.308) - Batch(s): 0.564 
(3.225) - AE Loss: 78609.703 (594076.562) - AE Rec Loss: 0.533 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.003 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 162286.578 (605218.250) - AE Rec Loss: 1.101 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.85 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 1512978.500 (605218.250) - AE Rec Loss: 10.261 (4.104) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.481 
(3.268) - AE Loss: 614149.562 (605218.250) - AE Rec Loss: 4.165 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 586711.250 (605218.250) - AE Rec Loss: 3.979 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.480 
(3.268) - AE Loss: 589410.500 (605218.250) - AE Rec Loss: 3.997 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <126/2280>] - Data(s): 0.000 (1.166) - Batch(s): 3.481 
(3.268) - AE Loss: 124756.352 (605218.250) - AE Rec Loss: 0.846 (4.104) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.563 
(2.881) - AE Loss: 232738.344 (618269.562) - AE Rec Loss: 1.578 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.001 (0.999) - Batch(s): 0.565 
(2.881) - AE Loss: 537856.625 (618269.562) - AE Rec Loss: 3.648 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.564 
(2.881) - AE Loss: 223561.234 (618269.562) - AE Rec Loss: 1.516 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.00 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.573 
(2.881) - AE Loss: 1617927.000 (618269.562) - AE Rec Loss: 10.972 (4.193) - Disc
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.565 
(2.881) - AE Loss: 182863.656 (618269.562) - AE Rec Loss: 1.240 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.00 m remaining

[Epoch <000/100>: Step <127/2280>] - Data(s): 0.000 (0.999) - Batch(s): 0.554 
(2.881) - AE Loss: 108054.305 (618269.562) - AE Rec Loss: 0.733 (4.193) - Disc 
Loss: 0.000 (0.000) - 6.05 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.564 
(2.592) - AE Loss: 293405.000 (614864.312) - AE Rec Loss: 1.990 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.566 
(2.592) - AE Loss: 241926.406 (614864.312) - AE Rec Loss: 1.641 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.573 
(2.592) - AE Loss: 1474750.750 (614864.312) - AE Rec Loss: 10.001 (4.170) - Disc
Loss: 0.000 (0.000) - 6.23 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.565 
(2.592) - AE Loss: 530331.562 (614864.312) - AE Rec Loss: 3.597 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.15 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.566 
(2.592) - AE Loss: 115963.602 (614864.312) - AE Rec Loss: 0.786 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.18 m remaining

[Epoch <000/100>: Step <128/2280>] - Data(s): 0.000 (0.874) - Batch(s): 0.554 
(2.592) - AE Loss: 588139.500 (614864.312) - AE Rec Loss: 3.989 (4.170) - Disc 
Loss: 0.000 (0.000) - 6.20 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.815 
(2.728) - AE Loss: 252624.688 (622381.062) - AE Rec Loss: 1.713 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.21 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 1636004.500 (622381.062) - AE Rec Loss: 11.095 (4.221) - Disc
Loss: 0.000 (0.000) - 7.22 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 155667.672 (622381.062) - AE Rec Loss: 1.056 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 276812.969 (622381.062) - AE Rec Loss: 1.877 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 1641054.500 (622381.062) - AE Rec Loss: 11.129 (4.221) - Disc
Loss: 0.000 (0.000) - 7.25 m remaining

[Epoch <000/100>: Step <129/2280>] - Data(s): 0.000 (0.815) - Batch(s): 3.814 
(2.728) - AE Loss: 417069.875 (622381.062) - AE Rec Loss: 2.828 (4.221) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.001 (0.736) - Batch(s): 0.847 
(2.530) - AE Loss: 165307.797 (639872.938) - AE Rec Loss: 1.121 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.42 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.836 
(2.530) - AE Loss: 78097.969 (639872.938) - AE Rec Loss: 0.530 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.47 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.848 
(2.530) - AE Loss: 1622771.250 (639872.938) - AE Rec Loss: 11.005 (4.339) - Disc
Loss: 0.000 (0.000) - 7.41 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.848 
(2.530) - AE Loss: 1768374.125 (639872.938) - AE Rec Loss: 11.993 (4.339) - Disc
Loss: 0.000 (0.000) - 7.44 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.853 
(2.530) - AE Loss: 177319.484 (639872.938) - AE Rec Loss: 1.203 (4.339) - Disc 
Loss: 0.000 (0.000) - 7.49 m remaining

[Epoch <000/100>: Step <130/2280>] - Data(s): 0.000 (0.736) - Batch(s): 0.847 
(2.530) - AE Loss: 1797096.375 (639872.938) - AE Rec Loss: 12.187 (4.339) - Disc
Loss: 0.000 (0.000) - 7.42 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.179 
(2.403) - AE Loss: 128730.539 (634068.125) - AE Rec Loss: 0.873 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.176 
(2.403) - AE Loss: 1495556.375 (634068.125) - AE Rec Loss: 10.142 (4.300) - Disc
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.181 
(2.403) - AE Loss: 181217.438 (634068.125) - AE Rec Loss: 1.229 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.72 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.184 
(2.403) - AE Loss: 118339.516 (634068.125) - AE Rec Loss: 0.803 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.001 (0.669) - Batch(s): 1.168 
(2.403) - AE Loss: 167374.672 (634068.125) - AE Rec Loss: 1.135 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <131/2280>] - Data(s): 0.000 (0.669) - Batch(s): 1.178 
(2.403) - AE Loss: 181614.219 (634068.125) - AE Rec Loss: 1.232 (4.300) - Disc 
Loss: 0.000 (0.000) - 7.72 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.613) - Batch(s): 0.732 
(2.264) - AE Loss: 101255.039 (608760.562) - AE Rec Loss: 0.687 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 162169.047 (608760.562) - AE Rec Loss: 1.100 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.90 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 82366.734 (608760.562) - AE Rec Loss: 0.559 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.95 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 145957.312 (608760.562) - AE Rec Loss: 0.990 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.001 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 531053.125 (608760.562) - AE Rec Loss: 3.601 (4.128) - Disc 
Loss: 0.000 (0.000) - 7.90 m remaining

[Epoch <000/100>: Step <132/2280>] - Data(s): 0.000 (0.613) - Batch(s): 0.734 
(2.264) - AE Loss: 1770444.375 (608760.562) - AE Rec Loss: 12.007 (4.128) - Disc
Loss: 0.000 (0.000) - 7.92 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.001 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 146098.438 (609790.438) - AE Rec Loss: 0.991 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.91 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 3.199 (0.595) - Batch(s): 3.772 
(2.357) - AE Loss: 200726.094 (609790.438) - AE Rec Loss: 1.361 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.90 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 77409.359 (609790.438) - AE Rec Loss: 0.525 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.89 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 1.100 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 1619700.750 (609790.438) - AE Rec Loss: 10.984 (4.135) - Disc
Loss: 0.000 (0.000) - 8.94 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.185 (0.595) - Batch(s): 3.776 
(2.357) - AE Loss: 246095.812 (609790.438) - AE Rec Loss: 1.669 (4.135) - Disc 
Loss: 0.000 (0.000) - 8.96 m remaining

[Epoch <000/100>: Step <133/2280>] - Data(s): 0.000 (0.595) - Batch(s): 3.416 
(2.357) - AE Loss: 2034126.500 (609790.438) - AE Rec Loss: 13.795 (4.135) - Disc
Loss: 0.000 (0.000) - 8.89 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.566 
(2.229) - AE Loss: 305554.312 (635441.875) - AE Rec Loss: 2.072 (4.309) - Disc 
Loss: 0.000 (0.000) - 9.04 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.567 
(2.229) - AE Loss: 113689.516 (635441.875) - AE Rec Loss: 0.771 (4.309) - Disc 
Loss: 0.000 (0.000) - 9.01 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.001 (0.552) - Batch(s): 0.566 
(2.229) - AE Loss: 1893901.500 (635441.875) - AE Rec Loss: 12.844 (4.309) - Disc
Loss: 0.000 (0.000) - 9.02 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.566 
(2.229) - AE Loss: 412455.688 (635441.875) - AE Rec Loss: 2.797 (4.309) - Disc 
Loss: 0.000 (0.000) - 9.02 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.575 
(2.229) - AE Loss: 1509175.500 (635441.875) - AE Rec Loss: 10.235 (4.309) - Disc
Loss: 0.000 (0.000) - 9.08 m remaining

[Epoch <000/100>: Step <134/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.553 
(2.229) - AE Loss: 2884558.000 (635441.875) - AE Rec Loss: 19.562 (4.309) - Disc
Loss: 0.000 (0.000) - 9.06 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 1597635.500 (661692.438) - AE Rec Loss: 10.835 (4.487) - Disc
Loss: 0.000 (0.000) - 10.58 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 452043.656 (661692.438) - AE Rec Loss: 3.066 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.57 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 1365424.750 (661692.438) - AE Rec Loss: 9.260 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.63 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 1323714.250 (661692.438) - AE Rec Loss: 8.977 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.56 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 1.493 (0.555) - Batch(s): 6.006 
(2.481) - AE Loss: 139019.609 (661692.438) - AE Rec Loss: 0.943 (4.487) - Disc 
Loss: 0.000 (0.000) - 10.56 m remaining

[Epoch <000/100>: Step <135/2280>] - Data(s): 0.000 (0.555) - Batch(s): 6.007 
(2.481) - AE Loss: 1679924.250 (661692.438) - AE Rec Loss: 11.393 (4.487) - Disc
Loss: 0.000 (0.000) - 10.61 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.521) - Batch(s): 0.566 
(2.361) - AE Loss: 201333.969 (684229.250) - AE Rec Loss: 1.365 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.69 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.565 
(2.361) - AE Loss: 1656175.375 (684229.250) - AE Rec Loss: 11.232 (4.640) - Disc
Loss: 0.000 (0.000) - 10.68 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.567 
(2.361) - AE Loss: 1370407.625 (684229.250) - AE Rec Loss: 9.294 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.67 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.001 (0.521) - Batch(s): 0.552 
(2.361) - AE Loss: 78278.328 (684229.250) - AE Rec Loss: 0.531 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.72 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.575 
(2.361) - AE Loss: 77448.484 (684229.250) - AE Rec Loss: 0.525 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.74 m remaining

[Epoch <000/100>: Step <136/2280>] - Data(s): 0.000 (0.521) - Batch(s): 0.566 
(2.361) - AE Loss: 100752.203 (684229.250) - AE Rec Loss: 0.683 (4.640) - Disc 
Loss: 0.000 (0.000) - 10.67 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.554 
(2.255) - AE Loss: 96174.930 (665083.438) - AE Rec Loss: 0.652 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.83 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.568 
(2.255) - AE Loss: 1577016.625 (665083.438) - AE Rec Loss: 10.695 (4.510) - Disc
Loss: 0.000 (0.000) - 10.78 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.001 (0.490) - Batch(s): 0.575 
(2.255) - AE Loss: 448824.938 (665083.438) - AE Rec Loss: 3.044 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.85 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.566 
(2.255) - AE Loss: 388051.719 (665083.438) - AE Rec Loss: 2.632 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.78 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.566 
(2.255) - AE Loss: 142067.578 (665083.438) - AE Rec Loss: 0.963 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.79 m remaining

[Epoch <000/100>: Step <137/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.566 
(2.255) - AE Loss: 130229.445 (665083.438) - AE Rec Loss: 0.883 (4.510) - Disc 
Loss: 0.000 (0.000) - 10.80 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.482) - Batch(s): 4.428 
(2.376) - AE Loss: 179618.656 (671393.250) - AE Rec Loss: 1.218 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.90 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.482) - Batch(s): 4.428 
(2.376) - AE Loss: 1364089.750 (671393.250) - AE Rec Loss: 9.251 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.88 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.482) - Batch(s): 4.429 
(2.376) - AE Loss: 155405.609 (671393.250) - AE Rec Loss: 1.054 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.88 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.482) - Batch(s): 4.429 
(2.376) - AE Loss: 166111.188 (671393.250) - AE Rec Loss: 1.127 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.92 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.000 (0.482) - Batch(s): 4.429 
(2.376) - AE Loss: 272307.562 (671393.250) - AE Rec Loss: 1.847 (4.553) - Disc 
Loss: 0.000 (0.000) - 11.94 m remaining

[Epoch <000/100>: Step <138/2280>] - Data(s): 0.334 (0.482) - Batch(s): 4.429 
(2.376) - AE Loss: 1676087.500 (671393.250) - AE Rec Loss: 11.367 (4.553) - Disc
Loss: 0.000 (0.000) - 11.87 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.565 
(2.281) - AE Loss: 75586.875 (656303.375) - AE Rec Loss: 0.513 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.98 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.566 
(2.281) - AE Loss: 118338.414 (656303.375) - AE Rec Loss: 0.803 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.99 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.574 
(2.281) - AE Loss: 67203.648 (656303.375) - AE Rec Loss: 0.456 (4.451) - Disc 
Loss: 0.000 (0.000) - 12.04 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.554 
(2.281) - AE Loss: 192917.188 (656303.375) - AE Rec Loss: 1.308 (4.451) - Disc 
Loss: 0.000 (0.000) - 12.02 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.568 
(2.281) - AE Loss: 75983.164 (656303.375) - AE Rec Loss: 0.515 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.97 m remaining

[Epoch <000/100>: Step <139/2280>] - Data(s): 0.000 (0.456) - Batch(s): 0.566 
(2.281) - AE Loss: 83646.305 (656303.375) - AE Rec Loss: 0.567 (4.451) - Disc 
Loss: 0.000 (0.000) - 11.97 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.564 
(2.195) - AE Loss: 155781.859 (641518.812) - AE Rec Loss: 1.056 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.07 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.001 (0.434) - Batch(s): 0.566 
(2.195) - AE Loss: 202773.688 (641518.812) - AE Rec Loss: 1.375 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.09 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.566 
(2.195) - AE Loss: 167270.422 (641518.812) - AE Rec Loss: 1.134 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.07 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.553 
(2.195) - AE Loss: 1897785.000 (641518.812) - AE Rec Loss: 12.870 (4.351) - Disc
Loss: 0.000 (0.000) - 12.11 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.568 
(2.195) - AE Loss: 86719.078 (641518.812) - AE Rec Loss: 0.588 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.06 m remaining

[Epoch <000/100>: Step <140/2280>] - Data(s): 0.000 (0.434) - Batch(s): 0.575 
(2.195) - AE Loss: 134822.984 (641518.812) - AE Rec Loss: 0.914 (4.351) - Disc 
Loss: 0.000 (0.000) - 12.13 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.001 (0.420) - Batch(s): 18.222 
(2.889) - AE Loss: 638367.500 (647573.188) - AE Rec Loss: 4.329 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.61 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.222 
(2.889) - AE Loss: 1744749.875 (647573.188) - AE Rec Loss: 11.832 (4.392) - Disc
Loss: 0.000 (0.000) - 16.60 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.222 
(2.889) - AE Loss: 1556644.250 (647573.188) - AE Rec Loss: 10.557 (4.392) - Disc
Loss: 0.000 (0.000) - 16.59 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 552625.500 (647573.188) - AE Rec Loss: 3.748 (4.392) - Disc 
Loss: 0.000 (0.000) - 16.65 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.222 
(2.889) - AE Loss: 1787216.750 (647573.188) - AE Rec Loss: 12.120 (4.392) - Disc
Loss: 0.000 (0.000) - 16.63 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 0.000 (0.420) - Batch(s): 18.221 
(2.889) - AE Loss: 1571864.750 (647573.188) - AE Rec Loss: 10.660 (4.392) - Disc
Loss: 0.000 (0.000) - 16.59 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.568 
(2.783) - AE Loss: 264789.750 (649543.438) - AE Rec Loss: 1.796 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.64 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.565 
(2.783) - AE Loss: 1685961.500 (649543.438) - AE Rec Loss: 11.434 (4.405) - Disc
Loss: 0.000 (0.000) - 16.67 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (0.401) - Batch(s): 0.565 
(2.783) - AE Loss: 1627053.750 (649543.438) - AE Rec Loss: 11.034 (4.405) - Disc
Loss: 0.000 (0.000) - 16.65 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.574 
(2.783) - AE Loss: 263759.062 (649543.438) - AE Rec Loss: 1.789 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.71 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.566 
(2.783) - AE Loss: 303333.062 (649543.438) - AE Rec Loss: 2.057 (4.405) - Disc 
Loss: 0.000 (0.000) - 16.65 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (0.401) - Batch(s): 0.553 
(2.783) - AE Loss: 1482376.250 (649543.438) - AE Rec Loss: 10.053 (4.405) - Disc
Loss: 0.000 (0.000) - 16.69 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.568 
(2.687) - AE Loss: 163757.844 (662540.250) - AE Rec Loss: 1.111 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.70 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.574 
(2.687) - AE Loss: 116115.672 (662540.250) - AE Rec Loss: 0.787 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.77 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.567 
(2.687) - AE Loss: 177974.938 (662540.250) - AE Rec Loss: 1.207 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.70 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.554 
(2.687) - AE Loss: 1663986.250 (662540.250) - AE Rec Loss: 11.285 (4.493) - Disc
Loss: 0.000 (0.000) - 16.75 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.566 
(2.687) - AE Loss: 631581.750 (662540.250) - AE Rec Loss: 4.283 (4.493) - Disc 
Loss: 0.000 (0.000) - 16.72 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (0.383) - Batch(s): 0.566 
(2.687) - AE Loss: 1496253.625 (662540.250) - AE Rec Loss: 10.147 (4.493) - Disc
Loss: 0.000 (0.000) - 16.71 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 187184.469 (660221.438) - AE Rec Loss: 1.269 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.78 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 281369.000 (660221.438) - AE Rec Loss: 1.908 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.79 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 1819410.625 (660221.438) - AE Rec Loss: 12.339 (4.477) - Disc
Loss: 0.000 (0.000) - 16.83 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 719296.125 (660221.438) - AE Rec Loss: 4.878 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.85 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 245361.141 (660221.438) - AE Rec Loss: 1.664 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.81 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (0.367) - Batch(s): 0.680 
(2.603) - AE Loss: 244088.219 (660221.438) - AE Rec Loss: 1.655 (4.477) - Disc 
Loss: 0.000 (0.000) - 16.79 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.567 
(2.522) - AE Loss: 495686.375 (650157.000) - AE Rec Loss: 3.362 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.85 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.569 
(2.522) - AE Loss: 169751.797 (650157.000) - AE Rec Loss: 1.151 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.84 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.567 
(2.522) - AE Loss: 325339.938 (650157.000) - AE Rec Loss: 2.206 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.86 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.001 (0.353) - Batch(s): 0.576 
(2.522) - AE Loss: 1583204.750 (650157.000) - AE Rec Loss: 10.737 (4.409) - Disc
Loss: 0.000 (0.000) - 16.91 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.553 
(2.522) - AE Loss: 153664.703 (650157.000) - AE Rec Loss: 1.042 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.89 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (0.353) - Batch(s): 0.568 
(2.522) - AE Loss: 418217.125 (650157.000) - AE Rec Loss: 2.836 (4.409) - Disc 
Loss: 0.000 (0.000) - 16.84 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (0.339) - Batch(s): 0.569 
(2.447) - AE Loss: 310161.719 (666274.125) - AE Rec Loss: 2.103 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.89 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.575 
(2.447) - AE Loss: 108474.219 (666274.125) - AE Rec Loss: 0.736 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.96 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.567 
(2.447) - AE Loss: 1643313.250 (666274.125) - AE Rec Loss: 11.144 (4.518) - Disc
Loss: 0.000 (0.000) - 16.92 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.566 
(2.447) - AE Loss: 270950.188 (666274.125) - AE Rec Loss: 1.837 (4.518) - Disc 
Loss: 0.000 (0.000) - 16.90 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.554 
(2.447) - AE Loss: 1608363.125 (666274.125) - AE Rec Loss: 10.907 (4.518) - Disc
Loss: 0.000 (0.000) - 16.94 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.568 
(2.447) - AE Loss: 1806543.625 (666274.125) - AE Rec Loss: 12.251 (4.518) - Disc
Loss: 0.000 (0.000) - 16.90 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.686 
(2.381) - AE Loss: 429231.062 (659674.688) - AE Rec Loss: 2.911 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.97 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.686 
(2.381) - AE Loss: 73179.727 (659674.688) - AE Rec Loss: 0.496 (4.474) - Disc 
Loss: 0.000 (0.000) - 17.00 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.686 
(2.381) - AE Loss: 122244.133 (659674.688) - AE Rec Loss: 0.829 (4.474) - Disc 
Loss: 0.000 (0.000) - 17.04 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.687 
(2.381) - AE Loss: 78406.172 (659674.688) - AE Rec Loss: 0.532 (4.474) - Disc 
Loss: 0.000 (0.000) - 17.02 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.686 
(2.381) - AE Loss: 1793243.250 (659674.688) - AE Rec Loss: 12.161 (4.474) - Disc
Loss: 0.000 (0.000) - 16.98 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.687 
(2.381) - AE Loss: 195795.375 (659674.688) - AE Rec Loss: 1.328 (4.474) - Disc 
Loss: 0.000 (0.000) - 16.98 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:23:03,563[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,660[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,844[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,847[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:03,920[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:23:04,008[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:23:05,813[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:05,827[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:06,055[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:06,085[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:23:06,227[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,269[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,275[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:23:06,287[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,569[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,601[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,683[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:23:06,720[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:23:06,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:23:06,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:23:06,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 03:23:06,723[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Mixed precision: no
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Running in inference mode: False
[[36m2023-11-29 03:23:06,725[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Mixed precision: no
len(train_dataloader) = 2279
len(valid_dataloader) = 1
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataset) = 4
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 03:23:06,728[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(valid_dataset) = 4
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:24:36,629[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,652[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,652[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,652[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,662[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:24:36,700[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:24:38,872[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,890[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,893[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,898[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:38,912[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:24:39,320[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,469[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,487[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,501[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:24:39,510[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:24:39,511[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:24:39,810[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:24:39,813[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:24:39,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:24:39,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating the optimizer 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
batch_size = 2, learning rate = 4.5e-06
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11Reached 1 on node 9

devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
Error executing job with overrides: ['experiment=vae']
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
Traceback (most recent call last):
    _run_hydra(  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    run_and_report(    
run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    return func()
      File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
        result = tuple(result = tuple(

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
        result = tuple(result = tuple(

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)    
self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<36780>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer fdaa:1:b86:a7b:9076:0:a:2202<58298>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<49586>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<52526>
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        
            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        


            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:26:09,005[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:09,028[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:09,068[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:09,077[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:09,102[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:26:09,110[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:26:11,193[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:11,254[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:11,303[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:11,311[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:11,319[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:26:11,342[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,794[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,845[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:26:11,850[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,907[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:26:11,960[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:26:11,969[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:26:11,969[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:26:11,972[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 03:26:11,974[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
[[36m2023-11-29 03:26:11,976[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataloader) = 1
=> Preparing model 
[[36m2023-11-29 03:26:11,979[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 03:26:11,979[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Preparing opt_disc 
=> Running in inference mode: False
=> Instantiating train dataloader 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Instantiating the optimizer 
=> Preparing model 
len(train_dataset) = 54706
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 6
Reached 1.4 on node 6
=> Preparing criterion 
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8Reached 3 on node 6

Reached 5 on node 6
Reached end on node 6
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 11
Reached 5 on node 11
=> Preparing criterion 
Reached end on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6Reached 1.3 on node 9

Reached 1.4 on node 9Reached 1.4 on node 6

Reached 2 on node 6Reached 2 on node 9

Reached 3 on node 9Reached 3 on node 6

Reached 5 on node 6Reached 5 on node 9

Reached end on node 9Reached end on node 6

Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 1.3 on node 10
Reached 5 on node 7Reached 1.4 on node 10Reached 1.3 on node 11


Reached 1.4 on node 11
Reached 2 on node 10Reached end on node 7

Reached 2 on node 11
Reached 3 on node 10
Reached 3 on node 11
Reached 5 on node 10Reached 1.3 on node 8
Reached 5 on node 11

Reached 1.4 on node 8Reached end on node 10

Reached end on node 11
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 6Reached 2 on node 7

Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8Reached 1 on node 11Reached 1 on node 9


Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9Reached 1 on node 7
Reached 1.4 on node 11
Reached 1 on node 6

Reached 2 on node 11
Reached 1.4 on node 7
Reached 1.4 on node 6Reached 2 on node 7

Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8
Reached 3 on node 7
Reached 2 on node 8
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 1.4 on node 10
Reached 2 on node 8Reached 2 on node 10

Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9Reached 1.4 on node 11

Reached 2 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached end on node 6Reached 1.4 on node 10

Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 8Reached 1 on node 11

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 8
Reached 3 on node 11
Reached 2 on node 8Reached 3 on node 11

Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 8Reached 3 on node 11

Reached 3 on node 8Reached 5 on node 11

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 7
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7Reached 1 on node 9

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7Reached 2 on node 9

Reached 1 on node 7Reached 1 on node 9

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7Reached 2 on node 9

Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 11
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <141/2280>] - Data(s): 9.531 (5.639) - Batch(s): 11.034 
(11.231) - AE Loss: 1745222.500 (768796.000) - AE Rec Loss: 11.836 (5.214) - 
Disc Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 6.999 (5.639) - Batch(s): 11.055 
(11.231) - AE Loss: 1557080.750 (768796.000) - AE Rec Loss: 10.560 (5.214) - 
Disc Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 6.353 (5.639) - Batch(s): 11.069 
(11.231) - AE Loss: 638936.125 (768796.000) - AE Rec Loss: 4.333 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.317 (5.639) - Batch(s): 11.059 
(11.231) - AE Loss: 553087.375 (768796.000) - AE Rec Loss: 3.751 (5.214) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 6.132 (5.639) - Batch(s): 11.047 
(11.231) - AE Loss: 1786840.625 (768796.000) - AE Rec Loss: 12.118 (5.214) - 
Disc Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 9.025 (5.639) - Batch(s): 11.058 
(11.231) - AE Loss: 1571840.625 (768796.000) - AE Rec Loss: 10.660 (5.214) - 
Disc Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.563 
(5.897) - AE Loss: 288208.812 (725867.312) - AE Rec Loss: 1.955 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.564 
(5.897) - AE Loss: 1680853.750 (725867.312) - AE Rec Loss: 11.399 (4.923) - Disc
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.552 
(5.897) - AE Loss: 1476961.250 (725867.312) - AE Rec Loss: 10.016 (4.923) - Disc
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.820) - Batch(s): 0.566 
(5.897) - AE Loss: 252997.094 (725867.312) - AE Rec Loss: 1.716 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.561 
(5.897) - AE Loss: 1626154.750 (725867.312) - AE Rec Loss: 11.028 (4.923) - Disc
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.820) - Batch(s): 0.571 
(5.897) - AE Loss: 259812.625 (725867.312) - AE Rec Loss: 1.762 (4.923) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <143/2280>] - Data(s): 0.309 (1.904) - Batch(s): 0.956 
(4.250) - AE Loss: 1498968.125 (797648.438) - AE Rec Loss: 10.166 (5.409) - Disc
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.272 (1.904) - Batch(s): 0.958 
(4.250) - AE Loss: 163250.844 (797648.438) - AE Rec Loss: 1.107 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.212 (1.904) - Batch(s): 0.956 
(4.250) - AE Loss: 1656351.500 (797648.438) - AE Rec Loss: 11.233 (5.409) - Disc
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.904) - Batch(s): 0.955 
(4.250) - AE Loss: 148104.562 (797648.438) - AE Rec Loss: 1.004 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.904) - Batch(s): 0.958 
(4.250) - AE Loss: 617176.250 (797648.438) - AE Rec Loss: 4.185 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.001 (1.904) - Batch(s): 0.957 
(4.250) - AE Loss: 106038.398 (797648.438) - AE Rec Loss: 0.719 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.563 
(3.328) - AE Loss: 241729.375 (749024.438) - AE Rec Loss: 1.639 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.40 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.564 
(3.328) - AE Loss: 176630.516 (749024.438) - AE Rec Loss: 1.198 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (1.428) - Batch(s): 0.572 
(3.328) - AE Loss: 711901.875 (749024.438) - AE Rec Loss: 4.828 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.001 (1.428) - Batch(s): 0.564 
(3.328) - AE Loss: 236681.000 (749024.438) - AE Rec Loss: 1.605 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.563 
(3.328) - AE Loss: 273990.062 (749024.438) - AE Rec Loss: 1.858 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.428) - Batch(s): 0.552 
(3.328) - AE Loss: 1820812.000 (749024.438) - AE Rec Loss: 12.348 (5.080) - Disc
Loss: 0.000 (0.000) - 3.41 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.004 (1.192) - Batch(s): 3.549 
(3.349) - AE Loss: 483951.156 (679969.562) - AE Rec Loss: 3.282 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.556 
(3.349) - AE Loss: 1589256.750 (679969.562) - AE Rec Loss: 10.778 (4.611) - Disc
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.539 
(3.349) - AE Loss: 148919.344 (679969.562) - AE Rec Loss: 1.010 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.001 (1.192) - Batch(s): 3.550 
(3.349) - AE Loss: 166460.156 (679969.562) - AE Rec Loss: 1.129 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.551 
(3.349) - AE Loss: 321279.719 (679969.562) - AE Rec Loss: 2.179 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.192) - Batch(s): 3.549 
(3.349) - AE Loss: 410001.188 (679969.562) - AE Rec Loss: 2.780 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.29 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.645 (1.009) - Batch(s): 1.295 
(3.007) - AE Loss: 308961.344 (744299.438) - AE Rec Loss: 2.095 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (1.009) - Batch(s): 1.295 
(3.007) - AE Loss: 105749.477 (744299.438) - AE Rec Loss: 0.717 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.497 (1.009) - Batch(s): 1.298 
(3.007) - AE Loss: 267847.406 (744299.438) - AE Rec Loss: 1.816 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (1.009) - Batch(s): 1.295 
(3.007) - AE Loss: 1644079.250 (744299.438) - AE Rec Loss: 11.150 (5.048) - Disc
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.297 
(3.007) - AE Loss: 1613189.250 (744299.438) - AE Rec Loss: 10.940 (5.048) - Disc
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (1.009) - Batch(s): 1.297 
(3.007) - AE Loss: 1807074.000 (744299.438) - AE Rec Loss: 12.255 (5.048) - Disc
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 192170.547 (707155.875) - AE Rec Loss: 1.303 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 72567.320 (707155.875) - AE Rec Loss: 0.492 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 68768.734 (707155.875) - AE Rec Loss: 0.466 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 425576.875 (707155.875) - AE Rec Loss: 2.886 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.878) - Batch(s): 1.292 
(2.766) - AE Loss: 1795072.875 (707155.875) - AE Rec Loss: 12.174 (4.796) - Disc
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 1.084 (0.878) - Batch(s): 1.654 
(2.766) - AE Loss: 124783.570 (707155.875) - AE Rec Loss: 0.846 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.563 
(2.491) - AE Loss: 248016.797 (679896.938) - AE Rec Loss: 1.682 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.572 
(2.491) - AE Loss: 3391430.500 (679896.938) - AE Rec Loss: 23.000 (4.611) - Disc
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.564 
(2.491) - AE Loss: 228662.844 (679896.938) - AE Rec Loss: 1.551 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.552 
(2.491) - AE Loss: 63885.449 (679896.938) - AE Rec Loss: 0.433 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.563 
(2.491) - AE Loss: 128250.195 (679896.938) - AE Rec Loss: 0.870 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.564 
(2.491) - AE Loss: 325350.094 (679896.938) - AE Rec Loss: 2.206 (4.611) - Disc 
Loss: 0.000 (0.000) - 5.15 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 3.197 (0.842) - Batch(s): 8.575 
(3.167) - AE Loss: 76847.781 (656988.000) - AE Rec Loss: 0.521 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 1.804 (0.842) - Batch(s): 8.576 
(3.167) - AE Loss: 215500.000 (656988.000) - AE Rec Loss: 1.461 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.577 
(3.167) - AE Loss: 303198.938 (656988.000) - AE Rec Loss: 2.056 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 7.936 (0.842) - Batch(s): 8.575 
(3.167) - AE Loss: 74719.656 (656988.000) - AE Rec Loss: 0.507 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 4.265 (0.842) - Batch(s): 8.577 
(3.167) - AE Loss: 1790195.250 (656988.000) - AE Rec Loss: 12.141 (4.455) - Disc
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.842) - Batch(s): 8.575 
(3.167) - AE Loss: 1529789.125 (656988.000) - AE Rec Loss: 10.375 (4.455) - Disc
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.563 
(2.907) - AE Loss: 423960.312 (685899.125) - AE Rec Loss: 2.875 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.573 
(2.907) - AE Loss: 2854214.500 (685899.125) - AE Rec Loss: 19.356 (4.652) - Disc
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.552 
(2.907) - AE Loss: 2787751.500 (685899.125) - AE Rec Loss: 18.906 (4.652) - Disc
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.565 
(2.907) - AE Loss: 351482.938 (685899.125) - AE Rec Loss: 2.384 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.564 
(2.907) - AE Loss: 209931.750 (685899.125) - AE Rec Loss: 1.424 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.758) - Batch(s): 0.564 
(2.907) - AE Loss: 223984.031 (685899.125) - AE Rec Loss: 1.519 (4.652) - Disc 
Loss: 0.000 (0.000) - 7.30 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.256 
(2.751) - AE Loss: 289417.406 (687129.375) - AE Rec Loss: 1.963 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.262 
(2.751) - AE Loss: 1681252.875 (687129.375) - AE Rec Loss: 11.402 (4.660) - Disc
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.258 
(2.751) - AE Loss: 1474814.500 (687129.375) - AE Rec Loss: 10.002 (4.660) - Disc
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.258 
(2.751) - AE Loss: 232413.000 (687129.375) - AE Rec Loss: 1.576 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.689) - Batch(s): 1.257 
(2.751) - AE Loss: 125522.516 (687129.375) - AE Rec Loss: 0.851 (4.660) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.689) - Batch(s): 1.246 
(2.751) - AE Loss: 1543242.250 (687129.375) - AE Rec Loss: 10.466 (4.660) - Disc
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.716 
(2.665) - AE Loss: 1834700.000 (666986.688) - AE Rec Loss: 12.442 (4.523) - Disc
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.717 
(2.665) - AE Loss: 154356.688 (666986.688) - AE Rec Loss: 1.047 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.715 
(2.665) - AE Loss: 473243.281 (666986.688) - AE Rec Loss: 3.209 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.716 
(2.665) - AE Loss: 416074.750 (666986.688) - AE Rec Loss: 2.822 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.639) - Batch(s): 1.716 
(2.665) - AE Loss: 158496.203 (666986.688) - AE Rec Loss: 1.075 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 1.058 (0.639) - Batch(s): 1.717 
(2.665) - AE Loss: 174329.000 (666986.688) - AE Rec Loss: 1.182 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.573 
(2.504) - AE Loss: 209269.078 (638132.938) - AE Rec Loss: 1.419 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.564 
(2.504) - AE Loss: 382670.438 (638132.938) - AE Rec Loss: 2.595 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.07 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.567 
(2.504) - AE Loss: 270324.969 (638132.938) - AE Rec Loss: 1.833 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.566 
(2.504) - AE Loss: 301637.438 (638132.938) - AE Rec Loss: 2.046 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.554 
(2.504) - AE Loss: 332904.844 (638132.938) - AE Rec Loss: 2.258 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.590) - Batch(s): 0.566 
(2.504) - AE Loss: 280122.938 (638132.938) - AE Rec Loss: 1.900 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.565 
(2.365) - AE Loss: 120036.805 (641162.188) - AE Rec Loss: 0.814 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.574 
(2.365) - AE Loss: 1621344.000 (641162.188) - AE Rec Loss: 10.995 (4.348) - Disc
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.566 
(2.365) - AE Loss: 269337.938 (641162.188) - AE Rec Loss: 1.827 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.566 
(2.365) - AE Loss: 227370.375 (641162.188) - AE Rec Loss: 1.542 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.568 
(2.365) - AE Loss: 1714948.250 (641162.188) - AE Rec Loss: 11.630 (4.348) - Disc
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.548) - Batch(s): 0.555 
(2.365) - AE Loss: 147265.688 (641162.188) - AE Rec Loss: 0.999 (4.348) - Disc 
Loss: 0.000 (0.000) - 8.19 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 2.318 (0.569) - Batch(s): 4.112 
(2.482) - AE Loss: 113129.883 (640587.750) - AE Rec Loss: 0.767 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.09 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 1.796 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 755155.000 (640587.750) - AE Rec Loss: 5.121 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.569) - Batch(s): 4.112 
(2.482) - AE Loss: 324043.094 (640587.750) - AE Rec Loss: 2.198 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 3.433 (0.569) - Batch(s): 4.111 
(2.482) - AE Loss: 372703.750 (640587.750) - AE Rec Loss: 2.528 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 1.341 (0.569) - Batch(s): 4.112 
(2.482) - AE Loss: 267901.562 (640587.750) - AE Rec Loss: 1.817 (4.344) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 1.476 (0.569) - Batch(s): 4.112 
(2.482) - AE Loss: 1624815.500 (640587.750) - AE Rec Loss: 11.019 (4.344) - Disc
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 1723242.875 (656661.625) - AE Rec Loss: 11.686 (4.453) - Disc
Loss: 0.000 (0.000) - 10.55 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 4.971 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 1449116.500 (656661.625) - AE Rec Loss: 9.827 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.54 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 808930.688 (656661.625) - AE Rec Loss: 5.486 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.55 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 3.513 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 132041.844 (656661.625) - AE Rec Loss: 0.895 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.55 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 5.954 (0.609) - Batch(s): 6.533 
(2.714) - AE Loss: 129512.625 (656661.625) - AE Rec Loss: 0.878 (4.453) - Disc 
Loss: 0.000 (0.000) - 10.55 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.609) - Batch(s): 6.169 
(2.714) - AE Loss: 1718408.875 (656661.625) - AE Rec Loss: 11.654 (4.453) - Disc
Loss: 0.000 (0.000) - 10.55 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 282495.250 (641788.875) - AE Rec Loss: 1.916 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.36 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 3.256 (0.598) - Batch(s): 3.835 
(2.760) - AE Loss: 182133.406 (641788.875) - AE Rec Loss: 1.235 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.37 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 245712.906 (641788.875) - AE Rec Loss: 1.666 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.37 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 1.908 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 171631.844 (641788.875) - AE Rec Loss: 1.164 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.37 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 1549362.000 (641788.875) - AE Rec Loss: 10.507 (4.352) - Disc
Loss: 0.000 (0.000) - 11.37 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.598) - Batch(s): 3.472 
(2.760) - AE Loss: 104084.062 (641788.875) - AE Rec Loss: 0.706 (4.352) - Disc 
Loss: 0.000 (0.000) - 11.37 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.427 
(2.964) - AE Loss: 134455.922 (634833.750) - AE Rec Loss: 0.912 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.76 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.427 
(2.964) - AE Loss: 363889.938 (634833.750) - AE Rec Loss: 2.468 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.75 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 2.474 (0.611) - Batch(s): 6.427 
(2.964) - AE Loss: 1461352.000 (634833.750) - AE Rec Loss: 9.910 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.76 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 5.783 (0.611) - Batch(s): 6.428 
(2.964) - AE Loss: 454718.625 (634833.750) - AE Rec Loss: 3.084 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.76 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.611) - Batch(s): 6.428 
(2.964) - AE Loss: 305649.219 (634833.750) - AE Rec Loss: 2.073 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.76 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 1.704 (0.611) - Batch(s): 6.429 
(2.964) - AE Loss: 820272.562 (634833.750) - AE Rec Loss: 5.563 (4.305) - Disc 
Loss: 0.000 (0.000) - 12.76 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.566 
(2.839) - AE Loss: 102151.891 (628641.625) - AE Rec Loss: 0.693 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.86 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.172 (0.580) - Batch(s): 0.746 
(2.839) - AE Loss: 1621702.000 (628641.625) - AE Rec Loss: 10.998 (4.263) - Disc
Loss: 0.000 (0.000) - 12.87 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.567 
(2.839) - AE Loss: 227919.922 (628641.625) - AE Rec Loss: 1.546 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.87 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.555 
(2.839) - AE Loss: 1413643.000 (628641.625) - AE Rec Loss: 9.587 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.87 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.566 
(2.839) - AE Loss: 336339.750 (628641.625) - AE Rec Loss: 2.281 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.87 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.580) - Batch(s): 0.567 
(2.839) - AE Loss: 109237.945 (628641.625) - AE Rec Loss: 0.741 (4.263) - Disc 
Loss: 0.000 (0.000) - 12.87 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 248394.359 (622898.375) - AE Rec Loss: 1.685 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.16 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 1624335.125 (622898.375) - AE Rec Loss: 11.016 (4.224) - Disc
Loss: 0.000 (0.000) - 13.16 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 149635.109 (622898.375) - AE Rec Loss: 1.015 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.16 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 191515.922 (622898.375) - AE Rec Loss: 1.299 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.16 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.555) - Batch(s): 1.203 
(2.758) - AE Loss: 251362.047 (622898.375) - AE Rec Loss: 1.705 (4.224) - Disc 
Loss: 0.000 (0.000) - 13.16 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.994 (0.555) - Batch(s): 1.567 
(2.758) - AE Loss: 1708698.750 (622898.375) - AE Rec Loss: 11.588 (4.224) - Disc
Loss: 0.000 (0.000) - 13.16 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:29:14,406[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:14,426[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:14,426[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:14,426[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:14,435[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:29:14,638[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:29:16,652[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:16,670[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:16,671[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:16,697[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:16,712[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:29:16,861[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:17,181[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:17,227[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:29:17,312[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:29:17,323[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:17,356[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:29:17,442[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:29:17,445[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 03:29:17,447[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:29:17,447[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 03:29:17,448[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:29:17,448[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
[[36m2023-11-29 03:29:17,450[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached 3 on node 6Reached end on node 8

Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1.3 on node 8
Reached 5 on node 6
Reached 1.4 on node 8
Reached end on node 6
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10Reached 3 on node 11

Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10Reached 1.3 on node 9

Reached 1.4 on node 9
Reached 1.3 on node 7Reached 2 on node 10

Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 10
Reached 3 on node 9
Reached 5 on node 10
Reached 5 on node 9
Reached 3 on node 7
Reached end on node 10
Reached end on node 9
Reached 5 on node 7
Reached end on node 7Reached 1.3 on node 8

Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.3 on node 11Reached 1.3 on node 6

Reached 1.4 on node 11Reached 1.4 on node 6
Reached 3 on node 8

Reached 2 on node 11Reached 5 on node 8
Reached 2 on node 6

Reached end on node 8
Reached 3 on node 11Reached 3 on node 6

Reached 5 on node 11Reached 5 on node 6

Reached end on node 11
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
Loaded checkpoint at epoch 0 and step 141
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 8
Reached 1.4 on node 7
Reached 2 on node 8
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10Reached 1 on node 6

Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 9Reached 3 on node 6

Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 9
Reached 1 on node 11Reached 2 on node 9

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7Reached 1 on node 8

Reached 1.4 on node 8
Reached 1.4 on node 7
Reached 2 on node 8Reached 2 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 10Reached 3 on node 7

Reached 5 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11Reached 3 on node 9

Reached 2 on node 11Reached 3 on node 9

Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached end on node 6
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7Reached 1 on node 9

Reached 1.4 on node 7
Reached 1.4 on node 9Reached 2 on node 7

Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 1.4 on node 9Reached 2 on node 7

Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 11
Reached end on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <141/2280>] - Data(s): 6.577 (5.420) - Batch(s): 9.516 
(9.671) - AE Loss: 1557068.500 (768541.250) - AE Rec Loss: 10.560 (5.212) - Disc
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 8.562 (5.420) - Batch(s): 10.033 
(9.671) - AE Loss: 1744647.500 (768541.250) - AE Rec Loss: 11.832 (5.212) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 7.229 (5.420) - Batch(s): 9.523 
(9.671) - AE Loss: 636759.125 (768541.250) - AE Rec Loss: 4.318 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 3.733 (5.420) - Batch(s): 9.488 
(9.671) - AE Loss: 552314.188 (768541.250) - AE Rec Loss: 3.746 (5.212) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 6.001 (5.420) - Batch(s): 10.028 
(9.671) - AE Loss: 1786899.750 (768541.250) - AE Rec Loss: 12.118 (5.212) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <141/2280>] - Data(s): 6.521 (5.420) - Batch(s): 9.487 
(9.671) - AE Loss: 1572167.000 (768541.250) - AE Rec Loss: 10.662 (5.212) - Disc
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.710) - Batch(s): 1.199 
(5.406) - AE Loss: 258925.438 (725758.812) - AE Rec Loss: 1.756 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.197 
(5.406) - AE Loss: 253229.984 (725758.812) - AE Rec Loss: 1.717 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.710) - Batch(s): 1.193 
(5.406) - AE Loss: 288631.594 (725758.812) - AE Rec Loss: 1.957 (4.922) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.710) - Batch(s): 1.191 
(5.406) - AE Loss: 1626575.250 (725758.812) - AE Rec Loss: 11.031 (4.922) - Disc
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.001 (2.710) - Batch(s): 1.182 
(5.406) - AE Loss: 1476763.250 (725758.812) - AE Rec Loss: 10.015 (4.922) - Disc
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <142/2280>] - Data(s): 0.000 (2.710) - Batch(s): 1.194 
(5.406) - AE Loss: 1680743.500 (725758.812) - AE Rec Loss: 11.398 (4.922) - Disc
Loss: 0.000 (0.000) - 2.78 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <143/2280>] - Data(s): 2.256 (1.912) - Batch(s): 2.919 
(4.560) - AE Loss: 1656133.250 (797599.125) - AE Rec Loss: 11.231 (5.409) - Disc
Loss: 0.000 (0.000) - 3.65 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.355 (1.912) - Batch(s): 2.923 
(4.560) - AE Loss: 1499653.625 (797599.125) - AE Rec Loss: 10.170 (5.409) - Disc
Loss: 0.000 (0.000) - 3.66 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.922 
(4.560) - AE Loss: 148713.188 (797599.125) - AE Rec Loss: 1.009 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.920 
(4.560) - AE Loss: 162845.859 (797599.125) - AE Rec Loss: 1.104 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.923 
(4.560) - AE Loss: 105738.961 (797599.125) - AE Rec Loss: 0.717 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <143/2280>] - Data(s): 0.000 (1.912) - Batch(s): 2.923 
(4.560) - AE Loss: 617162.438 (797599.125) - AE Rec Loss: 4.185 (5.409) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.089 
(3.684) - AE Loss: 1821583.750 (749023.312) - AE Rec Loss: 12.353 (5.080) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.102 
(3.684) - AE Loss: 177493.188 (749023.312) - AE Rec Loss: 1.204 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.098 
(3.684) - AE Loss: 241531.500 (749023.312) - AE Rec Loss: 1.638 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.102 
(3.684) - AE Loss: 237057.000 (749023.312) - AE Rec Loss: 1.608 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.107 
(3.684) - AE Loss: 711233.875 (749023.312) - AE Rec Loss: 4.823 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <144/2280>] - Data(s): 0.000 (1.434) - Batch(s): 1.100 
(3.684) - AE Loss: 275587.625 (749023.312) - AE Rec Loss: 1.869 (5.080) - Disc 
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.323 
(3.198) - AE Loss: 166309.766 (679972.188) - AE Rec Loss: 1.128 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.326 
(3.198) - AE Loss: 1590025.500 (679972.188) - AE Rec Loss: 10.783 (4.611) - Disc
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.310 
(3.198) - AE Loss: 147998.500 (679972.188) - AE Rec Loss: 1.004 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.27 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.323 
(3.198) - AE Loss: 321341.250 (679972.188) - AE Rec Loss: 2.179 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.001 (1.151) - Batch(s): 1.319 
(3.198) - AE Loss: 484235.562 (679972.188) - AE Rec Loss: 3.284 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.27 m remaining

[Epoch <000/100>: Step <145/2280>] - Data(s): 0.000 (1.151) - Batch(s): 1.320 
(3.198) - AE Loss: 410062.688 (679972.188) - AE Rec Loss: 2.781 (4.611) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.138 (0.983) - Batch(s): 2.243 
(3.029) - AE Loss: 268191.406 (744320.875) - AE Rec Loss: 1.819 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.243 
(3.029) - AE Loss: 104874.477 (744320.875) - AE Rec Loss: 0.711 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.241 
(3.029) - AE Loss: 1644411.750 (744320.875) - AE Rec Loss: 11.152 (5.048) - Disc
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.000 (0.983) - Batch(s): 2.244 
(3.029) - AE Loss: 309307.438 (744320.875) - AE Rec Loss: 2.098 (5.048) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 1.567 (0.983) - Batch(s): 2.243 
(3.029) - AE Loss: 1612614.000 (744320.875) - AE Rec Loss: 10.936 (5.048) - Disc
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <146/2280>] - Data(s): 0.001 (0.983) - Batch(s): 2.243 
(3.029) - AE Loss: 1807192.125 (744320.875) - AE Rec Loss: 12.256 (5.048) - Disc
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.001 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 72526.031 (707127.438) - AE Rec Loss: 0.492 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 1.706 (0.863) - Batch(s): 2.285 
(2.868) - AE Loss: 125136.391 (707127.438) - AE Rec Loss: 0.849 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 425469.375 (707127.438) - AE Rec Loss: 2.885 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 68695.828 (707127.438) - AE Rec Loss: 0.466 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 191349.922 (707127.438) - AE Rec Loss: 1.298 (4.796) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <147/2280>] - Data(s): 0.000 (0.863) - Batch(s): 1.922 
(2.868) - AE Loss: 1793938.500 (707127.438) - AE Rec Loss: 12.166 (4.796) - Disc
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.129 
(2.645) - AE Loss: 246919.500 (679810.812) - AE Rec Loss: 1.675 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.133 
(2.645) - AE Loss: 228657.266 (679810.812) - AE Rec Loss: 1.551 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.119 
(2.645) - AE Loss: 62940.348 (679810.812) - AE Rec Loss: 0.427 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.132 
(2.645) - AE Loss: 325550.375 (679810.812) - AE Rec Loss: 2.208 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.129 
(2.645) - AE Loss: 127736.242 (679810.812) - AE Rec Loss: 0.866 (4.610) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <148/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.135 
(2.645) - AE Loss: 3391310.000 (679810.812) - AE Rec Loss: 22.999 (4.610) - Disc
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 1790496.250 (656885.562) - AE Rec Loss: 12.143 (4.455) - Disc
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 215130.656 (656885.562) - AE Rec Loss: 1.459 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 2.151 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 75514.078 (656885.562) - AE Rec Loss: 0.512 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 303080.062 (656885.562) - AE Rec Loss: 2.055 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 5.877 (0.745) - Batch(s): 6.531 
(3.070) - AE Loss: 73366.250 (656885.562) - AE Rec Loss: 0.498 (4.455) - Disc 
Loss: 0.000 (0.000) - 7.18 m remaining

[Epoch <000/100>: Step <149/2280>] - Data(s): 0.000 (0.745) - Batch(s): 6.532 
(3.070) - AE Loss: 1530175.750 (656885.562) - AE Rec Loss: 10.377 (4.455) - Disc
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.049 
(2.864) - AE Loss: 423785.000 (685805.438) - AE Rec Loss: 2.874 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.42 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.051 
(2.864) - AE Loss: 209330.375 (685805.438) - AE Rec Loss: 1.420 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.051 
(2.864) - AE Loss: 222925.484 (685805.438) - AE Rec Loss: 1.512 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.040 
(2.864) - AE Loss: 2787795.500 (685805.438) - AE Rec Loss: 18.906 (4.651) - Disc
Loss: 0.000 (0.000) - 7.42 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.052 
(2.864) - AE Loss: 351782.625 (685805.438) - AE Rec Loss: 2.386 (4.651) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <150/2280>] - Data(s): 0.000 (0.671) - Batch(s): 1.055 
(2.864) - AE Loss: 2854078.000 (685805.438) - AE Rec Loss: 19.355 (4.651) - Disc
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.134 
(2.703) - AE Loss: 291171.812 (687031.062) - AE Rec Loss: 1.975 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.135 
(2.703) - AE Loss: 125178.820 (687031.062) - AE Rec Loss: 0.849 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.124 
(2.703) - AE Loss: 1543900.250 (687031.062) - AE Rec Loss: 10.470 (4.659) - Disc
Loss: 0.000 (0.000) - 7.67 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.136 
(2.703) - AE Loss: 232382.719 (687031.062) - AE Rec Loss: 1.576 (4.659) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.001 (0.610) - Batch(s): 1.136 
(2.703) - AE Loss: 1474496.500 (687031.062) - AE Rec Loss: 10.000 (4.659) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <151/2280>] - Data(s): 0.000 (0.610) - Batch(s): 1.139 
(2.703) - AE Loss: 1681208.000 (687031.062) - AE Rec Loss: 11.401 (4.659) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.195 
(2.574) - AE Loss: 173969.094 (666926.438) - AE Rec Loss: 1.180 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.93 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.195 
(2.574) - AE Loss: 154708.188 (666926.438) - AE Rec Loss: 1.049 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.81 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.196 
(2.574) - AE Loss: 417397.375 (666926.438) - AE Rec Loss: 2.831 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.93 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.196 
(2.574) - AE Loss: 158515.203 (666926.438) - AE Rec Loss: 1.075 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.197 
(2.574) - AE Loss: 473499.188 (666926.438) - AE Rec Loss: 3.211 (4.523) - Disc 
Loss: 0.000 (0.000) - 7.81 m remaining

[Epoch <000/100>: Step <152/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.196 
(2.574) - AE Loss: 1835325.875 (666926.438) - AE Rec Loss: 12.447 (4.523) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.147 
(2.461) - AE Loss: 330373.250 (638127.875) - AE Rec Loss: 2.240 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.159 
(2.461) - AE Loss: 278937.969 (638127.875) - AE Rec Loss: 1.892 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.06 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.162 
(2.461) - AE Loss: 211265.672 (638127.875) - AE Rec Loss: 1.433 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.158 
(2.461) - AE Loss: 272035.344 (638127.875) - AE Rec Loss: 1.845 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.158 
(2.461) - AE Loss: 300972.031 (638127.875) - AE Rec Loss: 2.041 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <153/2280>] - Data(s): 0.000 (0.516) - Batch(s): 1.156 
(2.461) - AE Loss: 382889.438 (638127.875) - AE Rec Loss: 2.597 (4.328) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.240 
(2.370) - AE Loss: 149750.562 (641277.812) - AE Rec Loss: 1.016 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.44 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.256 
(2.370) - AE Loss: 1623434.250 (641277.812) - AE Rec Loss: 11.010 (4.349) - Disc
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.251 
(2.370) - AE Loss: 228556.984 (641277.812) - AE Rec Loss: 1.550 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.253 
(2.370) - AE Loss: 1716117.750 (641277.812) - AE Rec Loss: 11.638 (4.349) - Disc
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.252 
(2.370) - AE Loss: 270711.125 (641277.812) - AE Rec Loss: 1.836 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <154/2280>] - Data(s): 0.000 (0.479) - Batch(s): 1.249 
(2.370) - AE Loss: 124043.078 (641277.812) - AE Rec Loss: 0.841 (4.349) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.400 
(2.302) - AE Loss: 756401.500 (640812.375) - AE Rec Loss: 5.130 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.62 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.400 
(2.302) - AE Loss: 375497.156 (640812.375) - AE Rec Loss: 2.547 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.74 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.400 
(2.302) - AE Loss: 325791.469 (640812.375) - AE Rec Loss: 2.209 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.62 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.401 
(2.302) - AE Loss: 115297.797 (640812.375) - AE Rec Loss: 0.782 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.74 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.401 
(2.302) - AE Loss: 1625332.875 (640812.375) - AE Rec Loss: 11.022 (4.346) - Disc
Loss: 0.000 (0.000) - 8.62 m remaining

[Epoch <000/100>: Step <155/2280>] - Data(s): 0.000 (0.447) - Batch(s): 1.401 
(2.302) - AE Loss: 269337.000 (640812.375) - AE Rec Loss: 1.827 (4.346) - Disc 
Loss: 0.000 (0.000) - 8.62 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.248 
(2.233) - AE Loss: 811088.250 (656901.500) - AE Rec Loss: 5.501 (4.455) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.263 
(2.233) - AE Loss: 130099.516 (656901.500) - AE Rec Loss: 0.882 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.88 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.258 
(2.233) - AE Loss: 1450406.000 (656901.500) - AE Rec Loss: 9.836 (4.455) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.259 
(2.233) - AE Loss: 132944.875 (656901.500) - AE Rec Loss: 0.902 (4.455) - Disc 
Loss: 0.000 (0.000) - 8.88 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.001 (0.419) - Batch(s): 1.258 
(2.233) - AE Loss: 1718796.000 (656901.500) - AE Rec Loss: 11.656 (4.455) - Disc
Loss: 0.000 (0.000) - 8.88 m remaining

[Epoch <000/100>: Step <156/2280>] - Data(s): 0.000 (0.419) - Batch(s): 1.259 
(2.233) - AE Loss: 1715454.500 (656901.500) - AE Rec Loss: 11.634 (4.455) - Disc
Loss: 0.000 (0.000) - 8.88 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.323 
(2.177) - AE Loss: 173365.922 (642163.500) - AE Rec Loss: 1.176 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.31 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.919 (0.399) - Batch(s): 1.490 
(2.177) - AE Loss: 184635.359 (642163.500) - AE Rec Loss: 1.252 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.19 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.334 
(2.177) - AE Loss: 248430.719 (642163.500) - AE Rec Loss: 1.685 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.19 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.333 
(2.177) - AE Loss: 284423.500 (642163.500) - AE Rec Loss: 1.929 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.31 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.334 
(2.177) - AE Loss: 108407.930 (642163.500) - AE Rec Loss: 0.735 (4.355) - Disc 
Loss: 0.000 (0.000) - 9.19 m remaining

[Epoch <000/100>: Step <157/2280>] - Data(s): 0.000 (0.399) - Batch(s): 1.335 
(2.177) - AE Loss: 1551365.625 (642163.500) - AE Rec Loss: 10.521 (4.355) - Disc
Loss: 0.000 (0.000) - 9.19 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.181 
(2.286) - AE Loss: 1461691.250 (635277.312) - AE Rec Loss: 9.913 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.180 
(2.286) - AE Loss: 311824.062 (635277.312) - AE Rec Loss: 2.115 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.180 
(2.286) - AE Loss: 136919.938 (635277.312) - AE Rec Loss: 0.929 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.181 
(2.286) - AE Loss: 365087.156 (635277.312) - AE Rec Loss: 2.476 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.21 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 3.479 (0.393) - Batch(s): 4.181 
(2.286) - AE Loss: 455212.625 (635277.312) - AE Rec Loss: 3.087 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.21 m remaining

[Epoch <000/100>: Step <158/2280>] - Data(s): 0.000 (0.393) - Batch(s): 4.180 
(2.286) - AE Loss: 820989.000 (635277.312) - AE Rec Loss: 5.568 (4.308) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.154 
(2.223) - AE Loss: 228897.672 (629123.938) - AE Rec Loss: 1.552 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.151 
(2.223) - AE Loss: 100917.578 (629123.938) - AE Rec Loss: 0.684 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.43 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.157 
(2.223) - AE Loss: 1622717.750 (629123.938) - AE Rec Loss: 11.005 (4.267) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.152 
(2.223) - AE Loss: 337664.125 (629123.938) - AE Rec Loss: 2.290 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.32 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.140 
(2.223) - AE Loss: 1413412.500 (629123.938) - AE Rec Loss: 9.585 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.43 m remaining

[Epoch <000/100>: Step <159/2280>] - Data(s): 0.000 (0.373) - Batch(s): 1.153 
(2.223) - AE Loss: 110710.750 (629123.938) - AE Rec Loss: 0.751 (4.267) - Disc 
Loss: 0.000 (0.000) - 10.32 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.129 
(2.166) - AE Loss: 1624415.375 (623425.625) - AE Rec Loss: 11.016 (4.228) - Disc
Loss: 0.000 (0.000) - 10.53 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.126 
(2.166) - AE Loss: 254000.641 (623425.625) - AE Rec Loss: 1.723 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.115 
(2.166) - AE Loss: 193978.828 (623425.625) - AE Rec Loss: 1.316 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.127 
(2.166) - AE Loss: 150552.359 (623425.625) - AE Rec Loss: 1.021 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.53 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.132 
(2.166) - AE Loss: 1710000.750 (623425.625) - AE Rec Loss: 11.597 (4.228) - Disc
Loss: 0.000 (0.000) - 10.53 m remaining

[Epoch <000/100>: Step <160/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.127 
(2.166) - AE Loss: 251295.328 (623425.625) - AE Rec Loss: 1.704 (4.228) - Disc 
Loss: 0.000 (0.000) - 10.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 14.591 
(2.702) - AE Loss: 347934.250 (632527.125) - AE Rec Loss: 2.360 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.67 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 14.591 
(2.702) - AE Loss: 96667.703 (632527.125) - AE Rec Loss: 0.656 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.67 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 14.591 
(2.702) - AE Loss: 313623.250 (632527.125) - AE Rec Loss: 2.127 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.67 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 14.592 
(2.702) - AE Loss: 1465439.875 (632527.125) - AE Rec Loss: 9.938 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.67 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 4.168 (0.354) - Batch(s): 14.592 
(2.702) - AE Loss: 82029.609 (632527.125) - AE Rec Loss: 0.556 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.79 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 0.000 (0.354) - Batch(s): 14.592 
(2.702) - AE Loss: 176861.406 (632527.125) - AE Rec Loss: 1.199 (4.290) - Disc 
Loss: 0.000 (0.000) - 13.79 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.134 
(2.629) - AE Loss: 3407529.500 (646554.938) - AE Rec Loss: 23.109 (4.385) - Disc
Loss: 0.000 (0.000) - 13.86 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (0.338) - Batch(s): 1.133 
(2.629) - AE Loss: 1774559.500 (646554.938) - AE Rec Loss: 12.035 (4.385) - Disc
Loss: 0.000 (0.000) - 13.86 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.121 
(2.629) - AE Loss: 1643723.500 (646554.938) - AE Rec Loss: 11.147 (4.385) - Disc
Loss: 0.000 (0.000) - 13.98 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.132 
(2.629) - AE Loss: 1539842.250 (646554.938) - AE Rec Loss: 10.443 (4.385) - Disc
Loss: 0.000 (0.000) - 13.86 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.001 (0.338) - Batch(s): 1.137 
(2.629) - AE Loss: 115233.070 (646554.938) - AE Rec Loss: 0.781 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.86 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.131 
(2.629) - AE Loss: 242514.359 (646554.938) - AE Rec Loss: 1.645 (4.385) - Disc 
Loss: 0.000 (0.000) - 13.98 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.160 
(2.563) - AE Loss: 122120.883 (652551.562) - AE Rec Loss: 0.828 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.05 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.160 
(2.563) - AE Loss: 710750.125 (652551.562) - AE Rec Loss: 4.820 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.06 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.147 
(2.563) - AE Loss: 127037.703 (652551.562) - AE Rec Loss: 0.862 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.17 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.159 
(2.563) - AE Loss: 276626.312 (652551.562) - AE Rec Loss: 1.876 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.06 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.164 
(2.563) - AE Loss: 159297.031 (652551.562) - AE Rec Loss: 1.080 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.05 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (0.323) - Batch(s): 1.158 
(2.563) - AE Loss: 288723.250 (652551.562) - AE Rec Loss: 1.958 (4.425) - Disc 
Loss: 0.000 (0.000) - 14.17 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 283770.156 (665338.312) - AE Rec Loss: 1.924 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.29 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 135930.531 (665338.312) - AE Rec Loss: 0.922 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.40 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 206845.828 (665338.312) - AE Rec Loss: 1.403 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.28 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 1531603.500 (665338.312) - AE Rec Loss: 10.387 (4.512) - Disc
Loss: 0.000 (0.000) - 14.28 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 128994.641 (665338.312) - AE Rec Loss: 0.875 (4.512) - Disc 
Loss: 0.000 (0.000) - 14.40 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (0.310) - Batch(s): 1.349 
(2.510) - AE Loss: 1972870.750 (665338.312) - AE Rec Loss: 13.379 (4.512) - Disc
Loss: 0.000 (0.000) - 14.29 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.131 
(2.453) - AE Loss: 310100.125 (670601.750) - AE Rec Loss: 2.103 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.47 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.131 
(2.453) - AE Loss: 208116.797 (670601.750) - AE Rec Loss: 1.411 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.58 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.119 
(2.453) - AE Loss: 440441.562 (670601.750) - AE Rec Loss: 2.987 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.58 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.132 
(2.453) - AE Loss: 246889.469 (670601.750) - AE Rec Loss: 1.674 (4.548) - Disc 
Loss: 0.000 (0.000) - 14.46 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.136 
(2.453) - AE Loss: 1617483.375 (670601.750) - AE Rec Loss: 10.969 (4.548) - Disc
Loss: 0.000 (0.000) - 14.46 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (0.297) - Batch(s): 1.131 
(2.453) - AE Loss: 1617521.500 (670601.750) - AE Rec Loss: 10.970 (4.548) - Disc
Loss: 0.000 (0.000) - 14.47 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.261 
(2.405) - AE Loss: 168961.125 (679626.875) - AE Rec Loss: 1.146 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.79 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.272 
(2.405) - AE Loss: 247680.859 (679626.875) - AE Rec Loss: 1.680 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.68 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.274 
(2.405) - AE Loss: 315492.625 (679626.875) - AE Rec Loss: 2.140 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.67 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.279 
(2.405) - AE Loss: 1530172.250 (679626.875) - AE Rec Loss: 10.377 (4.609) - Disc
Loss: 0.000 (0.000) - 14.67 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.274 
(2.405) - AE Loss: 233846.188 (679626.875) - AE Rec Loss: 1.586 (4.609) - Disc 
Loss: 0.000 (0.000) - 14.68 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (0.286) - Batch(s): 1.272 
(2.405) - AE Loss: 1569468.375 (679626.875) - AE Rec Loss: 10.644 (4.609) - Disc
Loss: 0.000 (0.000) - 14.79 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:35:20,957[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,957[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,957[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,969[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,969[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:35:20,995[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:35:23,144[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:23,185[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:23,185[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:23,188[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:23,208[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:35:23,472[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:35:23,775[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:35:23,778[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:23,785[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:35:23,787[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:35:23,792[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:35:24,013[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:35:24,014[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 03:35:24,016[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
[[36m2023-11-29 03:35:24,016[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataset) = 4
=> Preparing model 
[[36m2023-11-29 03:35:24,021[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
[[36m2023-11-29 03:35:24,022[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating the optimizer 
len(train_dataset) = 54706
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 03:35:24,025[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
len(valid_dataset) = 4
len(train_dataset) = 54706
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
len(valid_dataloader) = 1
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Instantiating the optimizer 
len(valid_dataset) = 4
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 5 on node 11
Reached 2 on node 6Reached end on node 11

Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10Reached 1.3 on node 7

Reached 1.4 on node 10Reached 1.4 on node 7

Reached 2 on node 10Reached 2 on node 7

Reached 3 on node 10
Reached 3 on node 7
Reached 5 on node 10
Reached 5 on node 7
Reached 1.3 on node 9Reached end on node 10Reached end on node 7


Reached 1.4 on node 9
Reached 1.3 on node 6Reached 2 on node 9Reached 1.3 on node 8

Reached 1.4 on node 6

Reached 1.3 on node 11Reached 1.4 on node 8

Reached 2 on node 6
Reached 1.4 on node 11
Reached 3 on node 9Reached 2 on node 8

Reached 2 on node 11
Reached 5 on node 9Reached 3 on node 6

Reached 3 on node 8Reached 5 on node 6

Reached end on node 9
Reached 3 on node 11Reached 5 on node 8

Reached end on node 6
Reached 5 on node 11
Reached end on node 8
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10Reached 1 on node 8

Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 11
Reached 1.4 on node 6
Reached 1.4 on node 11Reached 2 on node 6

Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10Reached 1 on node 7

Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 11Reached 1.4 on node 6

Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 9Reached 3 on node 6

Reached 3 on node 6Reached 1.4 on node 11

Reached 3 on node 6
Reached 2 on node 11
Reached 5 on node 6Reached 1.4 on node 9

Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 10Reached 1.4 on node 8

Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7Reached 1 on node 11

Reached 3 on node 7
Reached 1 on node 9
Reached 5 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8Reached 1 on node 10

Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1.4 on node 10
Reached 3 on node 8
Reached 2 on node 10
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 11Reached 1 on node 9

Reached 1.4 on node 11Reached 1.4 on node 9

Reached 2 on node 11Reached 2 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 6
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 9Reached 2 on node 7

Reached 2 on node 9Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 8
Reached end on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <161/2280>] - Data(s): 6.453 (7.360) - Batch(s): 13.738 
(13.805) - AE Loss: 177006.188 (814676.750) - AE Rec Loss: 1.200 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 7.746 (7.360) - Batch(s): 13.741 
(13.805) - AE Loss: 346864.969 (814676.750) - AE Rec Loss: 2.352 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 8.273 (7.360) - Batch(s): 13.705 
(13.805) - AE Loss: 82084.875 (814676.750) - AE Rec Loss: 0.557 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 3.730 (7.360) - Batch(s): 13.748 
(13.805) - AE Loss: 313205.188 (814676.750) - AE Rec Loss: 2.124 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 11.272 (7.360) - Batch(s): 13.726 
(13.805) - AE Loss: 1465235.250 (814676.750) - AE Rec Loss: 9.937 (5.525) - Disc
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 6.047 (7.360) - Batch(s): 13.740 
(13.805) - AE Loss: 96742.898 (814676.750) - AE Rec Loss: 0.656 (5.525) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.158 
(7.461) - AE Loss: 1641964.250 (875303.812) - AE Rec Loss: 11.135 (5.936) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.170 
(7.461) - AE Loss: 3412806.500 (875303.812) - AE Rec Loss: 23.145 (5.936) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.166 
(7.461) - AE Loss: 231622.188 (875303.812) - AE Rec Loss: 1.571 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.174 
(7.461) - AE Loss: 108681.711 (875303.812) - AE Rec Loss: 0.737 (5.936) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.167 
(7.461) - AE Loss: 1540827.500 (875303.812) - AE Rec Loss: 10.449 (5.936) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.680) - Batch(s): 1.170 
(7.461) - AE Loss: 1771188.625 (875303.812) - AE Rec Loss: 12.012 (5.936) - Disc
Loss: 0.000 (0.000) - 3.32 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (2.484) - Batch(s): 1.783 
(5.552) - AE Loss: 286105.906 (843348.875) - AE Rec Loss: 1.940 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (2.484) - Batch(s): 1.782 
(5.552) - AE Loss: 108673.961 (843348.875) - AE Rec Loss: 0.737 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.781 
(5.552) - AE Loss: 153576.484 (843348.875) - AE Rec Loss: 1.042 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.484) - Batch(s): 1.781 
(5.552) - AE Loss: 271940.250 (843348.875) - AE Rec Loss: 1.844 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (2.484) - Batch(s): 1.780 
(5.552) - AE Loss: 724306.375 (843348.875) - AE Rec Loss: 4.912 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.001 (2.484) - Batch(s): 1.782 
(5.552) - AE Loss: 107994.109 (843348.875) - AE Rec Loss: 0.732 (5.719) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.097 
(4.427) - AE Loss: 222373.906 (873964.312) - AE Rec Loss: 1.508 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.001 (1.863) - Batch(s): 1.098 
(4.427) - AE Loss: 298485.000 (873964.312) - AE Rec Loss: 2.024 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.095 
(4.427) - AE Loss: 1974747.500 (873964.312) - AE Rec Loss: 13.392 (5.927) - Disc
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.086 
(4.427) - AE Loss: 131912.812 (873964.312) - AE Rec Loss: 0.895 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.094 
(4.427) - AE Loss: 143830.578 (873964.312) - AE Rec Loss: 0.975 (5.927) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.863) - Batch(s): 1.100 
(4.427) - AE Loss: 1532871.250 (873964.312) - AE Rec Loss: 10.395 (5.927) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.302 
(3.790) - AE Loss: 261956.984 (860321.562) - AE Rec Loss: 1.777 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.298 
(3.790) - AE Loss: 221550.953 (860321.562) - AE Rec Loss: 1.502 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.291 
(3.790) - AE Loss: 431633.438 (860321.562) - AE Rec Loss: 2.927 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.306 
(3.790) - AE Loss: 1634830.250 (860321.562) - AE Rec Loss: 11.087 (5.834) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.301 
(3.790) - AE Loss: 1610706.500 (860321.562) - AE Rec Loss: 10.923 (5.834) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.490) - Batch(s): 1.302 
(3.790) - AE Loss: 329731.500 (860321.562) - AE Rec Loss: 2.236 (5.834) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.297 
(3.366) - AE Loss: 1545185.125 (869722.750) - AE Rec Loss: 10.479 (5.898) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.296 
(3.366) - AE Loss: 250877.156 (869722.750) - AE Rec Loss: 1.701 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.296 
(3.366) - AE Loss: 1577664.500 (869722.750) - AE Rec Loss: 10.699 (5.898) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.297 
(3.366) - AE Loss: 186888.875 (869722.750) - AE Rec Loss: 1.267 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.297 
(3.366) - AE Loss: 302205.094 (869722.750) - AE Rec Loss: 2.049 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.242) - Batch(s): 1.297 
(3.366) - AE Loss: 250369.828 (869722.750) - AE Rec Loss: 1.698 (5.898) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (1.065) - Batch(s): 1.127 
(3.040) - AE Loss: 1908044.000 (848410.125) - AE Rec Loss: 12.940 (5.754) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.132 
(3.040) - AE Loss: 232480.938 (848410.125) - AE Rec Loss: 1.577 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.127 
(3.040) - AE Loss: 326611.875 (848410.125) - AE Rec Loss: 2.215 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (1.065) - Batch(s): 1.125 
(3.040) - AE Loss: 150954.734 (848410.125) - AE Rec Loss: 1.024 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (1.065) - Batch(s): 1.125 
(3.040) - AE Loss: 1591971.250 (848410.125) - AE Rec Loss: 10.796 (5.754) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (1.065) - Batch(s): 1.116 
(3.040) - AE Loss: 146194.625 (848410.125) - AE Rec Loss: 0.991 (5.754) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.328 (0.935) - Batch(s): 1.159 
(2.799) - AE Loss: 446840.594 (837860.688) - AE Rec Loss: 3.030 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.935) - Batch(s): 1.166 
(2.799) - AE Loss: 1614142.750 (837860.688) - AE Rec Loss: 10.947 (5.682) - Disc
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.935) - Batch(s): 1.163 
(2.799) - AE Loss: 1898324.250 (837860.688) - AE Rec Loss: 12.874 (5.682) - Disc
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.162 
(2.799) - AE Loss: 410177.094 (837860.688) - AE Rec Loss: 2.782 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.935) - Batch(s): 1.160 
(2.799) - AE Loss: 233202.328 (837860.688) - AE Rec Loss: 1.582 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.02 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.935) - Batch(s): 1.149 
(2.799) - AE Loss: 470650.125 (837860.688) - AE Rec Loss: 3.192 (5.682) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.475 
(2.645) - AE Loss: 2281990.000 (873454.688) - AE Rec Loss: 15.476 (5.923) - Disc
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.475 
(2.645) - AE Loss: 1555493.625 (873454.688) - AE Rec Loss: 10.549 (5.923) - Disc
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.475 
(2.645) - AE Loss: 1974714.500 (873454.688) - AE Rec Loss: 13.392 (5.923) - Disc
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.476 
(2.645) - AE Loss: 724703.062 (873454.688) - AE Rec Loss: 4.915 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.477 
(2.645) - AE Loss: 1533978.750 (873454.688) - AE Rec Loss: 10.403 (5.923) - Disc
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.832) - Batch(s): 1.478 
(2.645) - AE Loss: 74119.891 (873454.688) - AE Rec Loss: 0.503 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.33 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.281 
(2.502) - AE Loss: 139497.641 (815807.188) - AE Rec Loss: 0.946 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.281 
(2.502) - AE Loss: 67287.680 (815807.188) - AE Rec Loss: 0.456 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.279 
(2.502) - AE Loss: 84597.156 (815807.188) - AE Rec Loss: 0.574 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.285 
(2.502) - AE Loss: 531393.312 (815807.188) - AE Rec Loss: 3.604 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.001 (0.755) - Batch(s): 1.278 
(2.502) - AE Loss: 95054.984 (815807.188) - AE Rec Loss: 0.645 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.755) - Batch(s): 1.268 
(2.502) - AE Loss: 151644.938 (815807.188) - AE Rec Loss: 1.028 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.58 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 2.490 (0.712) - Batch(s): 3.062 
(2.531) - AE Loss: 252125.828 (798588.375) - AE Rec Loss: 1.710 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.001 (0.712) - Batch(s): 3.046 
(2.531) - AE Loss: 440122.906 (798588.375) - AE Rec Loss: 2.985 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 3.064 
(2.531) - AE Loss: 1889473.250 (798588.375) - AE Rec Loss: 12.814 (5.416) - Disc
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 3.058 
(2.531) - AE Loss: 372762.406 (798588.375) - AE Rec Loss: 2.528 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.925 (0.712) - Batch(s): 3.062 
(2.531) - AE Loss: 297152.375 (798588.375) - AE Rec Loss: 2.015 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.712) - Batch(s): 3.059 
(2.531) - AE Loss: 430765.094 (798588.375) - AE Rec Loss: 2.921 (5.416) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.488 
(2.439) - AE Loss: 157617.000 (793862.812) - AE Rec Loss: 1.069 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.489 
(2.439) - AE Loss: 1488389.250 (793862.812) - AE Rec Loss: 10.094 (5.384) - Disc
Loss: 0.000 (0.000) - 6.51 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.488 
(2.439) - AE Loss: 1668769.000 (793862.812) - AE Rec Loss: 11.317 (5.384) - Disc
Loss: 0.000 (0.000) - 6.51 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.489 
(2.439) - AE Loss: 495062.688 (793862.812) - AE Rec Loss: 3.357 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.51 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.490 
(2.439) - AE Loss: 1586508.875 (793862.812) - AE Rec Loss: 10.759 (5.384) - Disc
Loss: 0.000 (0.000) - 6.51 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.653) - Batch(s): 1.490 
(2.439) - AE Loss: 147324.219 (793862.812) - AE Rec Loss: 0.999 (5.384) - Disc 
Loss: 0.000 (0.000) - 6.51 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.001 (0.603) - Batch(s): 1.235 
(2.342) - AE Loss: 232543.391 (780838.688) - AE Rec Loss: 1.577 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.223 
(2.342) - AE Loss: 1516439.000 (780838.688) - AE Rec Loss: 10.284 (5.295) - Disc
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.001 (0.603) - Batch(s): 1.235 
(2.342) - AE Loss: 113250.938 (780838.688) - AE Rec Loss: 0.768 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.234 
(2.342) - AE Loss: 1556973.250 (780838.688) - AE Rec Loss: 10.559 (5.295) - Disc
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.113 (0.603) - Batch(s): 1.239 
(2.342) - AE Loss: 115333.430 (780838.688) - AE Rec Loss: 0.782 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.603) - Batch(s): 1.232 
(2.342) - AE Loss: 299221.125 (780838.688) - AE Rec Loss: 2.029 (5.295) - Disc 
Loss: 0.000 (0.000) - 6.75 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 222131.688 (776389.188) - AE Rec Loss: 1.506 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.23 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.572) - Batch(s): 2.463 
(2.329) - AE Loss: 326268.500 (776389.188) - AE Rec Loss: 2.213 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 1.890 (0.572) - Batch(s): 2.467 
(2.329) - AE Loss: 315141.188 (776389.188) - AE Rec Loss: 2.137 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.463 
(2.329) - AE Loss: 264073.281 (776389.188) - AE Rec Loss: 1.791 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.110 
(2.329) - AE Loss: 293663.438 (776389.188) - AE Rec Loss: 1.992 (5.265) - Disc 
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.572) - Batch(s): 2.469 
(2.329) - AE Loss: 3086869.500 (776389.188) - AE Rec Loss: 20.934 (5.265) - Disc
Loss: 0.000 (0.000) - 7.24 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.001 (0.534) - Batch(s): 1.427 
(2.265) - AE Loss: 1756101.250 (771923.000) - AE Rec Loss: 11.909 (5.235) - Disc
Loss: 0.000 (0.000) - 7.50 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.427 
(2.265) - AE Loss: 1657771.375 (771923.000) - AE Rec Loss: 11.242 (5.235) - Disc
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.428 
(2.265) - AE Loss: 1716035.500 (771923.000) - AE Rec Loss: 11.638 (5.235) - Disc
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.428 
(2.265) - AE Loss: 225806.891 (771923.000) - AE Rec Loss: 1.531 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.427 
(2.265) - AE Loss: 394737.625 (771923.000) - AE Rec Loss: 2.677 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.534) - Batch(s): 1.429 
(2.265) - AE Loss: 557992.250 (771923.000) - AE Rec Loss: 3.784 (5.235) - Disc 
Loss: 0.000 (0.000) - 7.51 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.001 (0.500) - Batch(s): 1.199 
(2.196) - AE Loss: 1898148.750 (762615.688) - AE Rec Loss: 12.873 (5.172) - Disc
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.213 
(2.196) - AE Loss: 257121.891 (762615.688) - AE Rec Loss: 1.744 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.210 
(2.196) - AE Loss: 303056.844 (762615.688) - AE Rec Loss: 2.055 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.216 
(2.196) - AE Loss: 292742.188 (762615.688) - AE Rec Loss: 1.985 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.211 
(2.196) - AE Loss: 1612396.875 (762615.688) - AE Rec Loss: 10.935 (5.172) - Disc
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.500) - Batch(s): 1.210 
(2.196) - AE Loss: 407081.125 (762615.688) - AE Rec Loss: 2.761 (5.172) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.459 
(2.156) - AE Loss: 1422584.000 (743296.000) - AE Rec Loss: 9.648 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.07 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.813 
(2.156) - AE Loss: 573297.875 (743296.000) - AE Rec Loss: 3.888 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.458 
(2.156) - AE Loss: 232559.266 (743296.000) - AE Rec Loss: 1.577 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.818 
(2.156) - AE Loss: 123637.344 (743296.000) - AE Rec Loss: 0.838 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.811 
(2.156) - AE Loss: 263120.688 (743296.000) - AE Rec Loss: 1.784 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 1.250 (0.477) - Batch(s): 1.815 
(2.156) - AE Loss: 114561.844 (743296.000) - AE Rec Loss: 0.777 (5.041) - Disc 
Loss: 0.000 (0.000) - 8.08 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.001 (0.452) - Batch(s): 1.266 
(2.104) - AE Loss: 117924.016 (735501.188) - AE Rec Loss: 0.800 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.266 
(2.104) - AE Loss: 284645.531 (735501.188) - AE Rec Loss: 1.930 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.001 (0.452) - Batch(s): 1.263 
(2.104) - AE Loss: 150212.094 (735501.188) - AE Rec Loss: 1.019 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.294 (0.452) - Batch(s): 1.263 
(2.104) - AE Loss: 773773.500 (735501.188) - AE Rec Loss: 5.247 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.30 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.265 
(2.104) - AE Loss: 547053.000 (735501.188) - AE Rec Loss: 3.710 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.001 (0.452) - Batch(s): 1.265 
(2.104) - AE Loss: 79085.203 (735501.188) - AE Rec Loss: 0.536 (4.988) - Disc 
Loss: 0.000 (0.000) - 8.31 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.199 
(2.054) - AE Loss: 166274.000 (734373.312) - AE Rec Loss: 1.128 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.53 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.202 
(2.054) - AE Loss: 604025.875 (734373.312) - AE Rec Loss: 4.096 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.52 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.203 
(2.054) - AE Loss: 1594053.125 (734373.312) - AE Rec Loss: 10.810 (4.980) - Disc
Loss: 0.000 (0.000) - 8.52 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.190 
(2.054) - AE Loss: 1908508.000 (734373.312) - AE Rec Loss: 12.943 (4.980) - Disc
Loss: 0.000 (0.000) - 8.52 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.198 
(2.054) - AE Loss: 113132.648 (734373.312) - AE Rec Loss: 0.767 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.52 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.431) - Batch(s): 1.206 
(2.054) - AE Loss: 71617.344 (734373.312) - AE Rec Loss: 0.486 (4.980) - Disc 
Loss: 0.000 (0.000) - 8.53 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.438) - Batch(s): 6.517 
(2.262) - AE Loss: 1413464.000 (725848.062) - AE Rec Loss: 9.586 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.001 (0.438) - Batch(s): 6.523 
(2.262) - AE Loss: 292041.438 (725848.062) - AE Rec Loss: 1.981 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 5.943 (0.438) - Batch(s): 6.520 
(2.262) - AE Loss: 207983.656 (725848.062) - AE Rec Loss: 1.410 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.438) - Batch(s): 6.162 
(2.262) - AE Loss: 84580.297 (725848.062) - AE Rec Loss: 0.574 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.76 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.438) - Batch(s): 6.516 
(2.262) - AE Loss: 205207.812 (725848.062) - AE Rec Loss: 1.392 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.438) - Batch(s): 6.162 
(2.262) - AE Loss: 1457715.250 (725848.062) - AE Rec Loss: 9.886 (4.922) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:36:54,050[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:54,106[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:54,125[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:54,265[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:54,285[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:36:54,285[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:36:56,279[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,328[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,369[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,471[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,540[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:36:56,595[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,845[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,873[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,909[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:56,994[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:57,090[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:36:57,137[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:36:57,137[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:36:57,137[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 03:36:57,140[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
[[36m2023-11-29 03:36:57,142[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Running in inference mode: False
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating train dataloader 
[[36m2023-11-29 03:36:57,144[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(train_dataset) = 54706
=> Preparing model 
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Running in inference mode: False
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
[[36m2023-11-29 03:36:57,148[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Error executing job with overrides: ['experiment=vae']
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
    main()
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
        return func()
lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
        result = tuple(result = tuple(
    
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
result = tuple(  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<35478>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<43616>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer fdaa:1:b86:a7b:9076:0:a:2202<47680>
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<44924>
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:38:26,431[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,453[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,491[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,714[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,716[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:38:26,969[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:38:28,654[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,696[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,742[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,918[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:38:28,965[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:29,113[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:29,158[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:38:29,179[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:29,252[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:38:29,454[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 03:38:29,454[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:38:29,625[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:38:29,628[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
[[36m2023-11-29 03:38:29,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:38:29,633[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached 3 on node 6
Reached end on node 7
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached 3 on node 11
Reached end on node 9Reached 5 on node 11

Reached end on node 11
=> Preparing model 
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:39:58,906[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:58,918[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:59,127[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:59,201[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:59,256[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:39:59,291[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:40:01,114[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:01,158[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:01,485[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,515[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:40:01,528[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:40:01,543[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,623[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:40:01,805[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:01,926[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:40:02,050[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 03:40:02,058[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:40:02,199[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:40:02,202[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 03:40:02,204[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
[[36m2023-11-29 03:40:02,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
[[36m2023-11-29 03:40:02,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
[[36m2023-11-29 03:40:02,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:40:02,207[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Instantiating train dataloader 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 1.3 on node 7
Reached 2 on node 8Reached 1.4 on node 7

Reached 2 on node 7
Reached 1.3 on node 11Reached 3 on node 8

Reached 1.4 on node 11
Reached 3 on node 7
Reached 2 on node 11
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 5 on node 7Reached 3 on node 11

Reached end on node 7
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 8
Reached 5 on node 8
Reached 3 on node 7
Reached end on node 8
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6
Reached 1.3 on node 9
Reached 1.4 on node 6
Reached 1.4 on node 9
Reached 2 on node 6
Reached 2 on node 9
Reached 3 on node 6Reached 3 on node 9

Reached 5 on node 6Reached 5 on node 9

Reached end on node 9Reached end on node 6

Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.3 on node 11Reached end on node 10

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
Loaded checkpoint at epoch 0 and step 161
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8Reached 1 on node 7

Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 1.4 on node 6
Reached 2 on node 10Reached 2 on node 6

Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 1.4 on node 9Reached 2 on node 11

Reached 2 on node 9
Reached 1 on node 7Reached 1 on node 8

Reached 1.4 on node 7Reached 1.4 on node 8

Reached 2 on node 7Reached 2 on node 8

Reached 1 on node 6Reached 1 on node 10

Reached 1.4 on node 10Reached 1.4 on node 6

Reached 2 on node 10Reached 2 on node 6

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 1.4 on node 11Reached 2 on node 9

Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8Reached 1.4 on node 7

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 10Reached 5 on node 7

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 9
Reached 1 on node 8
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11Reached 1.4 on node 9

Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11
Reached 3 on node 9
Reached 2 on node 11Reached 3 on node 9

Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6Reached 1 on node 11

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 1 on node 10Reached 2 on node 8

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 1 on node 10Reached 2 on node 8

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 1 on node 6Reached 2 on node 8

Reached 1 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 7
Reached end on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <161/2280>] - Data(s): 8.450 (6.171) - Batch(s): 11.348 
(11.345) - AE Loss: 347999.688 (814762.812) - AE Rec Loss: 2.360 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 4.323 (6.171) - Batch(s): 11.791 
(11.345) - AE Loss: 177144.094 (814762.812) - AE Rec Loss: 1.201 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 3.983 (6.171) - Batch(s): 11.452 
(11.345) - AE Loss: 314170.312 (814762.812) - AE Rec Loss: 2.131 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 6.336 (6.171) - Batch(s): 11.311 
(11.345) - AE Loss: 81369.453 (814762.812) - AE Rec Loss: 0.552 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 6.237 (6.171) - Batch(s): 11.349 
(11.345) - AE Loss: 1465566.250 (814762.812) - AE Rec Loss: 9.939 (5.525) - Disc
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <161/2280>] - Data(s): 8.400 (6.171) - Batch(s): 11.563 
(11.345) - AE Loss: 96810.672 (814762.812) - AE Rec Loss: 0.657 (5.525) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.365 
(6.322) - AE Loss: 231284.719 (875283.812) - AE Rec Loss: 1.568 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.374 
(6.322) - AE Loss: 108997.562 (875283.812) - AE Rec Loss: 0.739 (5.936) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.369 
(6.322) - AE Loss: 3412808.000 (875283.812) - AE Rec Loss: 23.145 (5.936) - Disc
Loss: 0.000 (0.000) - 2.85 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.371 
(6.322) - AE Loss: 1541014.750 (875283.812) - AE Rec Loss: 10.451 (5.936) - Disc
Loss: 0.000 (0.000) - 2.85 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.357 
(6.322) - AE Loss: 1642386.250 (875283.812) - AE Rec Loss: 11.138 (5.936) - Disc
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <162/2280>] - Data(s): 0.000 (3.086) - Batch(s): 1.368 
(6.322) - AE Loss: 1771220.250 (875283.812) - AE Rec Loss: 12.012 (5.936) - Disc
Loss: 0.000 (0.000) - 2.90 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.093 
(5.231) - AE Loss: 109123.695 (843394.562) - AE Rec Loss: 0.740 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.096 
(5.231) - AE Loss: 286977.500 (843394.562) - AE Rec Loss: 1.946 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.092 
(5.231) - AE Loss: 109057.188 (843394.562) - AE Rec Loss: 0.740 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.094 
(5.231) - AE Loss: 271800.375 (843394.562) - AE Rec Loss: 1.843 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.095 
(5.231) - AE Loss: 153254.766 (843394.562) - AE Rec Loss: 1.039 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <163/2280>] - Data(s): 0.000 (2.164) - Batch(s): 3.094 
(5.231) - AE Loss: 724541.125 (843394.562) - AE Rec Loss: 4.914 (5.720) - Disc 
Loss: 0.000 (0.000) - 3.58 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.288 
(4.231) - AE Loss: 144828.656 (874117.000) - AE Rec Loss: 0.982 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.91 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.292 
(4.231) - AE Loss: 222280.828 (874117.000) - AE Rec Loss: 1.507 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.296 
(4.231) - AE Loss: 1532837.500 (874117.000) - AE Rec Loss: 10.395 (5.928) - Disc
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.291 
(4.231) - AE Loss: 1974262.500 (874117.000) - AE Rec Loss: 13.389 (5.928) - Disc
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.291 
(4.231) - AE Loss: 298306.250 (874117.000) - AE Rec Loss: 2.023 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.86 m remaining

[Epoch <000/100>: Step <164/2280>] - Data(s): 0.000 (1.623) - Batch(s): 1.281 
(4.231) - AE Loss: 133926.328 (874117.000) - AE Rec Loss: 0.908 (5.928) - Disc 
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.281 
(3.628) - AE Loss: 262922.625 (860617.625) - AE Rec Loss: 1.783 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.269 
(3.628) - AE Loss: 433149.031 (860617.625) - AE Rec Loss: 2.937 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.277 
(3.628) - AE Loss: 221865.047 (860617.625) - AE Rec Loss: 1.505 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.279 
(3.628) - AE Loss: 330699.594 (860617.625) - AE Rec Loss: 2.243 (5.836) - Disc 
Loss: 0.000 (0.000) - 4.15 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.284 
(3.628) - AE Loss: 1636265.000 (860617.625) - AE Rec Loss: 11.097 (5.836) - Disc
Loss: 0.000 (0.000) - 4.12 m remaining

[Epoch <000/100>: Step <165/2280>] - Data(s): 0.000 (1.298) - Batch(s): 1.279 
(3.628) - AE Loss: 1610233.500 (860617.625) - AE Rec Loss: 10.920 (5.836) - Disc
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 187757.375 (870101.125) - AE Rec Loss: 1.273 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 251373.281 (870101.125) - AE Rec Loss: 1.705 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.68 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 1546381.000 (870101.125) - AE Rec Loss: 10.487 (5.901) - Disc
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 304129.500 (870101.125) - AE Rec Loss: 2.063 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.68 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 1578835.500 (870101.125) - AE Rec Loss: 10.707 (5.901) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <166/2280>] - Data(s): 0.000 (1.110) - Batch(s): 2.726 
(3.470) - AE Loss: 251050.109 (870101.125) - AE Rec Loss: 1.703 (5.901) - Disc 
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (0.952) - Batch(s): 1.227 
(3.143) - AE Loss: 145767.672 (848637.125) - AE Rec Loss: 0.989 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.237 
(3.143) - AE Loss: 149220.875 (848637.125) - AE Rec Loss: 1.012 (5.755) - Disc 
Loss: 0.000 (0.000) - 5.03 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (0.952) - Batch(s): 1.238 
(3.143) - AE Loss: 1590756.000 (848637.125) - AE Rec Loss: 10.788 (5.755) - Disc
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.243 
(3.143) - AE Loss: 232179.000 (848637.125) - AE Rec Loss: 1.575 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.001 (0.952) - Batch(s): 1.238 
(3.143) - AE Loss: 326995.469 (848637.125) - AE Rec Loss: 2.218 (5.755) - Disc 
Loss: 0.000 (0.000) - 4.99 m remaining

[Epoch <000/100>: Step <167/2280>] - Data(s): 0.000 (0.952) - Batch(s): 1.239 
(3.143) - AE Loss: 1906556.750 (848637.125) - AE Rec Loss: 12.930 (5.755) - Disc
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.037 
(2.876) - AE Loss: 470120.906 (837975.812) - AE Rec Loss: 3.188 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.16 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.833) - Batch(s): 1.048 
(2.876) - AE Loss: 410160.969 (837975.812) - AE Rec Loss: 2.782 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.16 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.833) - Batch(s): 1.052 
(2.876) - AE Loss: 1613003.125 (837975.812) - AE Rec Loss: 10.939 (5.683) - Disc
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.001 (0.833) - Batch(s): 1.050 
(2.876) - AE Loss: 1898028.250 (837975.812) - AE Rec Loss: 12.872 (5.683) - Disc
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.046 
(2.876) - AE Loss: 445736.594 (837975.812) - AE Rec Loss: 3.023 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.25 m remaining

[Epoch <000/100>: Step <168/2280>] - Data(s): 0.000 (0.833) - Batch(s): 1.047 
(2.876) - AE Loss: 231875.875 (837975.812) - AE Rec Loss: 1.573 (5.683) - Disc 
Loss: 0.000 (0.000) - 5.16 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 723365.625 (873452.000) - AE Rec Loss: 4.906 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.740) - Batch(s): 1.441 
(2.710) - AE Loss: 1534332.750 (873452.000) - AE Rec Loss: 10.405 (5.923) - Disc
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.441 
(2.710) - AE Loss: 72214.625 (873452.000) - AE Rec Loss: 0.490 (5.923) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 2280111.500 (873452.000) - AE Rec Loss: 15.463 (5.923) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.001 (0.740) - Batch(s): 1.443 
(2.710) - AE Loss: 1973900.625 (873452.000) - AE Rec Loss: 13.386 (5.923) - Disc
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <169/2280>] - Data(s): 0.000 (0.740) - Batch(s): 1.444 
(2.710) - AE Loss: 1553497.500 (873452.000) - AE Rec Loss: 10.535 (5.923) - Disc
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.321 
(2.565) - AE Loss: 85689.031 (815871.875) - AE Rec Loss: 0.581 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.309 
(2.565) - AE Loss: 153182.625 (815871.875) - AE Rec Loss: 1.039 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.325 
(2.565) - AE Loss: 531266.062 (815871.875) - AE Rec Loss: 3.603 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.75 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.319 
(2.565) - AE Loss: 95457.609 (815871.875) - AE Rec Loss: 0.647 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.325 
(2.565) - AE Loss: 67608.672 (815871.875) - AE Rec Loss: 0.459 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.78 m remaining

[Epoch <000/100>: Step <170/2280>] - Data(s): 0.000 (0.666) - Batch(s): 1.321 
(2.565) - AE Loss: 140572.844 (815871.875) - AE Rec Loss: 0.953 (5.533) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.282 
(2.443) - AE Loss: 374421.688 (798714.438) - AE Rec Loss: 2.539 (5.417) - Disc 
Loss: 0.000 (0.000) - 6.08 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.288 
(2.443) - AE Loss: 1889842.000 (798714.438) - AE Rec Loss: 12.816 (5.417) - Disc
Loss: 0.000 (0.000) - 6.01 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.284 
(2.443) - AE Loss: 252812.922 (798714.438) - AE Rec Loss: 1.714 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.284 
(2.443) - AE Loss: 431870.625 (798714.438) - AE Rec Loss: 2.929 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.273 
(2.443) - AE Loss: 441058.250 (798714.438) - AE Rec Loss: 2.991 (5.417) - Disc 
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <171/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.286 
(2.443) - AE Loss: 297497.938 (798714.438) - AE Rec Loss: 2.018 (5.417) - Disc 
Loss: 0.000 (0.000) - 6.04 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.165 
(2.582) - AE Loss: 1669514.250 (794005.625) - AE Rec Loss: 11.322 (5.385) - Disc
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.164 
(2.582) - AE Loss: 147818.594 (794005.625) - AE Rec Loss: 1.002 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.85 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.163 
(2.582) - AE Loss: 158073.656 (794005.625) - AE Rec Loss: 1.072 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.164 
(2.582) - AE Loss: 495977.969 (794005.625) - AE Rec Loss: 3.364 (5.385) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.164 
(2.582) - AE Loss: 1488862.500 (794005.625) - AE Rec Loss: 10.097 (5.385) - Disc
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <172/2280>] - Data(s): 0.000 (0.579) - Batch(s): 4.163 
(2.582) - AE Loss: 1586119.000 (794005.625) - AE Rec Loss: 10.757 (5.385) - Disc
Loss: 0.000 (0.000) - 6.88 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.084 
(2.463) - AE Loss: 115898.828 (781052.188) - AE Rec Loss: 0.786 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.080 
(2.463) - AE Loss: 236385.984 (781052.188) - AE Rec Loss: 1.603 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.082 
(2.463) - AE Loss: 114322.297 (781052.188) - AE Rec Loss: 0.775 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.068 
(2.463) - AE Loss: 1517901.875 (781052.188) - AE Rec Loss: 10.294 (5.297) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.079 
(2.463) - AE Loss: 302615.625 (781052.188) - AE Rec Loss: 2.052 (5.297) - Disc 
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <173/2280>] - Data(s): 0.000 (0.535) - Batch(s): 1.079 
(2.463) - AE Loss: 1558145.750 (781052.188) - AE Rec Loss: 10.567 (5.297) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.497) - Batch(s): 1.312 
(2.376) - AE Loss: 3087054.750 (776708.312) - AE Rec Loss: 20.935 (5.267) - Disc
Loss: 0.000 (0.000) - 7.31 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.001 (0.497) - Batch(s): 1.309 
(2.376) - AE Loss: 316651.750 (776708.312) - AE Rec Loss: 2.147 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.306 
(2.376) - AE Loss: 329137.812 (776708.312) - AE Rec Loss: 2.232 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.306 
(2.376) - AE Loss: 265211.562 (776708.312) - AE Rec Loss: 1.799 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.296 
(2.376) - AE Loss: 222838.141 (776708.312) - AE Rec Loss: 1.511 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <174/2280>] - Data(s): 0.000 (0.497) - Batch(s): 1.308 
(2.376) - AE Loss: 294228.938 (776708.312) - AE Rec Loss: 1.995 (5.267) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.437 
(2.309) - AE Loss: 1659557.500 (772298.938) - AE Rec Loss: 11.255 (5.237) - Disc
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.440 
(2.309) - AE Loss: 558332.812 (772298.938) - AE Rec Loss: 3.786 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.65 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.437 
(2.309) - AE Loss: 1715435.750 (772298.938) - AE Rec Loss: 11.634 (5.237) - Disc
Loss: 0.000 (0.000) - 7.61 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.436 
(2.309) - AE Loss: 397218.125 (772298.938) - AE Rec Loss: 2.694 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.57 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.000 (0.466) - Batch(s): 1.438 
(2.309) - AE Loss: 227366.797 (772298.938) - AE Rec Loss: 1.542 (5.237) - Disc 
Loss: 0.000 (0.000) - 7.57 m remaining

[Epoch <000/100>: Step <175/2280>] - Data(s): 0.509 (0.466) - Batch(s): 1.438 
(2.309) - AE Loss: 1758270.875 (772298.938) - AE Rec Loss: 11.924 (5.237) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.245 
(2.239) - AE Loss: 256401.891 (762932.812) - AE Rec Loss: 1.739 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.84 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.243 
(2.239) - AE Loss: 301748.156 (762932.812) - AE Rec Loss: 2.046 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.247 
(2.239) - AE Loss: 291163.719 (762932.812) - AE Rec Loss: 1.975 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.242 
(2.239) - AE Loss: 405650.812 (762932.812) - AE Rec Loss: 2.751 (5.174) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.244 
(2.239) - AE Loss: 1611894.750 (762932.812) - AE Rec Loss: 10.931 (5.174) - Disc
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <176/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.231 
(2.239) - AE Loss: 1897908.500 (762932.812) - AE Rec Loss: 12.871 (5.174) - Disc
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.226 
(2.176) - AE Loss: 124392.156 (743556.250) - AE Rec Loss: 0.844 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.223 
(2.176) - AE Loss: 572119.625 (743556.250) - AE Rec Loss: 3.880 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.225 
(2.176) - AE Loss: 113846.000 (743556.250) - AE Rec Loss: 0.772 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.07 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.221 
(2.176) - AE Loss: 262445.219 (743556.250) - AE Rec Loss: 1.780 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.11 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.211 
(2.176) - AE Loss: 1421825.750 (743556.250) - AE Rec Loss: 9.642 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <177/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.223 
(2.176) - AE Loss: 231411.312 (743556.250) - AE Rec Loss: 1.569 (5.043) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.592 
(2.196) - AE Loss: 149260.203 (735706.312) - AE Rec Loss: 1.012 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.53 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.593 
(2.196) - AE Loss: 79414.344 (735706.312) - AE Rec Loss: 0.539 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.593 
(2.196) - AE Loss: 117517.406 (735706.312) - AE Rec Loss: 0.797 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.592 
(2.196) - AE Loss: 284405.875 (735706.312) - AE Rec Loss: 1.929 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.56 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 1.879 (0.397) - Batch(s): 2.593 
(2.196) - AE Loss: 772999.750 (735706.312) - AE Rec Loss: 5.242 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <178/2280>] - Data(s): 0.000 (0.397) - Batch(s): 2.594 
(2.196) - AE Loss: 543994.000 (735706.312) - AE Rec Loss: 3.689 (4.989) - Disc 
Loss: 0.000 (0.000) - 8.60 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 1.086 
(2.135) - AE Loss: 169887.250 (734630.062) - AE Rec Loss: 1.152 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.71 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 1.087 
(2.135) - AE Loss: 603756.312 (734630.062) - AE Rec Loss: 4.094 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.71 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 1.089 
(2.135) - AE Loss: 1594199.000 (734630.062) - AE Rec Loss: 10.811 (4.982) - Disc
Loss: 0.000 (0.000) - 8.75 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.075 
(2.135) - AE Loss: 1908514.625 (734630.062) - AE Rec Loss: 12.943 (4.982) - Disc
Loss: 0.000 (0.000) - 8.70 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.000 (0.376) - Batch(s): 1.090 
(2.135) - AE Loss: 73309.891 (734630.062) - AE Rec Loss: 0.497 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.73 m remaining

[Epoch <000/100>: Step <179/2280>] - Data(s): 0.001 (0.376) - Batch(s): 1.084 
(2.135) - AE Loss: 115741.602 (734630.062) - AE Rec Loss: 0.785 (4.982) - Disc 
Loss: 0.000 (0.000) - 8.79 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.514 
(2.101) - AE Loss: 1412673.250 (726112.438) - AE Rec Loss: 9.580 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.515 
(2.101) - AE Loss: 1457677.750 (726112.438) - AE Rec Loss: 9.886 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.503 
(2.101) - AE Loss: 83741.039 (726112.438) - AE Rec Loss: 0.568 (4.924) - Disc 
Loss: 0.000 (0.000) - 8.97 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.518 
(2.101) - AE Loss: 293959.312 (726112.438) - AE Rec Loss: 1.994 (4.924) - Disc 
Loss: 0.000 (0.000) - 9.00 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.322 (0.360) - Batch(s): 1.516 
(2.101) - AE Loss: 209901.672 (726112.438) - AE Rec Loss: 1.423 (4.924) - Disc 
Loss: 0.000 (0.000) - 9.02 m remaining

[Epoch <000/100>: Step <180/2280>] - Data(s): 0.000 (0.360) - Batch(s): 1.513 
(2.101) - AE Loss: 203957.719 (726112.438) - AE Rec Loss: 1.383 (4.924) - Disc 
Loss: 0.000 (0.000) - 9.06 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 1.334 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 169194.719 (731306.812) - AE Rec Loss: 1.147 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 162178.156 (731306.812) - AE Rec Loss: 1.100 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.48 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 114448.664 (731306.812) - AE Rec Loss: 0.776 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.41 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 1678430.625 (731306.812) - AE Rec Loss: 11.383 (4.959) - Disc
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.001 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 156334.875 (731306.812) - AE Rec Loss: 1.060 (4.959) - Disc 
Loss: 0.000 (0.000) - 13.39 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 0.000 (0.348) - Batch(s): 23.083 
(3.011) - AE Loss: 1677681.500 (731306.812) - AE Rec Loss: 11.378 (4.959) - Disc
Loss: 0.000 (0.000) - 13.44 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.004 
(2.919) - AE Loss: 136867.547 (721530.188) - AE Rec Loss: 0.928 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.53 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.015 
(2.919) - AE Loss: 107206.234 (721530.188) - AE Rec Loss: 0.727 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.62 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.016 
(2.919) - AE Loss: 1412562.250 (721530.188) - AE Rec Loss: 9.580 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.54 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.020 
(2.919) - AE Loss: 1502513.500 (721530.188) - AE Rec Loss: 10.190 (4.893) - Disc
Loss: 0.000 (0.000) - 13.55 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.019 
(2.919) - AE Loss: 264501.656 (721530.188) - AE Rec Loss: 1.794 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.58 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (0.333) - Batch(s): 1.017 
(2.919) - AE Loss: 126109.023 (721530.188) - AE Rec Loss: 0.855 (4.893) - Disc 
Loss: 0.000 (0.000) - 13.54 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:41:33,648[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,671[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,911[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:33,988[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:34,024[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:41:34,031[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:41:35,893[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:35,904[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:36,138[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:36,243[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:36,253[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:41:36,290[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,344[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,399[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,635[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,738[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,759[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:41:36,778[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:41:36,780[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:41:36,782[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:41:36,782[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:41:36,782[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
[[36m2023-11-29 03:41:36,786[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Preparing model 
=> Instantiating the optimizer 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(train_dataset) = 54706
[[36m2023-11-29 03:41:36,789[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Preparing opt_disc 
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(train_dataloader) = 2279
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1 on node 11
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
=> Preparing criterion 
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 8

Reached 1.4 on node 8Reached 1.4 on node 9

Reached 2 on node 8Reached 2 on node 9

Reached 1.3 on node 6
Reached 1.3 on node 10
Reached 1.4 on node 6
Reached 1.4 on node 10Reached 3 on node 8Reached 3 on node 9


Reached 2 on node 6
Reached 5 on node 8Reached 5 on node 9Reached 2 on node 10


Reached end on node 8Reached end on node 9Reached 3 on node 6


Reached 3 on node 10
Reached 5 on node 6
Reached 5 on node 10Reached 1.3 on node 11
Reached 1.3 on node 7
Reached end on node 6

Reached 1.4 on node 11Reached end on node 10Reached 1.4 on node 7


Reached 2 on node 11
Reached 2 on node 7
Reached 3 on node 11Reached 3 on node 7

Reached 5 on node 7
Reached 5 on node 11
Reached end on node 7
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 7Reached 1.4 on node 9

Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 7
Reached 1.4 on node 8
Reached 2 on node 7Reached 2 on node 8

Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1 on node 10Reached 3 on node 6

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 7
Reached 5 on node 6Reached 1.4 on node 10

Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 1 on node 8
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11Reached 1 on node 8

Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9Reached 1.4 on node 7

Reached 3 on node 9
Reached 2 on node 7Reached 3 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached end on node 6Reached 3 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 11Reached 5 on node 7

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8Reached 1.4 on node 6

Reached 2 on node 6Reached 2 on node 8

Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10Reached 1 on node 9

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1 on node 7
Reached end on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 9
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <181/2280>] - Data(s): 11.468 (6.666) - Batch(s): 13.189 
(13.302) - AE Loss: 1677677.250 (835069.188) - AE Rec Loss: 11.377 (5.663) - 
Disc Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 11.837 (6.666) - Batch(s): 13.173 
(13.302) - AE Loss: 1678596.500 (835069.188) - AE Rec Loss: 11.384 (5.663) - 
Disc Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 3.126 (6.666) - Batch(s): 13.162 
(13.302) - AE Loss: 156647.375 (835069.188) - AE Rec Loss: 1.062 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 6.061 (6.666) - Batch(s): 13.178 
(13.302) - AE Loss: 168977.641 (835069.188) - AE Rec Loss: 1.146 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 4.221 (6.666) - Batch(s): 13.167 
(13.302) - AE Loss: 162142.406 (835069.188) - AE Rec Loss: 1.100 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 5.278 (6.666) - Batch(s): 13.194 
(13.302) - AE Loss: 114973.211 (835069.188) - AE Rec Loss: 0.780 (5.663) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (3.333) - Batch(s): 1.175 
(7.213) - AE Loss: 122043.094 (676377.688) - AE Rec Loss: 0.828 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (3.333) - Batch(s): 1.178 
(7.213) - AE Loss: 270318.219 (676377.688) - AE Rec Loss: 1.833 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (3.333) - Batch(s): 1.173 
(7.213) - AE Loss: 108659.352 (676377.688) - AE Rec Loss: 0.737 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.164 
(7.213) - AE Loss: 132883.391 (676377.688) - AE Rec Loss: 0.901 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (3.333) - Batch(s): 1.174 
(7.213) - AE Loss: 1416123.500 (676377.688) - AE Rec Loss: 9.604 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (3.333) - Batch(s): 1.181 
(7.213) - AE Loss: 1508072.625 (676377.688) - AE Rec Loss: 10.227 (4.587) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <183/2280>] - Data(s): 0.443 (2.326) - Batch(s): 3.966 
(6.113) - AE Loss: 127416.641 (603449.812) - AE Rec Loss: 0.864 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.326) - Batch(s): 3.968 
(6.113) - AE Loss: 1537558.125 (603449.812) - AE Rec Loss: 10.427 (4.092) - Disc
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 3.300 (2.326) - Batch(s): 3.967 
(6.113) - AE Loss: 1643084.250 (603449.812) - AE Rec Loss: 11.143 (4.092) - Disc
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.963 
(6.113) - AE Loss: 114446.828 (603449.812) - AE Rec Loss: 0.776 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.326) - Batch(s): 3.968 
(6.113) - AE Loss: 222758.250 (603449.812) - AE Rec Loss: 1.511 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.59 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.326) - Batch(s): 3.968 
(6.113) - AE Loss: 363251.188 (603449.812) - AE Rec Loss: 2.463 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.60 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.140 
(4.858) - AE Loss: 75720.969 (572650.438) - AE Rec Loss: 0.514 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.141 
(4.858) - AE Loss: 1515360.750 (572650.438) - AE Rec Loss: 10.277 (3.884) - Disc
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.143 
(4.858) - AE Loss: 1465794.500 (572650.438) - AE Rec Loss: 9.941 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.138 
(4.858) - AE Loss: 117362.570 (572650.438) - AE Rec Loss: 0.796 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.128 
(4.858) - AE Loss: 395208.438 (572650.438) - AE Rec Loss: 2.680 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.745) - Batch(s): 1.146 
(4.858) - AE Loss: 142266.281 (572650.438) - AE Rec Loss: 0.965 (3.884) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.245 
(4.123) - AE Loss: 1549555.125 (633130.000) - AE Rec Loss: 10.509 (4.294) - Disc
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.001 (1.396) - Batch(s): 1.242 
(4.123) - AE Loss: 1630778.500 (633130.000) - AE Rec Loss: 11.059 (4.294) - Disc
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.247 
(4.123) - AE Loss: 1362995.000 (633130.000) - AE Rec Loss: 9.243 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.243 
(4.123) - AE Loss: 359138.594 (633130.000) - AE Rec Loss: 2.436 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.240 
(4.123) - AE Loss: 113161.555 (633130.000) - AE Rec Loss: 0.767 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.396) - Batch(s): 1.230 
(4.123) - AE Loss: 128447.555 (633130.000) - AE Rec Loss: 0.871 (4.294) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.184) - Batch(s): 2.107 
(3.778) - AE Loss: 95731.672 (554779.750) - AE Rec Loss: 0.649 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.106 
(3.778) - AE Loss: 63375.172 (554779.750) - AE Rec Loss: 0.430 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.184) - Batch(s): 2.106 
(3.778) - AE Loss: 114449.172 (554779.750) - AE Rec Loss: 0.776 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.107 
(3.778) - AE Loss: 179023.734 (554779.750) - AE Rec Loss: 1.214 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 1.449 (1.184) - Batch(s): 2.108 
(3.778) - AE Loss: 119005.406 (554779.750) - AE Rec Loss: 0.807 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.184) - Batch(s): 2.107 
(3.778) - AE Loss: 178179.297 (554779.750) - AE Rec Loss: 1.208 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.46 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.118 
(3.391) - AE Loss: 124014.641 (598700.375) - AE Rec Loss: 0.841 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.120 
(3.391) - AE Loss: 119609.727 (598700.375) - AE Rec Loss: 0.811 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.001 (1.015) - Batch(s): 1.120 
(3.391) - AE Loss: 1471624.875 (598700.375) - AE Rec Loss: 9.980 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.107 
(3.391) - AE Loss: 247192.344 (598700.375) - AE Rec Loss: 1.676 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (1.015) - Batch(s): 1.124 
(3.391) - AE Loss: 340986.906 (598700.375) - AE Rec Loss: 2.312 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.001 (1.015) - Batch(s): 1.116 
(3.391) - AE Loss: 94475.031 (598700.375) - AE Rec Loss: 0.641 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.107 
(3.100) - AE Loss: 1508033.000 (596513.500) - AE Rec Loss: 10.227 (4.045) - Disc
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.108 
(3.100) - AE Loss: 1734286.250 (596513.500) - AE Rec Loss: 11.761 (4.045) - Disc
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.110 
(3.100) - AE Loss: 1818859.250 (596513.500) - AE Rec Loss: 12.335 (4.045) - Disc
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.096 
(3.100) - AE Loss: 320994.594 (596513.500) - AE Rec Loss: 2.177 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.001 (0.888) - Batch(s): 1.105 
(3.100) - AE Loss: 127420.273 (596513.500) - AE Rec Loss: 0.864 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.888) - Batch(s): 1.112 
(3.100) - AE Loss: 230705.109 (596513.500) - AE Rec Loss: 1.565 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.756 
(2.946) - AE Loss: 134171.297 (600716.812) - AE Rec Loss: 0.910 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.758 
(2.946) - AE Loss: 187626.766 (600716.812) - AE Rec Loss: 1.272 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 1.103 (0.799) - Batch(s): 1.757 
(2.946) - AE Loss: 134915.125 (600716.812) - AE Rec Loss: 0.915 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.759 
(2.946) - AE Loss: 82641.117 (600716.812) - AE Rec Loss: 0.560 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.001 (0.799) - Batch(s): 1.759 
(2.946) - AE Loss: 1679697.250 (600716.812) - AE Rec Loss: 11.391 (4.074) - Disc
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.799) - Batch(s): 1.762 
(2.946) - AE Loss: 1545714.250 (600716.812) - AE Rec Loss: 10.483 (4.074) - Disc
Loss: 0.000 (0.000) - 5.20 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.054 
(2.753) - AE Loss: 106920.312 (636318.688) - AE Rec Loss: 0.725 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.720) - Batch(s): 1.054 
(2.753) - AE Loss: 181526.266 (636318.688) - AE Rec Loss: 1.231 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.059 
(2.753) - AE Loss: 573537.312 (636318.688) - AE Rec Loss: 3.890 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.056 
(2.753) - AE Loss: 257530.578 (636318.688) - AE Rec Loss: 1.746 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.720) - Batch(s): 1.044 
(2.753) - AE Loss: 106852.312 (636318.688) - AE Rec Loss: 0.725 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.40 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.720) - Batch(s): 1.052 
(2.753) - AE Loss: 1892105.250 (636318.688) - AE Rec Loss: 12.832 (4.315) - Disc
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.629 
(2.997) - AE Loss: 174042.625 (615716.562) - AE Rec Loss: 1.180 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.629 
(2.997) - AE Loss: 313754.969 (615716.562) - AE Rec Loss: 2.128 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.41 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.616 
(2.997) - AE Loss: 104830.531 (615716.562) - AE Rec Loss: 0.711 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.107 (0.693) - Batch(s): 5.630 
(2.997) - AE Loss: 70189.844 (615716.562) - AE Rec Loss: 0.476 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.693) - Batch(s): 5.634 
(2.997) - AE Loss: 240606.125 (615716.562) - AE Rec Loss: 1.632 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.001 (0.693) - Batch(s): 5.626 
(2.997) - AE Loss: 98424.625 (615716.562) - AE Rec Loss: 0.667 (4.176) - Disc 
Loss: 0.000 (0.000) - 6.41 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.294 
(2.851) - AE Loss: 120630.961 (587467.250) - AE Rec Loss: 0.818 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.295 
(2.851) - AE Loss: 265840.031 (587467.250) - AE Rec Loss: 1.803 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.296 
(2.851) - AE Loss: 349713.062 (587467.250) - AE Rec Loss: 2.372 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.295 
(2.851) - AE Loss: 113121.469 (587467.250) - AE Rec Loss: 0.767 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.294 
(2.851) - AE Loss: 317759.469 (587467.250) - AE Rec Loss: 2.155 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.294 
(2.851) - AE Loss: 1341377.500 (587467.250) - AE Rec Loss: 9.097 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.64 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.149 
(2.716) - AE Loss: 328174.938 (594993.125) - AE Rec Loss: 2.226 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.150 
(2.716) - AE Loss: 108219.500 (594993.125) - AE Rec Loss: 0.734 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.83 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.139 
(2.716) - AE Loss: 219412.906 (594993.125) - AE Rec Loss: 1.488 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.149 
(2.716) - AE Loss: 497876.000 (594993.125) - AE Rec Loss: 3.376 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.156 
(2.716) - AE Loss: 1552817.250 (594993.125) - AE Rec Loss: 10.531 (4.035) - Disc
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.594) - Batch(s): 1.152 
(2.716) - AE Loss: 140655.172 (594993.125) - AE Rec Loss: 0.954 (4.035) - Disc 
Loss: 0.000 (0.000) - 6.84 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 4.250 
(2.814) - AE Loss: 270020.719 (583840.188) - AE Rec Loss: 1.831 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.594) - Batch(s): 4.251 
(2.814) - AE Loss: 98062.953 (583840.188) - AE Rec Loss: 0.665 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 4.238 
(2.814) - AE Loss: 658077.500 (583840.188) - AE Rec Loss: 4.463 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 4.249 
(2.814) - AE Loss: 256475.469 (583840.188) - AE Rec Loss: 1.739 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.594) - Batch(s): 4.256 
(2.814) - AE Loss: 102414.344 (583840.188) - AE Rec Loss: 0.695 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.594) - Batch(s): 4.252 
(2.814) - AE Loss: 1432390.875 (583840.188) - AE Rec Loss: 9.714 (3.959) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.001 (0.574) - Batch(s): 3.947 
(2.887) - AE Loss: 1464859.500 (583514.062) - AE Rec Loss: 9.934 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.947 
(2.887) - AE Loss: 1412935.125 (583514.062) - AE Rec Loss: 9.582 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.001 (0.574) - Batch(s): 3.947 
(2.887) - AE Loss: 796947.688 (583514.062) - AE Rec Loss: 5.405 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.947 
(2.887) - AE Loss: 193979.531 (583514.062) - AE Rec Loss: 1.316 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.946 
(2.887) - AE Loss: 1653892.000 (583514.062) - AE Rec Loss: 11.216 (3.957) - Disc
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.574) - Batch(s): 3.947 
(2.887) - AE Loss: 136959.391 (583514.062) - AE Rec Loss: 0.929 (3.957) - Disc 
Loss: 0.000 (0.000) - 8.27 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.093 
(2.772) - AE Loss: 199111.781 (580215.438) - AE Rec Loss: 1.350 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.095 
(2.772) - AE Loss: 74853.094 (580215.438) - AE Rec Loss: 0.508 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.44 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.092 
(2.772) - AE Loss: 1582495.625 (580215.438) - AE Rec Loss: 10.732 (3.935) - Disc
Loss: 0.000 (0.000) - 8.44 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.096 
(2.772) - AE Loss: 391305.875 (580215.438) - AE Rec Loss: 2.654 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.082 
(2.772) - AE Loss: 218686.625 (580215.438) - AE Rec Loss: 1.483 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.538) - Batch(s): 1.099 
(2.772) - AE Loss: 65168.457 (580215.438) - AE Rec Loss: 0.442 (3.935) - Disc 
Loss: 0.000 (0.000) - 8.45 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.833 
(2.824) - AE Loss: 139745.016 (584446.375) - AE Rec Loss: 0.948 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.818 
(2.824) - AE Loss: 170524.375 (584446.375) - AE Rec Loss: 1.156 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.836 
(2.824) - AE Loss: 3202753.000 (584446.375) - AE Rec Loss: 21.720 (3.964) - Disc
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.830 
(2.824) - AE Loss: 1608022.500 (584446.375) - AE Rec Loss: 10.905 (3.964) - Disc
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.830 
(2.824) - AE Loss: 1598274.875 (584446.375) - AE Rec Loss: 10.839 (3.964) - Disc
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.523) - Batch(s): 3.831 
(2.824) - AE Loss: 73172.555 (584446.375) - AE Rec Loss: 0.496 (3.964) - Disc 
Loss: 0.000 (0.000) - 9.10 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.411 
(2.742) - AE Loss: 166444.500 (582335.688) - AE Rec Loss: 1.129 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.33 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.412 
(2.742) - AE Loss: 776285.250 (582335.688) - AE Rec Loss: 5.265 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.32 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.412 
(2.742) - AE Loss: 123622.438 (582335.688) - AE Rec Loss: 0.838 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.32 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.411 
(2.742) - AE Loss: 140139.984 (582335.688) - AE Rec Loss: 0.950 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.33 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.411 
(2.742) - AE Loss: 336784.531 (582335.688) - AE Rec Loss: 2.284 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.32 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.410 
(2.742) - AE Loss: 269419.062 (582335.688) - AE Rec Loss: 1.827 (3.949) - Disc 
Loss: 0.000 (0.000) - 9.32 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.051 
(2.651) - AE Loss: 683062.250 (606794.688) - AE Rec Loss: 4.632 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.049 
(2.651) - AE Loss: 160839.078 (606794.688) - AE Rec Loss: 1.091 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.056 
(2.651) - AE Loss: 260439.266 (606794.688) - AE Rec Loss: 1.766 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.040 
(2.651) - AE Loss: 1689021.375 (606794.688) - AE Rec Loss: 11.454 (4.115) - Disc
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.054 
(2.651) - AE Loss: 313113.875 (606794.688) - AE Rec Loss: 2.123 (4.115) - Disc 
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.469) - Batch(s): 1.052 
(2.651) - AE Loss: 1568135.375 (606794.688) - AE Rec Loss: 10.635 (4.115) - Disc
Loss: 0.000 (0.000) - 9.48 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.661 
(2.694) - AE Loss: 295040.156 (618744.250) - AE Rec Loss: 2.001 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.661 
(2.694) - AE Loss: 253947.234 (618744.250) - AE Rec Loss: 1.722 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.660 
(2.694) - AE Loss: 1893249.625 (618744.250) - AE Rec Loss: 12.839 (4.196) - Disc
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.648 
(2.694) - AE Loss: 299247.031 (618744.250) - AE Rec Loss: 2.029 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.667 
(2.694) - AE Loss: 209629.594 (618744.250) - AE Rec Loss: 1.422 (4.196) - Disc 
Loss: 0.000 (0.000) - 10.09 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.458) - Batch(s): 3.663 
(2.694) - AE Loss: 3345719.500 (618744.250) - AE Rec Loss: 22.690 (4.196) - Disc
Loss: 0.000 (0.000) - 10.09 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:43:07,565[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,663[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,853[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,855[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,874[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:43:07,974[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:43:09,759[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:09,859[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:10,094[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:10,104[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:43:10,119[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,229[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:43:10,246[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,312[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,626[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,644[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:43:10,646[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:43:10,721[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:43:10,723[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:43:10,723[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:43:10,723[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
[[36m2023-11-29 03:43:10,726[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
len(train_dataloader) = 2279
[[36m2023-11-29 03:43:10,726[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Mixed precision: no
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(train_dataloader) = 2279
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
[[36m2023-11-29 03:43:10,733[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Running in inference mode: False
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:50:44,120[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,123[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,323[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,570[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,570[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:50:44,988[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:50:46,309[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,335[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,549[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,730[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:50:46,752[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:50:46,793[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:46,806[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:47,045[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:47,162[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:50:47,206[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:47,248[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:50:47,566[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:50:47,569[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
[[36m2023-11-29 03:50:47,575[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:50:47,575[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:50:47,575[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 03:50:47,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:50:47,579[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10Reached 3 on node 7

Reached 5 on node 10
Reached 5 on node 7
Reached end on node 7
Reached end on node 10
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 7
Reached 5 on node 7Reached 1.3 on node 11
Reached 5 on node 6
Reached end on node 7

Reached 1.4 on node 11
Reached end on node 6
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing criterion 
Reached 1.3 on node 10
Reached 1.4 on node 10
=> Preparing opt_ae 
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 10

Reached 1.4 on node 9Reached 1.4 on node 10

Reached 2 on node 9Reached 2 on node 10

Reached 3 on node 9Reached 3 on node 10

Reached 1.3 on node 7Reached 1.3 on node 8

Reached 5 on node 9
Reached 1.4 on node 8Reached 1.4 on node 7Reached 5 on node 10


Reached end on node 9
Reached 2 on node 7Reached 2 on node 8

Reached end on node 10
Reached 3 on node 8Reached 3 on node 7

Reached 5 on node 7
Reached 5 on node 8
Reached end on node 7
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 3 on node 11
Reached 2 on node 6
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
Loaded checkpoint at epoch 0 and step 181
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 6
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7Reached 1.4 on node 6

Reached 2 on node 7Reached 2 on node 6

Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9Reached 1 on node 6

Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 1.4 on node 7Reached 2 on node 9

Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 6
Reached 1 on node 9Reached 1 on node 7

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 3 on node 6Reached 2 on node 10Reached 1.4 on node 7
Reached 1.4 on node 9Reached 1 on node 11



Reached 3 on node 6Reached 2 on node 9Reached 2 on node 7


Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 11Reached 1 on node 8

Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7Reached 1 on node 9

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7Reached 2 on node 9

Reached 1 on node 11
Reached 3 on node 7
Reached 3 on node 7
Reached 1 on node 8
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 11
Reached 3 on node 7
Reached 2 on node 11
Reached 5 on node 7Reached 1.4 on node 8
Reached 1 on node 10

Reached 2 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11Reached 1.4 on node 8

Reached 2 on node 8
Reached 2 on node 11
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1 on node 11Reached 3 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10Reached 1 on node 11

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 8
Reached end on node 9
Reached end on node 11
Reached end on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 1 on node 9Reached 2 on node 6

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 9
Reached end on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <181/2280>] - Data(s): 5.868 (5.574) - Batch(s): 10.071 
(9.963) - AE Loss: 169762.844 (835197.438) - AE Rec Loss: 1.151 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 5.736 (5.574) - Batch(s): 9.876 
(9.963) - AE Loss: 114689.742 (835197.438) - AE Rec Loss: 0.778 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 3.155 (5.574) - Batch(s): 9.869 
(9.963) - AE Loss: 162360.531 (835197.438) - AE Rec Loss: 1.101 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 3.499 (5.574) - Batch(s): 9.871 
(9.963) - AE Loss: 157135.953 (835197.438) - AE Rec Loss: 1.066 (5.664) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 7.764 (5.574) - Batch(s): 10.022 
(9.963) - AE Loss: 1678423.000 (835197.438) - AE Rec Loss: 11.383 (5.664) - Disc
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <181/2280>] - Data(s): 8.360 (5.574) - Batch(s): 9.887 
(9.963) - AE Loss: 1678075.000 (835197.438) - AE Rec Loss: 11.380 (5.664) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.349 
(5.624) - AE Loss: 269559.875 (676363.688) - AE Rec Loss: 1.828 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.23 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.349 
(5.624) - AE Loss: 1416292.500 (676363.688) - AE Rec Loss: 9.605 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.26 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.001 (2.787) - Batch(s): 1.349 
(5.624) - AE Loss: 108608.523 (676363.688) - AE Rec Loss: 0.737 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.350 
(5.624) - AE Loss: 121770.836 (676363.688) - AE Rec Loss: 0.826 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.341 
(5.624) - AE Loss: 132165.562 (676363.688) - AE Rec Loss: 0.896 (4.587) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <182/2280>] - Data(s): 0.000 (2.787) - Batch(s): 1.356 
(5.624) - AE Loss: 1507296.000 (676363.688) - AE Rec Loss: 10.222 (4.587) - Disc
Loss: 0.000 (0.000) - 2.23 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.083) - Batch(s): 6.699 
(5.959) - AE Loss: 362843.062 (603447.812) - AE Rec Loss: 2.461 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 6.060 (2.083) - Batch(s): 6.699 
(5.959) - AE Loss: 1642282.250 (603447.812) - AE Rec Loss: 11.137 (4.092) - Disc
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.699 
(5.959) - AE Loss: 223244.469 (603447.812) - AE Rec Loss: 1.514 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 2.019 (2.083) - Batch(s): 6.699 
(5.959) - AE Loss: 128614.898 (603447.812) - AE Rec Loss: 0.872 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.55 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.001 (2.083) - Batch(s): 6.699 
(5.959) - AE Loss: 114276.555 (603447.812) - AE Rec Loss: 0.775 (4.092) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <183/2280>] - Data(s): 0.000 (2.083) - Batch(s): 6.700 
(5.959) - AE Loss: 1537217.000 (603447.812) - AE Rec Loss: 10.425 (4.092) - Disc
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.102 
(4.734) - AE Loss: 117042.289 (572640.938) - AE Rec Loss: 0.794 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.105 
(4.734) - AE Loss: 1465644.000 (572640.938) - AE Rec Loss: 9.940 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.106 
(4.734) - AE Loss: 75455.094 (572640.938) - AE Rec Loss: 0.512 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.76 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.105 
(4.734) - AE Loss: 1515760.125 (572640.938) - AE Rec Loss: 10.279 (3.883) - Disc
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.110 
(4.734) - AE Loss: 141845.547 (572640.938) - AE Rec Loss: 0.962 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <184/2280>] - Data(s): 0.000 (1.562) - Batch(s): 1.094 
(4.734) - AE Loss: 395248.156 (572640.938) - AE Rec Loss: 2.680 (3.883) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.165 
(4.011) - AE Loss: 112981.617 (633100.562) - AE Rec Loss: 0.766 (4.293) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.166 
(4.011) - AE Loss: 1549080.000 (633100.562) - AE Rec Loss: 10.505 (4.293) - Disc
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.168 
(4.011) - AE Loss: 1630745.250 (633100.562) - AE Rec Loss: 11.059 (4.293) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.155 
(4.011) - AE Loss: 128047.633 (633100.562) - AE Rec Loss: 0.868 (4.293) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.167 
(4.011) - AE Loss: 359369.562 (633100.562) - AE Rec Loss: 2.437 (4.293) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <185/2280>] - Data(s): 0.000 (1.250) - Batch(s): 1.172 
(4.011) - AE Loss: 1363858.375 (633100.562) - AE Rec Loss: 9.249 (4.293) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 177799.000 (554740.875) - AE Rec Loss: 1.206 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 114062.805 (554740.875) - AE Rec Loss: 0.774 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.000 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 63357.559 (554740.875) - AE Rec Loss: 0.430 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.786 
(3.796) - AE Loss: 95084.141 (554740.875) - AE Rec Loss: 0.645 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 0.001 (1.071) - Batch(s): 2.785 
(3.796) - AE Loss: 179047.781 (554740.875) - AE Rec Loss: 1.214 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <186/2280>] - Data(s): 2.152 (1.071) - Batch(s): 2.788 
(3.796) - AE Loss: 118727.883 (554740.875) - AE Rec Loss: 0.805 (3.762) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.123 
(3.409) - AE Loss: 247159.125 (598665.938) - AE Rec Loss: 1.676 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.134 
(3.409) - AE Loss: 94848.734 (598665.938) - AE Rec Loss: 0.643 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.134 
(3.409) - AE Loss: 1471398.000 (598665.938) - AE Rec Loss: 9.979 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.135 
(3.409) - AE Loss: 118433.164 (598665.938) - AE Rec Loss: 0.803 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.139 
(3.409) - AE Loss: 341424.875 (598665.938) - AE Rec Loss: 2.315 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <187/2280>] - Data(s): 0.000 (0.918) - Batch(s): 1.136 
(3.409) - AE Loss: 123879.258 (598665.938) - AE Rec Loss: 0.840 (4.060) - Disc 
Loss: 0.000 (0.000) - 4.73 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.264 
(3.135) - AE Loss: 320962.562 (596501.688) - AE Rec Loss: 2.177 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.98 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 126832.680 (596501.688) - AE Rec Loss: 0.860 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.001 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 1509137.500 (596501.688) - AE Rec Loss: 10.234 (4.045) - Disc
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 1818431.875 (596501.688) - AE Rec Loss: 12.332 (4.045) - Disc
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.278 
(3.135) - AE Loss: 231693.484 (596501.688) - AE Rec Loss: 1.571 (4.045) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <188/2280>] - Data(s): 0.000 (0.804) - Batch(s): 1.275 
(3.135) - AE Loss: 1733834.000 (596501.688) - AE Rec Loss: 11.758 (4.045) - Disc
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.346 
(2.929) - AE Loss: 133455.359 (600690.312) - AE Rec Loss: 0.905 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.19 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 1546710.125 (600690.312) - AE Rec Loss: 10.489 (4.074) - Disc
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.348 
(2.929) - AE Loss: 83468.555 (600690.312) - AE Rec Loss: 0.566 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.18 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 1680306.750 (600690.312) - AE Rec Loss: 11.395 (4.074) - Disc
Loss: 0.000 (0.000) - 5.19 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 133901.031 (600690.312) - AE Rec Loss: 0.908 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <189/2280>] - Data(s): 0.000 (0.714) - Batch(s): 1.347 
(2.929) - AE Loss: 186880.094 (600690.312) - AE Rec Loss: 1.267 (4.074) - Disc 
Loss: 0.000 (0.000) - 5.23 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.301 
(2.760) - AE Loss: 257794.141 (636311.062) - AE Rec Loss: 1.748 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.302 
(2.760) - AE Loss: 1892047.750 (636311.062) - AE Rec Loss: 12.831 (4.315) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.643) - Batch(s): 1.306 
(2.760) - AE Loss: 574658.125 (636311.062) - AE Rec Loss: 3.897 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.643) - Batch(s): 1.305 
(2.760) - AE Loss: 107320.562 (636311.062) - AE Rec Loss: 0.728 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.001 (0.643) - Batch(s): 1.290 
(2.760) - AE Loss: 105848.875 (636311.062) - AE Rec Loss: 0.718 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <190/2280>] - Data(s): 0.000 (0.643) - Batch(s): 1.303 
(2.760) - AE Loss: 182684.750 (636311.062) - AE Rec Loss: 1.239 (4.315) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.263 
(2.619) - AE Loss: 99091.188 (615732.562) - AE Rec Loss: 0.672 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.263 
(2.619) - AE Loss: 173805.453 (615732.562) - AE Rec Loss: 1.179 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.68 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.267 
(2.619) - AE Loss: 240924.031 (615732.562) - AE Rec Loss: 1.634 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.262 
(2.619) - AE Loss: 69376.477 (615732.562) - AE Rec Loss: 0.470 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.251 
(2.619) - AE Loss: 105867.180 (615732.562) - AE Rec Loss: 0.718 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <191/2280>] - Data(s): 0.000 (0.585) - Batch(s): 1.263 
(2.619) - AE Loss: 313277.281 (615732.562) - AE Rec Loss: 2.125 (4.176) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.000 (0.568) - Batch(s): 3.339 
(2.674) - AE Loss: 120306.039 (587502.250) - AE Rec Loss: 0.816 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 3.339 
(2.674) - AE Loss: 351346.312 (587502.250) - AE Rec Loss: 2.383 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 3.337 
(2.674) - AE Loss: 265793.812 (587502.250) - AE Rec Loss: 1.803 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 3.336 
(2.674) - AE Loss: 318197.375 (587502.250) - AE Rec Loss: 2.158 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 1.877 (0.568) - Batch(s): 3.337 
(2.674) - AE Loss: 1341463.250 (587502.250) - AE Rec Loss: 9.097 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <192/2280>] - Data(s): 0.001 (0.568) - Batch(s): 3.338 
(2.674) - AE Loss: 113640.492 (587502.250) - AE Rec Loss: 0.771 (3.984) - Disc 
Loss: 0.000 (0.000) - 6.25 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.001 (0.524) - Batch(s): 1.204 
(2.557) - AE Loss: 332289.312 (595288.125) - AE Rec Loss: 2.253 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.49 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.192 
(2.557) - AE Loss: 224166.547 (595288.125) - AE Rec Loss: 1.520 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.50 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.203 
(2.557) - AE Loss: 143677.562 (595288.125) - AE Rec Loss: 0.974 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.203 
(2.557) - AE Loss: 114622.562 (595288.125) - AE Rec Loss: 0.777 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.204 
(2.557) - AE Loss: 499278.438 (595288.125) - AE Rec Loss: 3.386 (4.037) - Disc 
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <193/2280>] - Data(s): 0.000 (0.524) - Batch(s): 1.207 
(2.557) - AE Loss: 1557449.125 (595288.125) - AE Rec Loss: 10.562 (4.037) - Disc
Loss: 0.000 (0.000) - 6.46 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.246 
(2.459) - AE Loss: 273223.938 (584414.188) - AE Rec Loss: 1.853 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.70 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 1.235 
(2.459) - AE Loss: 660157.000 (584414.188) - AE Rec Loss: 4.477 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.71 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 1.244 
(2.459) - AE Loss: 257829.922 (584414.188) - AE Rec Loss: 1.749 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 1.248 
(2.459) - AE Loss: 110139.469 (584414.188) - AE Rec Loss: 0.747 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.000 (0.487) - Batch(s): 1.245 
(2.459) - AE Loss: 1432860.875 (584414.188) - AE Rec Loss: 9.717 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <194/2280>] - Data(s): 0.001 (0.487) - Batch(s): 1.246 
(2.459) - AE Loss: 104786.109 (584414.188) - AE Rec Loss: 0.711 (3.963) - Disc 
Loss: 0.000 (0.000) - 6.67 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.775 
(2.476) - AE Loss: 1471267.625 (584378.875) - AE Rec Loss: 9.978 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.775 
(2.476) - AE Loss: 800495.250 (584378.875) - AE Rec Loss: 5.429 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.777 
(2.476) - AE Loss: 1415156.250 (584378.875) - AE Rec Loss: 9.597 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.19 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.776 
(2.476) - AE Loss: 1657670.875 (584378.875) - AE Rec Loss: 11.242 (3.963) - Disc
Loss: 0.000 (0.000) - 7.16 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.777 
(2.476) - AE Loss: 199853.094 (584378.875) - AE Rec Loss: 1.355 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.16 m remaining

[Epoch <000/100>: Step <195/2280>] - Data(s): 0.000 (0.466) - Batch(s): 2.777 
(2.476) - AE Loss: 140364.234 (584378.875) - AE Rec Loss: 0.952 (3.963) - Disc 
Loss: 0.000 (0.000) - 7.15 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.127 
(2.389) - AE Loss: 192178.125 (580707.062) - AE Rec Loss: 1.303 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.37 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.114 
(2.389) - AE Loss: 212529.500 (580707.062) - AE Rec Loss: 1.441 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.126 
(2.389) - AE Loss: 73242.211 (580707.062) - AE Rec Loss: 0.497 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.125 
(2.389) - AE Loss: 380029.906 (580707.062) - AE Rec Loss: 2.577 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.124 
(2.389) - AE Loss: 1582155.750 (580707.062) - AE Rec Loss: 10.730 (3.938) - Disc
Loss: 0.000 (0.000) - 7.34 m remaining

[Epoch <000/100>: Step <196/2280>] - Data(s): 0.000 (0.437) - Batch(s): 1.128 
(2.389) - AE Loss: 64585.672 (580707.062) - AE Rec Loss: 0.438 (3.938) - Disc 
Loss: 0.000 (0.000) - 7.35 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 1606908.000 (584585.625) - AE Rec Loss: 10.898 (3.964) - Disc
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.264 
(2.319) - AE Loss: 3202956.500 (584585.625) - AE Rec Loss: 21.721 (3.964) - Disc
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.411) - Batch(s): 1.262 
(2.319) - AE Loss: 130786.109 (584585.625) - AE Rec Loss: 0.887 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.411) - Batch(s): 1.261 
(2.319) - AE Loss: 1592812.125 (584585.625) - AE Rec Loss: 10.802 (3.964) - Disc
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.000 (0.411) - Batch(s): 1.252 
(2.319) - AE Loss: 164351.594 (584585.625) - AE Rec Loss: 1.115 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <197/2280>] - Data(s): 0.001 (0.411) - Batch(s): 1.263 
(2.319) - AE Loss: 71570.562 (584585.625) - AE Rec Loss: 0.485 (3.964) - Disc 
Loss: 0.000 (0.000) - 7.55 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.389) - Batch(s): 1.412 
(2.265) - AE Loss: 132070.656 (582029.438) - AE Rec Loss: 0.896 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.389) - Batch(s): 1.412 
(2.265) - AE Loss: 769462.625 (582029.438) - AE Rec Loss: 5.218 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.78 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.413 
(2.265) - AE Loss: 259176.500 (582029.438) - AE Rec Loss: 1.758 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.001 (0.389) - Batch(s): 1.414 
(2.265) - AE Loss: 118531.773 (582029.438) - AE Rec Loss: 0.804 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.78 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.414 
(2.265) - AE Loss: 157077.328 (582029.438) - AE Rec Loss: 1.065 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.81 m remaining

[Epoch <000/100>: Step <198/2280>] - Data(s): 0.000 (0.389) - Batch(s): 1.413 
(2.265) - AE Loss: 326673.062 (582029.438) - AE Rec Loss: 2.215 (3.947) - Disc 
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.182 
(2.205) - AE Loss: 679750.125 (605738.500) - AE Rec Loss: 4.610 (4.108) - Disc 
Loss: 0.000 (0.000) - 8.00 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.182 
(2.205) - AE Loss: 310394.969 (605738.500) - AE Rec Loss: 2.105 (4.108) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.183 
(2.205) - AE Loss: 1565628.000 (605738.500) - AE Rec Loss: 10.618 (4.108) - Disc
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.171 
(2.205) - AE Loss: 1655230.375 (605738.500) - AE Rec Loss: 11.225 (4.108) - Disc
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.187 
(2.205) - AE Loss: 255079.266 (605738.500) - AE Rec Loss: 1.730 (4.108) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <199/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.182 
(2.205) - AE Loss: 113324.375 (605738.500) - AE Rec Loss: 0.769 (4.108) - Disc 
Loss: 0.000 (0.000) - 7.97 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.001 (0.350) - Batch(s): 1.294 
(2.157) - AE Loss: 250698.391 (617109.375) - AE Rec Loss: 1.700 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.21 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.283 
(2.157) - AE Loss: 263587.188 (617109.375) - AE Rec Loss: 1.788 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.22 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.293 
(2.157) - AE Loss: 3344550.500 (617109.375) - AE Rec Loss: 22.682 (4.185) - Disc
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.001 (0.350) - Batch(s): 1.295 
(2.157) - AE Loss: 291372.062 (617109.375) - AE Rec Loss: 1.976 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.293 
(2.157) - AE Loss: 1890498.250 (617109.375) - AE Rec Loss: 12.821 (4.185) - Disc
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <200/2280>] - Data(s): 0.000 (0.350) - Batch(s): 1.299 
(2.157) - AE Loss: 204232.203 (617109.375) - AE Rec Loss: 1.385 (4.185) - Disc 
Loss: 0.000 (0.000) - 8.18 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.630 
(2.477) - AE Loss: 898030.625 (602837.000) - AE Rec Loss: 6.090 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.84 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.000 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 149252.703 (602837.000) - AE Rec Loss: 1.012 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.81 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.000 (0.334) - Batch(s): 9.630 
(2.477) - AE Loss: 193697.312 (602837.000) - AE Rec Loss: 1.314 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.85 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 186637.000 (602837.000) - AE Rec Loss: 1.266 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 247365.938 (602837.000) - AE Rec Loss: 1.678 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 0.001 (0.334) - Batch(s): 9.629 
(2.477) - AE Loss: 275050.031 (602837.000) - AE Rec Loss: 1.865 (4.088) - Disc 
Loss: 0.000 (0.000) - 9.81 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.117 
(2.413) - AE Loss: 62201.898 (613918.125) - AE Rec Loss: 0.422 (4.163) - Disc 
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.112 
(2.413) - AE Loss: 337124.250 (613918.125) - AE Rec Loss: 2.286 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.01 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.111 
(2.413) - AE Loss: 144156.000 (613918.125) - AE Rec Loss: 0.978 (4.163) - Disc 
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.113 
(2.413) - AE Loss: 258727.125 (613918.125) - AE Rec Loss: 1.755 (4.163) - Disc 
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.112 
(2.413) - AE Loss: 1665871.750 (613918.125) - AE Rec Loss: 11.297 (4.163) - Disc
Loss: 0.000 (0.000) - 9.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (0.318) - Batch(s): 1.101 
(2.413) - AE Loss: 1380593.500 (613918.125) - AE Rec Loss: 9.363 (4.163) - Disc 
Loss: 0.000 (0.000) - 10.02 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.125 
(2.355) - AE Loss: 124169.922 (638830.250) - AE Rec Loss: 0.842 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.126 
(2.355) - AE Loss: 2012097.750 (638830.250) - AE Rec Loss: 13.645 (4.332) - Disc
Loss: 0.000 (0.000) - 10.17 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.113 
(2.355) - AE Loss: 2947206.750 (638830.250) - AE Rec Loss: 19.987 (4.332) - Disc
Loss: 0.000 (0.000) - 10.18 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.126 
(2.355) - AE Loss: 130547.688 (638830.250) - AE Rec Loss: 0.885 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.14 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.125 
(2.355) - AE Loss: 396399.531 (638830.250) - AE Rec Loss: 2.688 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.15 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (0.305) - Batch(s): 1.129 
(2.355) - AE Loss: 267778.812 (638830.250) - AE Rec Loss: 1.816 (4.332) - Disc 
Loss: 0.000 (0.000) - 10.15 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 1448954.000 (636527.312) - AE Rec Loss: 9.826 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 393813.812 (636527.312) - AE Rec Loss: 2.671 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.35 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 1712294.625 (636527.312) - AE Rec Loss: 11.612 (4.317) - Disc
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 148628.781 (636527.312) - AE Rec Loss: 1.008 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.001 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 176042.938 (636527.312) - AE Rec Loss: 1.194 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.31 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (0.292) - Batch(s): 1.145 
(2.302) - AE Loss: 168451.875 (636527.312) - AE Rec Loss: 1.142 (4.317) - Disc 
Loss: 0.000 (0.000) - 10.34 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.118 
(2.253) - AE Loss: 380390.625 (640285.188) - AE Rec Loss: 2.580 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.117 
(2.253) - AE Loss: 224362.562 (640285.188) - AE Rec Loss: 1.522 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.47 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.121 
(2.253) - AE Loss: 1586777.875 (640285.188) - AE Rec Loss: 10.761 (4.342) - Disc
Loss: 0.000 (0.000) - 10.47 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.117 
(2.253) - AE Loss: 247150.984 (640285.188) - AE Rec Loss: 1.676 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.47 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.106 
(2.253) - AE Loss: 225805.047 (640285.188) - AE Rec Loss: 1.531 (4.342) - Disc 
Loss: 0.000 (0.000) - 10.50 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (0.280) - Batch(s): 1.118 
(2.253) - AE Loss: 1674243.250 (640285.188) - AE Rec Loss: 11.354 (4.342) - Disc
Loss: 0.000 (0.000) - 10.47 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.083 
(2.207) - AE Loss: 107669.742 (633752.812) - AE Rec Loss: 0.730 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.65 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.082 
(2.207) - AE Loss: 69275.375 (633752.812) - AE Rec Loss: 0.470 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.087 
(2.207) - AE Loss: 121808.906 (633752.812) - AE Rec Loss: 0.826 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.072 
(2.207) - AE Loss: 86220.750 (633752.812) - AE Rec Loss: 0.585 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.66 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.083 
(2.207) - AE Loss: 314331.906 (633752.812) - AE Rec Loss: 2.132 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.269) - Batch(s): 1.084 
(2.207) - AE Loss: 559759.438 (633752.812) - AE Rec Loss: 3.796 (4.298) - Disc 
Loss: 0.000 (0.000) - 10.62 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 68121.859 (646624.188) - AE Rec Loss: 0.462 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.33 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 196180.266 (646624.188) - AE Rec Loss: 1.330 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.30 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 156336.688 (646624.188) - AE Rec Loss: 1.060 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.30 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 194150.625 (646624.188) - AE Rec Loss: 1.317 (4.385) - Disc 
Loss: 0.000 (0.000) - 11.31 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 2172185.500 (646624.188) - AE Rec Loss: 14.731 (4.385) - Disc
Loss: 0.000 (0.000) - 11.31 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.269) - Batch(s): 4.306 
(2.283) - AE Loss: 1557423.000 (646624.188) - AE Rec Loss: 10.562 (4.385) - Disc
Loss: 0.000 (0.000) - 11.34 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:53:49,983[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:49,986[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,160[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,246[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,258[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:53:50,357[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:53:52,184[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,203[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,353[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,420[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,439[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:53:52,543[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:53:52,761[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:53:52,770[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:52,854[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:52,946[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:52,968[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:53:53,098[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:53:53,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:53:53,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:53:53,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:53:53,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:53:53,262[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 03:53:53,262[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 10=> Preparing model 

Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1 on node 11
Reached 1.2 on node 9
Reached 1.2 on node 11
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8Reached 1.3 on node 10

Reached 1.4 on node 10Reached 1.4 on node 8

Reached 2 on node 10
Reached 2 on node 8
Reached 3 on node 10
Reached 3 on node 8
Reached 5 on node 10Reached 5 on node 8

Reached end on node 10Reached end on node 8

Reached 1.3 on node 7Reached 1.3 on node 9

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7Reached 2 on node 9

Reached 3 on node 7Reached 3 on node 9
Reached 1.3 on node 11

Reached 5 on node 9Reached 1.3 on node 6Reached 1.4 on node 11
Reached 5 on node 7


Reached 1.4 on node 6
Reached end on node 9
Reached 2 on node 11Reached end on node 7

Reached 2 on node 6
Reached 3 on node 11
Reached 3 on node 6
Reached 5 on node 11Reached 5 on node 6

Reached end on node 6
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9Reached 1.4 on node 6

Reached 2 on node 6Reached 1.4 on node 7

Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 6
Reached 1 on node 9Reached 1 on node 7

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7Reached 2 on node 9
Reached 3 on node 6

Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 8Reached 3 on node 6

Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 11
Reached 1.4 on node 7
Reached 2 on node 11
Reached 2 on node 7Reached 1.4 on node 9

Reached 2 on node 9Reached 3 on node 7
Reached 1 on node 8

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8Reached 3 on node 7

Reached 2 on node 8
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 1.4 on node 9Reached 2 on node 11

Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1 on node 10Reached 3 on node 8

Reached 5 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9Reached 1.4 on node 11

Reached 2 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10Reached end on node 6

Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 6.398 (5.733) - Batch(s): 11.333 
(11.317) - AE Loss: 274718.625 (317748.375) - AE Rec Loss: 1.863 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 3.957 (5.733) - Batch(s): 11.322 
(11.317) - AE Loss: 897247.188 (317748.375) - AE Rec Loss: 6.085 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.630 (5.733) - Batch(s): 11.318 
(11.317) - AE Loss: 152023.250 (317748.375) - AE Rec Loss: 1.031 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 7.767 (5.733) - Batch(s): 11.312 
(11.317) - AE Loss: 187761.500 (317748.375) - AE Rec Loss: 1.273 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 4.818 (5.733) - Batch(s): 11.316 
(11.317) - AE Loss: 189997.781 (317748.375) - AE Rec Loss: 1.289 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.336 (5.733) - Batch(s): 11.321 
(11.317) - AE Loss: 247577.609 (317748.375) - AE Rec Loss: 1.679 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.867) - Batch(s): 1.239 
(6.251) - AE Loss: 164867.781 (588477.688) - AE Rec Loss: 1.118 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.231 
(6.251) - AE Loss: 1384978.000 (588477.688) - AE Rec Loss: 9.392 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.867) - Batch(s): 1.248 
(6.251) - AE Loss: 112341.367 (588477.688) - AE Rec Loss: 0.762 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.001 (2.867) - Batch(s): 1.244 
(6.251) - AE Loss: 294309.031 (588477.688) - AE Rec Loss: 1.996 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.867) - Batch(s): 1.241 
(6.251) - AE Loss: 336329.594 (588477.688) - AE Rec Loss: 2.281 (3.991) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.867) - Batch(s): 1.242 
(6.251) - AE Loss: 1667499.125 (588477.688) - AE Rec Loss: 11.308 (3.991) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.374 
(4.609) - AE Loss: 2010511.250 (791981.438) - AE Rec Loss: 13.635 (5.371) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.375 
(4.609) - AE Loss: 285645.562 (791981.438) - AE Rec Loss: 1.937 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.376 
(4.609) - AE Loss: 2950037.750 (791981.438) - AE Rec Loss: 20.006 (5.371) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.377 
(4.609) - AE Loss: 396356.438 (791981.438) - AE Rec Loss: 2.688 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.442 (1.923) - Batch(s): 1.378 
(4.609) - AE Loss: 165727.547 (791981.438) - AE Rec Loss: 1.124 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.923) - Batch(s): 1.378 
(4.609) - AE Loss: 138692.781 (791981.438) - AE Rec Loss: 0.941 (5.371) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.311 
(4.020) - AE Loss: 162401.438 (738389.312) - AE Rec Loss: 1.101 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.314 
(4.020) - AE Loss: 169895.328 (738389.312) - AE Rec Loss: 1.152 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.001 (1.465) - Batch(s): 2.302 
(4.020) - AE Loss: 386416.125 (738389.312) - AE Rec Loss: 2.621 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.310 
(4.020) - AE Loss: 1442191.250 (738389.312) - AE Rec Loss: 9.780 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.314 
(4.020) - AE Loss: 142267.234 (738389.312) - AE Rec Loss: 0.965 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.465) - Batch(s): 2.319 
(4.020) - AE Loss: 1705111.500 (738389.312) - AE Rec Loss: 11.564 (5.008) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.092 
(3.426) - AE Loss: 222684.516 (734964.000) - AE Rec Loss: 1.510 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.093 
(3.426) - AE Loss: 356844.156 (734964.000) - AE Rec Loss: 2.420 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.095 
(3.426) - AE Loss: 1675001.750 (734964.000) - AE Rec Loss: 11.359 (4.984) - Disc
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.001 (1.172) - Batch(s): 1.097 
(3.426) - AE Loss: 232648.156 (734964.000) - AE Rec Loss: 1.578 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.084 
(3.426) - AE Loss: 213494.812 (734964.000) - AE Rec Loss: 1.448 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.172) - Batch(s): 1.100 
(3.426) - AE Loss: 1575052.625 (734964.000) - AE Rec Loss: 10.682 (4.984) - Disc
Loss: 0.000 (0.000) - 3.07 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.720 
(3.133) - AE Loss: 106540.164 (689423.062) - AE Rec Loss: 0.723 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.990) - Batch(s): 1.720 
(3.133) - AE Loss: 286566.438 (689423.062) - AE Rec Loss: 1.943 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.990) - Batch(s): 1.721 
(3.133) - AE Loss: 104139.852 (689423.062) - AE Rec Loss: 0.706 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.990) - Batch(s): 1.720 
(3.133) - AE Loss: 563617.625 (689423.062) - AE Rec Loss: 3.822 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.999 (0.990) - Batch(s): 1.722 
(3.133) - AE Loss: 66651.367 (689423.062) - AE Rec Loss: 0.452 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.990) - Batch(s): 1.722 
(3.133) - AE Loss: 81594.375 (689423.062) - AE Rec Loss: 0.553 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.115 
(2.839) - AE Loss: 191026.500 (729835.812) - AE Rec Loss: 1.295 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.117 
(2.839) - AE Loss: 62030.164 (729835.812) - AE Rec Loss: 0.421 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.118 
(2.839) - AE Loss: 132108.812 (729835.812) - AE Rec Loss: 0.896 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.849) - Batch(s): 1.106 
(2.839) - AE Loss: 1554076.500 (729835.812) - AE Rec Loss: 10.539 (4.950) - Disc
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.118 
(2.839) - AE Loss: 184109.641 (729835.812) - AE Rec Loss: 1.249 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.849) - Batch(s): 1.123 
(2.839) - AE Loss: 2163092.250 (729835.812) - AE Rec Loss: 14.669 (4.950) - Disc
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.031 
(2.608) - AE Loss: 193958.406 (714499.938) - AE Rec Loss: 1.315 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.033 
(2.608) - AE Loss: 120536.164 (714499.938) - AE Rec Loss: 0.817 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.021 
(2.608) - AE Loss: 88538.438 (714499.938) - AE Rec Loss: 0.600 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.033 
(2.608) - AE Loss: 656462.375 (714499.938) - AE Rec Loss: 4.452 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.030 
(2.608) - AE Loss: 111985.656 (714499.938) - AE Rec Loss: 0.759 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.743) - Batch(s): 1.037 
(2.608) - AE Loss: 331755.531 (714499.938) - AE Rec Loss: 2.250 (4.846) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 1828751.750 (720151.125) - AE Rec Loss: 12.402 (4.884) - Disc
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 2.371 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 690459.562 (720151.125) - AE Rec Loss: 4.682 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.110 
(2.659) - AE Loss: 233275.844 (720151.125) - AE Rec Loss: 1.582 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 1576202.000 (720151.125) - AE Rec Loss: 10.689 (4.884) - Disc
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 1380535.375 (720151.125) - AE Rec Loss: 9.362 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.876 (0.690) - Batch(s): 3.111 
(2.659) - AE Loss: 354028.875 (720151.125) - AE Rec Loss: 2.401 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.304 
(2.518) - AE Loss: 397838.094 (714919.375) - AE Rec Loss: 2.698 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.306 
(2.518) - AE Loss: 142295.875 (714919.375) - AE Rec Loss: 0.965 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.294 
(2.518) - AE Loss: 113787.836 (714919.375) - AE Rec Loss: 0.772 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.305 
(2.518) - AE Loss: 195640.953 (714919.375) - AE Rec Loss: 1.327 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.306 
(2.518) - AE Loss: 2799609.250 (714919.375) - AE Rec Loss: 18.986 (4.848) - Disc
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.621) - Batch(s): 1.310 
(2.518) - AE Loss: 524174.531 (714919.375) - AE Rec Loss: 3.555 (4.848) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.612) - Batch(s): 4.048 
(2.634) - AE Loss: 69040.281 (692610.562) - AE Rec Loss: 0.468 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 2.670 (0.612) - Batch(s): 4.050 
(2.634) - AE Loss: 385191.188 (692610.562) - AE Rec Loss: 2.612 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.612) - Batch(s): 3.694 
(2.634) - AE Loss: 103609.375 (692610.562) - AE Rec Loss: 0.703 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.612) - Batch(s): 4.053 
(2.634) - AE Loss: 1567189.750 (692610.562) - AE Rec Loss: 10.628 (4.697) - Disc
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 3.479 (0.612) - Batch(s): 4.039 
(2.634) - AE Loss: 1787256.000 (692610.562) - AE Rec Loss: 12.121 (4.697) - Disc
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.001 (0.612) - Batch(s): 4.048 
(2.634) - AE Loss: 112100.492 (692610.562) - AE Rec Loss: 0.760 (4.697) - Disc 
Loss: 0.000 (0.000) - 5.14 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.001 
(2.911) - AE Loss: 244919.109 (678535.562) - AE Rec Loss: 1.661 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 2.404 (0.614) - Batch(s): 6.001 
(2.911) - AE Loss: 1493429.875 (678535.562) - AE Rec Loss: 10.128 (4.602) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 5.267 (0.614) - Batch(s): 6.001 
(2.911) - AE Loss: 285372.188 (678535.562) - AE Rec Loss: 1.935 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.001 (0.614) - Batch(s): 6.001 
(2.911) - AE Loss: 101172.875 (678535.562) - AE Rec Loss: 0.686 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.003 
(2.911) - AE Loss: 125829.742 (678535.562) - AE Rec Loss: 0.853 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.614) - Batch(s): 6.003 
(2.911) - AE Loss: 193841.156 (678535.562) - AE Rec Loss: 1.315 (4.602) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.045 
(2.764) - AE Loss: 295242.562 (660731.500) - AE Rec Loss: 2.002 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.049 
(2.764) - AE Loss: 1560537.875 (660731.500) - AE Rec Loss: 10.583 (4.481) - Disc
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.046 
(2.764) - AE Loss: 227736.031 (660731.500) - AE Rec Loss: 1.544 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.033 
(2.764) - AE Loss: 156678.016 (660731.500) - AE Rec Loss: 1.063 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.046 
(2.764) - AE Loss: 205941.000 (660731.500) - AE Rec Loss: 1.397 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.567) - Batch(s): 1.046 
(2.764) - AE Loss: 97393.531 (660731.500) - AE Rec Loss: 0.660 (4.481) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 4.633 (0.585) - Batch(s): 5.837 
(2.966) - AE Loss: 223858.422 (686706.812) - AE Rec Loss: 1.518 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.837 
(2.966) - AE Loss: 1617012.250 (686706.812) - AE Rec Loss: 10.966 (4.657) - Disc
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.836 
(2.966) - AE Loss: 1505724.750 (686706.812) - AE Rec Loss: 10.211 (4.657) - Disc
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.841 
(2.966) - AE Loss: 73893.047 (686706.812) - AE Rec Loss: 0.501 (4.657) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 5.263 (0.585) - Batch(s): 5.826 
(2.966) - AE Loss: 1589044.500 (686706.812) - AE Rec Loss: 10.776 (4.657) - Disc
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.585) - Batch(s): 5.481 
(2.966) - AE Loss: 1636082.750 (686706.812) - AE Rec Loss: 11.095 (4.657) - Disc
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.196 
(2.845) - AE Loss: 283153.500 (688282.500) - AE Rec Loss: 1.920 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.196 
(2.845) - AE Loss: 236360.188 (688282.500) - AE Rec Loss: 1.603 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.195 
(2.845) - AE Loss: 165109.172 (688282.500) - AE Rec Loss: 1.120 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.195 
(2.845) - AE Loss: 1674231.000 (688282.500) - AE Rec Loss: 11.354 (4.668) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.196 
(2.845) - AE Loss: 241834.594 (688282.500) - AE Rec Loss: 1.640 (4.668) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.546) - Batch(s): 1.196 
(2.845) - AE Loss: 1696486.625 (688282.500) - AE Rec Loss: 11.505 (4.668) - Disc
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.097 
(2.733) - AE Loss: 1407067.750 (684843.688) - AE Rec Loss: 9.542 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.103 
(2.733) - AE Loss: 399936.250 (684843.688) - AE Rec Loss: 2.712 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.099 
(2.733) - AE Loss: 1590024.750 (684843.688) - AE Rec Loss: 10.783 (4.644) - Disc
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.086 
(2.733) - AE Loss: 184345.219 (684843.688) - AE Rec Loss: 1.250 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.098 
(2.733) - AE Loss: 63280.098 (684843.688) - AE Rec Loss: 0.429 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.512) - Batch(s): 1.098 
(2.733) - AE Loss: 112085.570 (684843.688) - AE Rec Loss: 0.760 (4.644) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.567 
(2.825) - AE Loss: 683030.625 (665709.625) - AE Rec Loss: 4.632 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 2.836 (0.515) - Batch(s): 4.569 
(2.825) - AE Loss: 1407929.250 (665709.625) - AE Rec Loss: 9.548 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.569 
(2.825) - AE Loss: 265347.500 (665709.625) - AE Rec Loss: 1.800 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.215 
(2.825) - AE Loss: 387227.781 (665709.625) - AE Rec Loss: 2.626 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 3.993 (0.515) - Batch(s): 4.560 
(2.825) - AE Loss: 71310.836 (665709.625) - AE Rec Loss: 0.484 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.515) - Batch(s): 4.573 
(2.825) - AE Loss: 502157.344 (665709.625) - AE Rec Loss: 3.405 (4.515) - Disc 
Loss: 0.000 (0.000) - 8.25 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.506) - Batch(s): 4.765 
(2.931) - AE Loss: 156243.062 (659210.250) - AE Rec Loss: 1.060 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.506) - Batch(s): 4.765 
(2.931) - AE Loss: 124207.109 (659210.250) - AE Rec Loss: 0.842 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.766 
(2.931) - AE Loss: 208679.625 (659210.250) - AE Rec Loss: 1.415 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 4.058 (0.506) - Batch(s): 4.766 
(2.931) - AE Loss: 72548.031 (659210.250) - AE Rec Loss: 0.492 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.506) - Batch(s): 4.764 
(2.931) - AE Loss: 202370.656 (659210.250) - AE Rec Loss: 1.372 (4.471) - Disc 
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.001 (0.506) - Batch(s): 4.765 
(2.931) - AE Loss: 1878711.250 (659210.250) - AE Rec Loss: 12.741 (4.471) - Disc
Loss: 0.000 (0.000) - 8.98 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.037 
(2.829) - AE Loss: 390372.000 (674436.188) - AE Rec Loss: 2.647 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.042 
(2.829) - AE Loss: 214705.688 (674436.188) - AE Rec Loss: 1.456 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.036 
(2.829) - AE Loss: 1661474.875 (674436.188) - AE Rec Loss: 11.268 (4.574) - Disc
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.115 (0.480) - Batch(s): 1.025 
(2.829) - AE Loss: 349792.625 (674436.188) - AE Rec Loss: 2.372 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.037 
(2.829) - AE Loss: 233171.094 (674436.188) - AE Rec Loss: 1.581 (4.574) - Disc 
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.037 
(2.829) - AE Loss: 1683903.250 (674436.188) - AE Rec Loss: 11.420 (4.574) - Disc
Loss: 0.000 (0.000) - 9.12 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.064 
(2.738) - AE Loss: 110221.750 (673712.188) - AE Rec Loss: 0.747 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.067 
(2.738) - AE Loss: 157832.062 (673712.188) - AE Rec Loss: 1.070 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.458) - Batch(s): 1.027 
(2.738) - AE Loss: 191733.797 (673712.188) - AE Rec Loss: 1.300 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.063 
(2.738) - AE Loss: 322628.406 (673712.188) - AE Rec Loss: 2.188 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.503 (0.458) - Batch(s): 1.052 
(2.738) - AE Loss: 290855.750 (673712.188) - AE Rec Loss: 1.972 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.458) - Batch(s): 1.062 
(2.738) - AE Loss: 172186.828 (673712.188) - AE Rec Loss: 1.168 (4.569) - Disc 
Loss: 0.000 (0.000) - 9.26 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:55:23,829[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:23,903[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:24,037[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:24,176[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:24,182[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:55:24,183[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:55:26,053[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:26,099[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:26,244[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:26,371[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:26,425[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:55:26,452[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,562[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,591[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,783[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,898[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,941[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:55:26,980[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 03:55:26,983[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 03:55:26,984[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:55:26,984[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:55:26,984[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 03:55:26,987[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Instantiating the optimizer 
[[36m2023-11-29 03:55:26,992[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 9
Reached 5 on node 9
=> Preparing opt_disc 
Reached end on node 9
Reached 3 on node 7
=> Preparing opt_disc 
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Running in inference mode: False
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 03:56:56,628[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:56,637[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:56,737[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:56,750[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:56,751[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 03:56:57,067[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 03:56:58,797[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:58,805[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:58,955[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:58,965[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 03:56:59,011[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:59,260[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:59,315[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 03:56:59,339[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 03:56:59,521[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 03:56:59,531[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:59,544[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 03:56:59,796[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 03:56:59,797[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,797[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,797[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,797[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 03:56:59,798[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
[[36m2023-11-29 03:56:59,799[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 9Reached 3 on node 7

Reached 5 on node 7Reached 5 on node 9

Reached end on node 7
Reached end on node 9
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:03:02,499[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,509[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,597[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,636[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,639[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:03:02,696[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:03:04,759[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,762[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,785[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,883[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,885[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:03:04,914[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:05,309[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:03:05,355[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:03:05,366[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:05,410[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:05,469[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:03:05,492[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 04:03:05,495[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:03:05,497[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
[[36m2023-11-29 04:03:05,498[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating train dataloader 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
len(valid_dataloader) = 1
=> Preparing model 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataset) = 4
=> Preparing model 
[[36m2023-11-29 04:03:05,503[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:03:05,503[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 04:03:05,504[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Error executing job with overrides: ['experiment=vae']
Error executing job with overrides: ['experiment=vae']
Error executing job with overrides: ['experiment=vae']
Error executing job with overrides: ['experiment=vae']
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
Traceback (most recent call last):
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 310, in <module>
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    main()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_hydra(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    _run_app(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    run_and_report(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    raise ex
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    return func()
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
        return func()
lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    lambda: hydra.run(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    _ = ret.return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    raise self._return_value
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    ret.return_value = task_function(task_cfg)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/comprx/train_vae.py", line 132, in main
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    model = accelerator.prepare(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1289, in prepare
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    result = tuple(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1290, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1094, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    return self.prepare_model(obj, device_placement=device_placement)
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 1437, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    model = torch.nn.parallel.DistributedDataParallel(
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
            _verify_param_shape_across_processes(self.process_group, parameters)_verify_param_shape_across_processes(self.process_group, parameters)_verify_param_shape_across_processes(self.process_group, parameters)

    
_verify_param_shape_across_processes(self.process_group, parameters)  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes

  File "/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)    
return dist._verify_params_across_processes(process_group, tensors, logger)    
return dist._verify_params_across_processes(process_group, tensors, logger)    
torch.distributedreturn dist._verify_params_across_processes(process_group, tensors, logger)torch.distributed.
.DistBackendErrorDistBackendError: : torch.distributedNCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<37272>NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<46984>
.torch.distributed
DistBackendError.DistBackendError: : NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer sc4<54358>NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1275, internal error, NCCL version 2.14.3
ncclInternalError: Internal check failed.
Last error:
Net : Connection closed by remote peer fdaa:1:b86:a7b:9076:0:a:2202<54864>

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:04:34,580[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,607[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,855[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,885[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:34,894[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:04:35,079[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:04:36,771[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:36,837[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:37,060[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:37,103[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:37,132[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,273[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:04:37,279[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,341[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,619[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,636[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:04:37,647[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:04:37,724[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 04:04:37,727[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:04:37,727[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:04:37,727[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 04:04:37,728[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
[[36m2023-11-29 04:04:37,729[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
[[36m2023-11-29 04:04:37,732[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
len(train_dataset) = 54706
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(train_dataloader) = 2279
=> Preparing model 
=> Preparing model 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_disc 
=> Preparing model 
len(valid_dataloader) = 1
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:07:37,943[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,181[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,416[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,450[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,459[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:07:38,670[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:07:40,145[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:40,547[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:07:40,585[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,644[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,682[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,765[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:07:40,917[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:41,034[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:41,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:41,150[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:41,247[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:07:41,361[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:07:41,364[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:07:41,369[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:07:41,369[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:07:41,369[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
[[36m2023-11-29 04:07:41,369[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:07:41,369[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 10
Reached 5 on node 10
=> Preparing opt_disc 
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 6
=> Preparing model 
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:09:10,890[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,890[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:10,921[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:11,141[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:11,162[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:09:11,199[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:09:13,121[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:13,133[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:13,199[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:13,405[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:13,432[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:09:13,451[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,552[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,669[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,752[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,903[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:13,987[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:09:14,002[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 04:09:14,003[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:09:14,004[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:09:14,004[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:09:14,004[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Mixed precision: no
[[36m2023-11-29 04:09:14,005[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
[[36m2023-11-29 04:09:14,013[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:13:45,608[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,638[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,735[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,753[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,819[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:13:45,822[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:13:47,812[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,857[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,955[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,972[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:47,996[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:13:48,099[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,272[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,373[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,457[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,546[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,562[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:13:48,601[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:13:48,602[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,602[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 04:13:48,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:13:48,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating the optimizer 
[[36m2023-11-29 04:13:48,611[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 11Reached 1.3 on node 8

Reached 1.4 on node 8Reached 1.4 on node 11Reached 1.3 on node 9


Reached 1.4 on node 9
Reached 2 on node 8
Reached 2 on node 11
Reached 2 on node 9
Reached 3 on node 8
Reached 3 on node 11
Reached 3 on node 9
Reached 5 on node 8
Reached 5 on node 11
Reached 5 on node 9Reached end on node 8

Reached end on node 11
Reached end on node 9
=> Preparing opt_ae 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 8Reached 3 on node 9

Reached 5 on node 8Reached 5 on node 9

Reached end on node 8Reached end on node 9

Reached 3 on node 11
Reached 5 on node 11
Reached 3 on node 6
Reached end on node 11
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6Reached 1.3 on node 11
Reached 1.3 on node 7

Reached 1.4 on node 11
Reached 1.4 on node 6
Reached 1.4 on node 7
Reached 2 on node 11Reached 2 on node 6

Reached 2 on node 7
Reached 3 on node 11Reached 3 on node 6

Reached 3 on node 7Reached 1.3 on node 8
Reached 1.3 on node 9
Reached 5 on node 11Reached 1.3 on node 10
Reached 1.4 on node 8Reached 5 on node 6

Reached 5 on node 7
Reached 1.4 on node 9

Reached 1.4 on node 10

Reached end on node 11Reached 2 on node 8Reached end on node 6

Reached end on node 7Reached 2 on node 9Reached 2 on node 10



Reached 3 on node 8
Reached 3 on node 9
Reached 3 on node 10
Reached 5 on node 8
Reached 5 on node 9
Reached 5 on node 10
Reached end on node 8Reached end on node 9

Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8Reached 1 on node 7

Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 7

Reached 1 on node 8
Reached 1.4 on node 7
Reached 1.4 on node 11Reached 2 on node 7
Reached 1.4 on node 8

Reached 2 on node 11
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8Reached 3 on node 7

Reached 1.4 on node 11Reached 2 on node 8

Reached 3 on node 7
Reached 2 on node 11
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8Reached 1.4 on node 11

Reached 3 on node 8Reached 2 on node 11

Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 8
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 5.578 (5.274) - Batch(s): 9.935 
(10.046) - AE Loss: 896167.125 (318208.938) - AE Rec Loss: 6.078 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.76 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 4.875 (5.274) - Batch(s): 10.454 
(10.046) - AE Loss: 149570.688 (318208.938) - AE Rec Loss: 1.014 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.85 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.031 (5.274) - Batch(s): 9.939 
(10.046) - AE Loss: 279146.500 (318208.938) - AE Rec Loss: 1.893 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.76 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 4.317 (5.274) - Batch(s): 10.238 
(10.046) - AE Loss: 192492.781 (318208.938) - AE Rec Loss: 1.305 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.143 (5.274) - Batch(s): 9.982 
(10.046) - AE Loss: 247461.953 (318208.938) - AE Rec Loss: 1.678 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.524 (5.274) - Batch(s): 10.259 
(10.046) - AE Loss: 188579.484 (318208.938) - AE Rec Loss: 1.279 (2.158) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.212 
(5.603) - AE Loss: 166015.062 (588618.438) - AE Rec Loss: 1.126 (3.992) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.214 
(5.603) - AE Loss: 1667667.000 (588618.438) - AE Rec Loss: 11.310 (3.992) - Disc
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.215 
(5.603) - AE Loss: 292553.000 (588618.438) - AE Rec Loss: 1.984 (3.992) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.222 
(5.603) - AE Loss: 110409.500 (588618.438) - AE Rec Loss: 0.749 (3.992) - Disc 
Loss: 0.000 (0.000) - 2.03 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.203 
(5.603) - AE Loss: 1385312.000 (588618.438) - AE Rec Loss: 9.395 (3.992) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.637) - Batch(s): 1.213 
(5.603) - AE Loss: 336584.938 (588618.438) - AE Rec Loss: 2.283 (3.992) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.325 
(4.162) - AE Loss: 395712.375 (792081.562) - AE Rec Loss: 2.684 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 140261.719 (792081.562) - AE Rec Loss: 0.951 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 2949908.500 (792081.562) - AE Rec Loss: 20.005 (5.372) - Disc
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.605 (1.794) - Batch(s): 1.325 
(4.162) - AE Loss: 165554.281 (792081.562) - AE Rec Loss: 1.123 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.31 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 287844.094 (792081.562) - AE Rec Loss: 1.952 (5.372) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.794) - Batch(s): 1.326 
(4.162) - AE Loss: 2010588.875 (792081.562) - AE Rec Loss: 13.635 (5.372) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.338 
(3.439) - AE Loss: 1704896.000 (738457.688) - AE Rec Loss: 11.562 (5.008) - Disc
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.329 
(3.439) - AE Loss: 161837.953 (738457.688) - AE Rec Loss: 1.098 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.329 
(3.439) - AE Loss: 1443004.250 (738457.688) - AE Rec Loss: 9.786 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.331 
(3.439) - AE Loss: 170074.797 (738457.688) - AE Rec Loss: 1.153 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.320 
(3.439) - AE Loss: 386018.375 (738457.688) - AE Rec Loss: 2.618 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.52 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.346) - Batch(s): 1.332 
(3.439) - AE Loss: 142655.062 (738457.688) - AE Rec Loss: 0.967 (5.008) - Disc 
Loss: 0.000 (0.000) - 2.46 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.198 
(2.979) - AE Loss: 233407.797 (735066.250) - AE Rec Loss: 1.583 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.206 
(2.979) - AE Loss: 1574709.375 (735066.250) - AE Rec Loss: 10.679 (4.985) - Disc
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.196 
(2.979) - AE Loss: 357648.469 (735066.250) - AE Rec Loss: 2.425 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.187 
(2.979) - AE Loss: 213546.141 (735066.250) - AE Rec Loss: 1.448 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.195 
(2.979) - AE Loss: 223292.156 (735066.250) - AE Rec Loss: 1.514 (4.985) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.087) - Batch(s): 1.198 
(2.979) - AE Loss: 1675040.750 (735066.250) - AE Rec Loss: 11.360 (4.985) - Disc
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.443 
(3.213) - AE Loss: 287208.219 (689502.938) - AE Rec Loss: 1.948 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.443 
(3.213) - AE Loss: 563038.625 (689502.938) - AE Rec Loss: 3.818 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.442 
(3.213) - AE Loss: 81060.500 (689502.938) - AE Rec Loss: 0.550 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 2.947 (1.025) - Batch(s): 4.443 
(3.213) - AE Loss: 65638.328 (689502.938) - AE Rec Loss: 0.445 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.443 
(3.213) - AE Loss: 106361.539 (689502.938) - AE Rec Loss: 0.721 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (1.025) - Batch(s): 4.442 
(3.213) - AE Loss: 104183.383 (689502.938) - AE Rec Loss: 0.707 (4.676) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.879) - Batch(s): 1.149 
(2.911) - AE Loss: 131078.812 (729972.375) - AE Rec Loss: 0.889 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.879) - Batch(s): 1.149 
(2.911) - AE Loss: 184436.859 (729972.375) - AE Rec Loss: 1.251 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.879) - Batch(s): 1.156 
(2.911) - AE Loss: 2163579.250 (729972.375) - AE Rec Loss: 14.673 (4.950) - Disc
Loss: 0.000 (0.000) - 3.68 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.879) - Batch(s): 1.147 
(2.911) - AE Loss: 63633.359 (729972.375) - AE Rec Loss: 0.432 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.879) - Batch(s): 1.137 
(2.911) - AE Loss: 1554499.000 (729972.375) - AE Rec Loss: 10.542 (4.950) - Disc
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.000 (0.879) - Batch(s): 1.145 
(2.911) - AE Loss: 192753.969 (729972.375) - AE Rec Loss: 1.307 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.169 
(2.687) - AE Loss: 656410.125 (714667.812) - AE Rec Loss: 4.452 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.83 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.168 
(2.687) - AE Loss: 119691.227 (714667.812) - AE Rec Loss: 0.812 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.175 
(2.687) - AE Loss: 332485.656 (714667.812) - AE Rec Loss: 2.255 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.88 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.769) - Batch(s): 1.165 
(2.687) - AE Loss: 112149.750 (714667.812) - AE Rec Loss: 0.761 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.92 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.769) - Batch(s): 1.167 
(2.687) - AE Loss: 195393.906 (714667.812) - AE Rec Loss: 1.325 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.83 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.769) - Batch(s): 1.156 
(2.687) - AE Loss: 87953.219 (714667.812) - AE Rec Loss: 0.596 (4.847) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.244 
(2.521) - AE Loss: 691840.875 (720356.875) - AE Rec Loss: 4.692 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.06 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.244 
(2.521) - AE Loss: 233422.625 (720356.875) - AE Rec Loss: 1.583 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.09 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.246 
(2.521) - AE Loss: 1576948.500 (720356.875) - AE Rec Loss: 10.694 (4.885) - Disc
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.245 
(2.521) - AE Loss: 1380467.250 (720356.875) - AE Rec Loss: 9.362 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.001 (0.684) - Batch(s): 1.245 
(2.521) - AE Loss: 354121.375 (720356.875) - AE Rec Loss: 2.402 (4.885) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.684) - Batch(s): 1.246 
(2.521) - AE Loss: 1828073.500 (720356.875) - AE Rec Loss: 12.397 (4.885) - Disc
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.283 
(2.391) - AE Loss: 523251.219 (715067.438) - AE Rec Loss: 3.549 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.31 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.275 
(2.391) - AE Loss: 142111.609 (715067.438) - AE Rec Loss: 0.964 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.275 
(2.391) - AE Loss: 2800206.500 (715067.438) - AE Rec Loss: 18.990 (4.849) - Disc
Loss: 0.000 (0.000) - 4.27 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.274 
(2.391) - AE Loss: 397421.344 (715067.438) - AE Rec Loss: 2.695 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.275 
(2.391) - AE Loss: 196102.766 (715067.438) - AE Rec Loss: 1.330 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.34 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.263 
(2.391) - AE Loss: 113812.156 (715067.438) - AE Rec Loss: 0.772 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.31 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.323 
(2.288) - AE Loss: 102598.469 (692742.062) - AE Rec Loss: 0.696 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.322 
(2.288) - AE Loss: 382724.500 (692742.062) - AE Rec Loss: 2.596 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.329 
(2.288) - AE Loss: 1567539.750 (692742.062) - AE Rec Loss: 10.631 (4.698) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.322 
(2.288) - AE Loss: 69223.500 (692742.062) - AE Rec Loss: 0.469 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.321 
(2.288) - AE Loss: 110662.227 (692742.062) - AE Rec Loss: 0.750 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.559) - Batch(s): 1.311 
(2.288) - AE Loss: 1787116.750 (692742.062) - AE Rec Loss: 12.120 (4.698) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.281 
(2.199) - AE Loss: 101487.578 (678694.875) - AE Rec Loss: 0.688 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.326 (0.515) - Batch(s): 1.281 
(2.199) - AE Loss: 1494303.125 (678694.875) - AE Rec Loss: 10.134 (4.603) - Disc
Loss: 0.000 (0.000) - 4.70 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.282 
(2.199) - AE Loss: 244764.562 (678694.875) - AE Rec Loss: 1.660 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.283 
(2.199) - AE Loss: 124971.852 (678694.875) - AE Rec Loss: 0.848 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.284 
(2.199) - AE Loss: 286797.562 (678694.875) - AE Rec Loss: 1.945 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.284 
(2.199) - AE Loss: 195751.922 (678694.875) - AE Rec Loss: 1.328 (4.603) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.477) - Batch(s): 1.402 
(2.134) - AE Loss: 93559.836 (660775.062) - AE Rec Loss: 0.634 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.477) - Batch(s): 1.402 
(2.134) - AE Loss: 203806.359 (660775.062) - AE Rec Loss: 1.382 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.477) - Batch(s): 1.401 
(2.134) - AE Loss: 228083.281 (660775.062) - AE Rec Loss: 1.547 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.00 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.477) - Batch(s): 1.409 
(2.134) - AE Loss: 1559669.500 (660775.062) - AE Rec Loss: 10.577 (4.481) - Disc
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.154 (0.477) - Batch(s): 1.400 
(2.134) - AE Loss: 293661.281 (660775.062) - AE Rec Loss: 1.992 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.92 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.477) - Batch(s): 1.389 
(2.134) - AE Loss: 154844.141 (660775.062) - AE Rec Loss: 1.050 (4.481) - Disc 
Loss: 0.000 (0.000) - 4.97 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 3.961 
(2.270) - AE Loss: 1636482.125 (686693.188) - AE Rec Loss: 11.098 (4.657) - Disc
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 4.318 
(2.270) - AE Loss: 221746.953 (686693.188) - AE Rec Loss: 1.504 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 4.317 
(2.270) - AE Loss: 1615446.250 (686693.188) - AE Rec Loss: 10.955 (4.657) - Disc
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 4.315 
(2.270) - AE Loss: 1504251.000 (686693.188) - AE Rec Loss: 10.201 (4.657) - Disc
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 3.746 (0.466) - Batch(s): 4.305 
(2.270) - AE Loss: 1589385.375 (686693.188) - AE Rec Loss: 10.779 (4.657) - Disc
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.466) - Batch(s): 4.324 
(2.270) - AE Loss: 73471.344 (686693.188) - AE Rec Loss: 0.498 (4.657) - Disc 
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.324 
(2.204) - AE Loss: 164871.594 (688232.188) - AE Rec Loss: 1.118 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.327 
(2.204) - AE Loss: 235165.609 (688232.188) - AE Rec Loss: 1.595 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.325 
(2.204) - AE Loss: 282379.406 (688232.188) - AE Rec Loss: 1.915 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.83 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.326 
(2.204) - AE Loss: 242204.000 (688232.188) - AE Rec Loss: 1.643 (4.667) - Disc 
Loss: 0.000 (0.000) - 5.90 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.326 
(2.204) - AE Loss: 1697277.375 (688232.188) - AE Rec Loss: 11.510 (4.667) - Disc
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.435) - Batch(s): 1.326 
(2.204) - AE Loss: 1673309.500 (688232.188) - AE Rec Loss: 11.348 (4.667) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.304 
(2.143) - AE Loss: 400971.250 (684776.625) - AE Rec Loss: 2.719 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.300 
(2.143) - AE Loss: 111967.773 (684776.625) - AE Rec Loss: 0.759 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.298 
(2.143) - AE Loss: 1406051.750 (684776.625) - AE Rec Loss: 9.535 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.300 
(2.143) - AE Loss: 1589913.625 (684776.625) - AE Rec Loss: 10.782 (4.644) - Disc
Loss: 0.000 (0.000) - 6.03 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.299 
(2.143) - AE Loss: 61797.039 (684776.625) - AE Rec Loss: 0.419 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.10 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.407) - Batch(s): 1.288 
(2.143) - AE Loss: 184746.000 (684776.625) - AE Rec Loss: 1.253 (4.644) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.089 
(2.078) - AE Loss: 386008.500 (665626.875) - AE Rec Loss: 2.618 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.18 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.088 
(2.078) - AE Loss: 265575.750 (665626.875) - AE Rec Loss: 1.801 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.088 
(2.078) - AE Loss: 1407509.750 (665626.875) - AE Rec Loss: 9.545 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.20 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.087 
(2.078) - AE Loss: 682568.062 (665626.875) - AE Rec Loss: 4.629 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.18 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.094 
(2.078) - AE Loss: 501704.062 (665626.875) - AE Rec Loss: 3.402 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.23 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.384) - Batch(s): 1.077 
(2.078) - AE Loss: 71216.516 (665626.875) - AE Rec Loss: 0.483 (4.514) - Disc 
Loss: 0.000 (0.000) - 6.24 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 4.357 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 72039.578 (659110.062) - AE Rec Loss: 0.489 (4.470) - Disc 
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 1.621 (0.390) - Batch(s): 5.004 
(2.238) - AE Loss: 155865.438 (659110.062) - AE Rec Loss: 1.057 (4.470) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.390) - Batch(s): 5.003 
(2.238) - AE Loss: 208319.250 (659110.062) - AE Rec Loss: 1.413 (4.470) - Disc 
Loss: 0.000 (0.000) - 7.01 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.390) - Batch(s): 5.004 
(2.238) - AE Loss: 1877795.375 (659110.062) - AE Rec Loss: 12.735 (4.470) - Disc
Loss: 0.000 (0.000) - 6.96 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.390) - Batch(s): 5.006 
(2.238) - AE Loss: 201494.859 (659110.062) - AE Rec Loss: 1.366 (4.470) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.390) - Batch(s): 5.006 
(2.238) - AE Loss: 124495.539 (659110.062) - AE Rec Loss: 0.844 (4.470) - Disc 
Loss: 0.000 (0.000) - 7.02 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.072 
(2.174) - AE Loss: 1661515.500 (674364.062) - AE Rec Loss: 11.268 (4.573) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.073 
(2.174) - AE Loss: 234372.078 (674364.062) - AE Rec Loss: 1.589 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.078 
(2.174) - AE Loss: 214846.234 (674364.062) - AE Rec Loss: 1.457 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.073 
(2.174) - AE Loss: 1684119.000 (674364.062) - AE Rec Loss: 11.421 (4.573) - Disc
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.062 
(2.174) - AE Loss: 349362.938 (674364.062) - AE Rec Loss: 2.369 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.369) - Batch(s): 1.072 
(2.174) - AE Loss: 388556.219 (674364.062) - AE Rec Loss: 2.635 (4.573) - Disc 
Loss: 0.000 (0.000) - 7.20 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 1.107 
(2.119) - AE Loss: 172246.641 (673665.750) - AE Rec Loss: 1.168 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.113 
(2.119) - AE Loss: 158719.125 (673665.750) - AE Rec Loss: 1.076 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.108 
(2.119) - AE Loss: 112430.516 (673665.750) - AE Rec Loss: 0.762 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.36 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.108 
(2.119) - AE Loss: 322450.844 (673665.750) - AE Rec Loss: 2.187 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.29 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.001 (0.351) - Batch(s): 1.108 
(2.119) - AE Loss: 191719.578 (673665.750) - AE Rec Loss: 1.300 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.28 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.351) - Batch(s): 1.097 
(2.119) - AE Loss: 291103.531 (673665.750) - AE Rec Loss: 1.974 (4.569) - Disc 
Loss: 0.000 (0.000) - 7.34 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:16:58,713[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,818[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,818[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,851[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,864[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:16:58,870[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:17:01,003[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:01,045[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:01,058[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:01,091[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:01,112[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:17:01,148[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,588[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:17:01,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,640[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,680[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:17:01,724[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 04:17:01,729[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:17:01,733[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
[[36m2023-11-29 04:17:01,739[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:17:01,739[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:17:01,739[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:17:01,739[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 04:17:01,742[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:18:30,976[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:30,987[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:31,227[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:31,231[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:31,235[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:18:31,355[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:18:33,236[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:33,266[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:33,475[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:33,491[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:33,499[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:18:33,600[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,696[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:33,753[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:34,000[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:34,039[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:34,055[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:18:34,116[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 04:18:34,117[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 04:18:34,119[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
[[36m2023-11-29 04:18:34,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:18:34,120[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataloader) = 1
[[36m2023-11-29 04:18:34,121[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Running in inference mode: False
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 6len(train_dataset) = 54706

Reached 5 on node 6
Reached end on node 6
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Instantiating the optimizer 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
=> Preparing opt_ae 
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.3 on node 8
Reached 1.4 on node 11
Reached 1.4 on node 8
Reached 2 on node 11
Reached 2 on node 8
Reached 3 on node 11
Reached 3 on node 8
Reached 1.3 on node 10Reached 5 on node 11
Reached 1.3 on node 7
Reached 5 on node 8
Reached 1.4 on node 10

Reached 1.4 on node 7Reached end on node 11

Reached end on node 8Reached 2 on node 10

Reached 2 on node 7
Reached 3 on node 10
Reached 1.3 on node 6Reached 3 on node 7

Reached 5 on node 10Reached 1.4 on node 6

Reached end on node 10Reached 5 on node 7Reached 2 on node 6


Reached end on node 7
Reached 1.3 on node 9
Reached 3 on node 6Reached 1.4 on node 9

Reached 5 on node 6
Reached 2 on node 9
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
Loaded checkpoint at epoch 0 and step 201
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8Reached 1 on node 7

Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 7
Reached 1.4 on node 8
Reached 2 on node 7
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 11
Reached 1.4 on node 9Reached 2 on node 11

Reached 1.4 on node 8
Reached 2 on node 9
Reached 2 on node 8Reached 1.4 on node 7

Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 11
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 8
Reached 1.4 on node 11Reached 2 on node 8

Reached 1.4 on node 9Reached 2 on node 11

Reached 1.4 on node 7Reached 2 on node 9

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11Reached 1 on node 8

Reached 1 on node 9
Reached 1.4 on node 8Reached 1.4 on node 11

Reached 2 on node 8Reached 2 on node 11

Reached 3 on node 8
Reached 1.4 on node 9Reached 3 on node 8

Reached 3 on node 8Reached 2 on node 9

Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 6
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11Reached 1 on node 8

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 11
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <201/2280>] - Data(s): 4.298 (5.306) - Batch(s): 10.086 
(10.183) - AE Loss: 190795.906 (317813.969) - AE Rec Loss: 1.294 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.407 (5.306) - Batch(s): 10.522 
(10.183) - AE Loss: 274910.062 (317813.969) - AE Rec Loss: 1.864 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.86 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.272 (5.306) - Batch(s): 10.439 
(10.183) - AE Loss: 247193.734 (317813.969) - AE Rec Loss: 1.676 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.84 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 6.523 (5.306) - Batch(s): 10.102 
(10.183) - AE Loss: 147597.109 (317813.969) - AE Rec Loss: 1.001 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 5.580 (5.306) - Batch(s): 10.101 
(10.183) - AE Loss: 186520.562 (317813.969) - AE Rec Loss: 1.265 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <201/2280>] - Data(s): 3.845 (5.306) - Batch(s): 10.193 
(10.183) - AE Loss: 897087.812 (317813.969) - AE Rec Loss: 6.084 (2.155) - Disc 
Loss: 0.000 (0.000) - 1.80 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.437 
(5.773) - AE Loss: 1667677.250 (588347.625) - AE Rec Loss: 11.310 (3.990) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.434 
(5.773) - AE Loss: 168391.625 (588347.625) - AE Rec Loss: 1.142 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.424 
(5.773) - AE Loss: 1385080.625 (588347.625) - AE Rec Loss: 9.393 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.435 
(5.773) - AE Loss: 336037.375 (588347.625) - AE Rec Loss: 2.279 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.440 
(5.773) - AE Loss: 110949.305 (588347.625) - AE Rec Loss: 0.752 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <202/2280>] - Data(s): 0.000 (2.653) - Batch(s): 1.437 
(5.773) - AE Loss: 290205.312 (588347.625) - AE Rec Loss: 1.968 (3.990) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.778 
(5.087) - AE Loss: 395981.875 (791719.000) - AE Rec Loss: 2.685 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.856) - Batch(s): 3.776 
(5.087) - AE Loss: 286133.375 (791719.000) - AE Rec Loss: 1.940 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.856) - Batch(s): 3.778 
(5.087) - AE Loss: 2949996.500 (791719.000) - AE Rec Loss: 20.006 (5.369) - Disc
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.001 (1.856) - Batch(s): 3.777 
(5.087) - AE Loss: 138242.219 (791719.000) - AE Rec Loss: 0.938 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 3.127 (1.856) - Batch(s): 3.778 
(5.087) - AE Loss: 163569.953 (791719.000) - AE Rec Loss: 1.109 (5.369) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <203/2280>] - Data(s): 0.000 (1.856) - Batch(s): 3.778 
(5.087) - AE Loss: 2011350.500 (791719.000) - AE Rec Loss: 13.640 (5.369) - Disc
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.319 
(4.129) - AE Loss: 171212.500 (738246.312) - AE Rec Loss: 1.161 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.319 
(4.129) - AE Loss: 142163.109 (738246.312) - AE Rec Loss: 0.964 (5.007) - Disc 
Loss: 0.000 (0.000) - 3.01 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.315 
(4.129) - AE Loss: 1442742.625 (738246.312) - AE Rec Loss: 9.784 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.317 
(4.129) - AE Loss: 162226.781 (738246.312) - AE Rec Loss: 1.100 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.96 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.307 
(4.129) - AE Loss: 386815.656 (738246.312) - AE Rec Loss: 2.623 (5.007) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <204/2280>] - Data(s): 0.000 (1.392) - Batch(s): 1.323 
(4.129) - AE Loss: 1705042.500 (738246.312) - AE Rec Loss: 11.563 (5.007) - Disc
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.099 
(3.513) - AE Loss: 1574404.000 (734903.000) - AE Rec Loss: 10.677 (4.984) - Disc
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.096 
(3.513) - AE Loss: 1675009.750 (734903.000) - AE Rec Loss: 11.359 (4.984) - Disc
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.106 (1.116) - Batch(s): 1.084 
(3.513) - AE Loss: 213743.984 (734903.000) - AE Rec Loss: 1.450 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.096 
(3.513) - AE Loss: 232415.578 (734903.000) - AE Rec Loss: 1.576 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.094 
(3.513) - AE Loss: 357565.938 (734903.000) - AE Rec Loss: 2.425 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <205/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.091 
(3.513) - AE Loss: 222993.562 (734903.000) - AE Rec Loss: 1.512 (4.984) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.557 
(3.513) - AE Loss: 285753.062 (689372.000) - AE Rec Loss: 1.938 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.79 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.557 
(3.513) - AE Loss: 562706.750 (689372.000) - AE Rec Loss: 3.816 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.81 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 2.930 (0.970) - Batch(s): 3.556 
(3.513) - AE Loss: 67346.125 (689372.000) - AE Rec Loss: 0.457 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.558 
(3.513) - AE Loss: 105999.898 (689372.000) - AE Rec Loss: 0.719 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.75 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.001 (0.970) - Batch(s): 3.557 
(3.513) - AE Loss: 81724.695 (689372.000) - AE Rec Loss: 0.554 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.74 m remaining

[Epoch <000/100>: Step <206/2280>] - Data(s): 0.000 (0.970) - Batch(s): 3.558 
(3.513) - AE Loss: 103921.617 (689372.000) - AE Rec Loss: 0.705 (4.675) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.157 
(3.169) - AE Loss: 183592.406 (729837.312) - AE Rec Loss: 1.245 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.157 
(3.169) - AE Loss: 131557.734 (729837.312) - AE Rec Loss: 0.892 (4.950) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.153 
(3.169) - AE Loss: 192864.641 (729837.312) - AE Rec Loss: 1.308 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.155 
(3.169) - AE Loss: 63948.285 (729837.312) - AE Rec Loss: 0.434 (4.950) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.144 
(3.169) - AE Loss: 1554855.875 (729837.312) - AE Rec Loss: 10.545 (4.950) - Disc
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <207/2280>] - Data(s): 0.001 (0.832) - Batch(s): 1.161 
(3.169) - AE Loss: 2163454.000 (729837.312) - AE Rec Loss: 14.672 (4.950) - Disc
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.074 
(2.901) - AE Loss: 656603.500 (714502.188) - AE Rec Loss: 4.453 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.071 
(2.901) - AE Loss: 112357.703 (714502.188) - AE Rec Loss: 0.762 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.12 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.728) - Batch(s): 1.073 
(2.901) - AE Loss: 194450.125 (714502.188) - AE Rec Loss: 1.319 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.075 
(2.901) - AE Loss: 118700.023 (714502.188) - AE Rec Loss: 0.805 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.001 (0.728) - Batch(s): 1.078 
(2.901) - AE Loss: 331579.625 (714502.188) - AE Rec Loss: 2.249 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <208/2280>] - Data(s): 0.000 (0.728) - Batch(s): 1.062 
(2.901) - AE Loss: 88057.477 (714502.188) - AE Rec Loss: 0.597 (4.846) - Disc 
Loss: 0.000 (0.000) - 4.12 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.867 
(2.782) - AE Loss: 1576048.125 (720205.625) - AE Rec Loss: 10.688 (4.884) - Disc
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.867 
(2.782) - AE Loss: 1827919.500 (720205.625) - AE Rec Loss: 12.396 (4.884) - Disc
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.868 
(2.782) - AE Loss: 233000.781 (720205.625) - AE Rec Loss: 1.580 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.868 
(2.782) - AE Loss: 1380472.125 (720205.625) - AE Rec Loss: 9.362 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.43 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 1.191 (0.658) - Batch(s): 1.868 
(2.782) - AE Loss: 353421.969 (720205.625) - AE Rec Loss: 2.397 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.43 m remaining

[Epoch <000/100>: Step <209/2280>] - Data(s): 0.000 (0.658) - Batch(s): 1.868 
(2.782) - AE Loss: 691860.250 (720205.625) - AE Rec Loss: 4.692 (4.884) - Disc 
Loss: 0.000 (0.000) - 4.48 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.170 
(2.615) - AE Loss: 396362.188 (714954.125) - AE Rec Loss: 2.688 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.171 
(2.615) - AE Loss: 2799686.000 (714954.125) - AE Rec Loss: 18.987 (4.849) - Disc
Loss: 0.000 (0.000) - 4.68 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.001 (0.592) - Batch(s): 1.159 
(2.615) - AE Loss: 113402.555 (714954.125) - AE Rec Loss: 0.769 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.176 
(2.615) - AE Loss: 524800.500 (714954.125) - AE Rec Loss: 3.559 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.171 
(2.615) - AE Loss: 196449.359 (714954.125) - AE Rec Loss: 1.332 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <210/2280>] - Data(s): 0.000 (0.592) - Batch(s): 1.171 
(2.615) - AE Loss: 142444.500 (714954.125) - AE Rec Loss: 0.966 (4.849) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.319 
(2.492) - AE Loss: 113979.312 (692697.062) - AE Rec Loss: 0.773 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.320 
(2.492) - AE Loss: 103932.938 (692697.062) - AE Rec Loss: 0.705 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.319 
(2.492) - AE Loss: 69947.031 (692697.062) - AE Rec Loss: 0.474 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.321 
(2.492) - AE Loss: 385098.188 (692697.062) - AE Rec Loss: 2.612 (4.698) - Disc 
Loss: 0.000 (0.000) - 4.89 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.323 
(2.492) - AE Loss: 1567365.625 (692697.062) - AE Rec Loss: 10.629 (4.698) - Disc
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <211/2280>] - Data(s): 0.000 (0.539) - Batch(s): 1.308 
(2.492) - AE Loss: 1787355.125 (692697.062) - AE Rec Loss: 12.121 (4.698) - Disc
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.170 (0.495) - Batch(s): 1.383 
(2.394) - AE Loss: 285695.750 (678648.250) - AE Rec Loss: 1.937 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.382 
(2.394) - AE Loss: 102372.289 (678648.250) - AE Rec Loss: 0.694 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.13 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.382 
(2.394) - AE Loss: 244969.875 (678648.250) - AE Rec Loss: 1.661 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.08 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.382 
(2.394) - AE Loss: 195737.750 (678648.250) - AE Rec Loss: 1.327 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.382 
(2.394) - AE Loss: 1494502.125 (678648.250) - AE Rec Loss: 10.135 (4.602) - Disc
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <212/2280>] - Data(s): 0.000 (0.495) - Batch(s): 1.382 
(2.394) - AE Loss: 125105.078 (678648.250) - AE Rec Loss: 0.848 (4.602) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 2.587 
(2.398) - AE Loss: 95725.570 (660804.000) - AE Rec Loss: 0.649 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.53 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.000 (0.475) - Batch(s): 2.587 
(2.398) - AE Loss: 228040.750 (660804.000) - AE Rec Loss: 1.547 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 2.588 
(2.398) - AE Loss: 205793.203 (660804.000) - AE Rec Loss: 1.396 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 2.592 
(2.398) - AE Loss: 1559735.500 (660804.000) - AE Rec Loss: 10.578 (4.481) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 2.587 
(2.398) - AE Loss: 294871.469 (660804.000) - AE Rec Loss: 2.000 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.50 m remaining

[Epoch <000/100>: Step <213/2280>] - Data(s): 0.001 (0.475) - Batch(s): 2.575 
(2.398) - AE Loss: 154336.781 (660804.000) - AE Rec Loss: 1.047 (4.481) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.099 
(2.302) - AE Loss: 1505946.000 (686788.750) - AE Rec Loss: 10.213 (4.658) - Disc
Loss: 0.000 (0.000) - 5.67 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.105 
(2.302) - AE Loss: 74345.484 (686788.750) - AE Rec Loss: 0.504 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.100 
(2.302) - AE Loss: 1617095.750 (686788.750) - AE Rec Loss: 10.967 (4.658) - Disc
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.100 
(2.302) - AE Loss: 1636426.125 (686788.750) - AE Rec Loss: 11.098 (4.658) - Disc
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.101 
(2.302) - AE Loss: 224800.531 (686788.750) - AE Rec Loss: 1.525 (4.658) - Disc 
Loss: 0.000 (0.000) - 5.71 m remaining

[Epoch <000/100>: Step <214/2280>] - Data(s): 0.000 (0.441) - Batch(s): 1.088 
(2.302) - AE Loss: 1589576.625 (686788.750) - AE Rec Loss: 10.780 (4.658) - Disc
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.334 
(2.233) - AE Loss: 1696846.625 (688386.250) - AE Rec Loss: 11.507 (4.668) - Disc
Loss: 0.000 (0.000) - 5.88 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.412) - Batch(s): 1.335 
(2.233) - AE Loss: 283316.719 (688386.250) - AE Rec Loss: 1.921 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.001 (0.412) - Batch(s): 1.335 
(2.233) - AE Loss: 1674453.750 (688386.250) - AE Rec Loss: 11.356 (4.668) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.336 
(2.233) - AE Loss: 235768.391 (688386.250) - AE Rec Loss: 1.599 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.336 
(2.233) - AE Loss: 166444.797 (688386.250) - AE Rec Loss: 1.129 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <215/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.336 
(2.233) - AE Loss: 244889.656 (688386.250) - AE Rec Loss: 1.661 (4.668) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.321 
(2.172) - AE Loss: 400262.562 (684943.812) - AE Rec Loss: 2.714 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.313 
(2.172) - AE Loss: 62238.633 (684943.812) - AE Rec Loss: 0.422 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.001 (0.387) - Batch(s): 1.314 
(2.172) - AE Loss: 1406062.250 (684943.812) - AE Rec Loss: 9.535 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.09 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.315 
(2.172) - AE Loss: 1590423.000 (684943.812) - AE Rec Loss: 10.786 (4.645) - Disc
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.313 
(2.172) - AE Loss: 112034.352 (684943.812) - AE Rec Loss: 0.760 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.14 m remaining

[Epoch <000/100>: Step <216/2280>] - Data(s): 0.000 (0.387) - Batch(s): 1.302 
(2.172) - AE Loss: 185114.766 (684943.812) - AE Rec Loss: 1.255 (4.645) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.365) - Batch(s): 1.316 
(2.118) - AE Loss: 387093.312 (665814.688) - AE Rec Loss: 2.625 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.316 
(2.118) - AE Loss: 265481.250 (665814.688) - AE Rec Loss: 1.800 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.365) - Batch(s): 1.315 
(2.118) - AE Loss: 682689.438 (665814.688) - AE Rec Loss: 4.630 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.29 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.000 (0.365) - Batch(s): 1.323 
(2.118) - AE Loss: 502306.250 (665814.688) - AE Rec Loss: 3.406 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.365) - Batch(s): 1.303 
(2.118) - AE Loss: 72011.727 (665814.688) - AE Rec Loss: 0.488 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <217/2280>] - Data(s): 0.001 (0.365) - Batch(s): 1.316 
(2.118) - AE Loss: 1407931.875 (665814.688) - AE Rec Loss: 9.548 (4.515) - Disc 
Loss: 0.000 (0.000) - 6.32 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.090 
(2.280) - AE Loss: 208514.875 (659316.000) - AE Rec Loss: 1.414 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.091 
(2.280) - AE Loss: 1879055.500 (659316.000) - AE Rec Loss: 12.743 (4.471) - Disc
Loss: 0.000 (0.000) - 7.13 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 4.455 (0.376) - Batch(s): 5.091 
(2.280) - AE Loss: 72398.016 (659316.000) - AE Rec Loss: 0.491 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.08 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.092 
(2.280) - AE Loss: 124568.328 (659316.000) - AE Rec Loss: 0.845 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.091 
(2.280) - AE Loss: 202465.000 (659316.000) - AE Rec Loss: 1.373 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <218/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.091 
(2.280) - AE Loss: 156585.391 (659316.000) - AE Rec Loss: 1.062 (4.471) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.115 
(2.316) - AE Loss: 390412.844 (674545.812) - AE Rec Loss: 2.648 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.001 (0.367) - Batch(s): 3.103 
(2.316) - AE Loss: 350111.281 (674545.812) - AE Rec Loss: 2.374 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.114 
(2.316) - AE Loss: 1661179.875 (674545.812) - AE Rec Loss: 11.266 (4.575) - Disc
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.116 
(2.316) - AE Loss: 233029.844 (674545.812) - AE Rec Loss: 1.580 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.61 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.001 (0.367) - Batch(s): 3.116 
(2.316) - AE Loss: 1684346.375 (674545.812) - AE Rec Loss: 11.423 (4.575) - Disc
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <219/2280>] - Data(s): 0.000 (0.367) - Batch(s): 3.122 
(2.316) - AE Loss: 214905.516 (674545.812) - AE Rec Loss: 1.457 (4.575) - Disc 
Loss: 0.000 (0.000) - 7.54 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.168 
(2.256) - AE Loss: 109685.695 (673821.812) - AE Rec Loss: 0.744 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.71 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.169 
(2.256) - AE Loss: 191790.453 (673821.812) - AE Rec Loss: 1.301 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.78 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.175 
(2.256) - AE Loss: 157084.828 (673821.812) - AE Rec Loss: 1.065 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.70 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.155 
(2.256) - AE Loss: 290793.188 (673821.812) - AE Rec Loss: 1.972 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.71 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.167 
(2.256) - AE Loss: 172448.891 (673821.812) - AE Rec Loss: 1.169 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.73 m remaining

[Epoch <000/100>: Step <220/2280>] - Data(s): 0.000 (0.349) - Batch(s): 1.168 
(2.256) - AE Loss: 323838.969 (673821.812) - AE Rec Loss: 2.196 (4.570) - Disc 
Loss: 0.000 (0.000) - 7.76 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:27:40,324[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,340[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,395[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,444[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,464[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:27:40,838[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:27:42,519[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,612[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,631[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,675[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:27:42,698[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,087[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:27:43,094[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,142[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,164[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:27:43,175[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,267[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:27:43,498[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:27:43,501[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:27:43,501[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(train_dataset) = 54706
[[36m2023-11-29 04:27:43,502[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
[[36m2023-11-29 04:27:43,503[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
[[36m2023-11-29 04:27:43,505[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Instantiating valid dataloader 
[[36m2023-11-29 04:27:43,505[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(train_dataloader) = 2279
=> Mixed precision: no
=> Preparing model 
len(train_dataloader) = 2279
=> Mixed precision: no
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataset) = 4
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 3 on node 6
Reached 5 on node 10
Reached 5 on node 6
Reached end on node 10
Reached end on node 6
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing model 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6Reached 1.3 on node 10

Reached 1.4 on node 10
Reached 1.4 on node 6
Reached 2 on node 10
Reached 2 on node 6
=> Preparing opt_ae 
Reached 3 on node 10
Reached 3 on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 5 on node 10
Reached 5 on node 6
Reached end on node 10Reached end on node 6

Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 10
Reached 3 on node 6
Reached 5 on node 10
Reached 5 on node 6
Reached end on node 10
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 1.3 on node 11Reached 2 on node 8

Reached 1.4 on node 11
Reached 2 on node 11Reached 3 on node 8

Reached 5 on node 8
Reached 3 on node 11
Reached end on node 8
Reached 5 on node 11
Reached 1.3 on node 6
Reached end on node 11Reached 1.4 on node 6

Reached 1.3 on node 10
Reached 2 on node 6Reached 1.4 on node 10

Reached 2 on node 10
Reached 3 on node 6
Reached 5 on node 6Reached 3 on node 10

Reached end on node 6Reached 5 on node 10

Reached end on node 10
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 1.3 on node 7Reached 2 on node 9

Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 9
Reached 3 on node 7Reached 5 on node 9

Reached 5 on node 7
Reached end on node 9
Reached end on node 7
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 1 on node 11Reached 2 on node 8

Reached 1 on node 6Reached 1.4 on node 11Reached 1 on node 7


Reached 2 on node 11
Reached 1.4 on node 6Reached 1.4 on node 7

Reached 2 on node 6Reached 2 on node 7

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 10
Reached 5 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 1.4 on node 8Reached 2 on node 9

Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7Reached 1 on node 10

Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9Reached 1 on node 8

Reached 1.4 on node 8Reached 1.4 on node 9

Reached 2 on node 8Reached 2 on node 9

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 1.4 on node 11Reached 3 on node 9

Reached 3 on node 9
Reached 2 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 7
Reached end on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 11
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
=> Starting model training 
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <221/2280>] - Data(s): 6.555 (5.557) - Batch(s): 10.350 
(10.452) - AE Loss: 74218.008 (384334.250) - AE Rec Loss: 0.503 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 8.552 (5.557) - Batch(s): 10.328 
(10.452) - AE Loss: 1428392.500 (384334.250) - AE Rec Loss: 9.687 (2.606) - Disc
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 4.284 (5.557) - Batch(s): 10.329 
(10.452) - AE Loss: 67403.258 (384334.250) - AE Rec Loss: 0.457 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 5.726 (5.557) - Batch(s): 10.345 
(10.452) - AE Loss: 75199.625 (384334.250) - AE Rec Loss: 0.510 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 5.914 (5.557) - Batch(s): 10.357 
(10.452) - AE Loss: 272192.438 (384334.250) - AE Rec Loss: 1.846 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 4.038 (5.557) - Batch(s): 10.353 
(10.452) - AE Loss: 555222.750 (384334.250) - AE Rec Loss: 3.765 (2.606) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.377 
(5.882) - AE Loss: 149238.312 (525178.688) - AE Rec Loss: 1.012 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.381 
(5.882) - AE Loss: 1665888.875 (525178.688) - AE Rec Loss: 11.298 (3.562) - Disc
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.779) - Batch(s): 1.380 
(5.882) - AE Loss: 1559262.000 (525178.688) - AE Rec Loss: 10.574 (3.562) - Disc
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.779) - Batch(s): 1.383 
(5.882) - AE Loss: 252758.312 (525178.688) - AE Rec Loss: 1.714 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.779) - Batch(s): 1.368 
(5.882) - AE Loss: 395184.500 (525178.688) - AE Rec Loss: 2.680 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.87 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.779) - Batch(s): 1.378 
(5.882) - AE Loss: 150342.891 (525178.688) - AE Rec Loss: 1.020 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.87 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <223/2280>] - Data(s): 0.863 (1.877) - Batch(s): 1.506 
(4.405) - AE Loss: 1526793.375 (561457.062) - AE Rec Loss: 10.354 (3.808) - Disc
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.506 
(4.405) - AE Loss: 75095.672 (561457.062) - AE Rec Loss: 0.509 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.507 
(4.405) - AE Loss: 72293.578 (561457.062) - AE Rec Loss: 0.490 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.506 
(4.405) - AE Loss: 109437.414 (561457.062) - AE Rec Loss: 0.742 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.507 
(4.405) - AE Loss: 143893.281 (561457.062) - AE Rec Loss: 0.976 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.877) - Batch(s): 1.506 
(4.405) - AE Loss: 140080.750 (561457.062) - AE Rec Loss: 0.950 (3.808) - Disc 
Loss: 0.000 (0.000) - 2.12 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.132 
(3.575) - AE Loss: 1821168.000 (598042.188) - AE Rec Loss: 12.351 (4.056) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.136 
(3.575) - AE Loss: 1509968.250 (598042.188) - AE Rec Loss: 10.240 (4.056) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.135 
(3.575) - AE Loss: 75090.062 (598042.188) - AE Rec Loss: 0.509 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.001 (1.408) - Batch(s): 1.139 
(3.575) - AE Loss: 386709.719 (598042.188) - AE Rec Loss: 2.623 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.001 (1.408) - Batch(s): 1.134 
(3.575) - AE Loss: 1473239.000 (598042.188) - AE Rec Loss: 9.991 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.408) - Batch(s): 1.122 
(3.575) - AE Loss: 246775.516 (598042.188) - AE Rec Loss: 1.674 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.245 
(3.098) - AE Loss: 63953.891 (596834.062) - AE Rec Loss: 0.434 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.126) - Batch(s): 1.236 
(3.098) - AE Loss: 255145.562 (596834.062) - AE Rec Loss: 1.730 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.247 
(3.098) - AE Loss: 576873.750 (596834.062) - AE Rec Loss: 3.912 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.248 
(3.098) - AE Loss: 314974.188 (596834.062) - AE Rec Loss: 2.136 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.252 
(3.098) - AE Loss: 1941752.125 (596834.062) - AE Rec Loss: 13.168 (4.048) - Disc
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.126) - Batch(s): 1.246 
(3.098) - AE Loss: 229996.109 (596834.062) - AE Rec Loss: 1.560 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 1.182 (0.962) - Batch(s): 1.845 
(2.882) - AE Loss: 560923.000 (659255.562) - AE Rec Loss: 3.804 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.846 
(2.882) - AE Loss: 188839.141 (659255.562) - AE Rec Loss: 1.281 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.515 (0.962) - Batch(s): 1.845 
(2.882) - AE Loss: 220331.297 (659255.562) - AE Rec Loss: 1.494 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.846 
(2.882) - AE Loss: 3135260.000 (659255.562) - AE Rec Loss: 21.262 (4.471) - Disc
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.847 
(2.882) - AE Loss: 146260.922 (659255.562) - AE Rec Loss: 0.992 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.962) - Batch(s): 1.848 
(2.882) - AE Loss: 1478536.000 (659255.562) - AE Rec Loss: 10.027 (4.471) - Disc
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.280 
(2.644) - AE Loss: 600872.375 (620250.312) - AE Rec Loss: 4.075 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.278 
(2.644) - AE Loss: 94753.430 (620250.312) - AE Rec Loss: 0.643 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.284 
(2.644) - AE Loss: 327500.188 (620250.312) - AE Rec Loss: 2.221 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.276 
(2.644) - AE Loss: 2022183.500 (620250.312) - AE Rec Loss: 13.714 (4.206) - Disc
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.277 
(2.644) - AE Loss: 103056.242 (620250.312) - AE Rec Loss: 0.699 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.825) - Batch(s): 1.267 
(2.644) - AE Loss: 338076.062 (620250.312) - AE Rec Loss: 2.293 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.291 
(2.467) - AE Loss: 203006.906 (572314.375) - AE Rec Loss: 1.377 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.290 
(2.467) - AE Loss: 114999.695 (572314.375) - AE Rec Loss: 0.780 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.278 
(2.467) - AE Loss: 113790.336 (572314.375) - AE Rec Loss: 0.772 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.287 
(2.467) - AE Loss: 421577.750 (572314.375) - AE Rec Loss: 2.859 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.289 
(2.467) - AE Loss: 219645.281 (572314.375) - AE Rec Loss: 1.490 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.000 (0.722) - Batch(s): 1.295 
(2.467) - AE Loss: 274726.906 (572314.375) - AE Rec Loss: 1.863 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.20 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 1.399 (0.678) - Batch(s): 3.117 
(2.535) - AE Loss: 272944.562 (558195.625) - AE Rec Loss: 1.851 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 1591274.250 (558195.625) - AE Rec Loss: 10.792 (3.786) - Disc
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.001 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 85494.281 (558195.625) - AE Rec Loss: 0.580 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 417528.594 (558195.625) - AE Rec Loss: 2.832 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.678) - Batch(s): 3.118 
(2.535) - AE Loss: 173191.031 (558195.625) - AE Rec Loss: 1.175 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 2.422 (0.678) - Batch(s): 3.119 
(2.535) - AE Loss: 394292.625 (558195.625) - AE Rec Loss: 2.674 (3.786) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.708 
(2.441) - AE Loss: 238209.062 (584214.375) - AE Rec Loss: 1.615 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.620) - Batch(s): 1.713 
(2.441) - AE Loss: 231062.922 (584214.375) - AE Rec Loss: 1.567 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.708 
(2.441) - AE Loss: 1733878.250 (584214.375) - AE Rec Loss: 11.759 (3.962) - Disc
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.696 
(2.441) - AE Loss: 590235.125 (584214.375) - AE Rec Loss: 4.003 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.708 
(2.441) - AE Loss: 525076.125 (584214.375) - AE Rec Loss: 3.561 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.620) - Batch(s): 1.711 
(2.441) - AE Loss: 1429809.375 (584214.375) - AE Rec Loss: 9.697 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.93 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.509 
(2.342) - AE Loss: 266422.594 (576558.688) - AE Rec Loss: 1.807 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.515 
(2.342) - AE Loss: 118996.727 (576558.688) - AE Rec Loss: 0.807 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.499 
(2.342) - AE Loss: 132249.016 (576558.688) - AE Rec Loss: 0.897 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.511 
(2.342) - AE Loss: 573954.500 (576558.688) - AE Rec Loss: 3.892 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.512 
(2.342) - AE Loss: 82890.367 (576558.688) - AE Rec Loss: 0.562 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.510 
(2.342) - AE Loss: 112218.406 (576558.688) - AE Rec Loss: 0.761 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 115145.648 (599062.250) - AE Rec Loss: 0.781 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 3.640 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 84579.125 (599062.250) - AE Rec Loss: 0.574 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 75802.344 (599062.250) - AE Rec Loss: 0.514 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 5.931 (0.590) - Batch(s): 6.570 
(2.690) - AE Loss: 224274.266 (599062.250) - AE Rec Loss: 1.521 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 1441835.500 (599062.250) - AE Rec Loss: 9.778 (4.063) - Disc 
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.590) - Batch(s): 6.568 
(2.690) - AE Loss: 1567715.000 (599062.250) - AE Rec Loss: 10.632 (4.063) - Disc
Loss: 0.000 (0.000) - 5.12 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.098 
(2.564) - AE Loss: 141401.719 (590506.562) - AE Rec Loss: 0.959 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.101 
(2.564) - AE Loss: 288427.344 (590506.562) - AE Rec Loss: 1.956 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.098 
(2.564) - AE Loss: 1406022.875 (590506.562) - AE Rec Loss: 9.535 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.103 
(2.564) - AE Loss: 121196.336 (590506.562) - AE Rec Loss: 0.822 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.099 
(2.564) - AE Loss: 1407230.625 (590506.562) - AE Rec Loss: 9.543 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.545) - Batch(s): 1.087 
(2.564) - AE Loss: 92158.977 (590506.562) - AE Rec Loss: 0.625 (4.005) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.001 (0.506) - Batch(s): 1.142 
(2.459) - AE Loss: 333930.375 (597921.938) - AE Rec Loss: 2.265 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.142 
(2.459) - AE Loss: 242174.234 (597921.938) - AE Rec Loss: 1.642 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.142 
(2.459) - AE Loss: 1650028.500 (597921.938) - AE Rec Loss: 11.190 (4.055) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.144 
(2.459) - AE Loss: 441198.188 (597921.938) - AE Rec Loss: 2.992 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.130 
(2.459) - AE Loss: 1376055.750 (597921.938) - AE Rec Loss: 9.332 (4.055) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.506) - Batch(s): 1.147 
(2.459) - AE Loss: 1535517.625 (597921.938) - AE Rec Loss: 10.413 (4.055) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.159 
(2.369) - AE Loss: 170054.438 (610322.188) - AE Rec Loss: 1.153 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.159 
(2.369) - AE Loss: 1566330.250 (610322.188) - AE Rec Loss: 10.622 (4.139) - Disc
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.472) - Batch(s): 1.159 
(2.369) - AE Loss: 77175.461 (610322.188) - AE Rec Loss: 0.523 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.001 (0.472) - Batch(s): 1.159 
(2.369) - AE Loss: 69392.664 (610322.188) - AE Rec Loss: 0.471 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.161 
(2.369) - AE Loss: 68873.219 (610322.188) - AE Rec Loss: 0.467 (4.139) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.472) - Batch(s): 1.161 
(2.369) - AE Loss: 1686062.875 (610322.188) - AE Rec Loss: 11.434 (4.139) - Disc
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.058 
(2.285) - AE Loss: 123027.836 (607751.188) - AE Rec Loss: 0.834 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.443) - Batch(s): 1.057 
(2.285) - AE Loss: 107658.641 (607751.188) - AE Rec Loss: 0.730 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.062 
(2.285) - AE Loss: 1646148.250 (607751.188) - AE Rec Loss: 11.164 (4.122) - Disc
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.046 
(2.285) - AE Loss: 86994.578 (607751.188) - AE Rec Loss: 0.590 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.058 
(2.285) - AE Loss: 276047.094 (607751.188) - AE Rec Loss: 1.872 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.443) - Batch(s): 1.060 
(2.285) - AE Loss: 194703.344 (607751.188) - AE Rec Loss: 1.320 (4.122) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.417) - Batch(s): 1.279 
(2.222) - AE Loss: 1862595.000 (606358.250) - AE Rec Loss: 12.632 (4.112) - Disc
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.282 
(2.222) - AE Loss: 207563.281 (606358.250) - AE Rec Loss: 1.408 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.417) - Batch(s): 1.280 
(2.222) - AE Loss: 138708.750 (606358.250) - AE Rec Loss: 0.941 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.287 
(2.222) - AE Loss: 194417.453 (606358.250) - AE Rec Loss: 1.318 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.269 
(2.222) - AE Loss: 182297.734 (606358.250) - AE Rec Loss: 1.236 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.417) - Batch(s): 1.280 
(2.222) - AE Loss: 1495916.875 (606358.250) - AE Rec Loss: 10.145 (4.112) - Disc
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 1.210 
(2.163) - AE Loss: 134737.312 (598708.875) - AE Rec Loss: 0.914 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.211 
(2.163) - AE Loss: 1862249.125 (598708.875) - AE Rec Loss: 12.629 (4.060) - Disc
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.211 
(2.163) - AE Loss: 196400.891 (598708.875) - AE Rec Loss: 1.332 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.211 
(2.163) - AE Loss: 150901.219 (598708.875) - AE Rec Loss: 1.023 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.394) - Batch(s): 1.212 
(2.163) - AE Loss: 173828.812 (598708.875) - AE Rec Loss: 1.179 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.001 (0.394) - Batch(s): 1.212 
(2.163) - AE Loss: 157992.859 (598708.875) - AE Rec Loss: 1.071 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.11 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.177 
(2.109) - AE Loss: 98086.438 (582979.062) - AE Rec Loss: 0.665 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.184 
(2.109) - AE Loss: 67623.938 (582979.062) - AE Rec Loss: 0.459 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.178 
(2.109) - AE Loss: 152874.906 (582979.062) - AE Rec Loss: 1.037 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.180 
(2.109) - AE Loss: 228998.969 (582979.062) - AE Rec Loss: 1.553 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.166 
(2.109) - AE Loss: 316704.438 (582979.062) - AE Rec Loss: 2.148 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.001 (0.373) - Batch(s): 1.177 
(2.109) - AE Loss: 128536.523 (582979.062) - AE Rec Loss: 0.872 (3.954) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.376) - Batch(s): 5.105 
(2.246) - AE Loss: 623083.125 (587034.875) - AE Rec Loss: 4.226 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 4.524 (0.376) - Batch(s): 5.087 
(2.246) - AE Loss: 364203.812 (587034.875) - AE Rec Loss: 2.470 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.376) - Batch(s): 5.097 
(2.246) - AE Loss: 2218903.750 (587034.875) - AE Rec Loss: 15.048 (3.981) - Disc
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.376) - Batch(s): 4.741 
(2.246) - AE Loss: 109046.133 (587034.875) - AE Rec Loss: 0.740 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.376) - Batch(s): 5.096 
(2.246) - AE Loss: 250635.641 (587034.875) - AE Rec Loss: 1.700 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.376) - Batch(s): 5.101 
(2.246) - AE Loss: 204804.375 (587034.875) - AE Rec Loss: 1.389 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.98 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:29:14,777[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,797[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:14,833[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:15,012[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:15,017[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:29:15,159[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:29:16,985[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:17,020[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:17,105[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:17,224[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:17,278[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,494[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,534[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,590[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:29:17,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,728[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:17,792[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:29:18,022[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 04:29:18,025[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
[[36m2023-11-29 04:29:18,032[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:29:18,033[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:29:18,033[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:29:18,033[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:29:18,034[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.3 on node 11Reached end on node 9

Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8Reached 1.3 on node 10

Reached 1.4 on node 8Reached 1.4 on node 10

Reached 1.3 on node 6Reached 2 on node 8Reached 2 on node 10


Reached 1.4 on node 6
Reached 1.3 on node 7Reached 1.3 on node 9Reached 2 on node 6

Reached 3 on node 8Reached 3 on node 10Reached 1.4 on node 9


Reached 1.4 on node 7

Reached 5 on node 8Reached 5 on node 10
Reached 2 on node 9

Reached 2 on node 7Reached 3 on node 6

Reached end on node 8Reached end on node 10

Reached 5 on node 6
Reached 3 on node 9
Reached 3 on node 7Reached end on node 6
Reached 5 on node 9

Reached 5 on node 7
Reached end on node 9
Reached 1.3 on node 11
Reached end on node 7Reached 1.4 on node 11

Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 221
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 7Reached 1.4 on node 9

Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11Reached 1 on node 6

Reached 1 on node 7
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6Reached 1.4 on node 7
Reached 1.4 on node 8

Reached 3 on node 6
Reached 2 on node 7Reached 2 on node 8Reached 3 on node 6


Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 7

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11Reached 3 on node 9

Reached 2 on node 11Reached 5 on node 9
Reached 1.4 on node 7

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10Reached end on node 6

Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 9
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <221/2280>] - Data(s): 4.963 (5.680) - Batch(s): 10.795 
(10.820) - AE Loss: 68777.969 (384473.156) - AE Rec Loss: 0.466 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 4.093 (5.680) - Batch(s): 10.775 
(10.820) - AE Loss: 554874.562 (384473.156) - AE Rec Loss: 3.763 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 5.971 (5.680) - Batch(s): 11.075 
(10.820) - AE Loss: 271077.812 (384473.156) - AE Rec Loss: 1.838 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 6.100 (5.680) - Batch(s): 10.772 
(10.820) - AE Loss: 76134.156 (384473.156) - AE Rec Loss: 0.516 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 8.118 (5.680) - Batch(s): 11.312 
(10.820) - AE Loss: 1428103.500 (384473.156) - AE Rec Loss: 9.685 (2.607) - Disc
Loss: 0.000 (0.000) - 1.79 m remaining

[Epoch <000/100>: Step <221/2280>] - Data(s): 6.662 (5.680) - Batch(s): 10.792 
(10.820) - AE Loss: 73162.922 (384473.156) - AE Rec Loss: 0.496 (2.607) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.224 
(5.995) - AE Loss: 149182.469 (525206.562) - AE Rec Loss: 1.012 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.228 
(5.995) - AE Loss: 1559422.250 (525206.562) - AE Rec Loss: 10.576 (3.562) - Disc
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.001 (2.840) - Batch(s): 1.224 
(5.995) - AE Loss: 150286.688 (525206.562) - AE Rec Loss: 1.019 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.213 
(5.995) - AE Loss: 395032.938 (525206.562) - AE Rec Loss: 2.679 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.229 
(5.995) - AE Loss: 253041.156 (525206.562) - AE Rec Loss: 1.716 (3.562) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <222/2280>] - Data(s): 0.000 (2.840) - Batch(s): 1.226 
(5.995) - AE Loss: 1665323.250 (525206.562) - AE Rec Loss: 11.294 (3.562) - Disc
Loss: 0.000 (0.000) - 1.99 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 109544.602 (561423.062) - AE Rec Loss: 0.743 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 72593.828 (561423.062) - AE Rec Loss: 0.492 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 143116.625 (561423.062) - AE Rec Loss: 0.971 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.000 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 140041.703 (561423.062) - AE Rec Loss: 0.950 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.964 (1.920) - Batch(s): 1.718 
(4.550) - AE Loss: 1526543.625 (561423.062) - AE Rec Loss: 10.353 (3.807) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <223/2280>] - Data(s): 0.001 (1.920) - Batch(s): 1.719 
(4.550) - AE Loss: 74553.891 (561423.062) - AE Rec Loss: 0.506 (3.807) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.277 
(3.716) - AE Loss: 385878.188 (598041.938) - AE Rec Loss: 2.617 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.275 
(3.716) - AE Loss: 75202.516 (598041.938) - AE Rec Loss: 0.510 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.272 
(3.716) - AE Loss: 1820969.750 (598041.938) - AE Rec Loss: 12.349 (4.056) - Disc
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.273 
(3.716) - AE Loss: 1509965.250 (598041.938) - AE Rec Loss: 10.240 (4.056) - Disc
Loss: 0.000 (0.000) - 2.48 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.272 
(3.716) - AE Loss: 1473213.250 (598041.938) - AE Rec Loss: 9.991 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <224/2280>] - Data(s): 0.000 (1.440) - Batch(s): 1.261 
(3.716) - AE Loss: 246775.766 (598041.938) - AE Rec Loss: 1.674 (4.056) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.258 
(3.213) - AE Loss: 65218.359 (596881.312) - AE Rec Loss: 0.442 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.152) - Batch(s): 1.245 
(3.213) - AE Loss: 255659.906 (596881.312) - AE Rec Loss: 1.734 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.258 
(3.213) - AE Loss: 315481.062 (596881.312) - AE Rec Loss: 2.139 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.264 
(3.213) - AE Loss: 1942288.250 (596881.312) - AE Rec Loss: 13.172 (4.048) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.000 (1.152) - Batch(s): 1.260 
(3.213) - AE Loss: 577051.500 (596881.312) - AE Rec Loss: 3.913 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <225/2280>] - Data(s): 0.001 (1.152) - Batch(s): 1.256 
(3.213) - AE Loss: 229869.641 (596881.312) - AE Rec Loss: 1.559 (4.048) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.009 (0.973) - Batch(s): 1.702 
(2.951) - AE Loss: 561003.375 (659272.312) - AE Rec Loss: 3.805 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.702 
(2.951) - AE Loss: 1478302.000 (659272.312) - AE Rec Loss: 10.025 (4.471) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.702 
(2.951) - AE Loss: 188195.656 (659272.312) - AE Rec Loss: 1.276 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.913 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 219877.469 (659272.312) - AE Rec Loss: 1.491 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.95 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.703 
(2.951) - AE Loss: 146071.781 (659272.312) - AE Rec Loss: 0.991 (4.471) - Disc 
Loss: 0.000 (0.000) - 2.92 m remaining

[Epoch <000/100>: Step <226/2280>] - Data(s): 0.000 (0.973) - Batch(s): 1.704 
(2.951) - AE Loss: 3135542.750 (659272.312) - AE Rec Loss: 21.264 (4.471) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.317 
(2.708) - AE Loss: 94733.289 (620228.562) - AE Rec Loss: 0.642 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.834) - Batch(s): 1.315 
(2.708) - AE Loss: 601594.750 (620228.562) - AE Rec Loss: 4.080 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.001 (0.834) - Batch(s): 1.302 
(2.708) - AE Loss: 335320.250 (620228.562) - AE Rec Loss: 2.274 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.002 (0.834) - Batch(s): 1.314 
(2.708) - AE Loss: 103414.352 (620228.562) - AE Rec Loss: 0.701 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.314 
(2.708) - AE Loss: 2022397.250 (620228.562) - AE Rec Loss: 13.715 (4.206) - Disc
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <227/2280>] - Data(s): 0.000 (0.834) - Batch(s): 1.321 
(2.708) - AE Loss: 327818.250 (620228.562) - AE Rec Loss: 2.223 (4.206) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.255 
(2.519) - AE Loss: 202940.578 (572260.688) - AE Rec Loss: 1.376 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.36 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.261 
(2.519) - AE Loss: 274584.656 (572260.688) - AE Rec Loss: 1.862 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.257 
(2.519) - AE Loss: 114908.055 (572260.688) - AE Rec Loss: 0.779 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.242 
(2.519) - AE Loss: 112907.242 (572260.688) - AE Rec Loss: 0.766 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.254 
(2.519) - AE Loss: 419696.219 (572260.688) - AE Rec Loss: 2.846 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <228/2280>] - Data(s): 0.001 (0.730) - Batch(s): 1.253 
(2.519) - AE Loss: 219828.250 (572260.688) - AE Rec Loss: 1.491 (3.881) - Disc 
Loss: 0.000 (0.000) - 3.28 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.449 
(2.616) - AE Loss: 272804.656 (558137.250) - AE Rec Loss: 1.850 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.449 
(2.616) - AE Loss: 85007.812 (558137.250) - AE Rec Loss: 0.576 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.449 
(2.616) - AE Loss: 418578.438 (558137.250) - AE Rec Loss: 2.839 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 2.675 (0.674) - Batch(s): 3.451 
(2.616) - AE Loss: 394554.062 (558137.250) - AE Rec Loss: 2.676 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.88 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.449 
(2.616) - AE Loss: 172632.531 (558137.250) - AE Rec Loss: 1.171 (3.785) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <229/2280>] - Data(s): 0.000 (0.674) - Batch(s): 3.451 
(2.616) - AE Loss: 1590852.000 (558137.250) - AE Rec Loss: 10.789 (3.785) - Disc
Loss: 0.000 (0.000) - 3.80 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.090 
(2.458) - AE Loss: 231097.578 (584155.188) - AE Rec Loss: 1.567 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.085 
(2.458) - AE Loss: 1429848.250 (584155.188) - AE Rec Loss: 9.697 (3.962) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.606) - Batch(s): 1.085 
(2.458) - AE Loss: 1734115.000 (584155.188) - AE Rec Loss: 11.760 (3.962) - Disc
Loss: 0.000 (0.000) - 4.04 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.606) - Batch(s): 1.074 
(2.458) - AE Loss: 591808.875 (584155.188) - AE Rec Loss: 4.013 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.000 (0.606) - Batch(s): 1.085 
(2.458) - AE Loss: 237737.156 (584155.188) - AE Rec Loss: 1.612 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <230/2280>] - Data(s): 0.001 (0.606) - Batch(s): 1.083 
(2.458) - AE Loss: 523502.250 (584155.188) - AE Rec Loss: 3.550 (3.962) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.314 
(2.348) - AE Loss: 118392.250 (576503.875) - AE Rec Loss: 0.803 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.310 
(2.348) - AE Loss: 82337.297 (576503.875) - AE Rec Loss: 0.558 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.21 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.001 (0.551) - Batch(s): 1.295 
(2.348) - AE Loss: 131418.406 (576503.875) - AE Rec Loss: 0.891 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.001 (0.551) - Batch(s): 1.308 
(2.348) - AE Loss: 574125.875 (576503.875) - AE Rec Loss: 3.894 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.24 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.307 
(2.348) - AE Loss: 111714.977 (576503.875) - AE Rec Loss: 0.758 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <231/2280>] - Data(s): 0.000 (0.551) - Batch(s): 1.306 
(2.348) - AE Loss: 266833.406 (576503.875) - AE Rec Loss: 1.810 (3.910) - Disc 
Loss: 0.000 (0.000) - 4.16 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.001 (0.550) - Batch(s): 4.144 
(2.493) - AE Loss: 75937.070 (598978.875) - AE Rec Loss: 0.515 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.144 
(2.493) - AE Loss: 113621.391 (598978.875) - AE Rec Loss: 0.771 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 1441474.125 (598978.875) - AE Rec Loss: 9.776 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 3.006 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 223897.672 (598978.875) - AE Rec Loss: 1.518 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.78 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 3.402 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 82934.336 (598978.875) - AE Rec Loss: 0.562 (4.062) - Disc 
Loss: 0.000 (0.000) - 4.85 m remaining

[Epoch <000/100>: Step <232/2280>] - Data(s): 0.000 (0.550) - Batch(s): 4.143 
(2.493) - AE Loss: 1567161.625 (598978.875) - AE Rec Loss: 10.628 (4.062) - Disc
Loss: 0.000 (0.000) - 4.77 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.238 
(2.391) - AE Loss: 120186.617 (590414.062) - AE Rec Loss: 0.815 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.233 
(2.391) - AE Loss: 287731.062 (590414.062) - AE Rec Loss: 1.951 (4.004) - Disc 
Loss: 0.000 (0.000) - 5.00 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.230 
(2.391) - AE Loss: 141014.672 (590414.062) - AE Rec Loss: 0.956 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.231 
(2.391) - AE Loss: 1406326.375 (590414.062) - AE Rec Loss: 9.537 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.96 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.001 (0.508) - Batch(s): 1.219 
(2.391) - AE Loss: 91732.492 (590414.062) - AE Rec Loss: 0.622 (4.004) - Disc 
Loss: 0.000 (0.000) - 4.95 m remaining

[Epoch <000/100>: Step <233/2280>] - Data(s): 0.000 (0.508) - Batch(s): 1.231 
(2.391) - AE Loss: 1406828.625 (590414.062) - AE Rec Loss: 9.541 (4.004) - Disc 
Loss: 0.000 (0.000) - 5.03 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.141 
(2.361) - AE Loss: 1535238.000 (597821.875) - AE Rec Loss: 10.411 (4.054) - Disc
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.132 
(2.361) - AE Loss: 333192.375 (597821.875) - AE Rec Loss: 2.260 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.26 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.121 
(2.361) - AE Loss: 1375664.000 (597821.875) - AE Rec Loss: 9.329 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.26 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.134 
(2.361) - AE Loss: 1649341.250 (597821.875) - AE Rec Loss: 11.185 (4.054) - Disc
Loss: 0.000 (0.000) - 5.34 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.136 
(2.361) - AE Loss: 441040.656 (597821.875) - AE Rec Loss: 2.991 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <234/2280>] - Data(s): 0.000 (0.481) - Batch(s): 2.134 
(2.361) - AE Loss: 242262.234 (597821.875) - AE Rec Loss: 1.643 (4.054) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.450 
(2.296) - AE Loss: 68308.688 (610202.688) - AE Rec Loss: 0.463 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.024 (0.449) - Batch(s): 1.449 
(2.296) - AE Loss: 77660.750 (610202.688) - AE Rec Loss: 0.527 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.55 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.452 
(2.296) - AE Loss: 1565701.625 (610202.688) - AE Rec Loss: 10.618 (4.138) - Disc
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.450 
(2.296) - AE Loss: 169244.359 (610202.688) - AE Rec Loss: 1.148 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.451 
(2.296) - AE Loss: 1684945.500 (610202.688) - AE Rec Loss: 11.427 (4.138) - Disc
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <235/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.453 
(2.296) - AE Loss: 69055.820 (610202.688) - AE Rec Loss: 0.468 (4.138) - Disc 
Loss: 0.000 (0.000) - 5.47 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.278 
(2.229) - AE Loss: 123969.484 (607696.812) - AE Rec Loss: 0.841 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.421) - Batch(s): 1.278 
(2.229) - AE Loss: 277605.812 (607696.812) - AE Rec Loss: 1.883 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.001 (0.421) - Batch(s): 1.280 
(2.229) - AE Loss: 196416.719 (607696.812) - AE Rec Loss: 1.332 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.266 
(2.229) - AE Loss: 88400.414 (607696.812) - AE Rec Loss: 0.600 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.284 
(2.229) - AE Loss: 1645580.875 (607696.812) - AE Rec Loss: 11.160 (4.121) - Disc
Loss: 0.000 (0.000) - 5.66 m remaining

[Epoch <000/100>: Step <236/2280>] - Data(s): 0.000 (0.421) - Batch(s): 1.277 
(2.229) - AE Loss: 110306.250 (607696.812) - AE Rec Loss: 0.748 (4.121) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.110 
(2.161) - AE Loss: 140203.031 (606332.312) - AE Rec Loss: 0.951 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.81 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.108 
(2.161) - AE Loss: 1863159.000 (606332.312) - AE Rec Loss: 12.635 (4.112) - Disc
Loss: 0.000 (0.000) - 5.81 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.396) - Batch(s): 1.098 
(2.161) - AE Loss: 182471.062 (606332.312) - AE Rec Loss: 1.237 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.81 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.396) - Batch(s): 1.116 
(2.161) - AE Loss: 194145.625 (606332.312) - AE Rec Loss: 1.317 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.81 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.001 (0.396) - Batch(s): 1.110 
(2.161) - AE Loss: 207617.266 (606332.312) - AE Rec Loss: 1.408 (4.112) - Disc 
Loss: 0.000 (0.000) - 5.85 m remaining

[Epoch <000/100>: Step <237/2280>] - Data(s): 0.000 (0.396) - Batch(s): 1.110 
(2.161) - AE Loss: 1496884.375 (606332.312) - AE Rec Loss: 10.151 (4.112) - Disc
Loss: 0.000 (0.000) - 5.89 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.229 
(2.106) - AE Loss: 150409.719 (598692.938) - AE Rec Loss: 1.020 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.227 
(2.106) - AE Loss: 158101.656 (598692.938) - AE Rec Loss: 1.072 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.228 
(2.106) - AE Loss: 175852.562 (598692.938) - AE Rec Loss: 1.193 (4.060) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.228 
(2.106) - AE Loss: 1861701.000 (598692.938) - AE Rec Loss: 12.625 (4.060) - Disc
Loss: 0.000 (0.000) - 5.99 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.228 
(2.106) - AE Loss: 196217.047 (598692.938) - AE Rec Loss: 1.331 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.06 m remaining

[Epoch <000/100>: Step <238/2280>] - Data(s): 0.000 (0.374) - Batch(s): 1.228 
(2.106) - AE Loss: 134475.547 (598692.938) - AE Rec Loss: 0.912 (4.060) - Disc 
Loss: 0.000 (0.000) - 6.03 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.265 
(2.059) - AE Loss: 230364.656 (582948.750) - AE Rec Loss: 1.562 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.20 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.254 
(2.059) - AE Loss: 315983.125 (582948.750) - AE Rec Loss: 2.143 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.264 
(2.059) - AE Loss: 96763.203 (582948.750) - AE Rec Loss: 0.656 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.264 
(2.059) - AE Loss: 128392.109 (582948.750) - AE Rec Loss: 0.871 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.265 
(2.059) - AE Loss: 150602.094 (582948.750) - AE Rec Loss: 1.021 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.23 m remaining

[Epoch <000/100>: Step <239/2280>] - Data(s): 0.000 (0.354) - Batch(s): 1.271 
(2.059) - AE Loss: 68043.734 (582948.750) - AE Rec Loss: 0.461 (3.953) - Disc 
Loss: 0.000 (0.000) - 6.16 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.268 (0.338) - Batch(s): 1.309 
(2.019) - AE Loss: 364579.688 (586997.438) - AE Rec Loss: 2.472 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.321 
(2.019) - AE Loss: 203755.391 (586997.438) - AE Rec Loss: 1.382 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.38 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.338) - Batch(s): 1.320 
(2.019) - AE Loss: 107471.539 (586997.438) - AE Rec Loss: 0.729 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.000 (0.338) - Batch(s): 1.319 
(2.019) - AE Loss: 2219799.500 (586997.438) - AE Rec Loss: 15.054 (3.981) - Disc
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.338) - Batch(s): 1.319 
(2.019) - AE Loss: 251151.812 (586997.438) - AE Rec Loss: 1.703 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <240/2280>] - Data(s): 0.001 (0.338) - Batch(s): 1.327 
(2.019) - AE Loss: 622750.000 (586997.438) - AE Rec Loss: 4.223 (3.981) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 140396.109 (595459.062) - AE Rec Loss: 0.952 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.77 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 196521.641 (595459.062) - AE Rec Loss: 1.333 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.001 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 1646484.500 (595459.062) - AE Rec Loss: 11.166 (4.038) - Disc
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 106976.711 (595459.062) - AE Rec Loss: 0.725 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.74 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 1670244.500 (595459.062) - AE Rec Loss: 11.327 (4.038) - Disc
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 0.000 (0.322) - Batch(s): 23.959 
(2.972) - AE Loss: 256219.562 (595459.062) - AE Rec Loss: 1.738 (4.038) - Disc 
Loss: 0.000 (0.000) - 9.70 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.045 
(2.882) - AE Loss: 146367.094 (597896.125) - AE Rec Loss: 0.993 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 88332.891 (597896.125) - AE Rec Loss: 0.599 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 88315.227 (597896.125) - AE Rec Loss: 0.599 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.026 
(2.882) - AE Loss: 77512.430 (597896.125) - AE Rec Loss: 0.526 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.82 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.039 
(2.882) - AE Loss: 1792518.500 (597896.125) - AE Rec Loss: 12.156 (4.055) - Disc
Loss: 0.000 (0.000) - 9.86 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (0.307) - Batch(s): 1.038 
(2.882) - AE Loss: 367937.406 (597896.125) - AE Rec Loss: 2.495 (4.055) - Disc 
Loss: 0.000 (0.000) - 9.90 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:33:51,671[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,753[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,825[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,828[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:51,850[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:33:52,220[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:33:53,856[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:53,945[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:54,020[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:54,039[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:54,053[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,336[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,416[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:33:54,426[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,546[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,576[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,611[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:33:54,849[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:33:54,852[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 04:33:54,855[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,855[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:33:54,856[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,856[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:33:54,856[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6Reached 3 on node 11

Reached end on node 6Reached 5 on node 11

Reached end on node 11
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing model 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8Reached 3 on node 10

Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:35:23,710[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,733[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:23,969[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:24,062[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:24,066[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:35:24,198[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:35:25,933[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:25,955[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:26,186[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,377[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:35:26,387[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,395[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:35:26,407[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 04:35:26,426[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,676[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,864[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 04:35:26,868[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:35:26,900[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:35:26,903[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:35:26,903[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:35:26,906[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
[[36m2023-11-29 04:35:26,907[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 04:35:26,907[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
[[36m2023-11-29 04:35:26,912[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Preparing model 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
len(train_dataset) = 54706
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Instantiating valid dataloader 
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
=> Preparing opt_ae 
Reached 3 on node 8Reached 1.3 on node 10

Reached 1.3 on node 9Reached 1.4 on node 10

Reached 1.4 on node 9
Reached 5 on node 8Reached 2 on node 10
Reached 2 on node 9

Reached end on node 8
Reached 3 on node 9Reached 3 on node 10

Reached 5 on node 9Reached 5 on node 10

Reached end on node 9
Reached end on node 10
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 9Reached 3 on node 8Reached 3 on node 10


Reached 5 on node 10Reached 5 on node 8
Reached 5 on node 9

Reached end on node 10Reached end on node 8

Reached end on node 9
Reached 3 on node 11
=> Preparing criterion 
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7Reached 1.3 on node 6

Reached 1.4 on node 7Reached 1.4 on node 6

Reached 2 on node 7Reached 2 on node 6

Reached 3 on node 6Reached 3 on node 7

Reached 5 on node 7Reached 5 on node 6

Reached end on node 7Reached end on node 6

Reached 1.3 on node 9Reached 1.3 on node 10
Reached 1.3 on node 8

Reached 1.4 on node 9Reached 1.4 on node 10

Reached 1.4 on node 8
Reached 2 on node 9Reached 2 on node 10
Reached 2 on node 8

Reached 3 on node 9Reached 3 on node 10Reached 3 on node 8


Reached 5 on node 9Reached 5 on node 8Reached 5 on node 10


Reached end on node 9Reached end on node 8Reached end on node 10


Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1 on node 8Reached 2 on node 7

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 1.4 on node 9
Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 9Reached 2 on node 6Reached 1 on node 8


Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7Reached 1 on node 6

Reached 1 on node 11
Reached 1 on node 9Reached 1.4 on node 7Reached 1.4 on node 6


Reached 2 on node 7Reached 2 on node 6

Reached 3 on node 6Reached 1.4 on node 11

Reached 1.4 on node 9Reached 3 on node 6Reached 1 on node 8

Reached 2 on node 11

Reached 2 on node 9
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6Reached 1.4 on node 8

Reached 2 on node 8
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 7Reached 1 on node 8

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8
Reached 3 on node 7
Reached 2 on node 8Reached 3 on node 7

Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11Reached 1 on node 9

Reached 1.4 on node 9
Reached 2 on node 9Reached 1.4 on node 11

Reached 2 on node 11
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 6Reached 1 on node 10

Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 1.4 on node 10Reached 2 on node 9

Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 10
Reached end on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 7
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 5.367 (6.133) - Batch(s): 10.905 
(11.005) - AE Loss: 1646903.500 (764854.500) - AE Rec Loss: 11.169 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.446 (6.133) - Batch(s): 10.908 
(11.005) - AE Loss: 195600.109 (764854.500) - AE Rec Loss: 1.326 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 9.425 (6.133) - Batch(s): 10.864 
(11.005) - AE Loss: 1670042.000 (764854.500) - AE Rec Loss: 11.326 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 3.814 (6.133) - Batch(s): 10.899 
(11.005) - AE Loss: 140307.328 (764854.500) - AE Rec Loss: 0.952 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.680 (6.133) - Batch(s): 10.906 
(11.005) - AE Loss: 107613.430 (764854.500) - AE Rec Loss: 0.730 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.947 (6.133) - Batch(s): 10.896 
(11.005) - AE Loss: 257003.375 (764854.500) - AE Rec Loss: 1.743 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.197 
(6.072) - AE Loss: 146882.375 (708585.750) - AE Rec Loss: 0.996 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.193 
(6.072) - AE Loss: 97622.734 (708585.750) - AE Rec Loss: 0.662 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.183 
(6.072) - AE Loss: 83224.047 (708585.750) - AE Rec Loss: 0.564 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.001 (3.067) - Batch(s): 1.192 
(6.072) - AE Loss: 375948.375 (708585.750) - AE Rec Loss: 2.550 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (3.067) - Batch(s): 1.193 
(6.072) - AE Loss: 1791498.750 (708585.750) - AE Rec Loss: 12.149 (4.805) - Disc
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.001 (3.067) - Batch(s): 1.189 
(6.072) - AE Loss: 98149.062 (708585.750) - AE Rec Loss: 0.666 (4.805) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.728 
(5.609) - AE Loss: 1863362.000 (744477.125) - AE Rec Loss: 12.637 (5.049) - Disc
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.727 
(5.609) - AE Loss: 239569.609 (744477.125) - AE Rec Loss: 1.625 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.727 
(5.609) - AE Loss: 532177.000 (744477.125) - AE Rec Loss: 3.609 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.727 
(5.609) - AE Loss: 121332.047 (744477.125) - AE Rec Loss: 0.823 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.256) - Batch(s): 4.727 
(5.609) - AE Loss: 111169.883 (744477.125) - AE Rec Loss: 0.754 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 3.523 (2.256) - Batch(s): 4.728 
(5.609) - AE Loss: 231944.016 (744477.125) - AE Rec Loss: 1.573 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.021 
(4.451) - AE Loss: 193767.531 (756529.500) - AE Rec Loss: 1.314 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.017 
(4.451) - AE Loss: 252338.078 (756529.500) - AE Rec Loss: 1.711 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.005 
(4.451) - AE Loss: 1548014.250 (756529.500) - AE Rec Loss: 10.498 (5.131) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.001 (1.692) - Batch(s): 1.015 
(4.451) - AE Loss: 123092.320 (756529.500) - AE Rec Loss: 0.835 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.013 
(4.451) - AE Loss: 1556334.500 (756529.500) - AE Rec Loss: 10.555 (5.131) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.692) - Batch(s): 1.016 
(4.451) - AE Loss: 224117.938 (756529.500) - AE Rec Loss: 1.520 (5.131) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.752 
(3.868) - AE Loss: 1607778.750 (747887.250) - AE Rec Loss: 10.903 (5.072) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.754 
(3.868) - AE Loss: 607854.938 (747887.250) - AE Rec Loss: 4.122 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.745 
(3.868) - AE Loss: 119604.367 (747887.250) - AE Rec Loss: 0.811 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.760 
(3.868) - AE Loss: 1945475.750 (747887.250) - AE Rec Loss: 13.194 (5.072) - Disc
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.374) - Batch(s): 1.755 
(3.868) - AE Loss: 340814.438 (747887.250) - AE Rec Loss: 2.311 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 1.193 (1.374) - Batch(s): 1.757 
(3.868) - AE Loss: 132903.844 (747887.250) - AE Rec Loss: 0.901 (5.072) - Disc 
Loss: 0.000 (0.000) - 2.83 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.154 
(3.408) - AE Loss: 1488721.750 (762172.438) - AE Rec Loss: 10.096 (5.169) - Disc
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.152 
(3.408) - AE Loss: 220118.812 (762172.438) - AE Rec Loss: 1.493 (5.169) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.152 
(3.408) - AE Loss: 178369.344 (762172.438) - AE Rec Loss: 1.210 (5.169) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.154 
(3.408) - AE Loss: 414512.000 (762172.438) - AE Rec Loss: 2.811 (5.169) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.149) - Batch(s): 1.154 
(3.408) - AE Loss: 1348422.750 (762172.438) - AE Rec Loss: 9.145 (5.169) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.149) - Batch(s): 1.154 
(3.408) - AE Loss: 633191.125 (762172.438) - AE Rec Loss: 4.294 (5.169) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.048 
(3.066) - AE Loss: 177322.078 (706478.562) - AE Rec Loss: 1.203 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.058 
(3.066) - AE Loss: 68484.312 (706478.562) - AE Rec Loss: 0.464 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.055 
(3.066) - AE Loss: 94519.391 (706478.562) - AE Rec Loss: 0.641 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.203 (0.987) - Batch(s): 1.060 
(3.066) - AE Loss: 255572.516 (706478.562) - AE Rec Loss: 1.733 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.063 
(3.066) - AE Loss: 118239.688 (706478.562) - AE Rec Loss: 0.802 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.987) - Batch(s): 1.058 
(3.066) - AE Loss: 160050.578 (706478.562) - AE Rec Loss: 1.085 (4.791) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.952 
(3.148) - AE Loss: 223857.734 (718335.438) - AE Rec Loss: 1.518 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 3.376 (0.908) - Batch(s): 3.950 
(3.148) - AE Loss: 1302463.500 (718335.438) - AE Rec Loss: 8.833 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.950 
(3.148) - AE Loss: 164596.016 (718335.438) - AE Rec Loss: 1.116 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.947 
(3.148) - AE Loss: 544071.750 (718335.438) - AE Rec Loss: 3.690 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.936 
(3.148) - AE Loss: 65020.258 (718335.438) - AE Rec Loss: 0.441 (4.872) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.908) - Batch(s): 3.947 
(3.148) - AE Loss: 1597717.375 (718335.438) - AE Rec Loss: 10.835 (4.872) - Disc
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 129026.391 (704437.750) - AE Rec Loss: 0.875 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 112446.156 (704437.750) - AE Rec Loss: 0.763 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 131171.422 (704437.750) - AE Rec Loss: 0.890 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 119921.859 (704437.750) - AE Rec Loss: 0.813 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 1462549.250 (704437.750) - AE Rec Loss: 9.919 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.902) - Batch(s): 9.129 
(3.808) - AE Loss: 1429416.000 (704437.750) - AE Rec Loss: 9.694 (4.777) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.812) - Batch(s): 1.004 
(3.523) - AE Loss: 706506.062 (680213.562) - AE Rec Loss: 4.791 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 1.002 
(3.523) - AE Loss: 1473543.125 (680213.562) - AE Rec Loss: 9.993 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.988 
(3.523) - AE Loss: 163930.812 (680213.562) - AE Rec Loss: 1.112 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.812) - Batch(s): 0.999 
(3.523) - AE Loss: 52238.508 (680213.562) - AE Rec Loss: 0.354 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.812) - Batch(s): 0.999 
(3.523) - AE Loss: 237143.281 (680213.562) - AE Rec Loss: 1.608 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.001 (0.812) - Batch(s): 0.999 
(3.523) - AE Loss: 110642.336 (680213.562) - AE Rec Loss: 0.750 (4.613) - Disc 
Loss: 0.000 (0.000) - 5.06 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.383 
(3.592) - AE Loss: 86653.336 (653895.812) - AE Rec Loss: 0.588 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.366 
(3.592) - AE Loss: 126559.039 (653895.812) - AE Rec Loss: 0.858 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.378 
(3.592) - AE Loss: 1427572.500 (653895.812) - AE Rec Loss: 9.681 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.377 
(3.592) - AE Loss: 1659154.125 (653895.812) - AE Rec Loss: 11.252 (4.435) - Disc
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.380 
(3.592) - AE Loss: 319724.375 (653895.812) - AE Rec Loss: 2.168 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.767) - Batch(s): 4.377 
(3.592) - AE Loss: 93408.570 (653895.812) - AE Rec Loss: 0.633 (4.435) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 75431.570 (662863.625) - AE Rec Loss: 0.512 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 493796.188 (662863.625) - AE Rec Loss: 3.349 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 1722576.375 (662863.625) - AE Rec Loss: 11.682 (4.495) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 446049.406 (662863.625) - AE Rec Loss: 3.025 (4.495) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 1476926.750 (662863.625) - AE Rec Loss: 10.016 (4.495) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.843) - Batch(s): 10.433 
(4.159) - AE Loss: 1599928.500 (662863.625) - AE Rec Loss: 10.850 (4.495) - Disc
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.553 
(4.252) - AE Loss: 155026.781 (686191.250) - AE Rec Loss: 1.051 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.566 
(4.252) - AE Loss: 1651849.625 (686191.250) - AE Rec Loss: 11.202 (4.654) - Disc
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.565 
(4.252) - AE Loss: 54261.012 (686191.250) - AE Rec Loss: 0.368 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.565 
(4.252) - AE Loss: 1508724.875 (686191.250) - AE Rec Loss: 10.232 (4.654) - Disc
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.564 
(4.252) - AE Loss: 493380.875 (686191.250) - AE Rec Loss: 3.346 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.810) - Batch(s): 5.570 
(4.252) - AE Loss: 414341.250 (686191.250) - AE Rec Loss: 2.810 (4.654) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 0.997 
(4.018) - AE Loss: 278677.125 (676526.688) - AE Rec Loss: 1.890 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.011 
(4.018) - AE Loss: 1635883.250 (676526.688) - AE Rec Loss: 11.094 (4.588) - Disc
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.008 
(4.018) - AE Loss: 229092.656 (676526.688) - AE Rec Loss: 1.554 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.010 
(4.018) - AE Loss: 150428.859 (676526.688) - AE Rec Loss: 1.020 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.013 
(4.018) - AE Loss: 154540.500 (676526.688) - AE Rec Loss: 1.048 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.752) - Batch(s): 1.007 
(4.018) - AE Loss: 434979.656 (676526.688) - AE Rec Loss: 2.950 (4.588) - Disc 
Loss: 0.000 (0.000) - 7.89 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:38:29,478[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,536[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,659[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,788[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,801[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:38:29,900[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:38:31,710[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,722[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,825[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,986[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:31,994[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:38:32,118[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,273[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,297[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,321[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,559[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:38:32,596[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:38:32,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:38:32,600[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
[[36m2023-11-29 04:38:32,600[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:38:32,600[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataset) = 54706
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(train_dataloader) = 2279
[[36m2023-11-29 04:38:32,604[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
[[36m2023-11-29 04:38:32,609[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing model 
Reached 3 on node 10
Reached 3 on node 7
Reached 5 on node 10
Reached 5 on node 7
Reached end on node 10
Reached end on node 7
=> Mixed precision: no
=> Preparing model 
=> Preparing model 
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 1.3 on node 8
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 11
Reached 3 on node 8
Reached 5 on node 11
Reached end on node 11
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing opt_ae 
Reached 3 on node 8Reached 3 on node 11

Reached 5 on node 8Reached 5 on node 11

Reached end on node 8Reached end on node 11

=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 7

Reached 1.4 on node 9Reached 1.4 on node 7

Reached 2 on node 9
Reached 2 on node 7
Reached 3 on node 9Reached 3 on node 7

Reached 5 on node 9Reached 5 on node 7

Reached end on node 9
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.3 on node 8
Reached 1.3 on node 11Reached 1.4 on node 8Reached 3 on node 6


Reached 1.4 on node 11
Reached 2 on node 8Reached 5 on node 6

Reached 2 on node 11
Reached end on node 6
Reached 3 on node 8
Reached 3 on node 11
Reached 5 on node 8
Reached 1.3 on node 10Reached 5 on node 11

Reached end on node 8Reached 1.4 on node 10

Reached end on node 11
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7Reached 1 on node 6

Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 7
Reached 1 on node 6Reached 2 on node 7
Reached 1.4 on node 8

Reached 2 on node 8Reached 1.4 on node 11

Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11Reached 1 on node 8

Reached 1 on node 7
Reached 1.4 on node 8Reached 1.4 on node 11

Reached 2 on node 8Reached 2 on node 11

Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8Reached 1 on node 11

Reached 1.4 on node 11
Reached 1.4 on node 8
Reached 2 on node 11
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10Reached end on node 6

Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6Reached 1 on node 7

Reached 1.4 on node 7
Reached 1.4 on node 6
Reached 2 on node 7Reached 2 on node 6

Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 1.4 on node 8
Reached 3 on node 11
Reached 3 on node 11
Reached 2 on node 8
Reached 5 on node 11
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached end on node 11
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 11.664 (5.957) - Batch(s): 12.952 
(13.049) - AE Loss: 1670193.500 (764843.500) - AE Rec Loss: 11.327 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.86 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.868 (5.957) - Batch(s): 12.963 
(13.049) - AE Loss: 107651.836 (764843.500) - AE Rec Loss: 0.730 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.86 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 3.488 (5.957) - Batch(s): 13.787 
(13.049) - AE Loss: 140258.812 (764843.500) - AE Rec Loss: 0.951 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.505 (5.957) - Batch(s): 12.979 
(13.049) - AE Loss: 255701.156 (764843.500) - AE Rec Loss: 1.734 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.86 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.356 (5.957) - Batch(s): 12.976 
(13.049) - AE Loss: 195747.969 (764843.500) - AE Rec Loss: 1.328 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.86 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.126 (5.957) - Batch(s): 13.380 
(13.049) - AE Loss: 1646723.500 (764843.500) - AE Rec Loss: 11.168 (5.187) - 
Disc Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.568 
(6.806) - AE Loss: 146344.703 (708657.188) - AE Rec Loss: 0.992 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.562 
(6.806) - AE Loss: 1792629.250 (708657.188) - AE Rec Loss: 12.157 (4.806) - Disc
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.563 
(6.806) - AE Loss: 377333.438 (708657.188) - AE Rec Loss: 2.559 (4.806) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.560 
(6.806) - AE Loss: 97933.703 (708657.188) - AE Rec Loss: 0.664 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.550 
(6.806) - AE Loss: 82223.523 (708657.188) - AE Rec Loss: 0.558 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.979) - Batch(s): 0.561 
(6.806) - AE Loss: 97347.344 (708657.188) - AE Rec Loss: 0.660 (4.806) - Disc 
Loss: 0.000 (0.000) - 2.01 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.852 
(6.155) - AE Loss: 529245.312 (744556.875) - AE Rec Loss: 3.589 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.853 
(6.155) - AE Loss: 240455.688 (744556.875) - AE Rec Loss: 1.631 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 4.215 (2.206) - Batch(s): 4.854 
(6.155) - AE Loss: 230435.094 (744556.875) - AE Rec Loss: 1.563 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.631 (2.206) - Batch(s): 4.853 
(6.155) - AE Loss: 113641.820 (744556.875) - AE Rec Loss: 0.771 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.853 
(6.155) - AE Loss: 1863998.750 (744556.875) - AE Rec Loss: 12.641 (5.049) - Disc
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.206) - Batch(s): 4.854 
(6.155) - AE Loss: 121613.008 (744556.875) - AE Rec Loss: 0.825 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.563 
(4.757) - AE Loss: 123784.383 (756369.188) - AE Rec Loss: 0.839 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.570 
(4.757) - AE Loss: 193278.969 (756369.188) - AE Rec Loss: 1.311 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.565 
(4.757) - AE Loss: 251935.016 (756369.188) - AE Rec Loss: 1.709 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.84 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.564 
(4.757) - AE Loss: 224535.141 (756369.188) - AE Rec Loss: 1.523 (5.129) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.553 
(4.757) - AE Loss: 1547088.375 (756369.188) - AE Rec Loss: 10.492 (5.129) - Disc
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.655) - Batch(s): 0.562 
(4.757) - AE Loss: 1556085.375 (756369.188) - AE Rec Loss: 10.553 (5.129) - Disc
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.566 
(3.918) - AE Loss: 133576.953 (747658.375) - AE Rec Loss: 0.906 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.563 
(3.918) - AE Loss: 607818.500 (747658.375) - AE Rec Loss: 4.122 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.564 
(3.918) - AE Loss: 340638.625 (747658.375) - AE Rec Loss: 2.310 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.553 
(3.918) - AE Loss: 119854.289 (747658.375) - AE Rec Loss: 0.813 (5.070) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.572 
(3.918) - AE Loss: 1944600.750 (747658.375) - AE Rec Loss: 13.188 (5.070) - Disc
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.324) - Batch(s): 0.563 
(3.918) - AE Loss: 1607640.250 (747658.375) - AE Rec Loss: 10.903 (5.070) - Disc
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.116) - Batch(s): 1.238 
(3.472) - AE Loss: 414628.094 (762029.750) - AE Rec Loss: 2.812 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.240 
(3.472) - AE Loss: 177950.203 (762029.750) - AE Rec Loss: 1.207 (5.168) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.312 (1.116) - Batch(s): 1.240 
(3.472) - AE Loss: 220838.281 (762029.750) - AE Rec Loss: 1.498 (5.168) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.240 
(3.472) - AE Loss: 1349520.375 (762029.750) - AE Rec Loss: 9.152 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.240 
(3.472) - AE Loss: 1488219.875 (762029.750) - AE Rec Loss: 10.093 (5.168) - Disc
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.116) - Batch(s): 1.239 
(3.472) - AE Loss: 632378.750 (762029.750) - AE Rec Loss: 4.289 (5.168) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.553 
(3.056) - AE Loss: 177567.797 (706268.562) - AE Rec Loss: 1.204 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.566 
(3.056) - AE Loss: 158481.453 (706268.562) - AE Rec Loss: 1.075 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (0.957) - Batch(s): 0.564 
(3.056) - AE Loss: 69126.125 (706268.562) - AE Rec Loss: 0.469 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (0.957) - Batch(s): 0.573 
(3.056) - AE Loss: 117305.359 (706268.562) - AE Rec Loss: 0.796 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (0.957) - Batch(s): 0.563 
(3.056) - AE Loss: 94130.758 (706268.562) - AE Rec Loss: 0.638 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (0.957) - Batch(s): 0.565 
(3.056) - AE Loss: 254531.531 (706268.562) - AE Rec Loss: 1.726 (4.790) - Disc 
Loss: 0.000 (0.000) - 3.19 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.864) - Batch(s): 3.202 
(3.053) - AE Loss: 543129.875 (718105.312) - AE Rec Loss: 3.683 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.864) - Batch(s): 3.204 
(3.053) - AE Loss: 164284.953 (718105.312) - AE Rec Loss: 1.114 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.864) - Batch(s): 3.209 
(3.053) - AE Loss: 223656.422 (718105.312) - AE Rec Loss: 1.517 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.52 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.864) - Batch(s): 3.203 
(3.053) - AE Loss: 1597628.500 (718105.312) - AE Rec Loss: 10.835 (4.870) - Disc
Loss: 0.000 (0.000) - 3.58 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 2.632 (0.864) - Batch(s): 3.207 
(3.053) - AE Loss: 1303705.125 (718105.312) - AE Rec Loss: 8.841 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.64 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.864) - Batch(s): 3.193 
(3.053) - AE Loss: 65083.398 (718105.312) - AE Rec Loss: 0.441 (4.870) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.653 
(2.786) - AE Loss: 112030.641 (704160.562) - AE Rec Loss: 0.760 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.653 
(2.786) - AE Loss: 1429221.500 (704160.562) - AE Rec Loss: 9.693 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.73 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.651 
(2.786) - AE Loss: 127743.227 (704160.562) - AE Rec Loss: 0.866 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.653 
(2.786) - AE Loss: 1462296.750 (704160.562) - AE Rec Loss: 9.917 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.653 
(2.786) - AE Loss: 130597.086 (704160.562) - AE Rec Loss: 0.886 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.768) - Batch(s): 0.651 
(2.786) - AE Loss: 119461.359 (704160.562) - AE Rec Loss: 0.810 (4.775) - Disc 
Loss: 0.000 (0.000) - 3.67 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.096 (0.692) - Batch(s): 0.660 
(2.568) - AE Loss: 236095.234 (679897.250) - AE Rec Loss: 1.601 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.82 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.661 
(2.568) - AE Loss: 1473494.000 (679897.250) - AE Rec Loss: 9.993 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.657 
(2.568) - AE Loss: 110363.523 (679897.250) - AE Rec Loss: 0.748 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.72 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.658 
(2.568) - AE Loss: 52135.953 (679897.250) - AE Rec Loss: 0.354 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.77 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.664 
(2.568) - AE Loss: 705505.625 (679897.250) - AE Rec Loss: 4.785 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.647 
(2.568) - AE Loss: 163308.141 (679897.250) - AE Rec Loss: 1.108 (4.611) - Disc 
Loss: 0.000 (0.000) - 3.71 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.807 
(2.751) - AE Loss: 1659361.250 (653562.688) - AE Rec Loss: 11.253 (4.432) - Disc
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.001 (0.662) - Batch(s): 4.811 
(2.751) - AE Loss: 87757.992 (653562.688) - AE Rec Loss: 0.595 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.806 
(2.751) - AE Loss: 92653.023 (653562.688) - AE Rec Loss: 0.628 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.662) - Batch(s): 4.809 
(2.751) - AE Loss: 318176.375 (653562.688) - AE Rec Loss: 2.158 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 4.234 (0.662) - Batch(s): 4.808 
(2.751) - AE Loss: 1426562.750 (653562.688) - AE Rec Loss: 9.674 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.47 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.091 (0.662) - Batch(s): 4.795 
(2.751) - AE Loss: 126316.133 (653562.688) - AE Rec Loss: 0.857 (4.432) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 1599555.875 (662484.250) - AE Rec Loss: 10.848 (4.493) - Disc
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 75659.078 (662484.250) - AE Rec Loss: 0.513 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.657 
(2.577) - AE Loss: 1476516.500 (662484.250) - AE Rec Loss: 10.013 (4.493) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.659 
(2.577) - AE Loss: 492074.281 (662484.250) - AE Rec Loss: 3.337 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.607) - Batch(s): 0.659 
(2.577) - AE Loss: 445203.188 (662484.250) - AE Rec Loss: 3.019 (4.493) - Disc 
Loss: 0.000 (0.000) - 4.51 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.607) - Batch(s): 0.658 
(2.577) - AE Loss: 1722804.500 (662484.250) - AE Rec Loss: 11.684 (4.493) - Disc
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.565 
(2.422) - AE Loss: 1503518.625 (685638.125) - AE Rec Loss: 10.196 (4.650) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.552 
(2.422) - AE Loss: 153477.750 (685638.125) - AE Rec Loss: 1.041 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.566 
(2.422) - AE Loss: 1653343.000 (685638.125) - AE Rec Loss: 11.212 (4.650) - Disc
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.574 
(2.422) - AE Loss: 410589.156 (685638.125) - AE Rec Loss: 2.784 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.565 
(2.422) - AE Loss: 56739.992 (685638.125) - AE Rec Loss: 0.385 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.560) - Batch(s): 0.565 
(2.422) - AE Loss: 494192.562 (685638.125) - AE Rec Loss: 3.351 (4.650) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.827 
(2.299) - AE Loss: 231113.859 (675938.688) - AE Rec Loss: 1.567 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.827 
(2.299) - AE Loss: 434488.125 (675938.688) - AE Rec Loss: 2.947 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.69 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.265 (0.523) - Batch(s): 0.830 
(2.299) - AE Loss: 148479.375 (675938.688) - AE Rec Loss: 1.007 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.135 (0.523) - Batch(s): 0.819 
(2.299) - AE Loss: 280552.625 (675938.688) - AE Rec Loss: 1.903 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.834 
(2.299) - AE Loss: 148214.312 (675938.688) - AE Rec Loss: 1.005 (4.584) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.832 
(2.299) - AE Loss: 1634701.875 (675938.688) - AE Rec Loss: 11.086 (4.584) - Disc
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.325 
(2.434) - AE Loss: 146353.375 (681074.375) - AE Rec Loss: 0.993 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.324 
(2.434) - AE Loss: 1421828.125 (681074.375) - AE Rec Loss: 9.642 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.325 
(2.434) - AE Loss: 227469.547 (681074.375) - AE Rec Loss: 1.543 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.324 
(2.434) - AE Loss: 3076419.000 (681074.375) - AE Rec Loss: 20.863 (4.619) - Disc
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.325 
(2.434) - AE Loss: 291506.375 (681074.375) - AE Rec Loss: 1.977 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.26 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.508) - Batch(s): 4.325 
(2.434) - AE Loss: 187901.000 (681074.375) - AE Rec Loss: 1.274 (4.619) - Disc 
Loss: 0.000 (0.000) - 5.21 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.565 
(2.317) - AE Loss: 169619.656 (673834.812) - AE Rec Loss: 1.150 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.565 
(2.317) - AE Loss: 104513.336 (673834.812) - AE Rec Loss: 0.709 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.566 
(2.317) - AE Loss: 482800.750 (673834.812) - AE Rec Loss: 3.274 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.565 
(2.317) - AE Loss: 72912.500 (673834.812) - AE Rec Loss: 0.494 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.34 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.554 
(2.317) - AE Loss: 1683094.250 (673834.812) - AE Rec Loss: 11.414 (4.570) - Disc
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.477) - Batch(s): 0.574 
(2.317) - AE Loss: 283094.406 (673834.812) - AE Rec Loss: 1.920 (4.570) - Disc 
Loss: 0.000 (0.000) - 5.28 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.308 
(2.247) - AE Loss: 202766.203 (675058.562) - AE Rec Loss: 1.375 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.307 
(2.247) - AE Loss: 1552151.750 (675058.562) - AE Rec Loss: 10.526 (4.578) - Disc
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.744 (0.452) - Batch(s): 1.311 
(2.247) - AE Loss: 78783.109 (675058.562) - AE Rec Loss: 0.534 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.001 (0.452) - Batch(s): 1.295 
(2.247) - AE Loss: 1668973.000 (675058.562) - AE Rec Loss: 11.318 (4.578) - Disc
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.310 
(2.247) - AE Loss: 60726.938 (675058.562) - AE Rec Loss: 0.412 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.452) - Batch(s): 1.312 
(2.247) - AE Loss: 238383.781 (675058.562) - AE Rec Loss: 1.617 (4.578) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.845 
(2.780) - AE Loss: 243341.562 (651380.125) - AE Rec Loss: 1.650 (4.417) - Disc 
Loss: 0.000 (0.000) - 7.10 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.845 
(2.780) - AE Loss: 192757.156 (651380.125) - AE Rec Loss: 1.307 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.99 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 58697.820 (651380.125) - AE Rec Loss: 0.398 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.99 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.845 
(2.780) - AE Loss: 93445.141 (651380.125) - AE Rec Loss: 0.634 (4.417) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 80974.070 (651380.125) - AE Rec Loss: 0.549 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.99 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.479) - Batch(s): 11.844 
(2.780) - AE Loss: 1023628.562 (651380.125) - AE Rec Loss: 6.942 (4.417) - Disc 
Loss: 0.000 (0.000) - 6.99 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.555 
(2.664) - AE Loss: 263849.500 (635454.250) - AE Rec Loss: 1.789 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.564 
(2.664) - AE Loss: 1479056.250 (635454.250) - AE Rec Loss: 10.030 (4.309) - Disc
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.574 
(2.664) - AE Loss: 109790.086 (635454.250) - AE Rec Loss: 0.745 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.567 
(2.664) - AE Loss: 277713.688 (635454.250) - AE Rec Loss: 1.883 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.16 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.567 
(2.664) - AE Loss: 144402.281 (635454.250) - AE Rec Loss: 0.979 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.05 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.454) - Batch(s): 0.566 
(2.664) - AE Loss: 96039.344 (635454.250) - AE Rec Loss: 0.651 (4.309) - Disc 
Loss: 0.000 (0.000) - 7.11 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.555 
(2.559) - AE Loss: 182576.750 (631961.750) - AE Rec Loss: 1.238 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.565 
(2.559) - AE Loss: 249725.406 (631961.750) - AE Rec Loss: 1.694 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.001 (0.431) - Batch(s): 0.574 
(2.559) - AE Loss: 1558068.625 (631961.750) - AE Rec Loss: 10.566 (4.286) - Disc
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.567 
(2.559) - AE Loss: 91413.250 (631961.750) - AE Rec Loss: 0.620 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.566 
(2.559) - AE Loss: 169625.750 (631961.750) - AE Rec Loss: 1.150 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.568 
(2.559) - AE Loss: 90381.969 (631961.750) - AE Rec Loss: 0.613 (4.286) - Disc 
Loss: 0.000 (0.000) - 7.22 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:40:03,111[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,201[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,270[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,361[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,373[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:40:03,390[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:40:05,348[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,377[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,482[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,563[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,620[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:40:05,644[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,852[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:05,870[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:06,015[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:06,128[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:06,148[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:40:06,210[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 04:40:06,213[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:40:06,213[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:40:06,213[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:40:06,213[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Running in inference mode: False
len(valid_dataloader) = 1
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
[[36m2023-11-29 04:40:06,216[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(train_dataset) = 54706
=> Preparing model 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 9
len(valid_dataloader) = 1
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
[[36m2023-11-29 04:40:06,221[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:41:35,893[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:36,000[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:36,013[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:36,024[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:36,040[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:41:36,065[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:41:38,173[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:38,210[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:38,252[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:38,269[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:38,280[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:41:38,328[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,740[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,831[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,853[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,874[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:41:38,913[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:41:38,914[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 04:41:38,916[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
[[36m2023-11-29 04:41:38,916[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
[[36m2023-11-29 04:41:38,917[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
[[36m2023-11-29 04:41:38,928[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:41:38,929[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:44:38,964[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:38,964[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:39,180[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:39,323[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:39,328[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:44:39,406[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:44:41,277[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:41,311[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:41,348[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:41,540[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:41,553[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:44:41,638[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:44:41,854[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 04:44:41,857[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:44:41,865[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:44:42,058[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:44:42,118[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 04:44:42,129[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:44:42,132[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
[[36m2023-11-29 04:44:42,134[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 04:44:42,135[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 04:44:42,135[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
[[36m2023-11-29 04:44:42,135[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Mixed precision: no
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
=> Instantiating train dataloader 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataloader) = 1
=> Preparing model 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 7
[[36m2023-11-29 04:44:42,139[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 5 on node 7
Reached end on node 7
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        
            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        


            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        


            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:46:11,769[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,895[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,895[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,903[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,918[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:46:11,965[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:46:13,928[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:14,104[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:14,111[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:14,141[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:14,168[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:46:14,266[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,439[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,669[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,698[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:46:14,703[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,741[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:46:14,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 04:46:14,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:46:14,816[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 04:46:14,819[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
[[36m2023-11-29 04:46:14,821[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
[[36m2023-11-29 04:46:14,823[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 04:46:14,823[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Preparing opt_disc 
len(train_dataloader) = 2279
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Mixed precision: no
=> Running in inference mode: False
=> Preparing model 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Instantiating train dataloader 
=> Running in inference mode: False
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataset) = 4
=> Preparing model 
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 8
Reached 1.4 on node 8
=> Preparing opt_ae 
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 3 on node 6
Reached 2 on node 10
Reached 5 on node 6
Reached 3 on node 10
Reached end on node 6
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 10
Reached 3 on node 6
Reached 5 on node 10
Reached 5 on node 6
Reached end on node 10
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 11

Reached 1.3 on node 8Reached 1.3 on node 7Reached 1.4 on node 11Reached 1.4 on node 9



Reached 1.4 on node 8Reached 1.4 on node 7

Reached 2 on node 11
Reached 2 on node 9
Reached 2 on node 8Reached 2 on node 7

Reached 3 on node 9Reached 3 on node 11

Reached 3 on node 8Reached 3 on node 7Reached 5 on node 9Reached 5 on node 11



Reached 5 on node 8Reached 5 on node 7
Reached end on node 11
Reached end on node 9

Reached end on node 8
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 1.3 on node 10
Reached 1.4 on node 10Reached 2 on node 6

Reached 2 on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached 3 on node 10
Reached end on node 6Reached 5 on node 10

Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
Loaded checkpoint at epoch 0 and step 241
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1 on node 9
Reached 1.4 on node 6Reached 1 on node 7

Reached 2 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 7Reached 1.4 on node 6Reached 1 on node 9


Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1.4 on node 7Reached 1.4 on node 9
Reached 3 on node 6
Reached 1 on node 11
Reached 2 on node 7
Reached 3 on node 6Reached 2 on node 9


Reached 3 on node 6Reached 1 on node 8

Reached 5 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7Reached 1 on node 9

Reached 1.4 on node 9
Reached 1.4 on node 7
Reached 2 on node 9
Reached 2 on node 7
Reached 3 on node 7
Reached 1 on node 8
Reached 3 on node 7
Reached 1 on node 11
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8
Reached 5 on node 7
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8Reached 1.4 on node 11

Reached 2 on node 8Reached 2 on node 11

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1 on node 11Reached 5 on node 9

Reached 1.4 on node 11
Reached 2 on node 11
Reached end on node 6Reached 1 on node 10

Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9Reached 1 on node 6

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <241/2280>] - Data(s): 8.477 (5.830) - Batch(s): 9.760 
(9.811) - AE Loss: 1670141.000 (764911.812) - AE Rec Loss: 11.326 (5.187) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 5.203 (5.830) - Batch(s): 10.198 
(9.811) - AE Loss: 256006.406 (764911.812) - AE Rec Loss: 1.736 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.435 (5.830) - Batch(s): 10.174 
(9.811) - AE Loss: 139974.438 (764911.812) - AE Rec Loss: 0.949 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.434 (5.830) - Batch(s): 9.785 
(9.811) - AE Loss: 195497.469 (764911.812) - AE Rec Loss: 1.326 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 4.675 (5.830) - Batch(s): 9.769 
(9.811) - AE Loss: 1646437.250 (764911.812) - AE Rec Loss: 11.166 (5.187) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <241/2280>] - Data(s): 7.170 (5.830) - Batch(s): 9.727 
(9.811) - AE Loss: 106985.477 (764911.812) - AE Rec Loss: 0.726 (5.187) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.682 
(5.242) - AE Loss: 98061.031 (708605.688) - AE Rec Loss: 0.665 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.686 
(5.242) - AE Loss: 374771.812 (708605.688) - AE Rec Loss: 2.542 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.688 
(5.242) - AE Loss: 145933.922 (708605.688) - AE Rec Loss: 0.990 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.52 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.688 
(5.242) - AE Loss: 96823.102 (708605.688) - AE Rec Loss: 0.657 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.52 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.000 (2.920) - Batch(s): 0.674 
(5.242) - AE Loss: 82548.500 (708605.688) - AE Rec Loss: 0.560 (4.806) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <242/2280>] - Data(s): 0.001 (2.920) - Batch(s): 0.684 
(5.242) - AE Loss: 1791516.000 (708605.688) - AE Rec Loss: 12.149 (4.806) - Disc
Loss: 0.000 (0.000) - 1.52 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 122559.680 (744516.312) - AE Rec Loss: 0.831 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 4.201 (2.310) - Batch(s): 4.860 
(5.115) - AE Loss: 231584.141 (744516.312) - AE Rec Loss: 1.571 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.511 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 1863698.000 (744516.312) - AE Rec Loss: 12.639 (5.049) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 1.971 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 111951.586 (744516.312) - AE Rec Loss: 0.759 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.310) - Batch(s): 4.859 
(5.115) - AE Loss: 238559.953 (744516.312) - AE Rec Loss: 1.618 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <243/2280>] - Data(s): 0.000 (2.310) - Batch(s): 4.860 
(5.115) - AE Loss: 529531.375 (744516.312) - AE Rec Loss: 3.591 (5.049) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.564 
(3.977) - AE Loss: 224114.922 (756405.812) - AE Rec Loss: 1.520 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.552 
(3.977) - AE Loss: 1547294.250 (756405.812) - AE Rec Loss: 10.493 (5.130) - Disc
Loss: 0.000 (0.000) - 2.31 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.562 
(3.977) - AE Loss: 1556041.250 (756405.812) - AE Rec Loss: 10.553 (5.130) - Disc
Loss: 0.000 (0.000) - 2.36 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.570 
(3.977) - AE Loss: 193691.531 (756405.812) - AE Rec Loss: 1.314 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.565 
(3.977) - AE Loss: 252749.344 (756405.812) - AE Rec Loss: 1.714 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.36 m remaining

[Epoch <000/100>: Step <244/2280>] - Data(s): 0.000 (1.733) - Batch(s): 0.562 
(3.977) - AE Loss: 123534.875 (756405.812) - AE Rec Loss: 0.838 (5.130) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.686 
(3.483) - AE Loss: 340257.938 (747729.000) - AE Rec Loss: 2.308 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.683 
(3.483) - AE Loss: 1608104.625 (747729.000) - AE Rec Loss: 10.906 (5.071) - Disc
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.690 
(3.483) - AE Loss: 1945016.375 (747729.000) - AE Rec Loss: 13.190 (5.071) - Disc
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.675 
(3.483) - AE Loss: 119907.398 (747729.000) - AE Rec Loss: 0.813 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 1.124 (1.405) - Batch(s): 1.688 
(3.483) - AE Loss: 133026.438 (747729.000) - AE Rec Loss: 0.902 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <245/2280>] - Data(s): 0.000 (1.405) - Batch(s): 1.685 
(3.483) - AE Loss: 607588.062 (747729.000) - AE Rec Loss: 4.120 (5.071) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.732 
(3.025) - AE Loss: 632998.500 (762049.250) - AE Rec Loss: 4.293 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.72 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.001 (1.172) - Batch(s): 0.733 
(3.025) - AE Loss: 177734.109 (762049.250) - AE Rec Loss: 1.205 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.734 
(3.025) - AE Loss: 1488514.000 (762049.250) - AE Rec Loss: 10.095 (5.168) - Disc
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.734 
(3.025) - AE Loss: 415091.375 (762049.250) - AE Rec Loss: 2.815 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.000 (1.172) - Batch(s): 0.734 
(3.025) - AE Loss: 1348734.500 (762049.250) - AE Rec Loss: 9.147 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <246/2280>] - Data(s): 0.074 (1.172) - Batch(s): 0.734 
(3.025) - AE Loss: 221215.828 (762049.250) - AE Rec Loss: 1.500 (5.168) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.077 (1.005) - Batch(s): 0.641 
(2.679) - AE Loss: 255565.922 (706354.000) - AE Rec Loss: 1.733 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (1.005) - Batch(s): 0.644 
(2.679) - AE Loss: 117414.859 (706354.000) - AE Rec Loss: 0.796 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.628 
(2.679) - AE Loss: 176906.734 (706354.000) - AE Rec Loss: 1.200 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.638 
(2.679) - AE Loss: 94457.023 (706354.000) - AE Rec Loss: 0.641 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.000 (1.005) - Batch(s): 0.639 
(2.679) - AE Loss: 69263.953 (706354.000) - AE Rec Loss: 0.470 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <247/2280>] - Data(s): 0.001 (1.005) - Batch(s): 0.640 
(2.679) - AE Loss: 159637.844 (706354.000) - AE Rec Loss: 1.083 (4.790) - Disc 
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.929) - Batch(s): 4.152 
(2.840) - AE Loss: 223348.016 (718188.000) - AE Rec Loss: 1.515 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 4.144 
(2.840) - AE Loss: 543273.000 (718188.000) - AE Rec Loss: 3.684 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.929) - Batch(s): 4.145 
(2.840) - AE Loss: 163954.531 (718188.000) - AE Rec Loss: 1.112 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.001 (0.929) - Batch(s): 4.135 
(2.840) - AE Loss: 64831.543 (718188.000) - AE Rec Loss: 0.440 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 0.000 (0.929) - Batch(s): 4.145 
(2.840) - AE Loss: 1597639.625 (718188.000) - AE Rec Loss: 10.835 (4.871) - Disc
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <248/2280>] - Data(s): 3.572 (0.929) - Batch(s): 4.150 
(2.840) - AE Loss: 1302908.500 (718188.000) - AE Rec Loss: 8.836 (4.871) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.661 
(2.598) - AE Loss: 128236.586 (704271.438) - AE Rec Loss: 0.870 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.662 
(2.598) - AE Loss: 1428922.375 (704271.438) - AE Rec Loss: 9.691 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.663 
(2.598) - AE Loss: 1463250.750 (704271.438) - AE Rec Loss: 9.923 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.001 (0.826) - Batch(s): 0.663 
(2.598) - AE Loss: 130535.453 (704271.438) - AE Rec Loss: 0.885 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.662 
(2.598) - AE Loss: 119743.156 (704271.438) - AE Rec Loss: 0.812 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.42 m remaining

[Epoch <000/100>: Step <249/2280>] - Data(s): 0.000 (0.826) - Batch(s): 0.663 
(2.598) - AE Loss: 112267.578 (704271.438) - AE Rec Loss: 0.761 (4.776) - Disc 
Loss: 0.000 (0.000) - 3.42 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.567 
(2.394) - AE Loss: 237637.953 (680061.062) - AE Rec Loss: 1.612 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.573 
(2.394) - AE Loss: 706018.000 (680061.062) - AE Rec Loss: 4.788 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.554 
(2.394) - AE Loss: 163579.938 (680061.062) - AE Rec Loss: 1.109 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.565 
(2.394) - AE Loss: 53092.688 (680061.062) - AE Rec Loss: 0.360 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.563 
(2.394) - AE Loss: 110719.633 (680061.062) - AE Rec Loss: 0.751 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.56 m remaining

[Epoch <000/100>: Step <250/2280>] - Data(s): 0.000 (0.743) - Batch(s): 0.565 
(2.394) - AE Loss: 1473345.500 (680061.062) - AE Rec Loss: 9.992 (4.612) - Disc 
Loss: 0.000 (0.000) - 3.51 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 4.096 (0.707) - Batch(s): 4.675 
(2.579) - AE Loss: 1427330.500 (653740.625) - AE Rec Loss: 9.680 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.675 
(2.579) - AE Loss: 87150.023 (653740.625) - AE Rec Loss: 0.591 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.670 
(2.579) - AE Loss: 1659055.250 (653740.625) - AE Rec Loss: 11.251 (4.433) - Disc
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.669 
(2.579) - AE Loss: 93266.023 (653740.625) - AE Rec Loss: 0.633 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.659 
(2.579) - AE Loss: 126120.211 (653740.625) - AE Rec Loss: 0.855 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <251/2280>] - Data(s): 0.000 (0.707) - Batch(s): 4.669 
(2.579) - AE Loss: 318845.938 (653740.625) - AE Rec Loss: 2.162 (4.433) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.782 
(2.429) - AE Loss: 1477301.250 (662681.812) - AE Rec Loss: 10.019 (4.494) - Disc
Loss: 0.000 (0.000) - 4.30 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.782 
(2.429) - AE Loss: 1599753.250 (662681.812) - AE Rec Loss: 10.849 (4.494) - Disc
Loss: 0.000 (0.000) - 4.30 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.783 
(2.429) - AE Loss: 445579.875 (662681.812) - AE Rec Loss: 3.022 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.649) - Batch(s): 0.783 
(2.429) - AE Loss: 75497.438 (662681.812) - AE Rec Loss: 0.512 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.001 (0.649) - Batch(s): 0.784 
(2.429) - AE Loss: 1723127.625 (662681.812) - AE Rec Loss: 11.686 (4.494) - Disc
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <252/2280>] - Data(s): 0.000 (0.649) - Batch(s): 0.784 
(2.429) - AE Loss: 492792.625 (662681.812) - AE Rec Loss: 3.342 (4.494) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.566 
(2.286) - AE Loss: 55552.543 (685868.812) - AE Rec Loss: 0.377 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.552 
(2.286) - AE Loss: 154273.703 (685868.812) - AE Rec Loss: 1.046 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.564 
(2.286) - AE Loss: 492698.188 (685868.812) - AE Rec Loss: 3.341 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.573 
(2.286) - AE Loss: 412589.125 (685868.812) - AE Rec Loss: 2.798 (4.651) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.001 (0.599) - Batch(s): 0.565 
(2.286) - AE Loss: 1653101.750 (685868.812) - AE Rec Loss: 11.211 (4.651) - Disc
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <253/2280>] - Data(s): 0.000 (0.599) - Batch(s): 0.564 
(2.286) - AE Loss: 1505542.000 (685868.812) - AE Rec Loss: 10.210 (4.651) - Disc
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.908 (0.562) - Batch(s): 1.476 
(2.215) - AE Loss: 150545.094 (676225.875) - AE Rec Loss: 1.021 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.001 (0.562) - Batch(s): 1.460 
(2.215) - AE Loss: 280545.125 (676225.875) - AE Rec Loss: 1.903 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.475 
(2.215) - AE Loss: 150950.219 (676225.875) - AE Rec Loss: 1.024 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.001 (0.562) - Batch(s): 1.470 
(2.215) - AE Loss: 435134.312 (676225.875) - AE Rec Loss: 2.951 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.469 
(2.215) - AE Loss: 1635936.625 (676225.875) - AE Rec Loss: 11.094 (4.586) - Disc
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <254/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.470 
(2.215) - AE Loss: 229842.359 (676225.875) - AE Rec Loss: 1.559 (4.586) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 188006.750 (681404.062) - AE Rec Loss: 1.275 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 293161.156 (681404.062) - AE Rec Loss: 1.988 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.417 
(2.428) - AE Loss: 229770.547 (681404.062) - AE Rec Loss: 1.558 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.417 
(2.428) - AE Loss: 1421214.250 (681404.062) - AE Rec Loss: 9.638 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 3076296.500 (681404.062) - AE Rec Loss: 20.862 (4.621) - Disc
Loss: 0.000 (0.000) - 5.24 m remaining

[Epoch <000/100>: Step <255/2280>] - Data(s): 0.000 (0.555) - Batch(s): 5.416 
(2.428) - AE Loss: 148618.766 (681404.062) - AE Rec Loss: 1.008 (4.621) - Disc 
Loss: 0.000 (0.000) - 5.29 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.567 
(2.312) - AE Loss: 102779.492 (674105.250) - AE Rec Loss: 0.697 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.36 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.573 
(2.312) - AE Loss: 281143.375 (674105.250) - AE Rec Loss: 1.907 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.567 
(2.312) - AE Loss: 483771.938 (674105.250) - AE Rec Loss: 3.281 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.567 
(2.312) - AE Loss: 71292.016 (674105.250) - AE Rec Loss: 0.483 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.001 (0.520) - Batch(s): 0.554 
(2.312) - AE Loss: 1682209.625 (674105.250) - AE Rec Loss: 11.408 (4.572) - Disc
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <256/2280>] - Data(s): 0.000 (0.520) - Batch(s): 0.565 
(2.312) - AE Loss: 168522.469 (674105.250) - AE Rec Loss: 1.143 (4.572) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.575 
(2.209) - AE Loss: 238450.891 (675240.688) - AE Rec Loss: 1.617 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.566 
(2.209) - AE Loss: 60733.340 (675240.688) - AE Rec Loss: 0.412 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.566 
(2.209) - AE Loss: 1550778.250 (675240.688) - AE Rec Loss: 10.517 (4.579) - Disc
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.554 
(2.209) - AE Loss: 1666626.500 (675240.688) - AE Rec Loss: 11.303 (4.579) - Disc
Loss: 0.000 (0.000) - 5.39 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.565 
(2.209) - AE Loss: 200906.609 (675240.688) - AE Rec Loss: 1.362 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <257/2280>] - Data(s): 0.000 (0.489) - Batch(s): 0.566 
(2.209) - AE Loss: 78436.328 (675240.688) - AE Rec Loss: 0.532 (4.579) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.049 
(2.200) - AE Loss: 81660.875 (651488.562) - AE Rec Loss: 0.554 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 92605.242 (651488.562) - AE Rec Loss: 0.628 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 59245.352 (651488.562) - AE Rec Loss: 0.402 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.001 (0.469) - Batch(s): 2.049 
(2.200) - AE Loss: 190882.250 (651488.562) - AE Rec Loss: 1.295 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.051 
(2.200) - AE Loss: 1023511.688 (651488.562) - AE Rec Loss: 6.941 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.64 m remaining

[Epoch <000/100>: Step <258/2280>] - Data(s): 0.000 (0.469) - Batch(s): 2.050 
(2.200) - AE Loss: 242419.094 (651488.562) - AE Rec Loss: 1.644 (4.418) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.566 
(2.114) - AE Loss: 145902.344 (635626.188) - AE Rec Loss: 0.989 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.574 
(2.114) - AE Loss: 109793.477 (635626.188) - AE Rec Loss: 0.745 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.001 (0.444) - Batch(s): 0.568 
(2.114) - AE Loss: 281462.438 (635626.188) - AE Rec Loss: 1.909 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.567 
(2.114) - AE Loss: 95772.242 (635626.188) - AE Rec Loss: 0.649 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.554 
(2.114) - AE Loss: 266738.875 (635626.188) - AE Rec Loss: 1.809 (4.311) - Disc 
Loss: 0.000 (0.000) - 5.72 m remaining

[Epoch <000/100>: Step <259/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.566 
(2.114) - AE Loss: 1479648.250 (635626.188) - AE Rec Loss: 10.035 (4.311) - Disc
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.566 
(2.037) - AE Loss: 169388.828 (632113.312) - AE Rec Loss: 1.149 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.553 
(2.037) - AE Loss: 182993.656 (632113.312) - AE Rec Loss: 1.241 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.565 
(2.037) - AE Loss: 249566.594 (632113.312) - AE Rec Loss: 1.692 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.567 
(2.037) - AE Loss: 91425.203 (632113.312) - AE Rec Loss: 0.620 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.574 
(2.037) - AE Loss: 1558349.500 (632113.312) - AE Rec Loss: 10.568 (4.287) - Disc
Loss: 0.000 (0.000) - 5.79 m remaining

[Epoch <000/100>: Step <260/2280>] - Data(s): 0.000 (0.422) - Batch(s): 0.568 
(2.037) - AE Loss: 90511.969 (632113.312) - AE Rec Loss: 0.614 (4.287) - Disc 
Loss: 0.000 (0.000) - 5.84 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.001 (0.404) - Batch(s): 11.585 
(2.448) - AE Loss: 88233.234 (628719.750) - AE Rec Loss: 0.598 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.32 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.586 
(2.448) - AE Loss: 130983.930 (628719.750) - AE Rec Loss: 0.888 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.32 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.586 
(2.448) - AE Loss: 214990.016 (628719.750) - AE Rec Loss: 1.458 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.586 
(2.448) - AE Loss: 1739559.375 (628719.750) - AE Rec Loss: 11.797 (4.264) - Disc
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.586 
(2.448) - AE Loss: 226009.641 (628719.750) - AE Rec Loss: 1.533 (4.264) - Disc 
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 0.000 (0.404) - Batch(s): 11.586 
(2.448) - AE Loss: 3216519.000 (628719.750) - AE Rec Loss: 21.813 (4.264) - Disc
Loss: 0.000 (0.000) - 7.27 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.566 
(2.362) - AE Loss: 248214.078 (630410.062) - AE Rec Loss: 1.683 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.568 
(2.362) - AE Loss: 99905.562 (630410.062) - AE Rec Loss: 0.678 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.38 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.565 
(2.362) - AE Loss: 1461989.250 (630410.062) - AE Rec Loss: 9.915 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.565 
(2.362) - AE Loss: 142359.828 (630410.062) - AE Rec Loss: 0.965 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.553 
(2.362) - AE Loss: 454329.312 (630410.062) - AE Rec Loss: 3.081 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (0.386) - Batch(s): 0.574 
(2.362) - AE Loss: 102508.133 (630410.062) - AE Rec Loss: 0.695 (4.275) - Disc 
Loss: 0.000 (0.000) - 7.33 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.553 
(2.284) - AE Loss: 87579.344 (628940.188) - AE Rec Loss: 0.594 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.40 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.575 
(2.284) - AE Loss: 112176.148 (628940.188) - AE Rec Loss: 0.761 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.566 
(2.284) - AE Loss: 1710784.500 (628940.188) - AE Rec Loss: 11.602 (4.265) - Disc
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.566 
(2.284) - AE Loss: 92624.422 (628940.188) - AE Rec Loss: 0.628 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.39 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.568 
(2.284) - AE Loss: 120332.539 (628940.188) - AE Rec Loss: 0.816 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.44 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (0.369) - Batch(s): 0.566 
(2.284) - AE Loss: 241500.891 (628940.188) - AE Rec Loss: 1.638 (4.265) - Disc 
Loss: 0.000 (0.000) - 7.45 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 1465657.875 (638246.062) - AE Rec Loss: 9.940 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 504845.406 (638246.062) - AE Rec Loss: 3.424 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.52 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 258333.297 (638246.062) - AE Rec Loss: 1.752 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.46 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 107914.812 (638246.062) - AE Rec Loss: 0.732 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.47 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 343480.188 (638246.062) - AE Rec Loss: 2.329 (4.328) - Disc 
Loss: 0.000 (0.000) - 7.47 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (0.354) - Batch(s): 0.668 
(2.217) - AE Loss: 1478802.750 (638246.062) - AE Rec Loss: 10.029 (4.328) - Disc
Loss: 0.000 (0.000) - 7.46 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.566 
(2.151) - AE Loss: 194885.953 (650649.812) - AE Rec Loss: 1.322 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.568 
(2.151) - AE Loss: 1492503.750 (650649.812) - AE Rec Loss: 10.122 (4.413) - Disc
Loss: 0.000 (0.000) - 7.58 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.568 
(2.151) - AE Loss: 1708900.750 (650649.812) - AE Rec Loss: 11.589 (4.413) - Disc
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.567 
(2.151) - AE Loss: 103310.664 (650649.812) - AE Rec Loss: 0.701 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.575 
(2.151) - AE Loss: 168517.797 (650649.812) - AE Rec Loss: 1.143 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (0.340) - Batch(s): 0.554 
(2.151) - AE Loss: 104456.055 (650649.812) - AE Rec Loss: 0.708 (4.413) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.567 
(2.090) - AE Loss: 88135.672 (646120.000) - AE Rec Loss: 0.598 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.554 
(2.090) - AE Loss: 253343.109 (646120.000) - AE Rec Loss: 1.718 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.574 
(2.090) - AE Loss: 425382.094 (646120.000) - AE Rec Loss: 2.885 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.566 
(2.090) - AE Loss: 68180.094 (646120.000) - AE Rec Loss: 0.462 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.64 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.568 
(2.090) - AE Loss: 150938.438 (646120.000) - AE Rec Loss: 1.024 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.64 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (0.327) - Batch(s): 0.567 
(2.090) - AE Loss: 210725.906 (646120.000) - AE Rec Loss: 1.429 (4.382) - Disc 
Loss: 0.000 (0.000) - 7.59 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.001 (0.322) - Batch(s): 3.039 
(2.125) - AE Loss: 169602.203 (640637.312) - AE Rec Loss: 1.150 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.041 
(2.125) - AE Loss: 167188.750 (640637.312) - AE Rec Loss: 1.134 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.95 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.039 
(2.125) - AE Loss: 62909.844 (640637.312) - AE Rec Loss: 0.427 (4.345) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.039 
(2.125) - AE Loss: 49215.254 (640637.312) - AE Rec Loss: 0.334 (4.345) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.039 
(2.125) - AE Loss: 1803863.250 (640637.312) - AE Rec Loss: 12.233 (4.345) - Disc
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.322) - Batch(s): 3.040 
(2.125) - AE Loss: 62797.961 (640637.312) - AE Rec Loss: 0.426 (4.345) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.285 (0.327) - Batch(s): 3.029 
(2.150) - AE Loss: 176969.859 (640264.500) - AE Rec Loss: 1.200 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.001 (0.327) - Batch(s): 3.029 
(2.150) - AE Loss: 1589159.250 (640264.500) - AE Rec Loss: 10.777 (4.342) - Disc
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.001 (0.327) - Batch(s): 3.030 
(2.150) - AE Loss: 120409.609 (640264.500) - AE Rec Loss: 0.817 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.37 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.327) - Batch(s): 3.034 
(2.150) - AE Loss: 219584.531 (640264.500) - AE Rec Loss: 1.489 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 2.454 (0.327) - Batch(s): 3.023 
(2.150) - AE Loss: 1480003.000 (640264.500) - AE Rec Loss: 10.037 (4.342) - Disc
Loss: 0.000 (0.000) - 8.32 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 1.967 (0.327) - Batch(s): 2.673 
(2.150) - AE Loss: 202212.094 (640264.500) - AE Rec Loss: 1.371 (4.342) - Disc 
Loss: 0.000 (0.000) - 8.37 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 82743.594 (646060.062) - AE Rec Loss: 0.561 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.56 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 166543.891 (646060.062) - AE Rec Loss: 1.129 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.318 
(2.122) - AE Loss: 327223.688 (646060.062) - AE Rec Loss: 2.219 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.57 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 1498244.000 (646060.062) - AE Rec Loss: 10.161 (4.381) - Disc
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 1.108 (0.319) - Batch(s): 1.680 
(2.122) - AE Loss: 465769.625 (646060.062) - AE Rec Loss: 3.159 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.51 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.319) - Batch(s): 1.317 
(2.122) - AE Loss: 1399663.000 (646060.062) - AE Rec Loss: 9.492 (4.381) - Disc 
Loss: 0.000 (0.000) - 8.52 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:47:45,702[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,707[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,749[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,993[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:45,998[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:47:46,035[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:47:47,945[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:47,973[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:48,057[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:48,214[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:48,219[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:47:48,303[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,460[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,531[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,553[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,784[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,797[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:47:48,811[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 04:47:48,813[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:47:48,813[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
[[36m2023-11-29 04:47:48,814[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
[[36m2023-11-29 04:47:48,819[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:47:48,819[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Running in inference mode: False
=> Running in inference mode: False
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 04:47:48,822[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 1.3 on node 6
Reached 1.4 on node 6Reached 2 on node 11

=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 2 on node 6
Reached 1.4 on node 10
Reached 3 on node 11
Reached 2 on node 10
Reached 3 on node 6
Reached 5 on node 11Reached 3 on node 10

Reached 5 on node 6Reached end on node 11

Reached end on node 6
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6
Reached 3 on node 11
Reached 5 on node 6
Reached 5 on node 11
Reached end on node 6
Reached end on node 11
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1 on node 11
Reached 1.25 on node 6
Reached 1.2 on node 11
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7Reached 1.3 on node 10

Reached 1.4 on node 7Reached 1.4 on node 10Reached 1.3 on node 9


Reached 1.4 on node 9
Reached 2 on node 10
Reached 2 on node 7
Reached 2 on node 9
Reached 3 on node 7Reached 3 on node 10

Reached 3 on node 9
Reached 5 on node 7
Reached 5 on node 10Reached 5 on node 9

Reached end on node 7
Reached end on node 9Reached end on node 10

Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 6
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 6Reached 2 on node 8

Reached 1 on node 9
Reached 1.4 on node 9
Reached 1 on node 7
Reached 2 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 7
Reached 1 on node 11Reached 1.4 on node 9
Reached 1.4 on node 7

Reached 2 on node 9
Reached 2 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8Reached 1 on node 6

Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 6Reached 2 on node 8

Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 9
Reached 1 on node 11Reached 1.4 on node 7

Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9Reached 3 on node 7

Reached 1.4 on node 11Reached 3 on node 7

Reached 2 on node 11Reached 3 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6Reached 1 on node 8

Reached 1.4 on node 6Reached 1.4 on node 8
Reached 2 on node 8

Reached 2 on node 6
Reached 3 on node 6Reached 1 on node 9

Reached 1 on node 11Reached 3 on node 6

Reached 3 on node 6
Reached 1.4 on node 9Reached 3 on node 6

Reached 1.4 on node 11Reached 2 on node 9

Reached 3 on node 6Reached 2 on node 11

Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1 on node 8Reached 3 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached end on node 6
Reached end on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 1 on node 9
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6Reached 1 on node 8

Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 11
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 10
Reached end on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <261/2280>] - Data(s): 10.061 (6.117) - Batch(s): 11.669 
(11.858) - AE Loss: 3216378.500 (560690.312) - AE Rec Loss: 21.812 (3.802) - 
Disc Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.626 (6.117) - Batch(s): 11.663 
(11.858) - AE Loss: 88651.969 (560690.312) - AE Rec Loss: 0.601 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 3.031 (6.117) - Batch(s): 11.652 
(11.858) - AE Loss: 226288.656 (560690.312) - AE Rec Loss: 1.535 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 5.722 (6.117) - Batch(s): 11.660 
(11.858) - AE Loss: 130636.656 (560690.312) - AE Rec Loss: 0.886 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.990 (6.117) - Batch(s): 11.664 
(11.858) - AE Loss: 214583.297 (560690.312) - AE Rec Loss: 1.455 (3.802) - Disc 
Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 8.718 (6.117) - Batch(s): 11.636 
(11.858) - AE Loss: 1739634.375 (560690.312) - AE Rec Loss: 11.798 (3.802) - 
Disc Loss: 0.000 (0.000) - 1.53 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.572 
(6.211) - AE Loss: 102668.914 (621043.625) - AE Rec Loss: 0.696 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 260172.297 (621043.625) - AE Rec Loss: 1.764 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 108852.562 (621043.625) - AE Rec Loss: 0.738 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.553 
(6.211) - AE Loss: 495502.875 (621043.625) - AE Rec Loss: 3.360 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 1464681.000 (621043.625) - AE Rec Loss: 9.933 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (3.059) - Batch(s): 0.565 
(6.211) - AE Loss: 149415.125 (621043.625) - AE Rec Loss: 1.013 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.779 
(5.067) - AE Loss: 270980.031 (617786.062) - AE Rec Loss: 1.838 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.157 (2.174) - Batch(s): 2.778 
(5.067) - AE Loss: 116014.336 (617786.062) - AE Rec Loss: 0.787 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.779 
(5.067) - AE Loss: 1708343.250 (617786.062) - AE Rec Loss: 11.585 (4.190) - Disc
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.001 (2.174) - Batch(s): 2.777 
(5.067) - AE Loss: 91926.047 (617786.062) - AE Rec Loss: 0.623 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.98 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.777 
(5.067) - AE Loss: 125196.328 (617786.062) - AE Rec Loss: 0.849 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.174) - Batch(s): 2.780 
(5.067) - AE Loss: 89066.453 (617786.062) - AE Rec Loss: 0.604 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.553 
(3.941) - AE Loss: 342072.281 (676608.750) - AE Rec Loss: 2.320 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.630) - Batch(s): 0.563 
(3.941) - AE Loss: 260150.906 (676608.750) - AE Rec Loss: 1.764 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.566 
(3.941) - AE Loss: 1478284.375 (676608.750) - AE Rec Loss: 10.025 (4.589) - Disc
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.567 
(3.941) - AE Loss: 504207.594 (676608.750) - AE Rec Loss: 3.419 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.573 
(3.941) - AE Loss: 106787.203 (676608.750) - AE Rec Loss: 0.724 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.001 (1.630) - Batch(s): 0.565 
(3.941) - AE Loss: 1466010.750 (676608.750) - AE Rec Loss: 9.942 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.554 
(3.266) - AE Loss: 107872.227 (732463.188) - AE Rec Loss: 0.732 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.566 
(3.266) - AE Loss: 1504391.500 (732463.188) - AE Rec Loss: 10.202 (4.967) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.566 
(3.266) - AE Loss: 103910.711 (732463.188) - AE Rec Loss: 0.705 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.565 
(3.266) - AE Loss: 1712690.000 (732463.188) - AE Rec Loss: 11.615 (4.967) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.565 
(3.266) - AE Loss: 209855.188 (732463.188) - AE Rec Loss: 1.423 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.304) - Batch(s): 0.574 
(3.266) - AE Loss: 191315.672 (732463.188) - AE Rec Loss: 1.297 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 67302.234 (699761.250) - AE Rec Loss: 0.456 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.162) - Batch(s): 3.156 
(3.248) - AE Loss: 79677.469 (699761.250) - AE Rec Loss: 0.540 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.162) - Batch(s): 3.156 
(3.248) - AE Loss: 158338.844 (699761.250) - AE Rec Loss: 1.074 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 217701.000 (699761.250) - AE Rec Loss: 1.476 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.162) - Batch(s): 3.158 
(3.248) - AE Loss: 263446.406 (699761.250) - AE Rec Loss: 1.787 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.162) - Batch(s): 3.157 
(3.248) - AE Loss: 409973.875 (699761.250) - AE Rec Loss: 2.780 (4.746) - Disc 
Loss: 0.000 (0.000) - 2.56 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.964 
(3.065) - AE Loss: 171098.656 (671487.250) - AE Rec Loss: 1.160 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.81 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.001 (1.013) - Batch(s): 1.966 
(3.065) - AE Loss: 68232.203 (671487.250) - AE Rec Loss: 0.463 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.964 
(3.065) - AE Loss: 175258.125 (671487.250) - AE Rec Loss: 1.189 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.964 
(3.065) - AE Loss: 68808.742 (671487.250) - AE Rec Loss: 0.467 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.969 
(3.065) - AE Loss: 55780.059 (671487.250) - AE Rec Loss: 0.378 (4.554) - Disc 
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (1.013) - Batch(s): 1.952 
(3.065) - AE Loss: 1807228.500 (671487.250) - AE Rec Loss: 12.256 (4.554) - Disc
Loss: 0.000 (0.000) - 2.82 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.567 
(2.752) - AE Loss: 179537.359 (665978.062) - AE Rec Loss: 1.218 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.001 (0.886) - Batch(s): 0.568 
(2.752) - AE Loss: 198040.344 (665978.062) - AE Rec Loss: 1.343 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.566 
(2.752) - AE Loss: 112233.039 (665978.062) - AE Rec Loss: 0.761 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.553 
(2.752) - AE Loss: 1479676.250 (665978.062) - AE Rec Loss: 10.035 (4.516) - Disc
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.566 
(2.752) - AE Loss: 1595777.125 (665978.062) - AE Rec Loss: 10.822 (4.516) - Disc
Loss: 0.000 (0.000) - 2.89 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.886) - Batch(s): 0.574 
(2.752) - AE Loss: 214256.219 (665978.062) - AE Rec Loss: 1.453 (4.516) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 1500135.875 (681738.375) - AE Rec Loss: 10.173 (4.623) - Disc
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 461004.562 (681738.375) - AE Rec Loss: 3.126 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 163475.422 (681738.375) - AE Rec Loss: 1.109 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 1401370.375 (681738.375) - AE Rec Loss: 9.504 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 325682.156 (681738.375) - AE Rec Loss: 2.209 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.816) - Batch(s): 3.244 
(2.807) - AE Loss: 74108.430 (681738.375) - AE Rec Loss: 0.503 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.30 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.547 
(2.781) - AE Loss: 485371.031 (701633.875) - AE Rec Loss: 3.292 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.547 
(2.781) - AE Loss: 575157.125 (701633.875) - AE Rec Loss: 3.901 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.548 
(2.781) - AE Loss: 98182.773 (701633.875) - AE Rec Loss: 0.666 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.547 
(2.781) - AE Loss: 242678.734 (701633.875) - AE Rec Loss: 1.646 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.535 
(2.781) - AE Loss: 779368.438 (701633.875) - AE Rec Loss: 5.285 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.62 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.751) - Batch(s): 2.551 
(2.781) - AE Loss: 1498664.125 (701633.875) - AE Rec Loss: 10.163 (4.758) - Disc
Loss: 0.000 (0.000) - 3.63 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.593 
(2.741) - AE Loss: 1696861.125 (703157.188) - AE Rec Loss: 11.508 (4.769) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 2.019 (0.698) - Batch(s): 2.583 
(2.741) - AE Loss: 194630.969 (703157.188) - AE Rec Loss: 1.320 (4.769) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.001 (0.698) - Batch(s): 2.593 
(2.741) - AE Loss: 1807572.250 (703157.188) - AE Rec Loss: 12.258 (4.769) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.597 
(2.741) - AE Loss: 120621.891 (703157.188) - AE Rec Loss: 0.818 (4.769) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.236 
(2.741) - AE Loss: 94725.883 (703157.188) - AE Rec Loss: 0.642 (4.769) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.698) - Batch(s): 2.592 
(2.741) - AE Loss: 1621832.125 (703157.188) - AE Rec Loss: 10.999 (4.769) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 129806.781 (689498.562) - AE Rec Loss: 0.880 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 313536.594 (689498.562) - AE Rec Loss: 2.126 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 230218.969 (689498.562) - AE Rec Loss: 1.561 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 364671.688 (689498.562) - AE Rec Loss: 2.473 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 57175.359 (689498.562) - AE Rec Loss: 0.388 (4.676) - Disc 
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.648 
(2.566) - AE Loss: 1535790.000 (689498.562) - AE Rec Loss: 10.415 (4.676) - Disc
Loss: 0.000 (0.000) - 4.03 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 3.299 
(2.609) - AE Loss: 133117.766 (683078.688) - AE Rec Loss: 0.903 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.43 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 3.300 
(2.609) - AE Loss: 120462.469 (683078.688) - AE Rec Loss: 0.817 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 3.288 
(2.609) - AE Loss: 1972699.750 (683078.688) - AE Rec Loss: 13.378 (4.632) - Disc
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.626) - Batch(s): 3.304 
(2.609) - AE Loss: 109616.305 (683078.688) - AE Rec Loss: 0.743 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 2.723 (0.626) - Batch(s): 3.301 
(2.609) - AE Loss: 1624033.250 (683078.688) - AE Rec Loss: 11.014 (4.632) - Disc
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 1.135 (0.626) - Batch(s): 3.299 
(2.609) - AE Loss: 151094.375 (683078.688) - AE Rec Loss: 1.025 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 1.900 (0.638) - Batch(s): 8.206 
(2.994) - AE Loss: 419819.625 (692177.312) - AE Rec Loss: 2.847 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.001 (0.638) - Batch(s): 8.206 
(2.994) - AE Loss: 237797.172 (692177.312) - AE Rec Loss: 1.613 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 8.210 
(2.994) - AE Loss: 1549054.250 (692177.312) - AE Rec Loss: 10.505 (4.694) - Disc
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 7.849 
(2.994) - AE Loss: 1678043.000 (692177.312) - AE Rec Loss: 11.380 (4.694) - Disc
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.638) - Batch(s): 8.205 
(2.994) - AE Loss: 253592.391 (692177.312) - AE Rec Loss: 1.720 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 7.634 (0.638) - Batch(s): 8.194 
(2.994) - AE Loss: 200862.797 (692177.312) - AE Rec Loss: 1.362 (4.694) - Disc 
Loss: 0.000 (0.000) - 5.43 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 148219.516 (675322.938) - AE Rec Loss: 1.005 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 246916.328 (675322.938) - AE Rec Loss: 1.675 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 83137.344 (675322.938) - AE Rec Loss: 0.564 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 354617.500 (675322.938) - AE Rec Loss: 2.405 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 516607.000 (675322.938) - AE Rec Loss: 3.503 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.001 (0.595) - Batch(s): 0.641 
(2.837) - AE Loss: 70432.734 (675322.938) - AE Rec Loss: 0.478 (4.580) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.199 (0.569) - Batch(s): 1.551 
(2.744) - AE Loss: 635166.312 (670693.062) - AE Rec Loss: 4.307 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.551 
(2.744) - AE Loss: 523491.812 (670693.062) - AE Rec Loss: 3.550 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.551 
(2.744) - AE Loss: 471782.438 (670693.062) - AE Rec Loss: 3.199 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.569) - Batch(s): 1.194 
(2.744) - AE Loss: 232471.750 (670693.062) - AE Rec Loss: 1.577 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.945 (0.569) - Batch(s): 1.557 
(2.744) - AE Loss: 98904.977 (670693.062) - AE Rec Loss: 0.671 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.991 (0.569) - Batch(s): 1.539 
(2.744) - AE Loss: 106708.766 (670693.062) - AE Rec Loss: 0.724 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.69 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.661) - Batch(s): 10.127 
(3.166) - AE Loss: 615965.125 (670652.688) - AE Rec Loss: 4.177 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 4.082 (0.661) - Batch(s): 10.128 
(3.166) - AE Loss: 179171.766 (670652.688) - AE Rec Loss: 1.215 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 6.509 (0.661) - Batch(s): 9.770 
(3.166) - AE Loss: 193325.031 (670652.688) - AE Rec Loss: 1.311 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 5.490 (0.661) - Batch(s): 10.126 
(3.166) - AE Loss: 385094.750 (670652.688) - AE Rec Loss: 2.612 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 9.555 (0.661) - Batch(s): 10.117 
(3.166) - AE Loss: 1802173.500 (670652.688) - AE Rec Loss: 12.222 (4.548) - Disc
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.661) - Batch(s): 10.132 
(3.166) - AE Loss: 214307.672 (670652.688) - AE Rec Loss: 1.453 (4.548) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.102 
(3.495) - AE Loss: 186809.672 (660251.562) - AE Rec Loss: 1.267 (4.478) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.102 
(3.495) - AE Loss: 228924.109 (660251.562) - AE Rec Loss: 1.552 (4.478) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.101 
(3.495) - AE Loss: 1962039.375 (660251.562) - AE Rec Loss: 13.306 (4.478) - Disc
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.101 
(3.495) - AE Loss: 1583544.750 (660251.562) - AE Rec Loss: 10.739 (4.478) - Disc
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 8.459 (0.664) - Batch(s): 9.101 
(3.495) - AE Loss: 154909.016 (660251.562) - AE Rec Loss: 1.051 (4.478) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.664) - Batch(s): 9.102 
(3.495) - AE Loss: 242601.625 (660251.562) - AE Rec Loss: 1.645 (4.478) - Disc 
Loss: 0.000 (0.000) - 7.98 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.001 (0.629) - Batch(s): 0.567 
(3.341) - AE Loss: 286313.188 (656645.938) - AE Rec Loss: 1.942 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.566 
(3.341) - AE Loss: 1685440.000 (656645.938) - AE Rec Loss: 11.430 (4.453) - Disc
Loss: 0.000 (0.000) - 8.03 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.567 
(3.341) - AE Loss: 554753.625 (656645.938) - AE Rec Loss: 3.762 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.554 
(3.341) - AE Loss: 121423.789 (656645.938) - AE Rec Loss: 0.823 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.001 (0.629) - Batch(s): 0.565 
(3.341) - AE Loss: 86516.984 (656645.938) - AE Rec Loss: 0.587 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.629) - Batch(s): 0.574 
(3.341) - AE Loss: 130806.844 (656645.938) - AE Rec Loss: 0.887 (4.453) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:50:50,937[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:50,958[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:51,042[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:51,061[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:51,087[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:50:51,177[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:50:53,135[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:53,160[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:53,235[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:53,265[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:53,314[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:50:53,450[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,713[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,740[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,785[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,802[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,902[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:50:53,966[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 04:50:53,969[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:50:53,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:50:53,970[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
[[36m2023-11-29 04:50:53,973[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
[[36m2023-11-29 04:50:53,974[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 6
len(valid_dataloader) = 1
Reached 5 on node 6
Reached end on node 6
[[36m2023-11-29 04:50:53,975[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
len(valid_dataloader) = 1
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing model 
=> Instantiating valid dataloader 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 6
Reached 2 on node 8
Reached 3 on node 6Reached 3 on node 8

Reached 5 on node 8
Reached 5 on node 6
Reached end on node 8
Reached end on node 6
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6Reached 3 on node 8

Reached 5 on node 8Reached 5 on node 6

Reached end on node 8Reached end on node 6

=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9Reached 1.3 on node 7

Reached 1.4 on node 7Reached 1.4 on node 9

Reached 2 on node 7
Reached 2 on node 9
Reached 3 on node 7
Reached 3 on node 9
Reached 5 on node 7
Reached 5 on node 9
Reached end on node 7
Reached end on node 9
Reached 1.3 on node 6Reached 1.3 on node 8

Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 8Reached 1.3 on node 11Reached 2 on node 6


Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 8Reached 3 on node 6

Reached 5 on node 8
Reached 5 on node 6Reached 3 on node 11

Reached end on node 8
Reached end on node 6Reached 5 on node 11

Reached 1.3 on node 10Reached end on node 11

Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
Loaded checkpoint at epoch 0 and step 261
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7Reached 1 on node 6

Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7Reached 1.4 on node 6

Reached 2 on node 7Reached 2 on node 6

Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 1 on node 8Reached 2 on node 9

Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 9
Reached 3 on node 6
Reached 3 on node 6
Reached 1.4 on node 7
Reached 3 on node 6
Reached 2 on node 7
Reached 3 on node 6Reached 1.4 on node 9

Reached 3 on node 6
Reached 1 on node 8Reached 2 on node 9

Reached 5 on node 6
Reached 1.4 on node 8Reached 1 on node 11

Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 9
Reached 1.4 on node 7Reached 2 on node 9

Reached 2 on node 7
Reached 1 on node 8
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7Reached 1.4 on node 8

Reached 3 on node 7
Reached 2 on node 8Reached 5 on node 7

Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1.4 on node 11
Reached 3 on node 8
Reached 2 on node 11
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10Reached end on node 6

Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 6
Reached end on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 9Reached 1 on node 7

Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 7
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <261/2280>] - Data(s): 3.585 (5.921) - Batch(s): 12.020 
(12.052) - AE Loss: 213753.547 (561036.250) - AE Rec Loss: 1.450 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 9.154 (5.921) - Batch(s): 12.310 
(12.052) - AE Loss: 3216464.500 (561036.250) - AE Rec Loss: 21.813 (3.805) - 
Disc Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.750 (5.921) - Batch(s): 12.245 
(12.052) - AE Loss: 88074.438 (561036.250) - AE Rec Loss: 0.597 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 2.986 (5.921) - Batch(s): 12.001 
(12.052) - AE Loss: 225583.797 (561036.250) - AE Rec Loss: 1.530 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 4.865 (5.921) - Batch(s): 12.033 
(12.052) - AE Loss: 130716.680 (561036.250) - AE Rec Loss: 0.886 (3.805) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <261/2280>] - Data(s): 8.885 (5.921) - Batch(s): 12.037 
(12.052) - AE Loss: 1739676.625 (561036.250) - AE Rec Loss: 11.798 (3.805) - 
Disc Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.550 
(6.307) - AE Loss: 494148.281 (621049.562) - AE Rec Loss: 3.351 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.564 
(6.307) - AE Loss: 262552.656 (621049.562) - AE Rec Loss: 1.781 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.561 
(6.307) - AE Loss: 148548.250 (621049.562) - AE Rec Loss: 1.007 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.567 
(6.307) - AE Loss: 102079.883 (621049.562) - AE Rec Loss: 0.692 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.564 
(6.307) - AE Loss: 109258.438 (621049.562) - AE Rec Loss: 0.741 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[Epoch <000/100>: Step <262/2280>] - Data(s): 0.000 (2.961) - Batch(s): 0.563 
(6.307) - AE Loss: 1464846.000 (621049.562) - AE Rec Loss: 9.934 (4.212) - Disc 
Loss: 0.000 (0.000) - 1.67 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <263/2280>] - Data(s): 1.253 (2.016) - Batch(s): 1.885 
(4.833) - AE Loss: 1708475.500 (617874.062) - AE Rec Loss: 11.586 (4.190) - Disc
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.883 
(4.833) - AE Loss: 124418.023 (617874.062) - AE Rec Loss: 0.844 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.886 
(4.833) - AE Loss: 116310.898 (617874.062) - AE Rec Loss: 0.789 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.886 
(4.833) - AE Loss: 91375.742 (617874.062) - AE Rec Loss: 0.620 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.886 
(4.833) - AE Loss: 89329.641 (617874.062) - AE Rec Loss: 0.606 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <263/2280>] - Data(s): 0.000 (2.016) - Batch(s): 1.886 
(4.833) - AE Loss: 270361.500 (617874.062) - AE Rec Loss: 1.834 (4.190) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.241 
(4.185) - AE Loss: 258924.344 (676632.438) - AE Rec Loss: 1.756 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.246 
(4.185) - AE Loss: 106507.305 (676632.438) - AE Rec Loss: 0.722 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.25 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.239 
(4.185) - AE Loss: 1466590.125 (676632.438) - AE Rec Loss: 9.946 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.230 
(4.185) - AE Loss: 342935.312 (676632.438) - AE Rec Loss: 2.326 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.242 
(4.185) - AE Loss: 1478334.625 (676632.438) - AE Rec Loss: 10.026 (4.589) - Disc
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <264/2280>] - Data(s): 0.000 (1.547) - Batch(s): 2.243 
(4.185) - AE Loss: 504595.000 (676632.438) - AE Rec Loss: 3.422 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.22 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.563 
(3.460) - AE Loss: 208585.641 (732412.250) - AE Rec Loss: 1.415 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.563 
(3.460) - AE Loss: 1712937.250 (732412.250) - AE Rec Loss: 11.617 (4.967) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.570 
(3.460) - AE Loss: 190307.844 (732412.250) - AE Rec Loss: 1.291 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.566 
(3.460) - AE Loss: 1503298.250 (732412.250) - AE Rec Loss: 10.195 (4.967) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.552 
(3.460) - AE Loss: 107641.195 (732412.250) - AE Rec Loss: 0.730 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <265/2280>] - Data(s): 0.000 (1.238) - Batch(s): 0.565 
(3.460) - AE Loss: 103991.633 (732412.250) - AE Rec Loss: 0.705 (4.967) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.738 
(3.006) - AE Loss: 263021.375 (699626.562) - AE Rec Loss: 1.784 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.033) - Batch(s): 0.736 
(3.006) - AE Loss: 78925.547 (699626.562) - AE Rec Loss: 0.535 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.033) - Batch(s): 0.738 
(3.006) - AE Loss: 66144.219 (699626.562) - AE Rec Loss: 0.449 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.000 (1.033) - Batch(s): 0.737 
(3.006) - AE Loss: 408995.625 (699626.562) - AE Rec Loss: 2.774 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.44 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.088 (1.033) - Batch(s): 0.738 
(3.006) - AE Loss: 216100.641 (699626.562) - AE Rec Loss: 1.466 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <266/2280>] - Data(s): 0.001 (1.033) - Batch(s): 0.738 
(3.006) - AE Loss: 158370.156 (699626.562) - AE Rec Loss: 1.074 (4.745) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.096 
(3.304) - AE Loss: 55861.188 (671368.688) - AE Rec Loss: 0.379 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.088 
(3.304) - AE Loss: 67951.758 (671368.688) - AE Rec Loss: 0.461 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.091 
(3.304) - AE Loss: 171309.172 (671368.688) - AE Rec Loss: 1.162 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.000 (0.941) - Batch(s): 5.092 
(3.304) - AE Loss: 68172.219 (671368.688) - AE Rec Loss: 0.462 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.001 (0.941) - Batch(s): 5.081 
(3.304) - AE Loss: 1807213.750 (671368.688) - AE Rec Loss: 12.256 (4.553) - Disc
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <267/2280>] - Data(s): 0.001 (0.941) - Batch(s): 5.092 
(3.304) - AE Loss: 175417.547 (671368.688) - AE Rec Loss: 1.190 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.572 
(2.962) - AE Loss: 214595.656 (665912.688) - AE Rec Loss: 1.455 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.16 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.562 
(2.962) - AE Loss: 111689.820 (665912.688) - AE Rec Loss: 0.757 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.15 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.563 
(2.962) - AE Loss: 1594779.250 (665912.688) - AE Rec Loss: 10.815 (4.516) - Disc
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.565 
(2.962) - AE Loss: 180279.516 (665912.688) - AE Rec Loss: 1.223 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.553 
(2.962) - AE Loss: 1478829.500 (665912.688) - AE Rec Loss: 10.029 (4.516) - Disc
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <268/2280>] - Data(s): 0.000 (0.823) - Batch(s): 0.565 
(2.962) - AE Loss: 198856.219 (665912.688) - AE Rec Loss: 1.349 (4.516) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.824 
(2.724) - AE Loss: 1401727.250 (681685.312) - AE Rec Loss: 9.506 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.824 
(2.724) - AE Loss: 461114.781 (681685.312) - AE Rec Loss: 3.127 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.826 
(2.724) - AE Loss: 75198.047 (681685.312) - AE Rec Loss: 0.510 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.825 
(2.724) - AE Loss: 325838.438 (681685.312) - AE Rec Loss: 2.210 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.26 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.826 
(2.724) - AE Loss: 1499775.000 (681685.312) - AE Rec Loss: 10.171 (4.623) - Disc
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <269/2280>] - Data(s): 0.000 (0.733) - Batch(s): 0.825 
(2.724) - AE Loss: 163555.953 (681685.312) - AE Rec Loss: 1.109 (4.623) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.802 
(3.032) - AE Loss: 97942.656 (701574.562) - AE Rec Loss: 0.664 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.790 
(3.032) - AE Loss: 779060.750 (701574.562) - AE Rec Loss: 5.283 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.802 
(3.032) - AE Loss: 575911.750 (701574.562) - AE Rec Loss: 3.906 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.001 (0.704) - Batch(s): 5.807 
(3.032) - AE Loss: 1498313.250 (701574.562) - AE Rec Loss: 10.161 (4.758) - Disc
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.799 
(3.032) - AE Loss: 484824.125 (701574.562) - AE Rec Loss: 3.288 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.99 m remaining

[Epoch <000/100>: Step <270/2280>] - Data(s): 0.000 (0.704) - Batch(s): 5.801 
(3.032) - AE Loss: 242091.797 (701574.562) - AE Rec Loss: 1.642 (4.758) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.161 
(2.857) - AE Loss: 120146.945 (703098.312) - AE Rec Loss: 0.815 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.155 
(2.857) - AE Loss: 1622242.250 (703098.312) - AE Rec Loss: 11.002 (4.768) - Disc
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.145 
(2.857) - AE Loss: 194401.797 (703098.312) - AE Rec Loss: 1.318 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.158 
(2.857) - AE Loss: 93873.531 (703098.312) - AE Rec Loss: 0.637 (4.768) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.157 
(2.857) - AE Loss: 1697110.000 (703098.312) - AE Rec Loss: 11.509 (4.768) - Disc
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <271/2280>] - Data(s): 0.000 (0.640) - Batch(s): 1.157 
(2.857) - AE Loss: 1808010.625 (703098.312) - AE Rec Loss: 12.261 (4.768) - Disc
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 1535667.000 (689406.562) - AE Rec Loss: 10.414 (4.675) - Disc
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.664 
(2.674) - AE Loss: 364097.625 (689406.562) - AE Rec Loss: 2.469 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.667 
(2.674) - AE Loss: 229968.484 (689406.562) - AE Rec Loss: 1.560 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.667 
(2.674) - AE Loss: 56785.281 (689406.562) - AE Rec Loss: 0.385 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.665 
(2.674) - AE Loss: 128524.258 (689406.562) - AE Rec Loss: 0.872 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <272/2280>] - Data(s): 0.000 (0.586) - Batch(s): 0.666 
(2.674) - AE Loss: 313459.875 (689406.562) - AE Rec Loss: 2.126 (4.675) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.477 
(2.659) - AE Loss: 151037.875 (682977.125) - AE Rec Loss: 1.024 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.001 (0.554) - Batch(s): 2.466 
(2.659) - AE Loss: 1972715.250 (682977.125) - AE Rec Loss: 13.378 (4.632) - Disc
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.478 
(2.659) - AE Loss: 1623727.125 (682977.125) - AE Rec Loss: 11.012 (4.632) - Disc
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.478 
(2.659) - AE Loss: 120637.586 (682977.125) - AE Rec Loss: 0.818 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.52 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.000 (0.554) - Batch(s): 2.477 
(2.659) - AE Loss: 132546.703 (682977.125) - AE Rec Loss: 0.899 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <273/2280>] - Data(s): 0.001 (0.554) - Batch(s): 2.482 
(2.659) - AE Loss: 109077.773 (682977.125) - AE Rec Loss: 0.740 (4.632) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.566 
(2.509) - AE Loss: 253285.656 (692070.500) - AE Rec Loss: 1.718 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.553 
(2.509) - AE Loss: 200361.219 (692070.500) - AE Rec Loss: 1.359 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.567 
(2.509) - AE Loss: 1678054.250 (692070.500) - AE Rec Loss: 11.380 (4.693) - Disc
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.564 
(2.509) - AE Loss: 237156.047 (692070.500) - AE Rec Loss: 1.608 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.59 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.573 
(2.509) - AE Loss: 1548482.250 (692070.500) - AE Rec Loss: 10.501 (4.693) - Disc
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <274/2280>] - Data(s): 0.000 (0.514) - Batch(s): 0.567 
(2.509) - AE Loss: 419662.938 (692070.500) - AE Rec Loss: 2.846 (4.693) - Disc 
Loss: 0.000 (0.000) - 4.56 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.649 
(2.385) - AE Loss: 69351.367 (675185.312) - AE Rec Loss: 0.470 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.649 
(2.385) - AE Loss: 354855.125 (675185.312) - AE Rec Loss: 2.407 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.647 
(2.385) - AE Loss: 148449.516 (675185.312) - AE Rec Loss: 1.007 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.649 
(2.385) - AE Loss: 81587.016 (675185.312) - AE Rec Loss: 0.553 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.647 
(2.385) - AE Loss: 515544.781 (675185.312) - AE Rec Loss: 3.496 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <275/2280>] - Data(s): 0.000 (0.480) - Batch(s): 0.649 
(2.385) - AE Loss: 246041.891 (675185.312) - AE Rec Loss: 1.669 (4.579) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.007 
(2.424) - AE Loss: 635655.375 (670561.312) - AE Rec Loss: 4.311 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.00 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.011 
(2.424) - AE Loss: 99430.883 (670561.312) - AE Rec Loss: 0.674 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.04 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.007 
(2.424) - AE Loss: 523112.281 (670561.312) - AE Rec Loss: 3.548 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 2.994 
(2.424) - AE Loss: 106112.648 (670561.312) - AE Rec Loss: 0.720 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.00 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.006 
(2.424) - AE Loss: 471795.906 (670561.312) - AE Rec Loss: 3.200 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.03 m remaining

[Epoch <000/100>: Step <276/2280>] - Data(s): 0.000 (0.463) - Batch(s): 3.006 
(2.424) - AE Loss: 232514.234 (670561.312) - AE Rec Loss: 1.577 (4.548) - Disc 
Loss: 0.000 (0.000) - 5.01 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.568 
(2.315) - AE Loss: 385144.000 (670543.125) - AE Rec Loss: 2.612 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.07 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.567 
(2.315) - AE Loss: 180189.391 (670543.125) - AE Rec Loss: 1.222 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.07 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.553 
(2.315) - AE Loss: 1802427.875 (670543.125) - AE Rec Loss: 12.223 (4.547) - Disc
Loss: 0.000 (0.000) - 5.07 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.574 
(2.315) - AE Loss: 214560.844 (670543.125) - AE Rec Loss: 1.455 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.11 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.567 
(2.315) - AE Loss: 193726.188 (670543.125) - AE Rec Loss: 1.314 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.07 m remaining

[Epoch <000/100>: Step <277/2280>] - Data(s): 0.000 (0.435) - Batch(s): 0.565 
(2.315) - AE Loss: 615991.375 (670543.125) - AE Rec Loss: 4.177 (4.547) - Disc 
Loss: 0.000 (0.000) - 5.10 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 187745.281 (660157.500) - AE Rec Loss: 1.273 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 1583745.750 (660157.500) - AE Rec Loss: 10.740 (4.477) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.328 
(2.316) - AE Loss: 242079.250 (660157.500) - AE Rec Loss: 1.642 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.329 
(2.316) - AE Loss: 1961569.250 (660157.500) - AE Rec Loss: 13.303 (4.477) - Disc
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.001 (0.419) - Batch(s): 2.329 
(2.316) - AE Loss: 155911.531 (660157.500) - AE Rec Loss: 1.057 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <278/2280>] - Data(s): 0.000 (0.419) - Batch(s): 2.330 
(2.316) - AE Loss: 229426.203 (660157.500) - AE Rec Loss: 1.556 (4.477) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.574 
(2.223) - AE Loss: 132054.547 (656595.500) - AE Rec Loss: 0.896 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.45 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.567 
(2.223) - AE Loss: 1684520.500 (656595.500) - AE Rec Loss: 11.424 (4.453) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.565 
(2.223) - AE Loss: 91493.000 (656595.500) - AE Rec Loss: 0.620 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.44 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.566 
(2.223) - AE Loss: 556122.250 (656595.500) - AE Rec Loss: 3.771 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.553 
(2.223) - AE Loss: 121840.922 (656595.500) - AE Rec Loss: 0.826 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <279/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.567 
(2.223) - AE Loss: 285756.312 (656595.500) - AE Rec Loss: 1.938 (4.453) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.575 
(2.141) - AE Loss: 149387.312 (664869.188) - AE Rec Loss: 1.013 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.001 (0.378) - Batch(s): 0.553 
(2.141) - AE Loss: 530900.438 (664869.188) - AE Rec Loss: 3.600 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.567 
(2.141) - AE Loss: 2212659.000 (664869.188) - AE Rec Loss: 15.006 (4.509) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.001 (0.378) - Batch(s): 0.570 
(2.141) - AE Loss: 1727444.250 (664869.188) - AE Rec Loss: 11.715 (4.509) - Disc
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.000 (0.378) - Batch(s): 0.566 
(2.141) - AE Loss: 103732.516 (664869.188) - AE Rec Loss: 0.703 (4.509) - Disc 
Loss: 0.000 (0.000) - 5.48 m remaining

[Epoch <000/100>: Step <280/2280>] - Data(s): 0.001 (0.378) - Batch(s): 0.565 
(2.141) - AE Loss: 1592607.500 (664869.188) - AE Rec Loss: 10.801 (4.509) - Disc
Loss: 0.000 (0.000) - 5.51 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.174 
(2.878) - AE Loss: 149501.703 (649645.688) - AE Rec Loss: 1.014 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.174 
(2.878) - AE Loss: 211095.031 (649645.688) - AE Rec Loss: 1.432 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.173 
(2.878) - AE Loss: 66623.375 (649645.688) - AE Rec Loss: 0.452 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.77 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.000 (0.364) - Batch(s): 19.174 
(2.878) - AE Loss: 753228.688 (649645.688) - AE Rec Loss: 5.108 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.001 (0.364) - Batch(s): 19.174 
(2.878) - AE Loss: 571270.750 (649645.688) - AE Rec Loss: 3.874 (4.406) - Disc 
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 0.001 (0.364) - Batch(s): 19.174 
(2.878) - AE Loss: 1500820.250 (649645.688) - AE Rec Loss: 10.178 (4.406) - Disc
Loss: 0.000 (0.000) - 7.74 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.554 
(2.773) - AE Loss: 1441933.250 (653407.062) - AE Rec Loss: 9.779 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.573 
(2.773) - AE Loss: 193036.031 (653407.062) - AE Rec Loss: 1.309 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.83 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.567 
(2.773) - AE Loss: 92689.422 (653407.062) - AE Rec Loss: 0.629 (4.431) - Disc 
Loss: 0.000 (0.000) - 7.80 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.565 
(2.773) - AE Loss: 1607637.750 (653407.062) - AE Rec Loss: 10.902 (4.431) - Disc
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.565 
(2.773) - AE Loss: 1524943.375 (653407.062) - AE Rec Loss: 10.342 (4.431) - Disc
Loss: 0.000 (0.000) - 7.82 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.567 
(2.773) - AE Loss: 1615242.750 (653407.062) - AE Rec Loss: 10.954 (4.431) - Disc
Loss: 0.000 (0.000) - 7.79 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.573 
(2.677) - AE Loss: 155855.172 (653220.500) - AE Rec Loss: 1.057 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.88 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.553 
(2.677) - AE Loss: 1507598.750 (653220.500) - AE Rec Loss: 10.224 (4.430) - Disc
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.566 
(2.677) - AE Loss: 205326.109 (653220.500) - AE Rec Loss: 1.392 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.566 
(2.677) - AE Loss: 137665.281 (653220.500) - AE Rec Loss: 0.934 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.87 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.001 (0.332) - Batch(s): 0.567 
(2.677) - AE Loss: 1517745.250 (653220.500) - AE Rec Loss: 10.293 (4.430) - Disc
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (0.332) - Batch(s): 0.567 
(2.677) - AE Loss: 121739.555 (653220.500) - AE Rec Loss: 0.826 (4.430) - Disc 
Loss: 0.000 (0.000) - 7.85 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.635 
(2.592) - AE Loss: 1605686.750 (652188.875) - AE Rec Loss: 10.889 (4.423) - Disc
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.636 
(2.592) - AE Loss: 85872.859 (652188.875) - AE Rec Loss: 0.582 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.635 
(2.592) - AE Loss: 126727.703 (652188.875) - AE Rec Loss: 0.859 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.94 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (0.318) - Batch(s): 0.635 
(2.592) - AE Loss: 91529.484 (652188.875) - AE Rec Loss: 0.621 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.636 
(2.592) - AE Loss: 226391.562 (652188.875) - AE Rec Loss: 1.535 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (0.318) - Batch(s): 0.637 
(2.592) - AE Loss: 281733.000 (652188.875) - AE Rec Loss: 1.911 (4.423) - Disc 
Loss: 0.000 (0.000) - 7.91 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.574 
(2.511) - AE Loss: 118305.711 (653049.750) - AE Rec Loss: 0.802 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.554 
(2.511) - AE Loss: 687999.875 (653049.750) - AE Rec Loss: 4.666 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 269524.312 (653049.750) - AE Rec Loss: 1.828 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 1455988.500 (653049.750) - AE Rec Loss: 9.874 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 120260.117 (653049.750) - AE Rec Loss: 0.816 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.99 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (0.305) - Batch(s): 0.567 
(2.511) - AE Loss: 434735.625 (653049.750) - AE Rec Loss: 2.948 (4.429) - Disc 
Loss: 0.000 (0.000) - 7.96 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.575 
(2.436) - AE Loss: 218216.984 (643148.625) - AE Rec Loss: 1.480 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.05 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.554 
(2.436) - AE Loss: 101293.734 (643148.625) - AE Rec Loss: 0.687 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.569 
(2.436) - AE Loss: 146984.594 (643148.625) - AE Rec Loss: 0.997 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.567 
(2.436) - AE Loss: 1355664.375 (643148.625) - AE Rec Loss: 9.194 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.04 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.569 
(2.436) - AE Loss: 357398.438 (643148.625) - AE Rec Loss: 2.424 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.02 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.294) - Batch(s): 0.568 
(2.436) - AE Loss: 248512.891 (643148.625) - AE Rec Loss: 1.685 (4.362) - Disc 
Loss: 0.000 (0.000) - 8.01 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 04:52:25,007[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,041[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,260[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,311[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,312[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 04:52:25,403[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 04:52:27,217[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,317[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,448[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,488[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,517[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 04:52:27,639[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,712[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,771[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:27,957[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:28,019[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:28,038[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 04:52:28,151[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 04:52:28,154[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:52:28,154[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
[[36m2023-11-29 04:52:28,156[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:52:28,155[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Running in inference mode: False
[[36m2023-11-29 04:52:28,156[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 04:52:28,156[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataloader) = 1
=> Preparing model 
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing model 
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 6
Reached 2 on node 9
Reached 3 on node 6
Reached 3 on node 9
Reached 5 on node 6Reached 5 on node 9

Reached end on node 9
Reached end on node 6
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 9
Reached 5 on node 9
Reached 3 on node 6
Reached end on node 9
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1 on node 8
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1 on node 11
Reached 1.2 on node 6
Reached 1.2 on node 11
Reached 1.25 on node 6
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}

Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 8
Reached 1.4 on node 8Reached 1.3 on node 10
Reached 1.3 on node 7

Reached 1.4 on node 10Reached 1.3 on node 6Reached 1.4 on node 7
Reached 2 on node 8Reached 1.3 on node 11



Reached 1.3 on node 9Reached 1.4 on node 6Reached 2 on node 10
Reached 2 on node 7
Reached 1.4 on node 11
Reached 1.4 on node 9


Reached 3 on node 8
Reached 2 on node 6
Reached 2 on node 11Reached 2 on node 9

Reached 5 on node 8Reached 3 on node 7Reached 3 on node 10


Reached 3 on node 6Reached 3 on node 11Reached 5 on node 10
Reached end on node 8Reached 5 on node 7

Reached 3 on node 9


Reached 5 on node 6
Reached 5 on node 11Reached end on node 10Reached 5 on node 9
Reached end on node 7
Reached end on node 6


Reached end on node 11Reached end on node 9

=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 9Reached 1 on node 7

Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 9Reached 1.4 on node 7

Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 6Reached 1.4 on node 11Reached 1 on node 8


Reached 2 on node 11
Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 6Reached 2 on node 8

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 9Reached 1.4 on node 7

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7Reached 1.4 on node 9

Reached 3 on node 7Reached 2 on node 9

Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 11
Reached 1 on node 8Reached 1.4 on node 11

Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 1 on node 8Reached 2 on node 11

Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9Reached 1 on node 11

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11
Reached 5 on node 9
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 1.4 on node 8
Reached 2 on node 6
Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1 on node 6
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached end on node 7Reached 3 on node 8

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 11
Reached end on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <281/2280>] - Data(s): 5.397 (5.253) - Batch(s): 11.660 
(12.091) - AE Loss: 753863.750 (345246.531) - AE Rec Loss: 5.112 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.440 (5.253) - Batch(s): 11.665 
(12.091) - AE Loss: 66416.461 (345246.531) - AE Rec Loss: 0.450 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.978 (5.253) - Batch(s): 11.643 
(12.091) - AE Loss: 211095.297 (345246.531) - AE Rec Loss: 1.432 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 10.172 (5.253) - Batch(s): 11.651 
(12.091) - AE Loss: 1500787.250 (345246.531) - AE Rec Loss: 10.178 (2.341) - 
Disc Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.557 (5.253) - Batch(s): 11.646 
(12.091) - AE Loss: 571698.500 (345246.531) - AE Rec Loss: 3.877 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.580 (5.253) - Batch(s): 11.677 
(12.091) - AE Loss: 149241.062 (345246.531) - AE Rec Loss: 1.012 (2.341) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.557 
(6.329) - AE Loss: 1433611.000 (533329.250) - AE Rec Loss: 9.722 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.566 
(6.329) - AE Loss: 1602564.125 (533329.250) - AE Rec Loss: 10.868 (3.617) - Disc
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.568 
(6.329) - AE Loss: 1598316.500 (533329.250) - AE Rec Loss: 10.839 (3.617) - Disc
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.567 
(6.329) - AE Loss: 71905.609 (533329.250) - AE Rec Loss: 0.488 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.567 
(6.329) - AE Loss: 1521838.625 (533329.250) - AE Rec Loss: 10.321 (3.617) - Disc
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.627) - Batch(s): 0.573 
(6.329) - AE Loss: 173313.781 (533329.250) - AE Rec Loss: 1.175 (3.617) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.020 
(4.560) - AE Loss: 192703.047 (568238.750) - AE Rec Loss: 1.307 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.024 
(4.560) - AE Loss: 1511342.125 (568238.750) - AE Rec Loss: 10.249 (3.854) - Disc
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.024 
(4.560) - AE Loss: 1502690.750 (568238.750) - AE Rec Loss: 10.191 (3.854) - Disc
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.024 
(4.560) - AE Loss: 147586.672 (568238.750) - AE Rec Loss: 1.001 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.336 (1.761) - Batch(s): 1.027 
(4.560) - AE Loss: 100026.898 (568238.750) - AE Rec Loss: 0.678 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.000 (1.761) - Batch(s): 1.027 
(4.560) - AE Loss: 133486.938 (568238.750) - AE Rec Loss: 0.905 (3.854) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.567 
(3.562) - AE Loss: 216412.000 (581274.688) - AE Rec Loss: 1.468 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.554 
(3.562) - AE Loss: 74590.469 (581274.688) - AE Rec Loss: 0.506 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.573 
(3.562) - AE Loss: 1602653.750 (581274.688) - AE Rec Loss: 10.869 (3.942) - Disc
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.566 
(3.562) - AE Loss: 78677.812 (581274.688) - AE Rec Loss: 0.534 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.565 
(3.562) - AE Loss: 118827.219 (581274.688) - AE Rec Loss: 0.806 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.321) - Batch(s): 0.568 
(3.562) - AE Loss: 275076.094 (581274.688) - AE Rec Loss: 1.865 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.924 
(3.010) - AE Loss: 1457590.250 (600211.438) - AE Rec Loss: 9.885 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.924 
(3.010) - AE Loss: 266649.375 (600211.438) - AE Rec Loss: 1.808 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.911 
(3.010) - AE Loss: 687494.062 (600211.438) - AE Rec Loss: 4.662 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.924 
(3.010) - AE Loss: 434070.844 (600211.438) - AE Rec Loss: 2.944 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.922 
(3.010) - AE Loss: 123216.461 (600211.438) - AE Rec Loss: 0.836 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.063) - Batch(s): 0.930 
(3.010) - AE Loss: 117973.289 (600211.438) - AE Rec Loss: 0.800 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (0.909) - Batch(s): 2.373 
(2.904) - AE Loss: 355947.156 (566687.125) - AE Rec Loss: 2.414 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.909) - Batch(s): 2.374 
(2.904) - AE Loss: 111159.234 (566687.125) - AE Rec Loss: 0.754 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.909) - Batch(s): 2.375 
(2.904) - AE Loss: 244620.375 (566687.125) - AE Rec Loss: 1.659 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.909) - Batch(s): 2.376 
(2.904) - AE Loss: 153578.281 (566687.125) - AE Rec Loss: 1.042 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.909) - Batch(s): 2.375 
(2.904) - AE Loss: 1356175.000 (566687.125) - AE Rec Loss: 9.197 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.001 (0.909) - Batch(s): 2.373 
(2.904) - AE Loss: 217585.891 (566687.125) - AE Rec Loss: 1.476 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.11 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 1.311 
(2.638) - AE Loss: 108793.680 (567626.500) - AE Rec Loss: 0.738 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 631026.688 (567626.500) - AE Rec Loss: 4.279 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 1.302 
(2.638) - AE Loss: 536570.188 (567626.500) - AE Rec Loss: 3.639 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 72481.375 (567626.500) - AE Rec Loss: 0.492 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.788) - Batch(s): 0.947 
(2.638) - AE Loss: 437610.719 (567626.500) - AE Rec Loss: 2.968 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.741 (0.788) - Batch(s): 1.306 
(2.638) - AE Loss: 125618.758 (567626.500) - AE Rec Loss: 0.852 (3.849) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.778) - Batch(s): 7.479 
(3.227) - AE Loss: 1379338.750 (584087.562) - AE Rec Loss: 9.354 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.778) - Batch(s): 7.460 
(3.227) - AE Loss: 242790.578 (584087.562) - AE Rec Loss: 1.647 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.778) - Batch(s): 7.469 
(3.227) - AE Loss: 840469.625 (584087.562) - AE Rec Loss: 5.700 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.778) - Batch(s): 7.471 
(3.227) - AE Loss: 1389097.375 (584087.562) - AE Rec Loss: 9.420 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.219 (0.778) - Batch(s): 7.473 
(3.227) - AE Loss: 1442622.500 (584087.562) - AE Rec Loss: 9.783 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 1.382 (0.778) - Batch(s): 7.472 
(3.227) - AE Loss: 100567.742 (584087.562) - AE Rec Loss: 0.682 (3.961) - Disc 
Loss: 0.000 (0.000) - 3.14 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.642 
(2.940) - AE Loss: 58858.195 (612802.250) - AE Rec Loss: 0.399 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.642 
(2.940) - AE Loss: 185278.766 (612802.250) - AE Rec Loss: 1.257 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.642 
(2.940) - AE Loss: 1521660.500 (612802.250) - AE Rec Loss: 10.319 (4.156) - Disc
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.643 
(2.940) - AE Loss: 99929.797 (612802.250) - AE Rec Loss: 0.678 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.692) - Batch(s): 0.643 
(2.940) - AE Loss: 871053.125 (612802.250) - AE Rec Loss: 5.907 (4.156) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.001 (0.692) - Batch(s): 0.642 
(2.940) - AE Loss: 2904869.000 (612802.250) - AE Rec Loss: 19.700 (4.156) - Disc
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.566 
(2.702) - AE Loss: 197536.719 (607850.562) - AE Rec Loss: 1.340 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.568 
(2.702) - AE Loss: 1494917.625 (607850.562) - AE Rec Loss: 10.138 (4.122) - Disc
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.567 
(2.702) - AE Loss: 142321.969 (607850.562) - AE Rec Loss: 0.965 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.573 
(2.702) - AE Loss: 185353.766 (607850.562) - AE Rec Loss: 1.257 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.553 
(2.702) - AE Loss: 219217.719 (607850.562) - AE Rec Loss: 1.487 (4.122) - Disc 
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.623) - Batch(s): 0.567 
(2.702) - AE Loss: 1669808.125 (607850.562) - AE Rec Loss: 11.324 (4.122) - Disc
Loss: 0.000 (0.000) - 3.29 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.266 
(2.920) - AE Loss: 628412.938 (583836.875) - AE Rec Loss: 4.262 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.267 
(2.920) - AE Loss: 266901.719 (583836.875) - AE Rec Loss: 1.810 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.269 
(2.920) - AE Loss: 1497275.750 (583836.875) - AE Rec Loss: 10.154 (3.959) - Disc
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.268 
(2.920) - AE Loss: 211201.938 (583836.875) - AE Rec Loss: 1.432 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.275 
(2.920) - AE Loss: 132662.281 (583836.875) - AE Rec Loss: 0.900 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.602) - Batch(s): 5.255 
(2.920) - AE Loss: 94148.398 (583836.875) - AE Rec Loss: 0.638 (3.959) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.638 
(2.730) - AE Loss: 1759326.250 (577743.375) - AE Rec Loss: 11.931 (3.918) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.638 
(2.730) - AE Loss: 214852.984 (577743.375) - AE Rec Loss: 1.457 (3.918) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.639 
(2.730) - AE Loss: 1507573.000 (577743.375) - AE Rec Loss: 10.224 (3.918) - Disc
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.638 
(2.730) - AE Loss: 314414.875 (577743.375) - AE Rec Loss: 2.132 (3.918) - Disc 
Loss: 0.000 (0.000) - 3.96 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.640 
(2.730) - AE Loss: 63626.957 (577743.375) - AE Rec Loss: 0.431 (3.918) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.552) - Batch(s): 0.640 
(2.730) - AE Loss: 109048.656 (577743.375) - AE Rec Loss: 0.740 (3.918) - Disc 
Loss: 0.000 (0.000) - 3.97 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.426 
(2.616) - AE Loss: 440515.000 (570977.000) - AE Rec Loss: 2.987 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.428 
(2.616) - AE Loss: 184952.203 (570977.000) - AE Rec Loss: 1.254 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.429 
(2.616) - AE Loss: 3106523.500 (570977.000) - AE Rec Loss: 21.067 (3.872) - Disc
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.865 (0.515) - Batch(s): 1.431 
(2.616) - AE Loss: 184481.328 (570977.000) - AE Rec Loss: 1.251 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.416 
(2.616) - AE Loss: 151260.281 (570977.000) - AE Rec Loss: 1.026 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.515) - Batch(s): 1.436 
(2.616) - AE Loss: 355096.438 (570977.000) - AE Rec Loss: 2.408 (3.872) - Disc 
Loss: 0.000 (0.000) - 4.13 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.309 
(3.443) - AE Loss: 305462.156 (571465.062) - AE Rec Loss: 2.072 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.310 
(3.443) - AE Loss: 202005.672 (571465.062) - AE Rec Loss: 1.370 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.311 
(3.443) - AE Loss: 2944094.000 (571465.062) - AE Rec Loss: 19.966 (3.875) - Disc
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.298 
(3.443) - AE Loss: 242158.359 (571465.062) - AE Rec Loss: 1.642 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.317 
(3.443) - AE Loss: 181962.922 (571465.062) - AE Rec Loss: 1.234 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.74 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.560) - Batch(s): 14.311 
(3.443) - AE Loss: 63638.648 (571465.062) - AE Rec Loss: 0.432 (3.875) - Disc 
Loss: 0.000 (0.000) - 5.73 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.635 
(3.256) - AE Loss: 203000.672 (593207.625) - AE Rec Loss: 1.377 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.636 
(3.256) - AE Loss: 373385.438 (593207.625) - AE Rec Loss: 2.532 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.636 
(3.256) - AE Loss: 123988.102 (593207.625) - AE Rec Loss: 0.841 (4.023) - Disc 
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.635 
(3.256) - AE Loss: 1488035.750 (593207.625) - AE Rec Loss: 10.091 (4.023) - Disc
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.635 
(3.256) - AE Loss: 1634073.000 (593207.625) - AE Rec Loss: 11.082 (4.023) - Disc
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.523) - Batch(s): 0.636 
(3.256) - AE Loss: 1707810.750 (593207.625) - AE Rec Loss: 11.582 (4.023) - Disc
Loss: 0.000 (0.000) - 5.80 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.569 
(3.088) - AE Loss: 510352.625 (593370.562) - AE Rec Loss: 3.461 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.567 
(3.088) - AE Loss: 338950.188 (593370.562) - AE Rec Loss: 2.299 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.567 
(3.088) - AE Loss: 2787497.000 (593370.562) - AE Rec Loss: 18.904 (4.024) - Disc
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.555 
(3.088) - AE Loss: 336003.000 (593370.562) - AE Rec Loss: 2.279 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.574 
(3.088) - AE Loss: 407781.781 (593370.562) - AE Rec Loss: 2.765 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.490) - Batch(s): 0.569 
(3.088) - AE Loss: 159800.938 (593370.562) - AE Rec Loss: 1.084 (4.024) - Disc 
Loss: 0.000 (0.000) - 5.86 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.238 
(3.090) - AE Loss: 60601.613 (580125.625) - AE Rec Loss: 0.411 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.21 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.237 
(3.090) - AE Loss: 72367.141 (580125.625) - AE Rec Loss: 0.491 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.225 
(3.090) - AE Loss: 137842.250 (580125.625) - AE Rec Loss: 0.935 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.237 
(3.090) - AE Loss: 1581977.500 (580125.625) - AE Rec Loss: 10.728 (3.934) - Disc
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.245 
(3.090) - AE Loss: 420840.750 (580125.625) - AE Rec Loss: 2.854 (3.934) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.474) - Batch(s): 3.239 
(3.090) - AE Loss: 1493733.250 (580125.625) - AE Rec Loss: 10.130 (3.934) - Disc
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 1455513.000 (589419.250) - AE Rec Loss: 9.871 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 1404063.000 (589419.250) - AE Rec Loss: 9.522 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 1777067.375 (589419.250) - AE Rec Loss: 12.052 (3.997) - Disc
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 239485.125 (589419.250) - AE Rec Loss: 1.624 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 85714.328 (589419.250) - AE Rec Loss: 0.581 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.001 (0.448) - Batch(s): 0.640 
(2.953) - AE Loss: 306639.031 (589419.250) - AE Rec Loss: 2.080 (3.997) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.567 
(2.828) - AE Loss: 1368616.250 (576836.438) - AE Rec Loss: 9.282 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.569 
(2.828) - AE Loss: 61648.680 (576836.438) - AE Rec Loss: 0.418 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.568 
(2.828) - AE Loss: 124496.023 (576836.438) - AE Rec Loss: 0.844 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.33 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.568 
(2.828) - AE Loss: 237848.734 (576836.438) - AE Rec Loss: 1.613 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.555 
(2.828) - AE Loss: 288244.781 (576836.438) - AE Rec Loss: 1.955 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.424) - Batch(s): 0.575 
(2.828) - AE Loss: 328512.531 (576836.438) - AE Rec Loss: 2.228 (3.912) - Disc 
Loss: 0.000 (0.000) - 6.34 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:03:06,522[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,628[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,687[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,695[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,704[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:03:06,763[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:03:08,711[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,824[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,870[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,903[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,929[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:03:08,989[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,266[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,333[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,428[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,480[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,514[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:03:09,555[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 05:03:09,557[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:03:09,558[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
[[36m2023-11-29 05:03:09,559[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
[[36m2023-11-29 05:03:09,559[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating the optimizer 
=> Mixed precision: no
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Running in inference mode: False
[[36m2023-11-29 05:03:09,561[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(train_dataset) = 54706
=> Preparing model 
len(train_dataset) = 54706
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating valid dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
[[36m2023-11-29 05:03:09,576[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1 on node 11
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:04:38,937[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:38,952[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:39,024[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:39,042[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:39,056[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:04:39,071[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:04:41,227[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:41,280[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:41,287[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:41,302[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:41,308[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:04:41,673[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,781[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,855[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:04:41,933[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 05:04:41,933[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:04:41,937[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:04:42,174[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 05:04:42,175[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:04:42,177[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
[[36m2023-11-29 05:04:42,182[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:04:42,182[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:04:42,182[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Preparing model 
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
[[36m2023-11-29 05:04:42,184[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Mixed precision: no
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
=> Preparing model 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 3 on node 10
Reached 2 on node 8
Reached 5 on node 10
Reached 3 on node 8
Reached end on node 10
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 10Reached 3 on node 8

Reached 5 on node 8
Reached 5 on node 10
Reached end on node 8
Reached end on node 10
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11Reached 1.3 on node 9Reached 1.3 on node 6


Reached 1.4 on node 11Reached 1.4 on node 9

Reached 1.4 on node 6
Reached 2 on node 9Reached 2 on node 11

Reached 2 on node 6Reached 1.3 on node 10
Reached 1.3 on node 8

Reached 1.4 on node 10Reached 3 on node 9Reached 3 on node 11

Reached 1.4 on node 8

Reached 3 on node 6
Reached 2 on node 10Reached 5 on node 11

Reached 5 on node 9Reached 2 on node 8

Reached 5 on node 6Reached end on node 11

Reached 1.3 on node 7Reached end on node 9

Reached 3 on node 10Reached end on node 6
Reached 1.4 on node 7Reached 3 on node 8


Reached 5 on node 10
Reached 5 on node 8Reached 2 on node 7

Reached end on node 10
Reached end on node 8
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
Loaded checkpoint at epoch 0 and step 281
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6Reached 1.4 on node 7

Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 1 on node 10Reached 2 on node 9

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8Reached 1 on node 11

Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 1.4 on node 7Reached 2 on node 6

Reached 2 on node 7
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 9
Reached 1 on node 10Reached 1.4 on node 9

Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8Reached 1 on node 11

Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1.4 on node 11Reached 3 on node 8

Reached 2 on node 11Reached 3 on node 8

Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9Reached 1.4 on node 10

Reached 3 on node 9Reached 2 on node 10

Reached 3 on node 9
Reached 3 on node 9Reached 3 on node 10

Reached 3 on node 9Reached 3 on node 10

Reached 5 on node 9Reached 3 on node 10

Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 6
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 11
Reached 1 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 11
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <281/2280>] - Data(s): 5.060 (4.858) - Batch(s): 7.503 
(7.570) - AE Loss: 66563.062 (345289.750) - AE Rec Loss: 0.451 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.546 (4.858) - Batch(s): 7.781 
(7.570) - AE Loss: 1500807.375 (345289.750) - AE Rec Loss: 10.178 (2.342) - Disc
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.303 (4.858) - Batch(s): 7.494 
(7.570) - AE Loss: 571379.125 (345289.750) - AE Rec Loss: 3.875 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.372 (4.858) - Batch(s): 7.729 
(7.570) - AE Loss: 753796.750 (345289.750) - AE Rec Loss: 5.112 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.95 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 6.101 (4.858) - Batch(s): 7.503 
(7.570) - AE Loss: 149298.797 (345289.750) - AE Rec Loss: 1.012 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <281/2280>] - Data(s): 5.888 (4.858) - Batch(s): 7.749 
(7.570) - AE Loss: 211227.406 (345289.750) - AE Rec Loss: 1.432 (2.342) - Disc 
Loss: 0.000 (0.000) - 0.95 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.429) - Batch(s): 0.562 
(4.066) - AE Loss: 1597965.375 (533248.062) - AE Rec Loss: 10.837 (3.616) - Disc
Loss: 0.000 (0.000) - 1.04 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.429) - Batch(s): 0.561 
(4.066) - AE Loss: 1602319.625 (533248.062) - AE Rec Loss: 10.866 (3.616) - Disc
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.429) - Batch(s): 0.562 
(4.066) - AE Loss: 72021.312 (533248.062) - AE Rec Loss: 0.488 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.00 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.569 
(4.066) - AE Loss: 174262.531 (533248.062) - AE Rec Loss: 1.182 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.00 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.000 (2.429) - Batch(s): 0.550 
(4.066) - AE Loss: 1432444.750 (533248.062) - AE Rec Loss: 9.714 (3.616) - Disc 
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <282/2280>] - Data(s): 0.001 (2.429) - Batch(s): 0.560 
(4.066) - AE Loss: 1521858.500 (533248.062) - AE Rec Loss: 10.321 (3.616) - Disc
Loss: 0.000 (0.000) - 1.00 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <283/2280>] - Data(s): 0.001 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 193981.047 (568088.688) - AE Rec Loss: 1.316 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.57 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 3.810 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 100093.094 (568088.688) - AE Rec Loss: 0.679 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.001 (2.057) - Batch(s): 4.514 
(4.214) - AE Loss: 1511418.750 (568088.688) - AE Rec Loss: 10.250 (3.853) - Disc
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.809 (2.057) - Batch(s): 4.510 
(4.214) - AE Loss: 132907.750 (568088.688) - AE Rec Loss: 0.901 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 1.366 (2.057) - Batch(s): 4.514 
(4.214) - AE Loss: 147000.234 (568088.688) - AE Rec Loss: 0.997 (3.853) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <283/2280>] - Data(s): 0.001 (2.057) - Batch(s): 4.514 
(4.214) - AE Loss: 1502292.125 (568088.688) - AE Rec Loss: 10.188 (3.853) - Disc
Loss: 0.000 (0.000) - 1.58 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.702 (1.564) - Batch(s): 1.266 
(3.432) - AE Loss: 217184.500 (581251.938) - AE Rec Loss: 1.473 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.74 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.564) - Batch(s): 1.262 
(3.432) - AE Loss: 118398.211 (581251.938) - AE Rec Loss: 0.803 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 1.265 
(3.432) - AE Loss: 275139.062 (581251.938) - AE Rec Loss: 1.866 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 1.253 
(3.432) - AE Loss: 76350.664 (581251.938) - AE Rec Loss: 0.518 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.74 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.000 (1.564) - Batch(s): 1.265 
(3.432) - AE Loss: 79706.617 (581251.938) - AE Rec Loss: 0.541 (3.942) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <284/2280>] - Data(s): 0.001 (1.564) - Batch(s): 1.269 
(3.432) - AE Loss: 1602556.000 (581251.938) - AE Rec Loss: 10.868 (3.942) - Disc
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.565 
(2.859) - AE Loss: 267316.938 (600216.812) - AE Rec Loss: 1.813 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.82 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.001 (1.251) - Batch(s): 0.564 
(2.859) - AE Loss: 1458218.125 (600216.812) - AE Rec Loss: 9.889 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.572 
(2.859) - AE Loss: 118343.430 (600216.812) - AE Rec Loss: 0.803 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.565 
(2.859) - AE Loss: 434586.438 (600216.812) - AE Rec Loss: 2.947 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.552 
(2.859) - AE Loss: 687818.188 (600216.812) - AE Rec Loss: 4.665 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <285/2280>] - Data(s): 0.000 (1.251) - Batch(s): 0.563 
(2.859) - AE Loss: 123234.109 (600216.812) - AE Rec Loss: 0.836 (4.070) - Disc 
Loss: 0.000 (0.000) - 1.79 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.171 
(3.244) - AE Loss: 357040.500 (566742.312) - AE Rec Loss: 2.421 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.170 
(3.244) - AE Loss: 112299.289 (566742.312) - AE Rec Loss: 0.762 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.171 
(3.244) - AE Loss: 1356158.875 (566742.312) - AE Rec Loss: 9.197 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.000 (1.109) - Batch(s): 5.171 
(3.244) - AE Loss: 244393.297 (566742.312) - AE Rec Loss: 1.657 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.143 (1.109) - Batch(s): 5.172 
(3.244) - AE Loss: 153777.250 (566742.312) - AE Rec Loss: 1.043 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <286/2280>] - Data(s): 0.170 (1.109) - Batch(s): 5.172 
(3.244) - AE Loss: 217795.391 (566742.312) - AE Rec Loss: 1.477 (3.843) - Disc 
Loss: 0.000 (0.000) - 2.39 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.563 
(2.861) - AE Loss: 537687.375 (567767.875) - AE Rec Loss: 3.646 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.564 
(2.861) - AE Loss: 72236.766 (567767.875) - AE Rec Loss: 0.490 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.564 
(2.861) - AE Loss: 128598.445 (567767.875) - AE Rec Loss: 0.872 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.001 (0.951) - Batch(s): 0.565 
(2.861) - AE Loss: 439311.875 (567767.875) - AE Rec Loss: 2.979 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.552 
(2.861) - AE Loss: 630732.375 (567767.875) - AE Rec Loss: 4.277 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.50 m remaining

[Epoch <000/100>: Step <287/2280>] - Data(s): 0.000 (0.951) - Batch(s): 0.572 
(2.861) - AE Loss: 109709.594 (567767.875) - AE Rec Loss: 0.744 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.552 
(2.574) - AE Loss: 243638.922 (584279.062) - AE Rec Loss: 1.652 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.563 
(2.574) - AE Loss: 841153.000 (584279.062) - AE Rec Loss: 5.704 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.564 
(2.574) - AE Loss: 1389857.250 (584279.062) - AE Rec Loss: 9.426 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.58 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.564 
(2.574) - AE Loss: 1442176.375 (584279.062) - AE Rec Loss: 9.780 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.565 
(2.574) - AE Loss: 101858.266 (584279.062) - AE Rec Loss: 0.691 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <288/2280>] - Data(s): 0.000 (0.832) - Batch(s): 0.571 
(2.574) - AE Loss: 1380211.250 (584279.062) - AE Rec Loss: 9.360 (3.962) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.871 
(2.496) - AE Loss: 186272.469 (613009.875) - AE Rec Loss: 1.263 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.870 
(2.496) - AE Loss: 869274.250 (613009.875) - AE Rec Loss: 5.895 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.871 
(2.496) - AE Loss: 1523303.250 (613009.875) - AE Rec Loss: 10.331 (4.157) - Disc
Loss: 0.000 (0.000) - 2.79 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.872 
(2.496) - AE Loss: 99287.273 (613009.875) - AE Rec Loss: 0.673 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.80 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.000 (0.759) - Batch(s): 1.873 
(2.496) - AE Loss: 2905023.500 (613009.875) - AE Rec Loss: 19.701 (4.157) - Disc
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <289/2280>] - Data(s): 0.954 (0.759) - Batch(s): 1.873 
(2.496) - AE Loss: 58860.750 (613009.875) - AE Rec Loss: 0.399 (4.157) - Disc 
Loss: 0.000 (0.000) - 2.80 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 1.155 
(2.345) - AE Loss: 221346.031 (608342.438) - AE Rec Loss: 1.501 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 1.165 
(2.345) - AE Loss: 205131.422 (608342.438) - AE Rec Loss: 1.391 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.603 (0.688) - Batch(s): 1.169 
(2.345) - AE Loss: 1499654.500 (608342.438) - AE Rec Loss: 10.170 (4.126) - Disc
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 1.167 
(2.345) - AE Loss: 1669815.500 (608342.438) - AE Rec Loss: 11.324 (4.126) - Disc
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 1.168 
(2.345) - AE Loss: 148681.656 (608342.438) - AE Rec Loss: 1.008 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.94 m remaining

[Epoch <000/100>: Step <290/2280>] - Data(s): 0.000 (0.688) - Batch(s): 1.172 
(2.345) - AE Loss: 191432.078 (608342.438) - AE Rec Loss: 1.298 (4.126) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.199 
(2.236) - AE Loss: 1499675.000 (584593.500) - AE Rec Loss: 10.170 (3.965) - Disc
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.199 
(2.236) - AE Loss: 211128.672 (584593.500) - AE Rec Loss: 1.432 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.199 
(2.236) - AE Loss: 633653.125 (584593.500) - AE Rec Loss: 4.297 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.200 
(2.236) - AE Loss: 271193.844 (584593.500) - AE Rec Loss: 1.839 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.187 
(2.236) - AE Loss: 99348.320 (584593.500) - AE Rec Loss: 0.674 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.08 m remaining

[Epoch <000/100>: Step <291/2280>] - Data(s): 0.000 (0.626) - Batch(s): 1.203 
(2.236) - AE Loss: 140999.984 (584593.500) - AE Rec Loss: 0.956 (3.965) - Disc 
Loss: 0.000 (0.000) - 3.05 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.079 
(2.140) - AE Loss: 319371.469 (578744.312) - AE Rec Loss: 2.166 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.079 
(2.140) - AE Loss: 1761154.000 (578744.312) - AE Rec Loss: 11.944 (3.925) - Disc
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 63800.039 (578744.312) - AE Rec Loss: 0.433 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 222759.203 (578744.312) - AE Rec Loss: 1.511 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.081 
(2.140) - AE Loss: 112962.680 (578744.312) - AE Rec Loss: 0.766 (3.925) - Disc 
Loss: 0.000 (0.000) - 3.21 m remaining

[Epoch <000/100>: Step <292/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.080 
(2.140) - AE Loss: 1508925.000 (578744.312) - AE Rec Loss: 10.233 (3.925) - Disc
Loss: 0.000 (0.000) - 3.18 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.911 
(2.570) - AE Loss: 442728.719 (572109.875) - AE Rec Loss: 3.002 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 7.339 (0.579) - Batch(s): 7.914 
(2.570) - AE Loss: 186763.391 (572109.875) - AE Rec Loss: 1.267 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.579) - Batch(s): 7.912 
(2.570) - AE Loss: 190610.922 (572109.875) - AE Rec Loss: 1.293 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.10 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.579) - Batch(s): 7.917 
(2.570) - AE Loss: 357292.969 (572109.875) - AE Rec Loss: 2.423 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.000 (0.579) - Batch(s): 7.912 
(2.570) - AE Loss: 3107181.000 (572109.875) - AE Rec Loss: 21.072 (3.880) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <293/2280>] - Data(s): 0.001 (0.579) - Batch(s): 7.900 
(2.570) - AE Loss: 151324.141 (572109.875) - AE Rec Loss: 1.026 (3.880) - Disc 
Loss: 0.000 (0.000) - 4.11 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.573 
(2.427) - AE Loss: 187157.531 (572737.625) - AE Rec Loss: 1.269 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.565 
(2.427) - AE Loss: 65186.145 (572737.625) - AE Rec Loss: 0.442 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.565 
(2.427) - AE Loss: 2945097.250 (572737.625) - AE Rec Loss: 19.973 (3.884) - Disc
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.565 
(2.427) - AE Loss: 307831.062 (572737.625) - AE Rec Loss: 2.088 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.14 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.554 
(2.427) - AE Loss: 245328.359 (572737.625) - AE Rec Loss: 1.664 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <294/2280>] - Data(s): 0.000 (0.538) - Batch(s): 0.565 
(2.427) - AE Loss: 207379.516 (572737.625) - AE Rec Loss: 1.406 (3.884) - Disc 
Loss: 0.000 (0.000) - 4.17 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.723 
(2.313) - AE Loss: 205098.219 (594527.625) - AE Rec Loss: 1.391 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.724 
(2.313) - AE Loss: 376918.281 (594527.625) - AE Rec Loss: 2.556 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.25 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.725 
(2.313) - AE Loss: 1634900.750 (594527.625) - AE Rec Loss: 11.087 (4.032) - Disc
Loss: 0.000 (0.000) - 4.26 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.725 
(2.313) - AE Loss: 1710757.375 (594527.625) - AE Rec Loss: 11.602 (4.032) - Disc
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.725 
(2.313) - AE Loss: 125359.344 (594527.625) - AE Rec Loss: 0.850 (4.032) - Disc 
Loss: 0.000 (0.000) - 4.23 m remaining

[Epoch <000/100>: Step <295/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.725 
(2.313) - AE Loss: 1488844.000 (594527.625) - AE Rec Loss: 10.097 (4.032) - Disc
Loss: 0.000 (0.000) - 4.22 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 3.130 
(2.353) - AE Loss: 163639.844 (594817.562) - AE Rec Loss: 1.110 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 2.554 (0.484) - Batch(s): 3.134 
(2.353) - AE Loss: 510690.312 (594817.562) - AE Rec Loss: 3.463 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 3.134 
(2.353) - AE Loss: 411385.250 (594817.562) - AE Rec Loss: 2.790 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 3.129 
(2.353) - AE Loss: 2787361.500 (594817.562) - AE Rec Loss: 18.903 (4.034) - Disc
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.001 (0.484) - Batch(s): 3.119 
(2.353) - AE Loss: 340246.812 (594817.562) - AE Rec Loss: 2.307 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <296/2280>] - Data(s): 0.000 (0.484) - Batch(s): 3.131 
(2.353) - AE Loss: 341417.844 (594817.562) - AE Rec Loss: 2.315 (4.034) - Disc 
Loss: 0.000 (0.000) - 4.60 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.552 
(2.248) - AE Loss: 139244.531 (581634.250) - AE Rec Loss: 0.944 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.573 
(2.248) - AE Loss: 419374.312 (581634.250) - AE Rec Loss: 2.844 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.565 
(2.248) - AE Loss: 60532.266 (581634.250) - AE Rec Loss: 0.411 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.566 
(2.248) - AE Loss: 71402.570 (581634.250) - AE Rec Loss: 0.484 (3.944) - Disc 
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.565 
(2.248) - AE Loss: 1497560.750 (581634.250) - AE Rec Loss: 10.156 (3.944) - Disc
Loss: 0.000 (0.000) - 4.67 m remaining

[Epoch <000/100>: Step <297/2280>] - Data(s): 0.000 (0.455) - Batch(s): 0.564 
(2.248) - AE Loss: 1584726.500 (581634.250) - AE Rec Loss: 10.747 (3.944) - Disc
Loss: 0.000 (0.000) - 4.64 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 239366.109 (590970.312) - AE Rec Loss: 1.623 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.72 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.689 
(2.161) - AE Loss: 1454813.875 (590970.312) - AE Rec Loss: 9.866 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.75 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 314388.062 (590970.312) - AE Rec Loss: 2.132 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.71 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.687 
(2.161) - AE Loss: 1778261.625 (590970.312) - AE Rec Loss: 12.060 (4.008) - Disc
Loss: 0.000 (0.000) - 4.71 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.688 
(2.161) - AE Loss: 84880.828 (590970.312) - AE Rec Loss: 0.576 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <298/2280>] - Data(s): 0.000 (0.430) - Batch(s): 0.688 
(2.161) - AE Loss: 1404878.750 (590970.312) - AE Rec Loss: 9.527 (4.008) - Disc 
Loss: 0.000 (0.000) - 4.74 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.001 (0.410) - Batch(s): 1.114 
(2.097) - AE Loss: 294050.500 (578554.625) - AE Rec Loss: 1.994 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 1.129 
(2.097) - AE Loss: 330406.375 (578554.625) - AE Rec Loss: 2.241 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 1.126 
(2.097) - AE Loss: 127584.117 (578554.625) - AE Rec Loss: 0.865 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 1.123 
(2.097) - AE Loss: 1368933.500 (578554.625) - AE Rec Loss: 9.284 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.000 (0.410) - Batch(s): 1.125 
(2.097) - AE Loss: 244311.484 (578554.625) - AE Rec Loss: 1.657 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <299/2280>] - Data(s): 0.561 (0.410) - Batch(s): 1.127 
(2.097) - AE Loss: 61228.461 (578554.625) - AE Rec Loss: 0.415 (3.924) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.619 
(2.023) - AE Loss: 1703752.250 (589031.125) - AE Rec Loss: 11.554 (3.995) - Disc
Loss: 0.000 (0.000) - 4.90 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.604 
(2.023) - AE Loss: 565179.062 (589031.125) - AE Rec Loss: 3.833 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.616 
(2.023) - AE Loss: 1667759.125 (589031.125) - AE Rec Loss: 11.310 (3.995) - Disc
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.001 (0.390) - Batch(s): 0.615 
(2.023) - AE Loss: 182519.453 (589031.125) - AE Rec Loss: 1.238 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.93 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.614 
(2.023) - AE Loss: 2898128.500 (589031.125) - AE Rec Loss: 19.654 (3.995) - Disc
Loss: 0.000 (0.000) - 4.91 m remaining

[Epoch <000/100>: Step <300/2280>] - Data(s): 0.001 (0.390) - Batch(s): 0.616 
(2.023) - AE Loss: 102230.914 (589031.125) - AE Rec Loss: 0.693 (3.995) - Disc 
Loss: 0.000 (0.000) - 4.94 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.950 
(2.713) - AE Loss: 132229.562 (590586.562) - AE Rec Loss: 0.897 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.86 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 56521.609 (590586.562) - AE Rec Loss: 0.383 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.86 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 1442108.500 (590586.562) - AE Rec Loss: 9.780 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.86 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 1489961.750 (590586.562) - AE Rec Loss: 10.104 (4.005) - Disc
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.826 (0.374) - Batch(s): 17.949 
(2.713) - AE Loss: 54440.871 (590586.562) - AE Rec Loss: 0.369 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.90 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 0.000 (0.374) - Batch(s): 17.950 
(2.713) - AE Loss: 275509.969 (590586.562) - AE Rec Loss: 1.868 (4.005) - Disc 
Loss: 0.000 (0.000) - 6.89 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.565 
(2.615) - AE Loss: 426043.000 (583897.688) - AE Rec Loss: 2.889 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.566 
(2.615) - AE Loss: 1445907.500 (583897.688) - AE Rec Loss: 9.806 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.95 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.553 
(2.615) - AE Loss: 92630.406 (583897.688) - AE Rec Loss: 0.628 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.94 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.573 
(2.615) - AE Loss: 1692235.375 (583897.688) - AE Rec Loss: 11.476 (3.960) - Disc
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.565 
(2.615) - AE Loss: 104807.758 (583897.688) - AE Rec Loss: 0.711 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.94 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (0.357) - Batch(s): 0.566 
(2.615) - AE Loss: 418345.906 (583897.688) - AE Rec Loss: 2.837 (3.960) - Disc 
Loss: 0.000 (0.000) - 6.92 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.566 
(2.526) - AE Loss: 306019.344 (577881.188) - AE Rec Loss: 2.075 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.567 
(2.526) - AE Loss: 516836.719 (577881.188) - AE Rec Loss: 3.505 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.566 
(2.526) - AE Loss: 140420.969 (577881.188) - AE Rec Loss: 0.952 (3.919) - Disc 
Loss: 0.000 (0.000) - 7.00 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.555 
(2.526) - AE Loss: 57587.617 (577881.188) - AE Rec Loss: 0.391 (3.919) - Disc 
Loss: 0.000 (0.000) - 7.00 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.568 
(2.526) - AE Loss: 1600799.125 (577881.188) - AE Rec Loss: 10.856 (3.919) - Disc
Loss: 0.000 (0.000) - 7.00 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (0.342) - Batch(s): 0.573 
(2.526) - AE Loss: 82821.914 (577881.188) - AE Rec Loss: 0.562 (3.919) - Disc 
Loss: 0.000 (0.000) - 6.97 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 100728.430 (591933.875) - AE Rec Loss: 0.683 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.04 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 305945.125 (591933.875) - AE Rec Loss: 2.075 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.07 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 54906.352 (591933.875) - AE Rec Loss: 0.372 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 1897812.000 (591933.875) - AE Rec Loss: 12.870 (4.014) - Disc
Loss: 0.000 (0.000) - 7.03 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 118995.258 (591933.875) - AE Rec Loss: 0.807 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.06 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.693 
(2.449) - AE Loss: 1399139.500 (591933.875) - AE Rec Loss: 9.489 (4.014) - Disc 
Loss: 0.000 (0.000) - 7.03 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.566 
(2.374) - AE Loss: 158651.906 (593328.312) - AE Rec Loss: 1.076 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.554 
(2.374) - AE Loss: 1841545.500 (593328.312) - AE Rec Loss: 12.489 (4.024) - Disc
Loss: 0.000 (0.000) - 7.11 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.567 
(2.374) - AE Loss: 115537.117 (593328.312) - AE Rec Loss: 0.784 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.12 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.575 
(2.374) - AE Loss: 52629.723 (593328.312) - AE Rec Loss: 0.357 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.567 
(2.374) - AE Loss: 67034.422 (593328.312) - AE Rec Loss: 0.455 (4.024) - Disc 
Loss: 0.000 (0.000) - 7.09 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.566 
(2.374) - AE Loss: 1545745.750 (593328.312) - AE Rec Loss: 10.483 (4.024) - Disc
Loss: 0.000 (0.000) - 7.11 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.305) - AE Loss: 192134.406 (603193.000) - AE Rec Loss: 1.303 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.554 
(2.305) - AE Loss: 1782039.750 (603193.000) - AE Rec Loss: 12.085 (4.091) - Disc
Loss: 0.000 (0.000) - 7.17 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.574 
(2.305) - AE Loss: 484978.656 (603193.000) - AE Rec Loss: 3.289 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.566 
(2.305) - AE Loss: 205999.125 (603193.000) - AE Rec Loss: 1.397 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.566 
(2.305) - AE Loss: 110693.445 (603193.000) - AE Rec Loss: 0.751 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.16 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.567 
(2.305) - AE Loss: 90016.195 (603193.000) - AE Rec Loss: 0.610 (4.091) - Disc 
Loss: 0.000 (0.000) - 7.14 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.001 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 185217.859 (600451.562) - AE Rec Loss: 1.256 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.783 
(2.359) - AE Loss: 184589.344 (600451.562) - AE Rec Loss: 1.252 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.001 (0.301) - Batch(s): 3.783 
(2.359) - AE Loss: 1329420.500 (600451.562) - AE Rec Loss: 9.016 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.53 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.781 
(2.359) - AE Loss: 350011.062 (600451.562) - AE Rec Loss: 2.374 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.001 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 400075.875 (600451.562) - AE Rec Loss: 2.713 (4.072) - Disc 
Loss: 0.000 (0.000) - 7.56 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.301) - Batch(s): 3.782 
(2.359) - AE Loss: 1701077.500 (600451.562) - AE Rec Loss: 11.536 (4.072) - Disc
Loss: 0.000 (0.000) - 7.53 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:07:43,590[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,648[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,787[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,805[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,832[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:07:43,843[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:07:45,849[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:45,862[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:46,027[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:46,071[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:07:46,290[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:07:46,403[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:07:46,406[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 05:07:46,431[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:46,522[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:46,568[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:46,769[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:07:46,868[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 05:07:46,871[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:07:46,871[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
[[36m2023-11-29 05:07:46,878[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing opt_disc 
[[36m2023-11-29 05:07:46,880[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
[[36m2023-11-29 05:07:46,880[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
len(valid_dataloader) = 1
=> Preparing model 
=> Mixed precision: no
=> Mixed precision: no
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(train_dataset) = 54706
=> Preparing model 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
[[36m2023-11-29 05:07:46,884[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:09:15,386[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,480[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,510[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,739[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,759[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:09:15,772[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:09:17,635[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,682[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,778[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,986[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:09:17,994[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,075[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,191[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 05:09:18,245[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,301[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,446[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,519[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:09:18,665[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 05:09:18,666[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 05:09:18,668[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
[[36m2023-11-29 05:09:18,671[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating the optimizer 
len(train_dataset) = 54706
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
[[36m2023-11-29 05:09:18,673[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
=> Preparing model 
len(valid_dataloader) = 1
=> Mixed precision: no
=> Instantiating the optimizer 
=> Preparing opt_disc 
=> Running in inference mode: False
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
=> Preparing model 
=> Preparing opt_disc 
len(train_dataset) = 54706
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 05:09:18,677[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
[[36m2023-11-29 05:09:18,678[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Preparing opt_disc 
=> Instantiating the optimizer 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:16:52,407[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,507[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,612[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,632[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,718[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:16:52,832[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:16:54,704[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,726[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,805[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,812[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:54,933[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:16:55,019[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,197[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,270[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,313[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,356[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,503[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:16:55,528[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:16:55,528[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
[[36m2023-11-29 05:16:55,530[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 05:16:55,531[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
[[36m2023-11-29 05:16:55,531[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:16:55,531[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Mixed precision: no
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Preparing model 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
len(valid_dataset) = 4
=> Preparing model 
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing opt_disc 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Instantiating the optimizer 
[[36m2023-11-29 05:16:55,538[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
batch_size = 2, learning rate = 4.5e-06
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10Reached 1 on node 9

Reached 1.2 on node 10
Reached 1.2 on node 9
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 6Reached 1.3 on node 7

Reached 1.4 on node 7
Reached 1.4 on node 6
Reached 2 on node 7
Reached 2 on node 6
Reached 3 on node 7Reached 3 on node 6

Reached 5 on node 6
Reached 5 on node 7
Reached end on node 6
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
=> Preparing opt_ae 
Reached end on node 10
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 6
Reached 5 on node 6
Reached 3 on node 7Reached end on node 6

Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1 on node 7
Reached 1.2 on node 6
Reached 1.2 on node 7
Reached 1.25 on node 7
Reached 1.25 on node 6
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}

Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10Reached 1.3 on node 9

Reached 1.4 on node 9Reached 1.4 on node 10

Reached 1.3 on node 7Reached 2 on node 10Reached 1.3 on node 6

Reached 2 on node 9

Reached 1.4 on node 7
Reached 1.4 on node 6Reached 1.3 on node 8Reached 1.3 on node 11


Reached 2 on node 7Reached 3 on node 10Reached 1.4 on node 11Reached 1.4 on node 8Reached 2 on node 6

Reached 3 on node 9



Reached 2 on node 8Reached 5 on node 10
Reached 2 on node 11
Reached 5 on node 9

Reached 3 on node 7
Reached 3 on node 6Reached end on node 10
Reached end on node 9
Reached 3 on node 8Reached 5 on node 7

Reached 3 on node 11
Reached 5 on node 6

Reached 5 on node 8
Reached end on node 7Reached 5 on node 11
Reached end on node 6

Reached end on node 8
Reached end on node 11
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
Loaded checkpoint at epoch 0 and step 301
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 1.4 on node 7
Reached 2 on node 6
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1 on node 7Reached 1.4 on node 8

Reached 1.4 on node 6Reached 2 on node 8

Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 6
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 1.4 on node 7
Reached 2 on node 8
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6Reached 1 on node 8

Reached 1 on node 7
Reached 1.4 on node 6Reached 1.4 on node 8

Reached 2 on node 6Reached 2 on node 8Reached 1.4 on node 7


Reached 2 on node 7
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 1.4 on node 7Reached 2 on node 8

Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 1.4 on node 11
Reached 3 on node 9Reached 2 on node 11

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 1.4 on node 11Reached 2 on node 6Reached 1.4 on node 7


Reached 2 on node 11
Reached 2 on node 7
Reached 1 on node 9
Reached 1 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1 on node 7
Reached 1.4 on node 11
Reached 1.4 on node 7
Reached 2 on node 11
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 9
Reached end on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 8
Reached end on node 11
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <301/2280>] - Data(s): 2.632 (5.479) - Batch(s): 10.788 
(10.907) - AE Loss: 56177.270 (621691.438) - AE Rec Loss: 0.381 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.796 (5.479) - Batch(s): 10.813 
(10.907) - AE Loss: 1490140.500 (621691.438) - AE Rec Loss: 10.106 (4.216) - 
Disc Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 9.261 (5.479) - Batch(s): 10.824 
(10.907) - AE Loss: 53969.117 (621691.438) - AE Rec Loss: 0.366 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 4.488 (5.479) - Batch(s): 10.823 
(10.907) - AE Loss: 1441928.750 (621691.438) - AE Rec Loss: 9.779 (4.216) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.951 (5.479) - Batch(s): 10.818 
(10.907) - AE Loss: 132442.406 (621691.438) - AE Rec Loss: 0.898 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <301/2280>] - Data(s): 5.035 (5.479) - Batch(s): 10.807 
(10.907) - AE Loss: 275402.938 (621691.438) - AE Rec Loss: 1.868 (4.216) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.001 (2.740) - Batch(s): 0.563 
(5.735) - AE Loss: 428667.312 (535277.562) - AE Rec Loss: 2.907 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.568 
(5.735) - AE Loss: 1700508.750 (535277.562) - AE Rec Loss: 11.532 (3.630) - Disc
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.551 
(5.735) - AE Loss: 93704.094 (535277.562) - AE Rec Loss: 0.635 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.562 
(5.735) - AE Loss: 1450375.000 (535277.562) - AE Rec Loss: 9.836 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.565 
(5.735) - AE Loss: 428073.312 (535277.562) - AE Rec Loss: 2.903 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <302/2280>] - Data(s): 0.000 (2.740) - Batch(s): 0.562 
(5.735) - AE Loss: 108231.164 (535277.562) - AE Rec Loss: 0.734 (3.630) - Disc 
Loss: 0.000 (0.000) - 1.28 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <303/2280>] - Data(s): 0.603 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 530154.500 (507055.000) - AE Rec Loss: 3.595 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.436 
(4.636) - AE Loss: 58072.902 (507055.000) - AE Rec Loss: 0.394 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.438 
(4.636) - AE Loss: 1604566.500 (507055.000) - AE Rec Loss: 10.882 (3.439) - Disc
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.472 (1.905) - Batch(s): 2.439 
(4.636) - AE Loss: 313718.531 (507055.000) - AE Rec Loss: 2.128 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.438 
(4.636) - AE Loss: 85095.867 (507055.000) - AE Rec Loss: 0.577 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <303/2280>] - Data(s): 0.000 (1.905) - Batch(s): 2.438 
(4.636) - AE Loss: 144360.000 (507055.000) - AE Rec Loss: 0.979 (3.439) - Disc 
Loss: 0.000 (0.000) - 1.56 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.564 
(3.618) - AE Loss: 306747.750 (609140.188) - AE Rec Loss: 2.080 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.565 
(3.618) - AE Loss: 1899827.625 (609140.188) - AE Rec Loss: 12.884 (4.131) - Disc
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.562 
(3.618) - AE Loss: 116787.695 (609140.188) - AE Rec Loss: 0.792 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.562 
(3.618) - AE Loss: 102029.711 (609140.188) - AE Rec Loss: 0.692 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.553 
(3.618) - AE Loss: 56742.363 (609140.188) - AE Rec Loss: 0.385 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <304/2280>] - Data(s): 0.000 (1.429) - Batch(s): 0.571 
(3.618) - AE Loss: 1398012.750 (609140.188) - AE Rec Loss: 9.481 (4.131) - Disc 
Loss: 0.000 (0.000) - 1.63 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.001 (1.159) - Batch(s): 1.524 
(3.193) - AE Loss: 62391.953 (612980.938) - AE Rec Loss: 0.423 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.001 (1.159) - Batch(s): 1.525 
(3.193) - AE Loss: 1556062.750 (612980.938) - AE Rec Loss: 10.553 (4.157) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.513 
(3.193) - AE Loss: 1845110.750 (612980.938) - AE Rec Loss: 12.513 (4.157) - Disc
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.525 
(3.193) - AE Loss: 114136.000 (612980.938) - AE Rec Loss: 0.774 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.001 (1.159) - Batch(s): 1.522 
(3.193) - AE Loss: 158086.500 (612980.938) - AE Rec Loss: 1.072 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <305/2280>] - Data(s): 0.000 (1.159) - Batch(s): 1.529 
(3.193) - AE Loss: 51886.797 (612980.938) - AE Rec Loss: 0.352 (4.157) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.661 
(2.938) - AE Loss: 189970.875 (652413.250) - AE Rec Loss: 1.288 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.662 
(2.938) - AE Loss: 93174.836 (652413.250) - AE Rec Loss: 0.632 (4.424) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.661 
(2.938) - AE Loss: 205032.031 (652413.250) - AE Rec Loss: 1.390 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.662 
(2.938) - AE Loss: 110038.945 (652413.250) - AE Rec Loss: 0.746 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.000 (0.993) - Batch(s): 1.663 
(2.938) - AE Loss: 1780660.250 (652413.250) - AE Rec Loss: 12.076 (4.424) - Disc
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <306/2280>] - Data(s): 0.999 (0.993) - Batch(s): 1.663 
(2.938) - AE Loss: 484781.250 (652413.250) - AE Rec Loss: 3.288 (4.424) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.564 
(2.599) - AE Loss: 183665.609 (635113.250) - AE Rec Loss: 1.246 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.565 
(2.599) - AE Loss: 397483.125 (635113.250) - AE Rec Loss: 2.696 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.571 
(2.599) - AE Loss: 1336342.750 (635113.250) - AE Rec Loss: 9.063 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.567 
(2.599) - AE Loss: 349486.531 (635113.250) - AE Rec Loss: 2.370 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.553 
(2.599) - AE Loss: 186654.469 (635113.250) - AE Rec Loss: 1.266 (4.307) - Disc 
Loss: 0.000 (0.000) - 2.07 m remaining

[Epoch <000/100>: Step <307/2280>] - Data(s): 0.000 (0.851) - Batch(s): 0.566 
(2.599) - AE Loss: 1701547.625 (635113.250) - AE Rec Loss: 11.539 (4.307) - Disc
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.552 
(2.345) - AE Loss: 121022.273 (605287.188) - AE Rec Loss: 0.821 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.001 (0.745) - Batch(s): 0.571 
(2.345) - AE Loss: 1645366.250 (605287.188) - AE Rec Loss: 11.158 (4.105) - Disc
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.563 
(2.345) - AE Loss: 78934.859 (605287.188) - AE Rec Loss: 0.535 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.564 
(2.345) - AE Loss: 96737.094 (605287.188) - AE Rec Loss: 0.656 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.565 
(2.345) - AE Loss: 137750.297 (605287.188) - AE Rec Loss: 0.934 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.13 m remaining

[Epoch <000/100>: Step <308/2280>] - Data(s): 0.000 (0.745) - Batch(s): 0.566 
(2.345) - AE Loss: 79870.906 (605287.188) - AE Rec Loss: 0.542 (4.105) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.000 (0.752) - Batch(s): 5.215 
(2.664) - AE Loss: 170123.516 (555707.750) - AE Rec Loss: 1.154 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.001 (0.752) - Batch(s): 5.215 
(2.664) - AE Loss: 102117.617 (555707.750) - AE Rec Loss: 0.693 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.001 (0.752) - Batch(s): 5.214 
(2.664) - AE Loss: 182691.359 (555707.750) - AE Rec Loss: 1.239 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.000 (0.752) - Batch(s): 5.213 
(2.664) - AE Loss: 246730.594 (555707.750) - AE Rec Loss: 1.673 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 0.001 (0.752) - Batch(s): 5.213 
(2.664) - AE Loss: 228570.266 (555707.750) - AE Rec Loss: 1.550 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <309/2280>] - Data(s): 2.000 (0.752) - Batch(s): 5.215 
(2.664) - AE Loss: 184972.594 (555707.750) - AE Rec Loss: 1.254 (3.769) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.553 
(2.454) - AE Loss: 548034.125 (568244.688) - AE Rec Loss: 3.717 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.77 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.572 
(2.454) - AE Loss: 103832.062 (568244.688) - AE Rec Loss: 0.704 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.564 
(2.454) - AE Loss: 88837.281 (568244.688) - AE Rec Loss: 0.602 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.566 
(2.454) - AE Loss: 679676.750 (568244.688) - AE Rec Loss: 4.609 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.567 
(2.454) - AE Loss: 1371136.250 (568244.688) - AE Rec Loss: 9.299 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <310/2280>] - Data(s): 0.000 (0.677) - Batch(s): 0.563 
(2.454) - AE Loss: 1431203.250 (568244.688) - AE Rec Loss: 9.706 (3.854) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.315 
(2.345) - AE Loss: 1763468.500 (561874.312) - AE Rec Loss: 11.959 (3.810) - Disc
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.326 
(2.345) - AE Loss: 106150.805 (561874.312) - AE Rec Loss: 0.720 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.326 
(2.345) - AE Loss: 349904.719 (561874.312) - AE Rec Loss: 2.373 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.323 
(2.345) - AE Loss: 570367.500 (561874.312) - AE Rec Loss: 3.868 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.331 
(2.345) - AE Loss: 79180.906 (561874.312) - AE Rec Loss: 0.537 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <311/2280>] - Data(s): 0.000 (0.615) - Batch(s): 1.326 
(2.345) - AE Loss: 150698.234 (561874.312) - AE Rec Loss: 1.022 (3.810) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.162 
(2.413) - AE Loss: 92100.695 (578382.688) - AE Rec Loss: 0.625 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.162 
(2.413) - AE Loss: 1605536.625 (578382.688) - AE Rec Loss: 10.888 (3.922) - Disc
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.163 
(2.413) - AE Loss: 58188.734 (578382.688) - AE Rec Loss: 0.395 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.162 
(2.413) - AE Loss: 405192.250 (578382.688) - AE Rec Loss: 2.748 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.162 
(2.413) - AE Loss: 1460233.250 (578382.688) - AE Rec Loss: 9.903 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.24 m remaining

[Epoch <000/100>: Step <312/2280>] - Data(s): 0.000 (0.586) - Batch(s): 3.164 
(2.413) - AE Loss: 60033.500 (578382.688) - AE Rec Loss: 0.407 (3.922) - Disc 
Loss: 0.000 (0.000) - 3.25 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.553 
(2.271) - AE Loss: 271723.406 (583027.375) - AE Rec Loss: 1.843 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.573 
(2.271) - AE Loss: 597163.688 (583027.375) - AE Rec Loss: 4.050 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.565 
(2.271) - AE Loss: 189478.578 (583027.375) - AE Rec Loss: 1.285 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.565 
(2.271) - AE Loss: 1857155.125 (583027.375) - AE Rec Loss: 12.595 (3.954) - Disc
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.564 
(2.271) - AE Loss: 215407.469 (583027.375) - AE Rec Loss: 1.461 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <313/2280>] - Data(s): 0.000 (0.541) - Batch(s): 0.564 
(2.271) - AE Loss: 307375.906 (583027.375) - AE Rec Loss: 2.085 (3.954) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.554 
(2.149) - AE Loss: 211529.375 (576240.125) - AE Rec Loss: 1.435 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.566 
(2.149) - AE Loss: 204320.641 (576240.125) - AE Rec Loss: 1.386 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.564 
(2.149) - AE Loss: 197944.391 (576240.125) - AE Rec Loss: 1.342 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.572 
(2.149) - AE Loss: 299206.188 (576240.125) - AE Rec Loss: 2.029 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.563 
(2.149) - AE Loss: 118083.953 (576240.125) - AE Rec Loss: 0.801 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <314/2280>] - Data(s): 0.000 (0.502) - Batch(s): 0.566 
(2.149) - AE Loss: 141545.531 (576240.125) - AE Rec Loss: 0.960 (3.908) - Disc 
Loss: 0.000 (0.000) - 3.38 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.865 
(2.130) - AE Loss: 75830.242 (586880.938) - AE Rec Loss: 0.514 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.000 (0.480) - Batch(s): 1.865 
(2.130) - AE Loss: 139347.312 (586880.938) - AE Rec Loss: 0.945 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.863 
(2.130) - AE Loss: 130076.312 (586880.938) - AE Rec Loss: 0.882 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.863 
(2.130) - AE Loss: 1482757.250 (586880.938) - AE Rec Loss: 10.056 (3.980) - Disc
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.865 
(2.130) - AE Loss: 103997.508 (586880.938) - AE Rec Loss: 0.705 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <315/2280>] - Data(s): 0.001 (0.480) - Batch(s): 1.865 
(2.130) - AE Loss: 166847.328 (586880.938) - AE Rec Loss: 1.132 (3.980) - Disc 
Loss: 0.000 (0.000) - 3.57 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.167 
(2.066) - AE Loss: 94293.930 (596921.000) - AE Rec Loss: 0.639 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.69 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.164 
(2.066) - AE Loss: 96502.555 (596921.000) - AE Rec Loss: 0.654 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.167 
(2.066) - AE Loss: 356725.625 (596921.000) - AE Rec Loss: 2.419 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.155 
(2.066) - AE Loss: 1337726.750 (596921.000) - AE Rec Loss: 9.072 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.171 
(2.066) - AE Loss: 1912802.875 (596921.000) - AE Rec Loss: 12.972 (4.048) - Disc
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <316/2280>] - Data(s): 0.000 (0.454) - Batch(s): 1.167 
(2.066) - AE Loss: 267892.938 (596921.000) - AE Rec Loss: 1.817 (4.048) - Disc 
Loss: 0.000 (0.000) - 3.70 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.990 
(2.105) - AE Loss: 67193.133 (594029.625) - AE Rec Loss: 0.456 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.635 
(2.105) - AE Loss: 211707.062 (594029.625) - AE Rec Loss: 1.436 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.995 
(2.105) - AE Loss: 284568.344 (594029.625) - AE Rec Loss: 1.930 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.636 
(2.105) - AE Loss: 65193.078 (594029.625) - AE Rec Loss: 0.442 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 0.000 (0.442) - Batch(s): 2.636 
(2.105) - AE Loss: 115808.508 (594029.625) - AE Rec Loss: 0.785 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <317/2280>] - Data(s): 2.417 (0.442) - Batch(s): 2.995 
(2.105) - AE Loss: 452516.562 (594029.625) - AE Rec Loss: 3.069 (4.029) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.000 (0.418) - Batch(s): 0.681 
(2.026) - AE Loss: 211879.531 (594256.688) - AE Rec Loss: 1.437 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.001 (0.418) - Batch(s): 0.679 
(2.026) - AE Loss: 97112.383 (594256.688) - AE Rec Loss: 0.659 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.000 (0.418) - Batch(s): 0.678 
(2.026) - AE Loss: 163107.469 (594256.688) - AE Rec Loss: 1.106 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.000 (0.418) - Batch(s): 0.679 
(2.026) - AE Loss: 247416.109 (594256.688) - AE Rec Loss: 1.678 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.000 (0.418) - Batch(s): 0.679 
(2.026) - AE Loss: 90509.375 (594256.688) - AE Rec Loss: 0.614 (4.030) - Disc 
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <318/2280>] - Data(s): 0.000 (0.418) - Batch(s): 0.679 
(2.026) - AE Loss: 2797294.500 (594256.688) - AE Rec Loss: 18.970 (4.030) - Disc
Loss: 0.000 (0.000) - 4.08 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.291 
(2.040) - AE Loss: 138502.641 (600663.875) - AE Rec Loss: 0.939 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.280 
(2.040) - AE Loss: 98441.141 (600663.875) - AE Rec Loss: 0.668 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.001 (0.411) - Batch(s): 2.292 
(2.040) - AE Loss: 51860.168 (600663.875) - AE Rec Loss: 0.352 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.31 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.292 
(2.040) - AE Loss: 54189.621 (600663.875) - AE Rec Loss: 0.367 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.296 
(2.040) - AE Loss: 248912.766 (600663.875) - AE Rec Loss: 1.688 (4.074) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <319/2280>] - Data(s): 0.000 (0.411) - Batch(s): 2.292 
(2.040) - AE Loss: 1649091.250 (600663.875) - AE Rec Loss: 11.184 (4.074) - Disc
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.001 (0.390) - Batch(s): 0.556 
(1.966) - AE Loss: 225070.047 (600587.062) - AE Rec Loss: 1.526 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.38 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.001 (0.390) - Batch(s): 0.566 
(1.966) - AE Loss: 1720648.250 (600587.062) - AE Rec Loss: 11.669 (4.073) - Disc
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.567 
(1.966) - AE Loss: 135021.797 (600587.062) - AE Rec Loss: 0.916 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.001 (0.390) - Batch(s): 0.566 
(1.966) - AE Loss: 61549.945 (600587.062) - AE Rec Loss: 0.417 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.573 
(1.966) - AE Loss: 62979.062 (600587.062) - AE Rec Loss: 0.427 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <320/2280>] - Data(s): 0.000 (0.390) - Batch(s): 0.568 
(1.966) - AE Loss: 114227.945 (600587.062) - AE Rec Loss: 0.775 (4.073) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.001 (0.372) - Batch(s): 12.060 
(2.401) - AE Loss: 324974.719 (614298.062) - AE Rec Loss: 2.204 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.59 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.060 
(2.401) - AE Loss: 1552690.250 (614298.062) - AE Rec Loss: 10.530 (4.166) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.060 
(2.401) - AE Loss: 48806.988 (614298.062) - AE Rec Loss: 0.331 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.060 
(2.401) - AE Loss: 159407.219 (614298.062) - AE Rec Loss: 1.081 (4.166) - Disc 
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 1624483.750 (614298.062) - AE Rec Loss: 11.017 (4.166) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 0.000 (0.372) - Batch(s): 12.059 
(2.401) - AE Loss: 2467070.750 (614298.062) - AE Rec Loss: 16.731 (4.166) - Disc
Loss: 0.000 (0.000) - 5.60 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.554 
(2.318) - AE Loss: 554386.625 (602571.188) - AE Rec Loss: 3.760 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.564 
(2.318) - AE Loss: 262812.500 (602571.188) - AE Rec Loss: 1.782 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.566 
(2.318) - AE Loss: 1724796.250 (602571.188) - AE Rec Loss: 11.697 (4.086) - Disc
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.567 
(2.318) - AE Loss: 140518.500 (602571.188) - AE Rec Loss: 0.953 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.574 
(2.318) - AE Loss: 288665.188 (602571.188) - AE Rec Loss: 1.958 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (0.355) - Batch(s): 0.566 
(2.318) - AE Loss: 167315.688 (602571.188) - AE Rec Loss: 1.135 (4.086) - Disc 
Loss: 0.000 (0.000) - 5.65 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.565 
(2.242) - AE Loss: 159569.578 (608967.875) - AE Rec Loss: 1.082 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.555 
(2.242) - AE Loss: 1497577.375 (608967.875) - AE Rec Loss: 10.156 (4.130) - Disc
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.567 
(2.242) - AE Loss: 249355.797 (608967.875) - AE Rec Loss: 1.691 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.572 
(2.242) - AE Loss: 88470.289 (608967.875) - AE Rec Loss: 0.600 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.566 
(2.242) - AE Loss: 2975491.750 (608967.875) - AE Rec Loss: 20.179 (4.130) - Disc
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (0.339) - Batch(s): 0.566 
(2.242) - AE Loss: 135668.688 (608967.875) - AE Rec Loss: 0.920 (4.130) - Disc 
Loss: 0.000 (0.000) - 5.70 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.673 
(2.177) - AE Loss: 196125.078 (600282.750) - AE Rec Loss: 1.330 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.674 
(2.177) - AE Loss: 495942.188 (600282.750) - AE Rec Loss: 3.363 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.001 (0.325) - Batch(s): 0.674 
(2.177) - AE Loss: 370078.594 (600282.750) - AE Rec Loss: 2.510 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.76 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.675 
(2.177) - AE Loss: 1438118.250 (600282.750) - AE Rec Loss: 9.753 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.675 
(2.177) - AE Loss: 107335.148 (600282.750) - AE Rec Loss: 0.728 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (0.325) - Batch(s): 0.675 
(2.177) - AE Loss: 80874.820 (600282.750) - AE Rec Loss: 0.548 (4.071) - Disc 
Loss: 0.000 (0.000) - 5.77 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.568 
(2.112) - AE Loss: 137278.531 (592112.000) - AE Rec Loss: 0.931 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.001 (0.312) - Batch(s): 0.573 
(2.112) - AE Loss: 162034.062 (592112.000) - AE Rec Loss: 1.099 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.567 
(2.112) - AE Loss: 248449.938 (592112.000) - AE Rec Loss: 1.685 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.566 
(2.112) - AE Loss: 64731.422 (592112.000) - AE Rec Loss: 0.439 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.001 (0.312) - Batch(s): 0.555 
(2.112) - AE Loss: 328312.188 (592112.000) - AE Rec Loss: 2.227 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.000 (0.312) - Batch(s): 0.567 
(2.112) - AE Loss: 159365.141 (592112.000) - AE Rec Loss: 1.081 (4.016) - Disc 
Loss: 0.000 (0.000) - 5.82 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.565 
(2.053) - AE Loss: 1513732.125 (610090.688) - AE Rec Loss: 10.266 (4.137) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (0.300) - Batch(s): 0.567 
(2.053) - AE Loss: 307003.500 (610090.688) - AE Rec Loss: 2.082 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.574 
(2.053) - AE Loss: 1462894.500 (610090.688) - AE Rec Loss: 9.921 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.567 
(2.053) - AE Loss: 1721015.500 (610090.688) - AE Rec Loss: 11.671 (4.137) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (0.300) - Batch(s): 0.568 
(2.053) - AE Loss: 3017799.500 (610090.688) - AE Rec Loss: 20.466 (4.137) - Disc
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (0.300) - Batch(s): 0.555 
(2.053) - AE Loss: 219405.094 (610090.688) - AE Rec Loss: 1.488 (4.137) - Disc 
Loss: 0.000 (0.000) - 5.87 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 115354.492 (602579.438) - AE Rec Loss: 0.782 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(2.003) - AE Loss: 90767.594 (602579.438) - AE Rec Loss: 0.616 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(2.003) - AE Loss: 113768.047 (602579.438) - AE Rec Loss: 0.772 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.704 
(2.003) - AE Loss: 149229.719 (602579.438) - AE Rec Loss: 1.012 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 119106.539 (602579.438) - AE Rec Loss: 0.808 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.94 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(2.003) - AE Loss: 240331.047 (602579.438) - AE Rec Loss: 1.630 (4.087) - Disc 
Loss: 0.000 (0.000) - 5.93 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.579 
(2.021) - AE Loss: 288653.594 (597892.188) - AE Rec Loss: 1.958 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.578 
(2.021) - AE Loss: 171995.250 (597892.188) - AE Rec Loss: 1.166 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.578 
(2.021) - AE Loss: 332568.344 (597892.188) - AE Rec Loss: 2.255 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.18 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.473 (0.295) - Batch(s): 2.576 
(2.021) - AE Loss: 243426.625 (597892.188) - AE Rec Loss: 1.651 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 1.289 (0.295) - Batch(s): 2.585 
(2.021) - AE Loss: 112602.570 (597892.188) - AE Rec Loss: 0.764 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.295) - Batch(s): 2.566 
(2.021) - AE Loss: 292664.250 (597892.188) - AE Rec Loss: 1.985 (4.055) - Disc 
Loss: 0.000 (0.000) - 6.19 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.001 (0.299) - Batch(s): 2.415 
(2.034) - AE Loss: 522320.406 (593295.500) - AE Rec Loss: 3.542 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.413 
(2.034) - AE Loss: 1422095.625 (593295.500) - AE Rec Loss: 9.644 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.759 (0.299) - Batch(s): 2.402 
(2.034) - AE Loss: 86719.320 (593295.500) - AE Rec Loss: 0.588 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.415 
(2.034) - AE Loss: 640069.250 (593295.500) - AE Rec Loss: 4.341 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 1.843 (0.299) - Batch(s): 2.420 
(2.034) - AE Loss: 99026.680 (593295.500) - AE Rec Loss: 0.672 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.299) - Batch(s): 2.421 
(2.034) - AE Loss: 187250.688 (593295.500) - AE Rec Loss: 1.270 (4.024) - Disc 
Loss: 0.000 (0.000) - 6.42 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 505394.812 (600443.438) - AE Rec Loss: 3.427 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.48 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.001 (0.289) - Batch(s): 0.706 
(1.990) - AE Loss: 261526.734 (600443.438) - AE Rec Loss: 1.774 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.48 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 1619803.750 (600443.438) - AE Rec Loss: 10.985 (4.072) - Disc
Loss: 0.000 (0.000) - 6.48 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(1.990) - AE Loss: 109928.023 (600443.438) - AE Rec Loss: 0.745 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.48 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.706 
(1.990) - AE Loss: 276594.062 (600443.438) - AE Rec Loss: 1.876 (4.072) - Disc 
Loss: 0.000 (0.000) - 6.48 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.289) - Batch(s): 0.705 
(1.990) - AE Loss: 3165721.500 (600443.438) - AE Rec Loss: 21.469 (4.072) - Disc
Loss: 0.000 (0.000) - 6.48 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
loaded pretrained LPIPS loss from .cache/vgg.pth
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:18:26,503[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,580[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,715[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,748[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,766[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:18:26,771[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:18:28,775[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,902[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,918[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,989[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:28,993[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:18:29,056[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:29,290[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:29,398[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:29,510[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:18:29,552[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:18:29,582[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 05:18:29,589[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 05:18:29,591[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:18:29,592[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:18:29,594[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Mixed precision: no
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
len(train_dataloader) = 2279
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
[[36m2023-11-29 05:18:29,598[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:18:29,598[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 05:18:29,599[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
=> Running in inference mode: False
=> Mixed precision: no
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Instantiating train dataloader 
=> Running in inference mode: False
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Preparing model 
=> Instantiating the optimizer 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_disc 
len(valid_dataset) = 4
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
=> Preparing opt_disc 
Reached end on node 6
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
=> Preparing model 
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
=> Preparing opt_ae 
Reached end on node 8
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 3 on node 9Reached 3 on node 6Reached 2 on node 11


Reached 5 on node 9
Reached end on node 9Reached 5 on node 6

Reached 3 on node 11
Reached end on node 6
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
Reached 3 on node 11
Reached 5 on node 11
Reached 3 on node 6
Reached end on node 11
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 3 on node 9
Reached 5 on node 9Reached 2 on node 10

Reached end on node 9
Reached 1.3 on node 11Reached 1.3 on node 7Reached 3 on node 10


Reached 1.4 on node 11Reached 1.4 on node 7

Reached 2 on node 7Reached 2 on node 11
Reached 5 on node 10

Reached 1.3 on node 8
Reached 1.4 on node 8Reached end on node 10

Reached 3 on node 11Reached 3 on node 7

Reached 2 on node 8
Reached 5 on node 11Reached 5 on node 7

Reached end on node 7Reached end on node 11

Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
Loaded checkpoint at epoch 0 and step 321
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7Reached 1 on node 8

Reached 1.4 on node 7
Reached 1.4 on node 8Reached 2 on node 7

Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7Reached 1 on node 9

Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 1 on node 6
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1.4 on node 11Reached 2 on node 7
Reached 1 on node 8

Reached 2 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 9
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 1.4 on node 9Reached 2 on node 6

Reached 2 on node 9
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 7
Reached 1 on node 11Reached 1.4 on node 7

Reached 2 on node 7
Reached 3 on node 7
Reached 1 on node 8Reached 3 on node 7Reached 1.4 on node 11


Reached 3 on node 7Reached 2 on node 11

Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 8Reached 5 on node 7

Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 1 on node 8Reached 2 on node 11

Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9Reached 1 on node 10

Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached end on node 6
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached 1 on node 9Reached end on node 7

Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 8
Reached end on node 10
Reached end on node 11
Reached end on node 9
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6Reached 1 on node 11

Reached 1.4 on node 11Reached 1.4 on node 6

Reached 2 on node 11Reached 2 on node 6

Reached 1 on node 6
Reached 1 on node 11
Reached 1.4 on node 6
Reached 1.4 on node 11
Reached 2 on node 6
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 7
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 11
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <321/2280>] - Data(s): 5.991 (5.836) - Batch(s): 10.084 
(10.296) - AE Loss: 1552441.125 (888465.250) - AE Rec Loss: 10.528 (6.025) - 
Disc Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 7.507 (5.836) - Batch(s): 10.103 
(10.296) - AE Loss: 2466679.500 (888465.250) - AE Rec Loss: 16.728 (6.025) - 
Disc Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 3.091 (5.836) - Batch(s): 10.079 
(10.296) - AE Loss: 48678.633 (888465.250) - AE Rec Loss: 0.330 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 3.906 (5.836) - Batch(s): 10.102 
(10.296) - AE Loss: 159309.250 (888465.250) - AE Rec Loss: 1.080 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 8.585 (5.836) - Batch(s): 10.079 
(10.296) - AE Loss: 1625576.500 (888465.250) - AE Rec Loss: 11.024 (6.025) - 
Disc Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <321/2280>] - Data(s): 6.587 (5.836) - Batch(s): 10.085 
(10.296) - AE Loss: 325056.969 (888465.250) - AE Rec Loss: 2.204 (6.025) - Disc 
Loss: 0.000 (0.000) - 1.05 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.565 
(5.431) - AE Loss: 168665.812 (622701.250) - AE Rec Loss: 1.144 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.554 
(5.431) - AE Loss: 553471.688 (622701.250) - AE Rec Loss: 3.753 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.572 
(5.431) - AE Loss: 290689.250 (622701.250) - AE Rec Loss: 1.971 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.565 
(5.431) - AE Loss: 269480.688 (622701.250) - AE Rec Loss: 1.828 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.568 
(5.431) - AE Loss: 137747.844 (622701.250) - AE Rec Loss: 0.934 (4.223) - Disc 
Loss: 0.000 (0.000) - 1.12 m remaining

[Epoch <000/100>: Step <322/2280>] - Data(s): 0.000 (2.918) - Batch(s): 0.567 
(5.431) - AE Loss: 1729953.250 (622701.250) - AE Rec Loss: 11.732 (4.223) - Disc
Loss: 0.000 (0.000) - 1.12 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 250914.875 (665745.812) - AE Rec Loss: 1.702 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.720 
(3.860) - AE Loss: 1500209.500 (665745.812) - AE Rec Loss: 10.174 (4.515) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.720 
(3.860) - AE Loss: 2977914.500 (665745.812) - AE Rec Loss: 20.195 (4.515) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.720 
(3.860) - AE Loss: 96871.523 (665745.812) - AE Rec Loss: 0.657 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 132281.109 (665745.812) - AE Rec Loss: 0.897 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <323/2280>] - Data(s): 0.000 (1.948) - Batch(s): 0.721 
(3.860) - AE Loss: 156348.969 (665745.812) - AE Rec Loss: 1.060 (4.515) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.568 
(3.037) - AE Loss: 85433.695 (600571.938) - AE Rec Loss: 0.579 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.566 
(3.037) - AE Loss: 1444202.000 (600571.938) - AE Rec Loss: 9.794 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.554 
(3.037) - AE Loss: 488730.094 (600571.938) - AE Rec Loss: 3.314 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.564 
(3.037) - AE Loss: 211836.656 (600571.938) - AE Rec Loss: 1.437 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.566 
(3.037) - AE Loss: 375756.000 (600571.938) - AE Rec Loss: 2.548 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <324/2280>] - Data(s): 0.000 (1.461) - Batch(s): 0.573 
(3.037) - AE Loss: 110905.250 (600571.938) - AE Rec Loss: 0.752 (4.073) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 1.136 (1.210) - Batch(s): 1.699 
(2.728) - AE Loss: 49183.938 (559399.125) - AE Rec Loss: 0.334 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 1.021 (1.210) - Batch(s): 1.586 
(2.728) - AE Loss: 128752.797 (559399.125) - AE Rec Loss: 0.873 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.001 (1.210) - Batch(s): 1.585 
(2.728) - AE Loss: 243640.141 (559399.125) - AE Rec Loss: 1.652 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.299 (1.210) - Batch(s): 1.573 
(2.728) - AE Loss: 331352.625 (559399.125) - AE Rec Loss: 2.247 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.001 (1.210) - Batch(s): 1.703 
(2.728) - AE Loss: 167722.500 (559399.125) - AE Rec Loss: 1.137 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <325/2280>] - Data(s): 0.001 (1.210) - Batch(s): 1.696 
(2.728) - AE Loss: 170203.516 (559399.125) - AE Rec Loss: 1.154 (3.794) - Disc 
Loss: 0.000 (0.000) - 1.46 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.446 
(2.514) - AE Loss: 3019613.250 (643439.750) - AE Rec Loss: 20.478 (4.364) - Disc
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.445 
(2.514) - AE Loss: 309530.500 (643439.750) - AE Rec Loss: 2.099 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.828 (1.021) - Batch(s): 1.445 
(2.514) - AE Loss: 1465882.875 (643439.750) - AE Rec Loss: 9.941 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.000 (1.021) - Batch(s): 1.445 
(2.514) - AE Loss: 1522911.500 (643439.750) - AE Rec Loss: 10.328 (4.364) - Disc
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.446 
(2.514) - AE Loss: 1731485.250 (643439.750) - AE Rec Loss: 11.742 (4.364) - Disc
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <326/2280>] - Data(s): 0.001 (1.021) - Batch(s): 1.446 
(2.514) - AE Loss: 217830.062 (643439.750) - AE Rec Loss: 1.477 (4.364) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.679 
(2.250) - AE Loss: 228262.516 (609344.312) - AE Rec Loss: 1.548 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.679 
(2.250) - AE Loss: 111212.883 (609344.312) - AE Rec Loss: 0.754 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.679 
(2.250) - AE Loss: 115136.367 (609344.312) - AE Rec Loss: 0.781 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.667 
(2.250) - AE Loss: 145390.078 (609344.312) - AE Rec Loss: 0.986 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.675 
(2.250) - AE Loss: 78070.375 (609344.312) - AE Rec Loss: 0.529 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <327/2280>] - Data(s): 0.001 (0.876) - Batch(s): 0.682 
(2.250) - AE Loss: 106480.141 (609344.312) - AE Rec Loss: 0.722 (4.132) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.737 
(2.058) - AE Loss: 170239.766 (591716.500) - AE Rec Loss: 1.155 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.738 
(2.058) - AE Loss: 325837.812 (591716.500) - AE Rec Loss: 2.210 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.725 
(2.058) - AE Loss: 287101.219 (591716.500) - AE Rec Loss: 1.947 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.738 
(2.058) - AE Loss: 277487.625 (591716.500) - AE Rec Loss: 1.882 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.000 (0.769) - Batch(s): 0.736 
(2.058) - AE Loss: 239428.531 (591716.500) - AE Rec Loss: 1.624 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <328/2280>] - Data(s): 0.001 (0.769) - Batch(s): 0.741 
(2.058) - AE Loss: 109327.875 (591716.500) - AE Rec Loss: 0.741 (4.013) - Disc 
Loss: 0.000 (0.000) - 1.77 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 1.194 (0.775) - Batch(s): 5.679 
(2.460) - AE Loss: 98352.102 (577525.812) - AE Rec Loss: 0.667 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.775) - Batch(s): 5.680 
(2.460) - AE Loss: 84728.164 (577525.812) - AE Rec Loss: 0.575 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 2.640 (0.775) - Batch(s): 5.682 
(2.460) - AE Loss: 180324.875 (577525.812) - AE Rec Loss: 1.223 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.001 (0.775) - Batch(s): 5.682 
(2.460) - AE Loss: 522868.469 (577525.812) - AE Rec Loss: 3.546 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.000 (0.775) - Batch(s): 5.679 
(2.460) - AE Loss: 1425145.750 (577525.812) - AE Rec Loss: 9.665 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <329/2280>] - Data(s): 0.001 (0.775) - Batch(s): 5.681 
(2.460) - AE Loss: 643523.250 (577525.812) - AE Rec Loss: 4.364 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.568 
(2.271) - AE Loss: 109869.922 (600816.688) - AE Rec Loss: 0.745 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.568 
(2.271) - AE Loss: 3165567.500 (600816.688) - AE Rec Loss: 21.468 (4.075) - Disc
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.565 
(2.271) - AE Loss: 516744.625 (600816.688) - AE Rec Loss: 3.504 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.554 
(2.271) - AE Loss: 1625060.500 (600816.688) - AE Rec Loss: 11.021 (4.075) - Disc
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.565 
(2.271) - AE Loss: 264873.500 (600816.688) - AE Rec Loss: 1.796 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <330/2280>] - Data(s): 0.000 (0.698) - Batch(s): 0.573 
(2.271) - AE Loss: 282202.844 (600816.688) - AE Rec Loss: 1.914 (4.075) - Disc 
Loss: 0.000 (0.000) - 2.40 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.001 (0.634) - Batch(s): 1.349 
(2.181) - AE Loss: 374464.625 (598338.188) - AE Rec Loss: 2.540 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.337 
(2.181) - AE Loss: 1646778.250 (598338.188) - AE Rec Loss: 11.168 (4.058) - Disc
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.348 
(2.181) - AE Loss: 208291.016 (598338.188) - AE Rec Loss: 1.413 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.350 
(2.181) - AE Loss: 1611463.250 (598338.188) - AE Rec Loss: 10.928 (4.058) - Disc
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.000 (0.634) - Batch(s): 1.350 
(2.181) - AE Loss: 1434207.375 (598338.188) - AE Rec Loss: 9.726 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <331/2280>] - Data(s): 0.001 (0.634) - Batch(s): 1.355 
(2.181) - AE Loss: 323344.906 (598338.188) - AE Rec Loss: 2.193 (4.058) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.001 (0.584) - Batch(s): 1.048 
(2.087) - AE Loss: 225837.078 (635582.750) - AE Rec Loss: 1.532 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.046 
(2.087) - AE Loss: 204263.156 (635582.750) - AE Rec Loss: 1.385 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.048 
(2.087) - AE Loss: 1367612.000 (635582.750) - AE Rec Loss: 9.275 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.048 
(2.087) - AE Loss: 272909.000 (635582.750) - AE Rec Loss: 1.851 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.047 
(2.087) - AE Loss: 1836351.625 (635582.750) - AE Rec Loss: 12.454 (4.310) - Disc
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <332/2280>] - Data(s): 0.000 (0.584) - Batch(s): 1.047 
(2.087) - AE Loss: 117597.289 (635582.750) - AE Rec Loss: 0.798 (4.310) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.570 
(1.970) - AE Loss: 634493.125 (613824.125) - AE Rec Loss: 4.303 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.567 
(1.970) - AE Loss: 136938.859 (613824.125) - AE Rec Loss: 0.929 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.574 
(1.970) - AE Loss: 341040.906 (613824.125) - AE Rec Loss: 2.313 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.568 
(1.970) - AE Loss: 51182.684 (613824.125) - AE Rec Loss: 0.347 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.555 
(1.970) - AE Loss: 266634.250 (613824.125) - AE Rec Loss: 1.808 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <333/2280>] - Data(s): 0.000 (0.539) - Batch(s): 0.568 
(1.970) - AE Loss: 218638.016 (613824.125) - AE Rec Loss: 1.483 (4.163) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.908 
(2.037) - AE Loss: 289958.469 (608413.500) - AE Rec Loss: 1.966 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.907 
(2.037) - AE Loss: 224933.609 (608413.500) - AE Rec Loss: 1.525 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.894 
(2.037) - AE Loss: 317273.156 (608413.500) - AE Rec Loss: 2.152 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.906 
(2.037) - AE Loss: 55480.672 (608413.500) - AE Rec Loss: 0.376 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.000 (0.523) - Batch(s): 2.904 
(2.037) - AE Loss: 1489870.750 (608413.500) - AE Rec Loss: 10.104 (4.126) - Disc
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <334/2280>] - Data(s): 0.766 (0.523) - Batch(s): 2.913 
(2.037) - AE Loss: 62171.742 (608413.500) - AE Rec Loss: 0.422 (4.126) - Disc 
Loss: 0.000 (0.000) - 3.00 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 533374.125 (613318.625) - AE Rec Loss: 3.617 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.001 (0.506) - Batch(s): 3.771 
(2.152) - AE Loss: 66757.594 (613318.625) - AE Rec Loss: 0.453 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.001 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 456045.625 (613318.625) - AE Rec Loss: 3.093 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.771 
(2.152) - AE Loss: 94180.258 (613318.625) - AE Rec Loss: 0.639 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 3.145 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 121249.625 (613318.625) - AE Rec Loss: 0.822 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <335/2280>] - Data(s): 0.000 (0.506) - Batch(s): 3.770 
(2.152) - AE Loss: 66227.422 (613318.625) - AE Rec Loss: 0.449 (4.159) - Disc 
Loss: 0.000 (0.000) - 3.37 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.567 
(2.053) - AE Loss: 212506.453 (641446.688) - AE Rec Loss: 1.441 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.553 
(2.053) - AE Loss: 180910.531 (641446.688) - AE Rec Loss: 1.227 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.568 
(2.053) - AE Loss: 1399612.750 (641446.688) - AE Rec Loss: 9.492 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.567 
(2.053) - AE Loss: 2705859.000 (641446.688) - AE Rec Loss: 18.350 (4.350) - Disc
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.566 
(2.053) - AE Loss: 2823776.000 (641446.688) - AE Rec Loss: 19.150 (4.350) - Disc
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <336/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.574 
(2.053) - AE Loss: 107560.680 (641446.688) - AE Rec Loss: 0.729 (4.350) - Disc 
Loss: 0.000 (0.000) - 3.43 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.568 
(1.966) - AE Loss: 41287.012 (639905.312) - AE Rec Loss: 0.280 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.574 
(1.966) - AE Loss: 1413722.500 (639905.312) - AE Rec Loss: 9.587 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.567 
(1.966) - AE Loss: 1375287.625 (639905.312) - AE Rec Loss: 9.327 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.566 
(1.966) - AE Loss: 1810726.250 (639905.312) - AE Rec Loss: 12.280 (4.340) - Disc
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.556 
(1.966) - AE Loss: 115229.617 (639905.312) - AE Rec Loss: 0.781 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <337/2280>] - Data(s): 0.000 (0.447) - Batch(s): 0.568 
(1.966) - AE Loss: 48308.547 (639905.312) - AE Rec Loss: 0.328 (4.340) - Disc 
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.291 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 1346272.375 (633713.938) - AE Rec Loss: 9.130 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 498086.562 (633713.938) - AE Rec Loss: 3.378 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.192 
(2.089) - AE Loss: 104477.133 (633713.938) - AE Rec Loss: 0.709 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 244982.078 (633713.938) - AE Rec Loss: 1.661 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 0.000 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 103413.930 (633713.938) - AE Rec Loss: 0.701 (4.298) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <338/2280>] - Data(s): 3.566 (0.440) - Batch(s): 4.191 
(2.089) - AE Loss: 1601194.250 (633713.938) - AE Rec Loss: 10.859 (4.298) - Disc
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.574 
(2.009) - AE Loss: 1493759.250 (627740.562) - AE Rec Loss: 10.130 (4.257) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.567 
(2.009) - AE Loss: 1677999.625 (627740.562) - AE Rec Loss: 11.380 (4.257) - Disc
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.555 
(2.009) - AE Loss: 381035.375 (627740.562) - AE Rec Loss: 2.584 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.566 
(2.009) - AE Loss: 127669.883 (627740.562) - AE Rec Loss: 0.866 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.569 
(2.009) - AE Loss: 99347.648 (627740.562) - AE Rec Loss: 0.674 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <339/2280>] - Data(s): 0.000 (0.417) - Batch(s): 0.567 
(2.009) - AE Loss: 100600.305 (627740.562) - AE Rec Loss: 0.682 (4.257) - Disc 
Loss: 0.000 (0.000) - 3.95 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.602 
(2.031) - AE Loss: 1632616.375 (630035.438) - AE Rec Loss: 11.072 (4.273) - Disc
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.001 (0.404) - Batch(s): 2.601 
(2.031) - AE Loss: 97037.781 (630035.438) - AE Rec Loss: 0.658 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.001 (0.404) - Batch(s): 2.600 
(2.031) - AE Loss: 169021.250 (630035.438) - AE Rec Loss: 1.146 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.608 
(2.031) - AE Loss: 127316.836 (630035.438) - AE Rec Loss: 0.863 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.588 
(2.031) - AE Loss: 285783.281 (630035.438) - AE Rec Loss: 1.938 (4.273) - Disc 
Loss: 0.000 (0.000) - 4.19 m remaining

[Epoch <000/100>: Step <340/2280>] - Data(s): 0.000 (0.404) - Batch(s): 2.600 
(2.031) - AE Loss: 1613778.500 (630035.438) - AE Rec Loss: 10.944 (4.273) - Disc
Loss: 0.000 (0.000) - 4.20 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.839 
(2.759) - AE Loss: 228749.438 (635335.750) - AE Rec Loss: 1.551 (4.309) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.837 
(2.759) - AE Loss: 329361.844 (635335.750) - AE Rec Loss: 2.234 (4.309) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.837 
(2.759) - AE Loss: 85829.898 (635335.750) - AE Rec Loss: 0.582 (4.309) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.839 
(2.759) - AE Loss: 147889.969 (635335.750) - AE Rec Loss: 1.003 (4.309) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 2.908 (0.397) - Batch(s): 18.838 
(2.759) - AE Loss: 47710.230 (635335.750) - AE Rec Loss: 0.324 (4.309) - Disc 
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 0.000 (0.397) - Batch(s): 18.837 
(2.759) - AE Loss: 1793367.125 (635335.750) - AE Rec Loss: 12.162 (4.309) - Disc
Loss: 0.000 (0.000) - 5.98 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.554 
(2.660) - AE Loss: 128976.992 (633998.562) - AE Rec Loss: 0.875 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.573 
(2.660) - AE Loss: 148906.578 (633998.562) - AE Rec Loss: 1.010 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.569 
(2.660) - AE Loss: 1381423.375 (633998.562) - AE Rec Loss: 9.368 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.566 
(2.660) - AE Loss: 214741.609 (633998.562) - AE Rec Loss: 1.456 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.566 
(2.660) - AE Loss: 1443223.625 (633998.562) - AE Rec Loss: 9.787 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (0.379) - Batch(s): 0.568 
(2.660) - AE Loss: 83365.141 (633998.562) - AE Rec Loss: 0.565 (4.300) - Disc 
Loss: 0.000 (0.000) - 6.02 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.571 
(2.569) - AE Loss: 251678.234 (629817.812) - AE Rec Loss: 1.707 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.574 
(2.569) - AE Loss: 203012.391 (629817.812) - AE Rec Loss: 1.377 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.557 
(2.569) - AE Loss: 1645145.750 (629817.812) - AE Rec Loss: 11.157 (4.271) - Disc
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.568 
(2.569) - AE Loss: 129032.617 (629817.812) - AE Rec Loss: 0.875 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.569 
(2.569) - AE Loss: 129362.266 (629817.812) - AE Rec Loss: 0.877 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (0.362) - Batch(s): 0.568 
(2.569) - AE Loss: 181575.875 (629817.812) - AE Rec Loss: 1.231 (4.271) - Disc 
Loss: 0.000 (0.000) - 6.07 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.645 
(2.489) - AE Loss: 1548187.250 (619628.125) - AE Rec Loss: 10.499 (4.202) - Disc
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.645 
(2.489) - AE Loss: 133125.094 (619628.125) - AE Rec Loss: 0.903 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.12 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (0.347) - Batch(s): 0.645 
(2.489) - AE Loss: 162223.375 (619628.125) - AE Rec Loss: 1.100 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.645 
(2.489) - AE Loss: 1632424.000 (619628.125) - AE Rec Loss: 11.071 (4.202) - Disc
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.644 
(2.489) - AE Loss: 166158.688 (619628.125) - AE Rec Loss: 1.127 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (0.347) - Batch(s): 0.645 
(2.489) - AE Loss: 214464.172 (619628.125) - AE Rec Loss: 1.454 (4.202) - Disc 
Loss: 0.000 (0.000) - 6.13 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.567 
(2.412) - AE Loss: 79044.094 (611424.625) - AE Rec Loss: 0.536 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.573 
(2.412) - AE Loss: 227880.047 (611424.625) - AE Rec Loss: 1.545 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.574 
(2.412) - AE Loss: 222719.453 (611424.625) - AE Rec Loss: 1.510 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.557 
(2.412) - AE Loss: 109198.820 (611424.625) - AE Rec Loss: 0.741 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.569 
(2.412) - AE Loss: 137420.562 (611424.625) - AE Rec Loss: 0.932 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (0.333) - Batch(s): 0.569 
(2.412) - AE Loss: 442696.781 (611424.625) - AE Rec Loss: 3.002 (4.146) - Disc 
Loss: 0.000 (0.000) - 6.17 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.569 
(2.341) - AE Loss: 201489.781 (619839.875) - AE Rec Loss: 1.366 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.569 
(2.341) - AE Loss: 76123.938 (619839.875) - AE Rec Loss: 0.516 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.567 
(2.341) - AE Loss: 2811871.000 (619839.875) - AE Rec Loss: 19.069 (4.204) - Disc
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.570 
(2.341) - AE Loss: 298505.750 (619839.875) - AE Rec Loss: 2.024 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.574 
(2.341) - AE Loss: 228621.781 (619839.875) - AE Rec Loss: 1.550 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (0.320) - Batch(s): 0.556 
(2.341) - AE Loss: 1445708.000 (619839.875) - AE Rec Loss: 9.804 (4.204) - Disc 
Loss: 0.000 (0.000) - 6.22 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.663 
(2.279) - AE Loss: 1840657.750 (616913.250) - AE Rec Loss: 12.483 (4.184) - Disc
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.662 
(2.279) - AE Loss: 506938.969 (616913.250) - AE Rec Loss: 3.438 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.664 
(2.279) - AE Loss: 136053.469 (616913.250) - AE Rec Loss: 0.923 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.665 
(2.279) - AE Loss: 1441679.500 (616913.250) - AE Rec Loss: 9.777 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.27 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.001 (0.308) - Batch(s): 0.664 
(2.279) - AE Loss: 115389.594 (616913.250) - AE Rec Loss: 0.783 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.308) - Batch(s): 0.665 
(2.279) - AE Loss: 211051.891 (616913.250) - AE Rec Loss: 1.431 (4.184) - Disc 
Loss: 0.000 (0.000) - 6.28 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:19:59,875[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:19:59,886[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:20:00,167[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:20:00,168[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:20:00,179[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:20:00,223[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:20:02,158[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:02,167[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:02,399[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:02,400[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:02,462[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:20:02,523[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,654[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,686[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,918[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:02,968[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:03,024[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:20:03,037[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:20:03,040[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,040[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Instantiating train dataloader 
[[36m2023-11-29 05:20:03,041[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Running in inference mode: False
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
len(train_dataloader) = 2279
=> Preparing model 
=> Preparing opt_disc 
=> Instantiating valid dataloader 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing model 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 05:20:03,049[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,050[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:20:03,050[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
=> Mixed precision: no
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Running in inference mode: False
=> Preparing model 
=> Instantiating train dataloader 
=> Mixed precision: no
=> Mixed precision: no
len(train_dataset) = 54706
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing model 
=> Preparing model 
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1.3 on node 6
Reached 1.4 on node 6
=> Preparing opt_ae 
Reached 2 on node 6
Reached 3 on node 6
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 5 on node 6
Reached end on node 6Reached 2 on node 8

Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 3 on node 8
Reached 2 on node 7
Reached 5 on node 8
Reached end on node 8
Reached 3 on node 7
=> Preparing criterion 
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
Reached 1 on node 11devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}

Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 6Reached 1.3 on node 9Reached 1.3 on node 11


Reached 1.4 on node 9
Reached 1.4 on node 6Reached 1.4 on node 11

Reached 2 on node 9
Reached 2 on node 11Reached 2 on node 6

Reached 1.3 on node 8
Reached 1.3 on node 10Reached 3 on node 9Reached 1.4 on node 8


Reached 3 on node 11Reached 3 on node 6Reached 1.4 on node 10

Reached 5 on node 9Reached 2 on node 8


Reached 5 on node 11
Reached 5 on node 6
Reached 2 on node 10
Reached end on node 9Reached end on node 11

Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8Reached 3 on node 10

Reached end on node 8Reached 5 on node 10

Reached 1.3 on node 7
Reached 1.4 on node 7Reached end on node 10

Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
Loaded checkpoint at epoch 0 and step 341
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7Reached 1 on node 6

Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 8Reached 1 on node 6

Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 6
Reached 2 on node 6Reached 1.4 on node 8

Reached 2 on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 1 on node 7
Reached 2 on node 9Reached 1 on node 6

Reached 1 on node 8Reached 1.4 on node 7

Reached 2 on node 7Reached 1.4 on node 6

Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1 on node 6Reached 1.4 on node 9Reached 1 on node 7


Reached 2 on node 9
Reached 1.4 on node 11Reached 1 on node 8

Reached 1.4 on node 6Reached 2 on node 11Reached 1.4 on node 7


Reached 2 on node 6Reached 2 on node 7

Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 7
Reached 1.4 on node 9
Reached 1 on node 8Reached 2 on node 9

Reached 1 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8Reached 3 on node 7
Reached 1.4 on node 11

Reached 2 on node 8Reached 3 on node 7

Reached 2 on node 11
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1 on node 8
Reached 1.4 on node 11
Reached 1.4 on node 8Reached 2 on node 11

Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8Reached 1 on node 10

Reached 5 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9Reached 1 on node 11

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1.4 on node 11Reached 5 on node 9

Reached 2 on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10Reached end on node 6

Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 1 on node 8
Reached 1 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 8
Reached end on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <341/2280>] - Data(s): 4.588 (6.141) - Batch(s): 10.509 
(10.663) - AE Loss: 85716.461 (741355.500) - AE Rec Loss: 0.581 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 3.544 (6.141) - Batch(s): 10.514 
(10.663) - AE Loss: 148912.312 (741355.500) - AE Rec Loss: 1.010 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 5.991 (6.141) - Batch(s): 10.499 
(10.663) - AE Loss: 1793815.250 (741355.500) - AE Rec Loss: 12.165 (5.028) - 
Disc Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 6.483 (6.141) - Batch(s): 10.531 
(10.663) - AE Loss: 228682.672 (741355.500) - AE Rec Loss: 1.551 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 7.561 (6.141) - Batch(s): 10.513 
(10.663) - AE Loss: 47026.992 (741355.500) - AE Rec Loss: 0.319 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <341/2280>] - Data(s): 3.610 (6.141) - Batch(s): 10.512 
(10.663) - AE Loss: 328604.125 (741355.500) - AE Rec Loss: 2.228 (5.028) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.554 
(5.614) - AE Loss: 118711.094 (669225.938) - AE Rec Loss: 0.805 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.567 
(5.614) - AE Loss: 1378619.000 (669225.938) - AE Rec Loss: 9.349 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.567 
(5.614) - AE Loss: 72178.734 (669225.938) - AE Rec Loss: 0.489 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.565 
(5.614) - AE Loss: 217539.797 (669225.938) - AE Rec Loss: 1.475 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.000 (3.071) - Batch(s): 0.565 
(5.614) - AE Loss: 1443093.250 (669225.938) - AE Rec Loss: 9.787 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[Epoch <000/100>: Step <342/2280>] - Data(s): 0.001 (3.071) - Batch(s): 0.573 
(5.614) - AE Loss: 130441.359 (669225.938) - AE Rec Loss: 0.885 (4.538) - Disc 
Loss: 0.000 (0.000) - 1.09 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.672 
(4.633) - AE Loss: 117680.672 (621787.000) - AE Rec Loss: 0.798 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.672 
(4.633) - AE Loss: 240943.141 (621787.000) - AE Rec Loss: 1.634 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.671 
(4.633) - AE Loss: 166490.219 (621787.000) - AE Rec Loss: 1.129 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.672 
(4.633) - AE Loss: 1637296.250 (621787.000) - AE Rec Loss: 11.104 (4.217) - Disc
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.178 (2.108) - Batch(s): 2.673 
(4.633) - AE Loss: 113358.180 (621787.000) - AE Rec Loss: 0.769 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <343/2280>] - Data(s): 0.000 (2.108) - Batch(s): 2.672 
(4.633) - AE Loss: 180153.953 (621787.000) - AE Rec Loss: 1.222 (4.217) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (1.581) - Batch(s): 0.565 
(3.617) - AE Loss: 167403.781 (562594.562) - AE Rec Loss: 1.135 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.566 
(3.617) - AE Loss: 162978.500 (562594.562) - AE Rec Loss: 1.105 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.001 (1.581) - Batch(s): 0.569 
(3.617) - AE Loss: 216776.781 (562594.562) - AE Rec Loss: 1.470 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.554 
(3.617) - AE Loss: 132576.422 (562594.562) - AE Rec Loss: 0.899 (3.815) - Disc 
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.567 
(3.617) - AE Loss: 1634710.250 (562594.562) - AE Rec Loss: 11.086 (3.815) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <344/2280>] - Data(s): 0.000 (1.581) - Batch(s): 0.573 
(3.617) - AE Loss: 1547021.750 (562594.562) - AE Rec Loss: 10.491 (3.815) - Disc
Loss: 0.000 (0.000) - 1.41 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.087 
(3.329) - AE Loss: 442853.656 (531338.312) - AE Rec Loss: 3.003 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.440 
(3.329) - AE Loss: 47096.980 (531338.312) - AE Rec Loss: 0.319 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 1.868 (1.296) - Batch(s): 2.448 
(3.329) - AE Loss: 115566.430 (531338.312) - AE Rec Loss: 0.784 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (1.296) - Batch(s): 2.087 
(3.329) - AE Loss: 110858.539 (531338.312) - AE Rec Loss: 0.752 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.000 (1.296) - Batch(s): 2.088 
(3.329) - AE Loss: 218248.766 (531338.312) - AE Rec Loss: 1.480 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <345/2280>] - Data(s): 0.001 (1.296) - Batch(s): 2.450 
(3.329) - AE Loss: 220905.844 (531338.312) - AE Rec Loss: 1.498 (3.603) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.659 
(2.884) - AE Loss: 189104.625 (579936.812) - AE Rec Loss: 1.282 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 275332.844 (579936.812) - AE Rec Loss: 1.867 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 1446678.000 (579936.812) - AE Rec Loss: 9.811 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (1.080) - Batch(s): 0.658 
(2.884) - AE Loss: 2810426.500 (579936.812) - AE Rec Loss: 19.059 (3.933) - Disc
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.000 (1.080) - Batch(s): 0.660 
(2.884) - AE Loss: 59732.051 (579936.812) - AE Rec Loss: 0.405 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <346/2280>] - Data(s): 0.001 (1.080) - Batch(s): 0.659 
(2.884) - AE Loss: 240073.609 (579936.812) - AE Rec Loss: 1.628 (3.933) - Disc 
Loss: 0.000 (0.000) - 1.72 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.566 
(2.553) - AE Loss: 1835998.375 (573376.688) - AE Rec Loss: 12.451 (3.888) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.566 
(2.553) - AE Loss: 130416.531 (573376.688) - AE Rec Loss: 0.884 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.567 
(2.553) - AE Loss: 485140.906 (573376.688) - AE Rec Loss: 3.290 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.554 
(2.553) - AE Loss: 1432211.750 (573376.688) - AE Rec Loss: 9.713 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.569 
(2.553) - AE Loss: 120441.555 (573376.688) - AE Rec Loss: 0.817 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <347/2280>] - Data(s): 0.000 (0.926) - Batch(s): 0.573 
(2.553) - AE Loss: 205228.234 (573376.688) - AE Rec Loss: 1.392 (3.888) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.706 
(2.414) - AE Loss: 542161.250 (589204.188) - AE Rec Loss: 3.677 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.714 
(2.414) - AE Loss: 108709.336 (589204.188) - AE Rec Loss: 0.737 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 135320.984 (589204.188) - AE Rec Loss: 0.918 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.352 
(2.414) - AE Loss: 567257.688 (589204.188) - AE Rec Loss: 3.847 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 0.000 (0.822) - Batch(s): 1.351 
(2.414) - AE Loss: 175810.641 (589204.188) - AE Rec Loss: 1.192 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <348/2280>] - Data(s): 1.145 (0.822) - Batch(s): 1.709 
(2.414) - AE Loss: 409691.156 (589204.188) - AE Rec Loss: 2.778 (3.996) - Disc 
Loss: 0.000 (0.000) - 1.95 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 162143.719 (569764.688) - AE Rec Loss: 1.100 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.001 (0.753) - Batch(s): 2.990 
(2.478) - AE Loss: 400557.188 (569764.688) - AE Rec Loss: 2.716 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.989 
(2.478) - AE Loss: 295490.250 (569764.688) - AE Rec Loss: 2.004 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.990 
(2.478) - AE Loss: 1396230.375 (569764.688) - AE Rec Loss: 9.469 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.23 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.074 (0.753) - Batch(s): 2.991 
(2.478) - AE Loss: 195343.312 (569764.688) - AE Rec Loss: 1.325 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <349/2280>] - Data(s): 0.000 (0.753) - Batch(s): 2.991 
(2.478) - AE Loss: 207783.688 (569764.688) - AE Rec Loss: 1.409 (3.864) - Disc 
Loss: 0.000 (0.000) - 2.24 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.001 (0.678) - Batch(s): 0.573 
(2.287) - AE Loss: 1910090.250 (577734.938) - AE Rec Loss: 12.954 (3.918) - Disc
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.553 
(2.287) - AE Loss: 402394.688 (577734.938) - AE Rec Loss: 2.729 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.566 
(2.287) - AE Loss: 143739.906 (577734.938) - AE Rec Loss: 0.975 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.566 
(2.287) - AE Loss: 2820598.750 (577734.938) - AE Rec Loss: 19.128 (3.918) - Disc
Loss: 0.000 (0.000) - 2.30 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.568 
(2.287) - AE Loss: 126846.570 (577734.938) - AE Rec Loss: 0.860 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <350/2280>] - Data(s): 0.000 (0.678) - Batch(s): 0.569 
(2.287) - AE Loss: 143793.297 (577734.938) - AE Rec Loss: 0.975 (3.918) - Disc 
Loss: 0.000 (0.000) - 2.29 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.355 
(2.195) - AE Loss: 78680.047 (576499.688) - AE Rec Loss: 0.534 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.42 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.348 
(2.195) - AE Loss: 225522.703 (576499.688) - AE Rec Loss: 1.529 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.348 
(2.195) - AE Loss: 1490801.000 (576499.688) - AE Rec Loss: 10.110 (3.910) - Disc
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.347 
(2.195) - AE Loss: 298268.219 (576499.688) - AE Rec Loss: 2.023 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.347 
(2.195) - AE Loss: 54629.254 (576499.688) - AE Rec Loss: 0.370 (3.910) - Disc 
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <351/2280>] - Data(s): 0.000 (0.616) - Batch(s): 1.336 
(2.195) - AE Loss: 1758551.250 (576499.688) - AE Rec Loss: 11.926 (3.910) - Disc
Loss: 0.000 (0.000) - 2.43 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.067 
(2.101) - AE Loss: 1501179.125 (594303.375) - AE Rec Loss: 10.181 (4.030) - Disc
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.001 (0.568) - Batch(s): 1.066 
(2.101) - AE Loss: 58094.672 (594303.375) - AE Rec Loss: 0.394 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.001 (0.568) - Batch(s): 1.068 
(2.101) - AE Loss: 391704.688 (594303.375) - AE Rec Loss: 2.656 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.069 
(2.101) - AE Loss: 73424.414 (594303.375) - AE Rec Loss: 0.498 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.001 (0.568) - Batch(s): 1.068 
(2.101) - AE Loss: 2073922.750 (594303.375) - AE Rec Loss: 14.065 (4.030) - Disc
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <352/2280>] - Data(s): 0.000 (0.568) - Batch(s): 1.068 
(2.101) - AE Loss: 163491.297 (594303.375) - AE Rec Loss: 1.109 (4.030) - Disc 
Loss: 0.000 (0.000) - 2.53 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.445 
(2.032) - AE Loss: 102592.180 (589624.562) - AE Rec Loss: 0.696 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.874 (0.530) - Batch(s): 1.440 
(2.032) - AE Loss: 280357.500 (589624.562) - AE Rec Loss: 1.901 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.436 
(2.032) - AE Loss: 1420006.375 (589624.562) - AE Rec Loss: 9.630 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.081 
(2.032) - AE Loss: 92791.156 (589624.562) - AE Rec Loss: 0.629 (3.999) - Disc 
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.082 
(2.032) - AE Loss: 1596882.375 (589624.562) - AE Rec Loss: 10.830 (3.999) - Disc
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <353/2280>] - Data(s): 0.000 (0.530) - Batch(s): 1.437 
(2.032) - AE Loss: 1686630.125 (589624.562) - AE Rec Loss: 11.438 (3.999) - Disc
Loss: 0.000 (0.000) - 2.67 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.480 
(2.071) - AE Loss: 1453199.000 (567723.062) - AE Rec Loss: 9.855 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.295 (0.507) - Batch(s): 2.845 
(2.071) - AE Loss: 133246.031 (567723.062) - AE Rec Loss: 0.904 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.480 
(2.071) - AE Loss: 328641.125 (567723.062) - AE Rec Loss: 2.229 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.835 
(2.071) - AE Loss: 59329.789 (567723.062) - AE Rec Loss: 0.402 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 0.000 (0.507) - Batch(s): 2.480 
(2.071) - AE Loss: 116344.227 (567723.062) - AE Rec Loss: 0.789 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <354/2280>] - Data(s): 2.260 (0.507) - Batch(s): 2.838 
(2.071) - AE Loss: 238316.281 (567723.062) - AE Rec Loss: 1.616 (3.850) - Disc 
Loss: 0.000 (0.000) - 2.93 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.651 
(1.976) - AE Loss: 146395.906 (576101.375) - AE Rec Loss: 0.993 (3.907) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.001 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 645002.375 (576101.375) - AE Rec Loss: 4.374 (3.907) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 1584974.500 (576101.375) - AE Rec Loss: 10.749 (3.907) - Disc
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 96991.094 (576101.375) - AE Rec Loss: 0.658 (3.907) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 112562.555 (576101.375) - AE Rec Loss: 0.763 (3.907) - Disc 
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <355/2280>] - Data(s): 0.000 (0.474) - Batch(s): 0.653 
(1.976) - AE Loss: 1660383.250 (576101.375) - AE Rec Loss: 11.260 (3.907) - Disc
Loss: 0.000 (0.000) - 2.99 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.572 
(1.891) - AE Loss: 333325.062 (574163.875) - AE Rec Loss: 2.261 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.713 
(1.891) - AE Loss: 1623197.750 (574163.875) - AE Rec Loss: 11.008 (3.894) - Disc
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.712 
(1.891) - AE Loss: 72559.742 (574163.875) - AE Rec Loss: 0.492 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.558 
(1.891) - AE Loss: 123629.945 (574163.875) - AE Rec Loss: 0.838 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.001 (0.445) - Batch(s): 0.718 
(1.891) - AE Loss: 157207.281 (574163.875) - AE Rec Loss: 1.066 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <356/2280>] - Data(s): 0.148 (0.445) - Batch(s): 0.716 
(1.891) - AE Loss: 232142.297 (574163.875) - AE Rec Loss: 1.574 (3.894) - Disc 
Loss: 0.000 (0.000) - 3.06 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.787 
(1.830) - AE Loss: 182388.547 (582683.812) - AE Rec Loss: 1.237 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.787 
(1.830) - AE Loss: 147046.953 (582683.812) - AE Rec Loss: 0.997 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.000 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 1830187.750 (582683.812) - AE Rec Loss: 12.412 (3.952) - Disc
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.001 (0.421) - Batch(s): 0.786 
(1.830) - AE Loss: 1956674.375 (582683.812) - AE Rec Loss: 13.270 (3.952) - Disc
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.580 (0.421) - Batch(s): 1.145 
(1.830) - AE Loss: 219034.422 (582683.812) - AE Rec Loss: 1.485 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <357/2280>] - Data(s): 0.001 (0.421) - Batch(s): 1.151 
(1.830) - AE Loss: 1618114.500 (582683.812) - AE Rec Loss: 10.974 (3.952) - Disc
Loss: 0.000 (0.000) - 3.17 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 6.831 (0.451) - Batch(s): 7.468 
(2.143) - AE Loss: 63631.234 (582704.688) - AE Rec Loss: 0.432 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.469 
(2.143) - AE Loss: 149741.453 (582704.688) - AE Rec Loss: 1.015 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 1978417.625 (582704.688) - AE Rec Loss: 13.417 (3.952) - Disc
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.547 (0.451) - Batch(s): 7.469 
(2.143) - AE Loss: 1629813.625 (582704.688) - AE Rec Loss: 11.053 (3.952) - Disc
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 2.883 (0.451) - Batch(s): 7.468 
(2.143) - AE Loss: 439734.531 (582704.688) - AE Rec Loss: 2.982 (3.952) - Disc 
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <358/2280>] - Data(s): 0.000 (0.451) - Batch(s): 7.467 
(2.143) - AE Loss: 1479562.750 (582704.688) - AE Rec Loss: 10.034 (3.952) - Disc
Loss: 0.000 (0.000) - 3.84 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.555 
(2.060) - AE Loss: 97572.586 (589840.625) - AE Rec Loss: 0.662 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 70729.086 (589840.625) - AE Rec Loss: 0.480 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 2756130.500 (589840.625) - AE Rec Loss: 18.691 (4.000) - Disc
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 138121.656 (589840.625) - AE Rec Loss: 0.937 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.574 
(2.060) - AE Loss: 1731920.000 (589840.625) - AE Rec Loss: 11.745 (4.000) - Disc
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <359/2280>] - Data(s): 0.000 (0.427) - Batch(s): 0.569 
(2.060) - AE Loss: 1421834.500 (589840.625) - AE Rec Loss: 9.642 (4.000) - Disc 
Loss: 0.000 (0.000) - 3.89 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.557 
(1.986) - AE Loss: 127353.055 (604717.188) - AE Rec Loss: 0.864 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.569 
(1.986) - AE Loss: 1505700.875 (604717.188) - AE Rec Loss: 10.211 (4.101) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.568 
(1.986) - AE Loss: 1560260.750 (604717.188) - AE Rec Loss: 10.581 (4.101) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.570 
(1.986) - AE Loss: 358509.500 (604717.188) - AE Rec Loss: 2.431 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.570 
(1.986) - AE Loss: 135134.797 (604717.188) - AE Rec Loss: 0.916 (4.101) - Disc 
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <360/2280>] - Data(s): 0.000 (0.406) - Batch(s): 0.574 
(1.986) - AE Loss: 1630452.000 (604717.188) - AE Rec Loss: 11.057 (4.101) - Disc
Loss: 0.000 (0.000) - 3.94 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 330715.562 (619681.250) - AE Rec Loss: 2.243 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.000 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 98651.023 (619681.250) - AE Rec Loss: 0.669 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 1462343.000 (619681.250) - AE Rec Loss: 9.917 (4.202) - Disc 
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.911 
(2.501) - AE Loss: 1723197.500 (619681.250) - AE Rec Loss: 11.686 (4.202) - Disc
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 1.500 (0.392) - Batch(s): 13.911 
(2.501) - AE Loss: 1678122.750 (619681.250) - AE Rec Loss: 11.380 (4.202) - Disc
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 0.001 (0.392) - Batch(s): 13.912 
(2.501) - AE Loss: 1573250.500 (619681.250) - AE Rec Loss: 10.669 (4.202) - Disc
Loss: 0.000 (0.000) - 5.17 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.568 
(2.413) - AE Loss: 97274.586 (632520.312) - AE Rec Loss: 0.660 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.575 
(2.413) - AE Loss: 1387183.125 (632520.312) - AE Rec Loss: 9.407 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.555 
(2.413) - AE Loss: 176210.500 (632520.312) - AE Rec Loss: 1.195 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.567 
(2.413) - AE Loss: 111638.195 (632520.312) - AE Rec Loss: 0.757 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.569 
(2.413) - AE Loss: 3021399.500 (632520.312) - AE Rec Loss: 20.490 (4.290) - Disc
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.570 
(2.413) - AE Loss: 156065.578 (632520.312) - AE Rec Loss: 1.058 (4.290) - Disc 
Loss: 0.000 (0.000) - 5.22 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.557 
(2.333) - AE Loss: 282490.062 (635260.062) - AE Rec Loss: 1.916 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.568 
(2.333) - AE Loss: 682180.750 (635260.062) - AE Rec Loss: 4.626 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.571 
(2.333) - AE Loss: 55822.398 (635260.062) - AE Rec Loss: 0.379 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.568 
(2.333) - AE Loss: 277776.625 (635260.062) - AE Rec Loss: 1.884 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.569 
(2.333) - AE Loss: 1578455.250 (635260.062) - AE Rec Loss: 10.705 (4.308) - Disc
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (0.358) - Batch(s): 0.575 
(2.333) - AE Loss: 208422.156 (635260.062) - AE Rec Loss: 1.413 (4.308) - Disc 
Loss: 0.000 (0.000) - 5.27 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.655 
(2.263) - AE Loss: 87348.695 (627962.875) - AE Rec Loss: 0.592 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 1471994.750 (627962.875) - AE Rec Loss: 9.983 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.657 
(2.263) - AE Loss: 198612.703 (627962.875) - AE Rec Loss: 1.347 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.001 (0.343) - Batch(s): 0.657 
(2.263) - AE Loss: 536743.062 (627962.875) - AE Rec Loss: 3.640 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.656 
(2.263) - AE Loss: 216428.203 (627962.875) - AE Rec Loss: 1.468 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.657 
(2.263) - AE Loss: 127104.852 (627962.875) - AE Rec Loss: 0.862 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.32 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.568 
(2.195) - AE Loss: 123758.984 (628186.875) - AE Rec Loss: 0.839 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.575 
(2.195) - AE Loss: 1589551.750 (628186.875) - AE Rec Loss: 10.780 (4.260) - Disc
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.557 
(2.195) - AE Loss: 176085.891 (628186.875) - AE Rec Loss: 1.194 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.569 
(2.195) - AE Loss: 1470809.375 (628186.875) - AE Rec Loss: 9.975 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.571 
(2.195) - AE Loss: 149487.938 (628186.875) - AE Rec Loss: 1.014 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (0.330) - Batch(s): 0.571 
(2.195) - AE Loss: 240979.484 (628186.875) - AE Rec Loss: 1.634 (4.260) - Disc 
Loss: 0.000 (0.000) - 5.37 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (0.317) - Batch(s): 0.557 
(2.133) - AE Loss: 1423346.250 (622504.312) - AE Rec Loss: 9.653 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.569 
(2.133) - AE Loss: 66265.688 (622504.312) - AE Rec Loss: 0.449 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (0.317) - Batch(s): 0.571 
(2.133) - AE Loss: 73786.172 (622504.312) - AE Rec Loss: 0.500 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.575 
(2.133) - AE Loss: 460868.938 (622504.312) - AE Rec Loss: 3.125 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.41 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (0.317) - Batch(s): 0.568 
(2.133) - AE Loss: 1342493.000 (622504.312) - AE Rec Loss: 9.104 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (0.317) - Batch(s): 0.571 
(2.133) - AE Loss: 56005.441 (622504.312) - AE Rec Loss: 0.380 (4.222) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.001 (0.310) - Batch(s): 2.355 
(2.141) - AE Loss: 303660.500 (633364.812) - AE Rec Loss: 2.059 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.001 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 1418725.875 (633364.812) - AE Rec Loss: 9.621 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 138282.422 (633364.812) - AE Rec Loss: 0.938 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 1833025.250 (633364.812) - AE Rec Loss: 12.431 (4.295) - Disc
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 69991.156 (633364.812) - AE Rec Loss: 0.475 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.61 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (0.310) - Batch(s): 2.357 
(2.141) - AE Loss: 194177.078 (633364.812) - AE Rec Loss: 1.317 (4.295) - Disc 
Loss: 0.000 (0.000) - 5.62 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.309) - Batch(s): 3.518 
(2.188) - AE Loss: 1448780.500 (635869.375) - AE Rec Loss: 9.825 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.309) - Batch(s): 3.520 
(2.188) - AE Loss: 369591.062 (635869.375) - AE Rec Loss: 2.506 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.309) - Batch(s): 3.519 
(2.188) - AE Loss: 201050.172 (635869.375) - AE Rec Loss: 1.363 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.520 
(2.188) - AE Loss: 1689826.000 (635869.375) - AE Rec Loss: 11.460 (4.312) - Disc
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.309) - Batch(s): 3.504 
(2.188) - AE Loss: 123180.172 (635869.375) - AE Rec Loss: 0.835 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.92 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.309) - Batch(s): 3.525 
(2.188) - AE Loss: 175944.125 (635869.375) - AE Rec Loss: 1.193 (4.312) - Disc 
Loss: 0.000 (0.000) - 5.91 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:23:05,259[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,310[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,311[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,409[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,422[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:23:05,500[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:23:07,532[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,556[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,559[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,586[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,615[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:23:07,721[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,187[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,198[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 05:23:08,206[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,234[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 05:23:08,234[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:23:08,256[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 05:23:08,261[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:23:08,263[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
[[36m2023-11-29 05:23:08,264[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:23:08,264[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(valid_dataloader) = 1
=> Mixed precision: no
=> Running in inference mode: False
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
len(valid_dataset) = 4
len(valid_dataset) = 4
[[36m2023-11-29 05:23:08,266[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
len(train_dataloader) = 2279
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(valid_dataloader) = 1
len(train_dataset) = 54706
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
[[36m2023-11-29 05:23:08,269[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing model 
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Mixed precision: no
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
=> Running in inference mode: False
len(valid_dataset) = 4
=> Instantiating train dataloader 
=> Preparing opt_disc 
len(valid_dataloader) = 1
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
len(train_dataset) = 54706
=> Preparing model 
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 1.3 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
Reached 1.3 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.3 on node 6
Reached 1.4 on node 6
Reached 3 on node 9
Reached 2 on node 6
Reached 5 on node 9Reached 3 on node 6

Reached end on node 9
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
=> Preparing criterion 
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 9
Reached 3 on node 6Reached 5 on node 9

Reached 5 on node 6
Reached end on node 9
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
Reached 1 on node 11
Reached 1 on node 10
Reached 1.2 on node 11
Reached 1.2 on node 10
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1 on node 7
Reached 1.25 on node 8
Reached 1.2 on node 7
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7Reached 1.3 on node 8

Reached 1.4 on node 8Reached 1.4 on node 7

Reached 2 on node 8Reached 2 on node 7

Reached 3 on node 8Reached 3 on node 7

Reached 5 on node 8Reached 5 on node 7

Reached end on node 7Reached end on node 8

Reached 1.3 on node 9
Reached 1.3 on node 6
Reached 1.4 on node 9
Reached 1.4 on node 6
Reached 2 on node 9
Reached 2 on node 6
Reached 3 on node 9
Reached 3 on node 6
Reached 5 on node 9Reached 1.3 on node 11

Reached 5 on node 6Reached 1.4 on node 11

Reached end on node 9
Reached end on node 6
Reached 2 on node 11
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 3 on node 11
Reached 2 on node 10
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
Loaded checkpoint at epoch 0 and step 361
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11Reached 1 on node 7

Reached 2 on node 11
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7Reached 1 on node 11

Reached 1.4 on node 11Reached 1.4 on node 7

Reached 2 on node 11Reached 2 on node 7

Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 1.4 on node 8
Reached 3 on node 6Reached 2 on node 8

Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 1 on node 11
Reached 1 on node 7Reached 5 on node 6

Reached 1.4 on node 11Reached 1.4 on node 7

Reached 2 on node 11Reached 2 on node 7

Reached 3 on node 7
Reached 1 on node 9Reached 3 on node 7

Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 1.4 on node 9Reached 5 on node 7

Reached 2 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8Reached 1 on node 11

Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1.4 on node 11
Reached 5 on node 8Reached 2 on node 11

Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 1 on node 10Reached 3 on node 9

Reached 5 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 6
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9Reached 1 on node 10

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 6
Reached 1 on node 10
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 1 on node 6Reached 1 on node 9

Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 9
Reached 3 on node 9Reached 3 on node 6

Reached 3 on node 6Reached 3 on node 9

Reached 3 on node 9Reached 3 on node 6

Reached 3 on node 9Reached 3 on node 6

Reached 3 on node 6
Reached 5 on node 9
Reached 5 on node 6
Reached end on node 6Reached end on node 9

Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 7
Reached end on node 8
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <361/2280>] - Data(s): 7.305 (6.891) - Batch(s): 12.209 
(12.415) - AE Loss: 1679446.750 (919133.000) - AE Rec Loss: 11.389 (6.233) - 
Disc Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 4.218 (6.891) - Batch(s): 12.189 
(12.415) - AE Loss: 98613.039 (919133.000) - AE Rec Loss: 0.669 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 9.856 (6.891) - Batch(s): 12.177 
(12.415) - AE Loss: 1572919.000 (919133.000) - AE Rec Loss: 10.667 (6.233) - 
Disc Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 5.932 (6.891) - Batch(s): 12.190 
(12.415) - AE Loss: 330649.625 (919133.000) - AE Rec Loss: 2.242 (6.233) - Disc 
Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 9.728 (6.891) - Batch(s): 12.216 
(12.415) - AE Loss: 1722968.000 (919133.000) - AE Rec Loss: 11.685 (6.233) - 
Disc Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <361/2280>] - Data(s): 5.236 (6.891) - Batch(s): 12.190 
(12.415) - AE Loss: 1461949.000 (919133.000) - AE Rec Loss: 9.914 (6.233) - Disc
Loss: 0.000 (0.000) - 1.10 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.568 
(6.490) - AE Loss: 1386995.000 (915964.000) - AE Rec Loss: 9.406 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.560 
(6.490) - AE Loss: 111678.469 (915964.000) - AE Rec Loss: 0.757 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.560 
(6.490) - AE Loss: 120786.812 (915964.000) - AE Rec Loss: 0.819 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.562 
(6.490) - AE Loss: 171154.703 (915964.000) - AE Rec Loss: 1.161 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.550 
(6.490) - AE Loss: 190880.203 (915964.000) - AE Rec Loss: 1.294 (6.212) - Disc 
Loss: 0.000 (0.000) - 1.16 m remaining

[Epoch <000/100>: Step <362/2280>] - Data(s): 0.000 (3.446) - Batch(s): 0.591 
(6.490) - AE Loss: 3024843.750 (915964.000) - AE Rec Loss: 20.514 (6.212) - Disc
Loss: 0.000 (0.000) - 1.16 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (2.297) - Batch(s): 0.735 
(4.571) - AE Loss: 216972.219 (845812.000) - AE Rec Loss: 1.471 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (2.297) - Batch(s): 0.734 
(4.571) - AE Loss: 677116.125 (845812.000) - AE Rec Loss: 4.592 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.737 
(4.571) - AE Loss: 1590719.875 (845812.000) - AE Rec Loss: 10.788 (5.736) - Disc
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.737 
(4.571) - AE Loss: 57086.414 (845812.000) - AE Rec Loss: 0.387 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.001 (2.297) - Batch(s): 0.735 
(4.571) - AE Loss: 296071.469 (845812.000) - AE Rec Loss: 2.008 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <363/2280>] - Data(s): 0.000 (2.297) - Batch(s): 0.737 
(4.571) - AE Loss: 298724.500 (845812.000) - AE Rec Loss: 2.026 (5.736) - Disc 
Loss: 0.000 (0.000) - 1.24 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (1.768) - Batch(s): 2.384 
(4.032) - AE Loss: 126861.570 (749269.312) - AE Rec Loss: 0.860 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 196937.438 (749269.312) - AE Rec Loss: 1.336 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (1.768) - Batch(s): 2.384 
(4.032) - AE Loss: 537910.000 (749269.312) - AE Rec Loss: 3.648 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 1470604.500 (749269.312) - AE Rec Loss: 9.973 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 0.000 (1.768) - Batch(s): 2.383 
(4.032) - AE Loss: 215592.766 (749269.312) - AE Rec Loss: 1.462 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <364/2280>] - Data(s): 2.163 (1.768) - Batch(s): 2.746 
(4.032) - AE Loss: 87507.148 (749269.312) - AE Rec Loss: 0.593 (5.081) - Disc 
Loss: 0.000 (0.000) - 1.49 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.564 
(3.338) - AE Loss: 225244.453 (724108.750) - AE Rec Loss: 1.528 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.562 
(3.338) - AE Loss: 1462742.750 (724108.750) - AE Rec Loss: 9.920 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.562 
(3.338) - AE Loss: 116584.680 (724108.750) - AE Rec Loss: 0.791 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.570 
(3.338) - AE Loss: 1579108.750 (724108.750) - AE Rec Loss: 10.709 (4.911) - Disc
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.566 
(3.338) - AE Loss: 140702.062 (724108.750) - AE Rec Loss: 0.954 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <365/2280>] - Data(s): 0.000 (1.415) - Batch(s): 0.552 
(3.338) - AE Loss: 159739.641 (724108.750) - AE Rec Loss: 1.083 (4.911) - Disc 
Loss: 0.000 (0.000) - 1.55 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.690 
(2.897) - AE Loss: 53082.211 (682492.625) - AE Rec Loss: 0.360 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.692 
(2.897) - AE Loss: 1340701.500 (682492.625) - AE Rec Loss: 9.092 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (1.179) - Batch(s): 0.692 
(2.897) - AE Loss: 64245.516 (682492.625) - AE Rec Loss: 0.436 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.691 
(2.897) - AE Loss: 1415414.750 (682492.625) - AE Rec Loss: 9.599 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.001 (1.179) - Batch(s): 0.692 
(2.897) - AE Loss: 448970.625 (682492.625) - AE Rec Loss: 3.045 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <366/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.692 
(2.897) - AE Loss: 73501.031 (682492.625) - AE Rec Loss: 0.498 (4.628) - Disc 
Loss: 0.000 (0.000) - 1.62 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.376 
(2.684) - AE Loss: 181187.672 (715171.250) - AE Rec Loss: 1.229 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.001 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 132942.234 (715171.250) - AE Rec Loss: 0.902 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.376 
(2.684) - AE Loss: 1828613.000 (715171.250) - AE Rec Loss: 12.401 (4.850) - Disc
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 1414546.625 (715171.250) - AE Rec Loss: 9.593 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 0.000 (1.024) - Batch(s): 1.375 
(2.684) - AE Loss: 299644.000 (715171.250) - AE Rec Loss: 2.032 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <367/2280>] - Data(s): 1.165 (1.024) - Batch(s): 1.736 
(2.684) - AE Loss: 68306.281 (715171.250) - AE Rec Loss: 0.463 (4.850) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.001 (0.916) - Batch(s): 2.393 
(2.640) - AE Loss: 200192.234 (713271.750) - AE Rec Loss: 1.358 (4.837) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.396 
(2.640) - AE Loss: 162827.812 (713271.750) - AE Rec Loss: 1.104 (4.837) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.394 
(2.640) - AE Loss: 1691833.500 (713271.750) - AE Rec Loss: 11.473 (4.837) - Disc
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.381 
(2.640) - AE Loss: 113524.023 (713271.750) - AE Rec Loss: 0.770 (4.837) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.393 
(2.640) - AE Loss: 365554.625 (713271.750) - AE Rec Loss: 2.479 (4.837) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <368/2280>] - Data(s): 0.000 (0.916) - Batch(s): 2.390 
(2.640) - AE Loss: 1450144.000 (713271.750) - AE Rec Loss: 9.834 (4.837) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.723 
(2.427) - AE Loss: 1596406.750 (739378.375) - AE Rec Loss: 10.826 (5.014) - Disc
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.723 
(2.427) - AE Loss: 59052.867 (739378.375) - AE Rec Loss: 0.400 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.725 
(2.427) - AE Loss: 144269.828 (739378.375) - AE Rec Loss: 0.978 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.725 
(2.427) - AE Loss: 105717.602 (739378.375) - AE Rec Loss: 0.717 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.726 
(2.427) - AE Loss: 1534214.125 (739378.375) - AE Rec Loss: 10.405 (5.014) - Disc
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <369/2280>] - Data(s): 0.000 (0.814) - Batch(s): 0.725 
(2.427) - AE Loss: 1287420.375 (739378.375) - AE Rec Loss: 8.731 (5.014) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.001 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 62883.391 (688241.188) - AE Rec Loss: 0.426 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.001 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 51888.398 (688241.188) - AE Rec Loss: 0.352 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.998 
(2.287) - AE Loss: 148774.078 (688241.188) - AE Rec Loss: 1.009 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.788 (0.739) - Batch(s): 1.359 
(2.287) - AE Loss: 1412387.750 (688241.188) - AE Rec Loss: 9.578 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.001 (0.739) - Batch(s): 0.997 
(2.287) - AE Loss: 81036.883 (688241.188) - AE Rec Loss: 0.550 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <370/2280>] - Data(s): 0.000 (0.739) - Batch(s): 0.997 
(2.287) - AE Loss: 176458.953 (688241.188) - AE Rec Loss: 1.197 (4.667) - Disc 
Loss: 0.000 (0.000) - 2.19 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.000 (0.707) - Batch(s): 3.223 
(2.357) - AE Loss: 102464.305 (686884.625) - AE Rec Loss: 0.695 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.001 (0.707) - Batch(s): 3.235 
(2.357) - AE Loss: 1621837.500 (686884.625) - AE Rec Loss: 10.999 (4.658) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.001 (0.707) - Batch(s): 3.235 
(2.357) - AE Loss: 1497124.000 (686884.625) - AE Rec Loss: 10.153 (4.658) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.000 (0.707) - Batch(s): 3.235 
(2.357) - AE Loss: 1895546.500 (686884.625) - AE Rec Loss: 12.855 (4.658) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.000 (0.707) - Batch(s): 3.239 
(2.357) - AE Loss: 336372.531 (686884.625) - AE Rec Loss: 2.281 (4.658) - Disc 
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <371/2280>] - Data(s): 0.000 (0.707) - Batch(s): 3.232 
(2.357) - AE Loss: 1653100.500 (686884.625) - AE Rec Loss: 11.211 (4.658) - Disc
Loss: 0.000 (0.000) - 2.47 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.713 
(2.220) - AE Loss: 132057.828 (698287.688) - AE Rec Loss: 0.896 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.001 (0.648) - Batch(s): 0.713 
(2.220) - AE Loss: 1455463.500 (698287.688) - AE Rec Loss: 9.870 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.001 (0.648) - Batch(s): 0.714 
(2.220) - AE Loss: 237243.281 (698287.688) - AE Rec Loss: 1.609 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.713 
(2.220) - AE Loss: 391279.750 (698287.688) - AE Rec Loss: 2.654 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.713 
(2.220) - AE Loss: 176871.719 (698287.688) - AE Rec Loss: 1.199 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <372/2280>] - Data(s): 0.000 (0.648) - Batch(s): 0.714 
(2.220) - AE Loss: 337264.719 (698287.688) - AE Rec Loss: 2.287 (4.736) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.566 
(2.092) - AE Loss: 133069.625 (676618.688) - AE Rec Loss: 0.902 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.553 
(2.092) - AE Loss: 113453.727 (676618.688) - AE Rec Loss: 0.769 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.564 
(2.092) - AE Loss: 223718.531 (676618.688) - AE Rec Loss: 1.517 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.573 
(2.092) - AE Loss: 178862.672 (676618.688) - AE Rec Loss: 1.213 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.567 
(2.092) - AE Loss: 185990.734 (676618.688) - AE Rec Loss: 1.261 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <373/2280>] - Data(s): 0.001 (0.598) - Batch(s): 0.564 
(2.092) - AE Loss: 374293.750 (676618.688) - AE Rec Loss: 2.538 (4.589) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.001 (0.562) - Batch(s): 1.329 
(2.030) - AE Loss: 1640839.125 (663598.125) - AE Rec Loss: 11.128 (4.500) - Disc
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.334 
(2.030) - AE Loss: 296877.969 (663598.125) - AE Rec Loss: 2.013 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.334 
(2.030) - AE Loss: 99839.430 (663598.125) - AE Rec Loss: 0.677 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.320 
(2.030) - AE Loss: 196652.375 (663598.125) - AE Rec Loss: 1.334 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.333 
(2.030) - AE Loss: 125458.461 (663598.125) - AE Rec Loss: 0.851 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <374/2280>] - Data(s): 0.000 (0.562) - Batch(s): 1.337 
(2.030) - AE Loss: 240191.328 (663598.125) - AE Rec Loss: 1.629 (4.500) - Disc 
Loss: 0.000 (0.000) - 2.71 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.720 
(1.942) - AE Loss: 135883.875 (661895.438) - AE Rec Loss: 0.922 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.720 
(1.942) - AE Loss: 76414.750 (661895.438) - AE Rec Loss: 0.518 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.720 
(1.942) - AE Loss: 113056.797 (661895.438) - AE Rec Loss: 0.767 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.721 
(1.942) - AE Loss: 232761.891 (661895.438) - AE Rec Loss: 1.579 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.721 
(1.942) - AE Loss: 298521.719 (661895.438) - AE Rec Loss: 2.024 (4.489) - Disc 
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <375/2280>] - Data(s): 0.000 (0.525) - Batch(s): 0.721 
(1.942) - AE Loss: 1518382.250 (661895.438) - AE Rec Loss: 10.297 (4.489) - Disc
Loss: 0.000 (0.000) - 2.78 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 3.385 (0.512) - Batch(s): 3.955 
(2.050) - AE Loss: 637885.688 (653874.625) - AE Rec Loss: 4.326 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.000 (0.512) - Batch(s): 3.599 
(2.050) - AE Loss: 1648970.250 (653874.625) - AE Rec Loss: 11.183 (4.434) - Disc
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.137 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 1514361.750 (653874.625) - AE Rec Loss: 10.270 (4.434) - Disc
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.001 (0.512) - Batch(s): 3.600 
(2.050) - AE Loss: 56167.453 (653874.625) - AE Rec Loss: 0.381 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.001 (0.512) - Batch(s): 3.599 
(2.050) - AE Loss: 1522478.375 (653874.625) - AE Rec Loss: 10.325 (4.434) - Disc
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <376/2280>] - Data(s): 0.295 (0.512) - Batch(s): 3.960 
(2.050) - AE Loss: 100283.305 (653874.625) - AE Rec Loss: 0.680 (4.434) - Disc 
Loss: 0.000 (0.000) - 3.11 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.769 
(2.031) - AE Loss: 71834.984 (638174.125) - AE Rec Loss: 0.487 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.766 
(2.031) - AE Loss: 1489364.500 (638174.125) - AE Rec Loss: 10.100 (4.328) - Disc
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.770 
(2.031) - AE Loss: 101970.242 (638174.125) - AE Rec Loss: 0.692 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.770 
(2.031) - AE Loss: 182596.703 (638174.125) - AE Rec Loss: 1.238 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.756 
(2.031) - AE Loss: 114088.945 (638174.125) - AE Rec Loss: 0.774 (4.328) - Disc 
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <377/2280>] - Data(s): 0.000 (0.488) - Batch(s): 1.773 
(2.031) - AE Loss: 1732568.875 (638174.125) - AE Rec Loss: 11.750 (4.328) - Disc
Loss: 0.000 (0.000) - 3.27 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.711 
(1.958) - AE Loss: 60295.102 (636598.875) - AE Rec Loss: 0.409 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.711 
(1.958) - AE Loss: 122158.273 (636598.875) - AE Rec Loss: 0.828 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.711 
(1.958) - AE Loss: 200144.297 (636598.875) - AE Rec Loss: 1.357 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.710 
(1.958) - AE Loss: 201461.219 (636598.875) - AE Rec Loss: 1.366 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.711 
(1.958) - AE Loss: 1639390.625 (636598.875) - AE Rec Loss: 11.118 (4.317) - Disc
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <378/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.712 
(1.958) - AE Loss: 59706.766 (636598.875) - AE Rec Loss: 0.405 (4.317) - Disc 
Loss: 0.000 (0.000) - 3.33 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 1436410.750 (642890.438) - AE Rec Loss: 9.741 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 1603504.625 (642890.438) - AE Rec Loss: 10.874 (4.360) - Disc
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.000 (0.449) - Batch(s): 1.460 
(1.936) - AE Loss: 106792.375 (642890.438) - AE Rec Loss: 0.724 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 0.499 (0.449) - Batch(s): 1.819 
(1.936) - AE Loss: 2033311.875 (642890.438) - AE Rec Loss: 13.789 (4.360) - Disc
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 1.132 (0.449) - Batch(s): 1.696 
(1.936) - AE Loss: 1513893.000 (642890.438) - AE Rec Loss: 10.267 (4.360) - Disc
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <379/2280>] - Data(s): 1.252 (0.449) - Batch(s): 1.813 
(1.936) - AE Loss: 1403859.000 (642890.438) - AE Rec Loss: 9.521 (4.360) - Disc 
Loss: 0.000 (0.000) - 3.48 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.553 
(1.867) - AE Loss: 161101.375 (631807.000) - AE Rec Loss: 1.093 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.566 
(1.867) - AE Loss: 62480.133 (631807.000) - AE Rec Loss: 0.424 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.000 (0.426) - Batch(s): 0.564 
(1.867) - AE Loss: 62255.211 (631807.000) - AE Rec Loss: 0.422 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.000 (0.426) - Batch(s): 0.565 
(1.867) - AE Loss: 1386221.250 (631807.000) - AE Rec Loss: 9.401 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.567 
(1.867) - AE Loss: 58165.617 (631807.000) - AE Rec Loss: 0.394 (4.285) - Disc 
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <380/2280>] - Data(s): 0.001 (0.426) - Batch(s): 0.574 
(1.867) - AE Loss: 1484463.500 (631807.000) - AE Rec Loss: 10.067 (4.285) - Disc
Loss: 0.000 (0.000) - 3.53 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.239 
(2.752) - AE Loss: 112273.961 (626334.875) - AE Rec Loss: 0.761 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.238 
(2.752) - AE Loss: 1673978.500 (626334.875) - AE Rec Loss: 11.352 (4.248) - Disc
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.429 (0.410) - Batch(s): 22.238 
(2.752) - AE Loss: 201296.734 (626334.875) - AE Rec Loss: 1.365 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.524 (0.410) - Batch(s): 22.238 
(2.752) - AE Loss: 267274.562 (626334.875) - AE Rec Loss: 1.813 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.238 
(2.752) - AE Loss: 279160.000 (626334.875) - AE Rec Loss: 1.893 (4.248) - Disc 
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 0.000 (0.410) - Batch(s): 22.238 
(2.752) - AE Loss: 1571070.500 (626334.875) - AE Rec Loss: 10.655 (4.248) - Disc
Loss: 0.000 (0.000) - 5.38 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.554 
(2.653) - AE Loss: 103449.469 (628039.250) - AE Rec Loss: 0.702 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.566 
(2.653) - AE Loss: 1841323.250 (628039.250) - AE Rec Loss: 12.487 (4.259) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.574 
(2.653) - AE Loss: 185666.953 (628039.250) - AE Rec Loss: 1.259 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.566 
(2.653) - AE Loss: 1552925.625 (628039.250) - AE Rec Loss: 10.531 (4.259) - Disc
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.564 
(2.653) - AE Loss: 134348.453 (628039.250) - AE Rec Loss: 0.911 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (0.391) - Batch(s): 0.566 
(2.653) - AE Loss: 1426634.250 (628039.250) - AE Rec Loss: 9.675 (4.259) - Disc 
Loss: 0.000 (0.000) - 5.42 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.566 
(2.562) - AE Loss: 152418.141 (620808.625) - AE Rec Loss: 1.034 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.575 
(2.562) - AE Loss: 1362049.500 (620808.625) - AE Rec Loss: 9.237 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.567 
(2.562) - AE Loss: 146051.766 (620808.625) - AE Rec Loss: 0.990 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.555 
(2.562) - AE Loss: 751359.375 (620808.625) - AE Rec Loss: 5.095 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.566 
(2.562) - AE Loss: 54116.660 (620808.625) - AE Rec Loss: 0.367 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (0.374) - Batch(s): 0.566 
(2.562) - AE Loss: 170935.859 (620808.625) - AE Rec Loss: 1.159 (4.210) - Disc 
Loss: 0.000 (0.000) - 5.46 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.718 
(2.485) - AE Loss: 628452.812 (621870.688) - AE Rec Loss: 4.262 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.719 
(2.485) - AE Loss: 1486897.750 (621870.688) - AE Rec Loss: 10.084 (4.217) - Disc
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.718 
(2.485) - AE Loss: 289749.094 (621870.688) - AE Rec Loss: 1.965 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.720 
(2.485) - AE Loss: 143554.406 (621870.688) - AE Rec Loss: 0.974 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.720 
(2.485) - AE Loss: 645929.438 (621870.688) - AE Rec Loss: 4.380 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (0.359) - Batch(s): 0.719 
(2.485) - AE Loss: 58325.441 (621870.688) - AE Rec Loss: 0.396 (4.217) - Disc 
Loss: 0.000 (0.000) - 5.52 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.567 
(2.408) - AE Loss: 80844.148 (631919.562) - AE Rec Loss: 0.548 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.566 
(2.408) - AE Loss: 49512.039 (631919.562) - AE Rec Loss: 0.336 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.001 (0.344) - Batch(s): 0.573 
(2.408) - AE Loss: 1880383.250 (631919.562) - AE Rec Loss: 12.752 (4.285) - Disc
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.555 
(2.408) - AE Loss: 72718.109 (631919.562) - AE Rec Loss: 0.493 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.566 
(2.408) - AE Loss: 126690.742 (631919.562) - AE Rec Loss: 0.859 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (0.344) - Batch(s): 0.567 
(2.408) - AE Loss: 224080.562 (631919.562) - AE Rec Loss: 1.520 (4.285) - Disc 
Loss: 0.000 (0.000) - 5.56 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.Working with z of shape (1, 1, 48, 48) = 2304 dimensions.

Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channelsmaking attention of type 'vanilla' with 512 in_channels

making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:27:41,326[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:41,374[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:41,380[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:41,381[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:41,391[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:27:41,415[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:27:43,578[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:43,598[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:43,602[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:43,614[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:43,621[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:27:43,634[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:44,168[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:27:44,210[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:44,215[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:44,226[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
[[36m2023-11-29 05:27:44,232[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:27:44,269[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:27:44,270[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
[[36m2023-11-29 05:27:44,272[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataset) = 54706
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
[[36m2023-11-29 05:27:44,273[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Mixed precision: no
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(valid_dataloader) = 1
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating the optimizer 
len(valid_dataloader) = 1
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing model 
=> Preparing model 
[[36m2023-11-29 05:27:44,288[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:27:44,288[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:27:44,288[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing model 
=> Preparing opt_disc 
=> Preparing opt_disc 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing model 
=> Preparing model 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1.25 on node 6
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1 on node 11
Reached 1.2 on node 11
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 1.3 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
Reached 3 on node 7
Reached 5 on node 7
Reached end on node 7
=> Preparing opt_ae 
Reached 1.3 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
Reached 1.3 on node 6Reached 1.3 on node 11

Reached 1.4 on node 11
Reached 1.4 on node 6
Reached 2 on node 11
Reached 2 on node 6
Reached 3 on node 11
Reached 3 on node 6
Reached 5 on node 11
Reached 5 on node 6
Reached end on node 11Reached end on node 6

Reached 3 on node 10
Reached 5 on node 10
Reached end on node 10
=> Preparing opt_ae 
Reached 1.3 on node 8
Reached 1.4 on node 8
=> Preparing criterion 
Reached 2 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing opt_ae 
=> Preparing opt_ae 
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
=> Preparing criterion 
=> Preparing opt_ae 
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 11
Reached 3 on node 6
Reached 5 on node 6
Reached end on node 6
=> Preparing criterion 
=> Preparing criterion 
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
=> Preparing criterion 
Reached 1 on node 6
Reached 1.2 on node 6
Reached 1 on node 11
Reached 1.25 on node 6
Reached 1.2 on node 11
devices: [0], output device: 0, kwargs: {'find_unused_parameters': True}
Reached 1.25 on node 11
devices: [5], output device: 5, kwargs: {'find_unused_parameters': True}
Reached 1 on node 9
Reached 1.2 on node 9
Reached 1.25 on node 9
devices: [3], output device: 3, kwargs: {'find_unused_parameters': True}
Reached 1 on node 8
Reached 1.2 on node 8
Reached 1.25 on node 8
devices: [2], output device: 2, kwargs: {'find_unused_parameters': True}
Reached 1 on node 7
Reached 1.2 on node 7
Reached 1.25 on node 7
devices: [1], output device: 1, kwargs: {'find_unused_parameters': True}
Reached 1 on node 10
Reached 1.2 on node 10
Reached 1.25 on node 10
devices: [4], output device: 4, kwargs: {'find_unused_parameters': True}
Reached 1.3 on node 10Reached 1.3 on node 7

Reached 1.4 on node 10Reached 1.4 on node 7

Reached 2 on node 7
Reached 2 on node 10
Reached 3 on node 7
Reached 3 on node 10
Reached 5 on node 7Reached 5 on node 10

Reached end on node 7Reached end on node 10

Reached 1.3 on node 9
Reached 1.3 on node 8Reached 1.4 on node 9

Reached 1.3 on node 11Reached 1.3 on node 6
Reached 1.4 on node 8
Reached 2 on node 9
Reached 1.4 on node 11Reached 1.4 on node 6


Reached 2 on node 8
Reached 2 on node 6Reached 2 on node 11

Reached 3 on node 9
Reached 3 on node 8
Reached 5 on node 9
Reached 3 on node 6Reached 3 on node 11

Reached 5 on node 8
Reached end on node 9Reached 5 on node 11
Reached 5 on node 6
Reached end on node 8

Reached end on node 11
Reached end on node 6
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
Loaded checkpoint at epoch 0 and step 381
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 7
Reached 1 on node 8
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 8Reached 2 on node 7

Reached 1.4 on node 8
Reached 1 on node 10Reached 2 on node 8

Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 11
Reached 1 on node 9
Reached 1.4 on node 9Reached 1.4 on node 11

Reached 2 on node 9
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 1 on node 8
Reached 2 on node 7
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 10
Reached 1 on node 6
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 8
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7Reached 1.4 on node 8

Reached 3 on node 7
Reached 2 on node 8
Reached 5 on node 7
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9Reached 1.4 on node 11

Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 1 on node 10Reached 5 on node 8

Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 9
Reached 1 on node 11
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 11
Reached 3 on node 9
Reached 2 on node 11Reached 3 on node 9

Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 1 on node 11
Reached 3 on node 10
Reached 5 on node 10
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 6
Reached end on node 7
Reached end on node 8
Reached end on node 9
Reached end on node 10
Reached end on node 11
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 7
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 6
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 11
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 11
Reached 1 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 1 on node 7
Reached 1 on node 11
Reached 1 on node 6
Reached 1 on node 10
Reached 1 on node 9
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 11
Reached 2 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 1.4 on node 9
Reached 2 on node 9
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 1 on node 8
Reached 1.4 on node 8
Reached 2 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 3 on node 8
Reached 5 on node 8
Reached end on node 8
Reached 1 on node 9
Reached 1.4 on node 9
Reached 2 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 3 on node 9
Reached 5 on node 9
Reached end on node 9
Reached 1 on node 6
Reached 1 on node 11
Reached 1.4 on node 6
Reached 2 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 3 on node 6
Reached 5 on node 6
Reached 1.4 on node 11
Reached 2 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 3 on node 11
Reached 5 on node 11
Reached end on node 6
Reached end on node 11
Reached 1 on node 7
Reached 1 on node 10
Reached 1.4 on node 7
Reached 2 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 3 on node 7
Reached 5 on node 7
Reached 1.4 on node 10
Reached 2 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 3 on node 10
Reached 5 on node 10
Reached end on node 7
Reached end on node 10
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <381/2280>] - Data(s): 7.353 (5.365) - Batch(s): 10.570 
(10.597) - AE Loss: 201023.266 (516901.969) - AE Rec Loss: 1.363 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 4.873 (5.365) - Batch(s): 10.569 
(10.597) - AE Loss: 279920.125 (516901.969) - AE Rec Loss: 1.898 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 5.794 (5.365) - Batch(s): 10.558 
(10.597) - AE Loss: 1571393.125 (516901.969) - AE Rec Loss: 10.657 (3.505) - 
Disc Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 6.127 (5.365) - Batch(s): 10.545 
(10.597) - AE Loss: 1674047.000 (516901.969) - AE Rec Loss: 11.353 (3.505) - 
Disc Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 6.136 (5.365) - Batch(s): 10.565 
(10.597) - AE Loss: 266680.156 (516901.969) - AE Rec Loss: 1.809 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <381/2280>] - Data(s): 4.282 (5.365) - Batch(s): 10.567 
(10.597) - AE Loss: 111748.055 (516901.969) - AE Rec Loss: 0.758 (3.505) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.567 
(5.579) - AE Loss: 184578.797 (588137.062) - AE Rec Loss: 1.252 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.562 
(5.579) - AE Loss: 1422094.750 (588137.062) - AE Rec Loss: 9.644 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.001 (2.683) - Batch(s): 0.561 
(5.579) - AE Loss: 131638.906 (588137.062) - AE Rec Loss: 0.893 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.001 (2.683) - Batch(s): 0.561 
(5.579) - AE Loss: 1560411.500 (588137.062) - AE Rec Loss: 10.582 (3.989) - Disc
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.001 (2.683) - Batch(s): 0.563 
(5.579) - AE Loss: 1805076.500 (588137.062) - AE Rec Loss: 12.241 (3.989) - Disc
Loss: 0.000 (0.000) - 0.96 m remaining

[Epoch <000/100>: Step <382/2280>] - Data(s): 0.000 (2.683) - Batch(s): 0.551 
(5.579) - AE Loss: 102371.758 (588137.062) - AE Rec Loss: 0.694 (3.989) - Disc 
Loss: 0.000 (0.000) - 0.96 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.801 
(4.653) - AE Loss: 142144.516 (544804.250) - AE Rec Loss: 0.964 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.801 
(4.653) - AE Loss: 1362360.250 (544804.250) - AE Rec Loss: 9.239 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.001 (1.847) - Batch(s): 2.799 
(4.653) - AE Loss: 745439.875 (544804.250) - AE Rec Loss: 5.055 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.802 
(4.653) - AE Loss: 52754.621 (544804.250) - AE Rec Loss: 0.358 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 2.098 (1.847) - Batch(s): 2.802 
(4.653) - AE Loss: 147502.672 (544804.250) - AE Rec Loss: 1.000 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <383/2280>] - Data(s): 0.000 (1.847) - Batch(s): 2.799 
(4.653) - AE Loss: 171178.250 (544804.250) - AE Rec Loss: 1.161 (3.695) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.710 
(3.895) - AE Loss: 624800.125 (569826.750) - AE Rec Loss: 4.237 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.711 
(3.895) - AE Loss: 1485875.375 (569826.750) - AE Rec Loss: 10.077 (3.864) - Disc
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.708 
(3.895) - AE Loss: 137296.781 (569826.750) - AE Rec Loss: 0.931 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.707 
(3.895) - AE Loss: 54143.066 (569826.750) - AE Rec Loss: 0.367 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.698 
(3.895) - AE Loss: 286594.062 (569826.750) - AE Rec Loss: 1.944 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <384/2280>] - Data(s): 0.000 (1.410) - Batch(s): 1.714 
(3.895) - AE Loss: 654004.125 (569826.750) - AE Rec Loss: 4.435 (3.864) - Disc 
Loss: 0.000 (0.000) - 1.35 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.001 (1.128) - Batch(s): 0.562 
(3.228) - AE Loss: 133128.375 (630892.062) - AE Rec Loss: 0.903 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.001 (1.128) - Batch(s): 0.563 
(3.228) - AE Loss: 222710.312 (630892.062) - AE Rec Loss: 1.510 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.563 
(3.228) - AE Loss: 44931.973 (630892.062) - AE Rec Loss: 0.305 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.001 (1.128) - Batch(s): 0.563 
(3.228) - AE Loss: 85627.125 (630892.062) - AE Rec Loss: 0.581 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.569 
(3.228) - AE Loss: 1904602.125 (630892.062) - AE Rec Loss: 12.916 (4.279) - Disc
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <385/2280>] - Data(s): 0.000 (1.128) - Batch(s): 0.553 
(3.228) - AE Loss: 72821.086 (630892.062) - AE Rec Loss: 0.494 (4.279) - Disc 
Loss: 0.000 (0.000) - 1.40 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.689 
(2.805) - AE Loss: 136399.703 (566632.125) - AE Rec Loss: 0.925 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 95565.102 (566632.125) - AE Rec Loss: 0.648 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.691 
(2.805) - AE Loss: 106544.250 (566632.125) - AE Rec Loss: 0.723 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.690 
(2.805) - AE Loss: 201264.547 (566632.125) - AE Rec Loss: 1.365 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.691 
(2.805) - AE Loss: 328629.312 (566632.125) - AE Rec Loss: 2.229 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <386/2280>] - Data(s): 0.000 (0.940) - Batch(s): 0.691 
(2.805) - AE Loss: 64805.852 (566632.125) - AE Rec Loss: 0.439 (3.843) - Disc 
Loss: 0.000 (0.000) - 1.47 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.656 
(2.776) - AE Loss: 77552.906 (586097.125) - AE Rec Loss: 0.526 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.662 
(2.776) - AE Loss: 268423.281 (586097.125) - AE Rec Loss: 1.820 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.655 
(2.776) - AE Loss: 271461.156 (586097.125) - AE Rec Loss: 1.841 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.001 (0.845) - Batch(s): 2.647 
(2.776) - AE Loss: 1702693.250 (586097.125) - AE Rec Loss: 11.547 (3.975) - Disc
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.659 
(2.776) - AE Loss: 242898.000 (586097.125) - AE Rec Loss: 1.647 (3.975) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <387/2280>] - Data(s): 0.000 (0.845) - Batch(s): 2.659 
(2.776) - AE Loss: 1791486.000 (586097.125) - AE Rec Loss: 12.149 (3.975) - Disc
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.552 
(2.499) - AE Loss: 182194.391 (604359.938) - AE Rec Loss: 1.236 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.564 
(2.499) - AE Loss: 350682.344 (604359.938) - AE Rec Loss: 2.378 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.570 
(2.499) - AE Loss: 1625929.250 (604359.938) - AE Rec Loss: 11.027 (4.099) - Disc
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.001 (0.740) - Batch(s): 0.563 
(2.499) - AE Loss: 247120.703 (604359.938) - AE Rec Loss: 1.676 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.000 (0.740) - Batch(s): 0.563 
(2.499) - AE Loss: 1323085.250 (604359.938) - AE Rec Loss: 8.973 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <388/2280>] - Data(s): 0.001 (0.740) - Batch(s): 0.563 
(2.499) - AE Loss: 138307.469 (604359.938) - AE Rec Loss: 0.938 (4.099) - Disc 
Loss: 0.000 (0.000) - 1.75 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.715 
(2.301) - AE Loss: 103269.609 (567768.250) - AE Rec Loss: 0.700 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.715 
(2.301) - AE Loss: 174752.516 (567768.250) - AE Rec Loss: 1.185 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.714 
(2.301) - AE Loss: 256914.000 (567768.250) - AE Rec Loss: 1.742 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.001 (0.657) - Batch(s): 0.714 
(2.301) - AE Loss: 70260.406 (567768.250) - AE Rec Loss: 0.476 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.715 
(2.301) - AE Loss: 190285.266 (567768.250) - AE Rec Loss: 1.290 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <389/2280>] - Data(s): 0.000 (0.657) - Batch(s): 0.714 
(2.301) - AE Loss: 103359.672 (567768.250) - AE Rec Loss: 0.701 (3.850) - Disc 
Loss: 0.000 (0.000) - 1.81 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.001 (0.633) - Batch(s): 3.454 
(2.409) - AE Loss: 300529.469 (577613.188) - AE Rec Loss: 2.038 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.000 (0.633) - Batch(s): 3.463 
(2.409) - AE Loss: 1846103.375 (577613.188) - AE Rec Loss: 12.520 (3.917) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.001 (0.633) - Batch(s): 3.470 
(2.409) - AE Loss: 1366108.500 (577613.188) - AE Rec Loss: 9.265 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.000 (0.633) - Batch(s): 3.466 
(2.409) - AE Loss: 157512.516 (577613.188) - AE Rec Loss: 1.068 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.000 (0.633) - Batch(s): 3.465 
(2.409) - AE Loss: 43406.031 (577613.188) - AE Rec Loss: 0.294 (3.917) - Disc 
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <390/2280>] - Data(s): 0.000 (0.633) - Batch(s): 3.465 
(2.409) - AE Loss: 1587790.750 (577613.188) - AE Rec Loss: 10.768 (3.917) - Disc
Loss: 0.000 (0.000) - 2.10 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.270 
(2.300) - AE Loss: 136433.797 (578191.250) - AE Rec Loss: 0.925 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.270 
(2.300) - AE Loss: 249362.734 (578191.250) - AE Rec Loss: 1.691 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.268 
(2.300) - AE Loss: 110727.750 (578191.250) - AE Rec Loss: 0.751 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.259 
(2.300) - AE Loss: 149486.062 (578191.250) - AE Rec Loss: 1.014 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.274 
(2.300) - AE Loss: 355063.312 (578191.250) - AE Rec Loss: 2.408 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <391/2280>] - Data(s): 0.000 (0.576) - Batch(s): 1.270 
(2.300) - AE Loss: 1333029.375 (578191.250) - AE Rec Loss: 9.040 (3.921) - Disc 
Loss: 0.000 (0.000) - 2.21 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.697 
(2.166) - AE Loss: 868391.625 (586092.750) - AE Rec Loss: 5.889 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.000 (0.528) - Batch(s): 0.699 
(2.166) - AE Loss: 315315.719 (586092.750) - AE Rec Loss: 2.138 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.699 
(2.166) - AE Loss: 158230.547 (586092.750) - AE Rec Loss: 1.073 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.000 (0.528) - Batch(s): 0.699 
(2.166) - AE Loss: 131458.781 (586092.750) - AE Rec Loss: 0.892 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.000 (0.528) - Batch(s): 0.699 
(2.166) - AE Loss: 1353964.125 (586092.750) - AE Rec Loss: 9.182 (3.975) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <392/2280>] - Data(s): 0.001 (0.528) - Batch(s): 0.698 
(2.166) - AE Loss: 1503719.000 (586092.750) - AE Rec Loss: 10.198 (3.975) - Disc
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.001 (0.524) - Batch(s): 3.684 
(2.274) - AE Loss: 208136.016 (590293.438) - AE Rec Loss: 1.412 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.001 (0.524) - Batch(s): 3.675 
(2.274) - AE Loss: 148281.797 (590293.438) - AE Rec Loss: 1.006 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.001 (0.524) - Batch(s): 3.687 
(2.274) - AE Loss: 62871.906 (590293.438) - AE Rec Loss: 0.426 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 1.585 (0.524) - Batch(s): 3.687 
(2.274) - AE Loss: 119382.219 (590293.438) - AE Rec Loss: 0.810 (4.003) - Disc 
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.001 (0.524) - Batch(s): 3.688 
(2.274) - AE Loss: 1821971.000 (590293.438) - AE Rec Loss: 12.356 (4.003) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <393/2280>] - Data(s): 0.000 (0.524) - Batch(s): 3.692 
(2.274) - AE Loss: 1760859.000 (590293.438) - AE Rec Loss: 11.942 (4.003) - Disc
Loss: 0.000 (0.000) - 2.57 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.590 
(2.206) - AE Loss: 129072.727 (602629.250) - AE Rec Loss: 0.875 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.230 
(2.206) - AE Loss: 82923.391 (602629.250) - AE Rec Loss: 0.562 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.230 
(2.206) - AE Loss: 1683399.500 (602629.250) - AE Rec Loss: 11.416 (4.087) - Disc
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.584 
(2.206) - AE Loss: 289143.750 (602629.250) - AE Rec Loss: 1.961 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 0.000 (0.493) - Batch(s): 1.230 
(2.206) - AE Loss: 1402184.500 (602629.250) - AE Rec Loss: 9.509 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <394/2280>] - Data(s): 1.024 (0.493) - Batch(s): 1.586 
(2.206) - AE Loss: 1437050.500 (602629.250) - AE Rec Loss: 9.746 (4.087) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.703 
(2.106) - AE Loss: 1855686.750 (640502.688) - AE Rec Loss: 12.585 (4.344) - Disc
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.703 
(2.106) - AE Loss: 1422853.875 (640502.688) - AE Rec Loss: 9.649 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.704 
(2.106) - AE Loss: 1524026.875 (640502.688) - AE Rec Loss: 10.335 (4.344) - Disc
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.704 
(2.106) - AE Loss: 1292216.500 (640502.688) - AE Rec Loss: 8.763 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.000 (0.460) - Batch(s): 0.705 
(2.106) - AE Loss: 124617.430 (640502.688) - AE Rec Loss: 0.845 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <395/2280>] - Data(s): 0.001 (0.460) - Batch(s): 0.704 
(2.106) - AE Loss: 1413811.500 (640502.688) - AE Rec Loss: 9.588 (4.344) - Disc 
Loss: 0.000 (0.000) - 2.76 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.899 
(2.398) - AE Loss: 159397.344 (637554.812) - AE Rec Loss: 1.081 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.000 (0.469) - Batch(s): 6.903 
(2.398) - AE Loss: 1390552.500 (637554.812) - AE Rec Loss: 9.430 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.342 (0.469) - Batch(s): 6.898 
(2.398) - AE Loss: 47417.746 (637554.812) - AE Rec Loss: 0.322 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.001 (0.469) - Batch(s): 6.899 
(2.398) - AE Loss: 102622.500 (637554.812) - AE Rec Loss: 0.696 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.000 (0.469) - Batch(s): 6.887 
(2.398) - AE Loss: 66875.781 (637554.812) - AE Rec Loss: 0.454 (4.324) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <396/2280>] - Data(s): 0.000 (0.469) - Batch(s): 6.896 
(2.398) - AE Loss: 1501120.875 (637554.812) - AE Rec Loss: 10.180 (4.324) - Disc
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.417 (0.444) - Batch(s): 0.965 
(2.302) - AE Loss: 1624279.250 (666015.500) - AE Rec Loss: 11.015 (4.517) - Disc
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.978 
(2.302) - AE Loss: 1548649.125 (666015.500) - AE Rec Loss: 10.502 (4.517) - Disc
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.001 (0.444) - Batch(s): 0.978 
(2.302) - AE Loss: 70187.031 (666015.500) - AE Rec Loss: 0.476 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.974 
(2.302) - AE Loss: 116278.594 (666015.500) - AE Rec Loss: 0.789 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.981 
(2.302) - AE Loss: 118425.234 (666015.500) - AE Rec Loss: 0.803 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <397/2280>] - Data(s): 0.000 (0.444) - Batch(s): 0.620 
(2.302) - AE Loss: 62372.750 (666015.500) - AE Rec Loss: 0.423 (4.517) - Disc 
Loss: 0.000 (0.000) - 3.39 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.704 
(2.213) - AE Loss: 246459.312 (659795.875) - AE Rec Loss: 1.671 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.705 
(2.213) - AE Loss: 181773.938 (659795.875) - AE Rec Loss: 1.233 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.704 
(2.213) - AE Loss: 291999.156 (659795.875) - AE Rec Loss: 1.980 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.704 
(2.213) - AE Loss: 2896171.750 (659795.875) - AE Rec Loss: 19.641 (4.475) - Disc
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.000 (0.419) - Batch(s): 0.704 
(2.213) - AE Loss: 180024.359 (659795.875) - AE Rec Loss: 1.221 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <398/2280>] - Data(s): 0.001 (0.419) - Batch(s): 0.706 
(2.213) - AE Loss: 142747.141 (659795.875) - AE Rec Loss: 0.968 (4.475) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.566 
(2.126) - AE Loss: 1501974.000 (651952.500) - AE Rec Loss: 10.186 (4.421) - Disc
Loss: 0.000 (0.000) - 3.49 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.554 
(2.126) - AE Loss: 302949.250 (651952.500) - AE Rec Loss: 2.055 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.574 
(2.126) - AE Loss: 1477087.250 (651952.500) - AE Rec Loss: 10.017 (4.421) - Disc
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.565 
(2.126) - AE Loss: 73945.000 (651952.500) - AE Rec Loss: 0.501 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.001 (0.397) - Batch(s): 0.567 
(2.126) - AE Loss: 272355.875 (651952.500) - AE Rec Loss: 1.847 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <399/2280>] - Data(s): 0.000 (0.397) - Batch(s): 0.565 
(2.126) - AE Loss: 371036.188 (651952.500) - AE Rec Loss: 2.516 (4.421) - Disc 
Loss: 0.000 (0.000) - 3.50 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.623 
(2.341) - AE Loss: 538539.000 (657132.875) - AE Rec Loss: 3.652 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.619 
(2.341) - AE Loss: 258998.953 (657132.875) - AE Rec Loss: 1.756 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 6.048 (0.402) - Batch(s): 6.610 
(2.341) - AE Loss: 58135.656 (657132.875) - AE Rec Loss: 0.394 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.001 (0.402) - Batch(s): 6.615 
(2.341) - AE Loss: 2888751.500 (657132.875) - AE Rec Loss: 19.591 (4.456) - Disc
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.263 
(2.341) - AE Loss: 149205.531 (657132.875) - AE Rec Loss: 1.012 (4.456) - Disc 
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <400/2280>] - Data(s): 0.000 (0.402) - Batch(s): 6.618 
(2.341) - AE Loss: 1887744.875 (657132.875) - AE Rec Loss: 12.802 (4.456) - Disc
Loss: 0.000 (0.000) - 4.01 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.615 
(2.957) - AE Loss: 1388174.750 (652401.750) - AE Rec Loss: 9.414 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.612 
(2.957) - AE Loss: 175509.031 (652401.750) - AE Rec Loss: 1.190 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.612 
(2.957) - AE Loss: 589374.125 (652401.750) - AE Rec Loss: 3.997 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.612 
(2.957) - AE Loss: 108159.875 (652401.750) - AE Rec Loss: 0.734 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.612 
(2.957) - AE Loss: 395379.062 (652401.750) - AE Rec Loss: 2.681 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 0.000 (0.383) - Batch(s): 16.612 
(2.957) - AE Loss: 1336290.125 (652401.750) - AE Rec Loss: 9.062 (4.424) - Disc 
Loss: 0.000 (0.000) - 5.31 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.565 
(2.848) - AE Loss: 155659.750 (666141.000) - AE Rec Loss: 1.056 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.563 
(2.848) - AE Loss: 2028000.500 (666141.000) - AE Rec Loss: 13.753 (4.518) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.573 
(2.848) - AE Loss: 428377.281 (666141.000) - AE Rec Loss: 2.905 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.552 
(2.848) - AE Loss: 2792752.000 (666141.000) - AE Rec Loss: 18.940 (4.518) - Disc
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.564 
(2.848) - AE Loss: 257212.031 (666141.000) - AE Rec Loss: 1.744 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (0.366) - Batch(s): 0.566 
(2.848) - AE Loss: 172331.328 (666141.000) - AE Rec Loss: 1.169 (4.518) - Disc 
Loss: 0.000 (0.000) - 5.35 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:36:49,894[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:49,899[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:49,919[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:49,952[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:50,262[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:36:50,334[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:36:52,106[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:52,124[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:52,143[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:52,196[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:52,482[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:36:52,527[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:52,657[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:52,675[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:52,693[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:36:52,742[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:36:53,035[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 05:36:53,044[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 05:36:53,047[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
[[36m2023-11-29 05:36:53,051[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
=> Preparing model 
=> Mixed precision: no
=> Running in inference mode: False
=> Instantiating train dataloader 
len(train_dataset) = 54706
[[36m2023-11-29 05:36:53,052[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Mixed precision: no
len(valid_dataloader) = 1
=> Running in inference mode: False
[[36m2023-11-29 05:36:53,054[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataset) = 54706
=> Mixed precision: no
[[36m2023-11-29 05:36:53,055[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Running in inference mode: False
=> Preparing opt_disc 
=> Preparing model 
=> Instantiating train dataloader 
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
[[36m2023-11-29 05:36:53,057[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
len(train_dataset) = 54706
len(valid_dataset) = 4
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Mixed precision: no
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataset) = 54706
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataset) = 4
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 6.801 (5.614) - Batch(s): 11.244 
(11.536) - AE Loss: 1388652.125 (557930.312) - AE Rec Loss: 9.417 (3.784) - Disc
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 9.893 (5.614) - Batch(s): 11.223 
(11.536) - AE Loss: 1336235.125 (557930.312) - AE Rec Loss: 9.062 (3.784) - Disc
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 4.410 (5.614) - Batch(s): 11.249 
(11.536) - AE Loss: 174826.688 (557930.312) - AE Rec Loss: 1.186 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 6.020 (5.614) - Batch(s): 11.213 
(11.536) - AE Loss: 590316.125 (557930.312) - AE Rec Loss: 4.003 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.069 (5.614) - Batch(s): 11.215 
(11.536) - AE Loss: 108457.477 (557930.312) - AE Rec Loss: 0.736 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 2.507 (5.614) - Batch(s): 11.232 
(11.536) - AE Loss: 395458.812 (557930.312) - AE Rec Loss: 2.682 (3.784) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.553 
(6.470) - AE Loss: 165933.281 (762580.312) - AE Rec Loss: 1.125 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.541 
(6.470) - AE Loss: 2796671.750 (762580.312) - AE Rec Loss: 18.966 (5.172) - Disc
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.849) - Batch(s): 1.551 
(6.470) - AE Loss: 287471.812 (762580.312) - AE Rec Loss: 1.950 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.849) - Batch(s): 1.552 
(6.470) - AE Loss: 182263.609 (762580.312) - AE Rec Loss: 1.236 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.02 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.550 
(6.470) - AE Loss: 2049332.250 (762580.312) - AE Rec Loss: 13.898 (5.172) - Disc
Loss: 0.000 (0.000) - 1.03 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.849) - Batch(s): 1.556 
(6.470) - AE Loss: 434684.906 (762580.312) - AE Rec Loss: 2.948 (5.172) - Disc 
Loss: 0.000 (0.000) - 1.03 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 2.369 (1.965) - Batch(s): 3.005 
(5.315) - AE Loss: 1638389.750 (836624.250) - AE Rec Loss: 11.111 (5.674) - Disc
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.965) - Batch(s): 3.006 
(5.315) - AE Loss: 1838109.000 (836624.250) - AE Rec Loss: 12.465 (5.674) - Disc
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.005 
(5.315) - AE Loss: 1463546.500 (836624.250) - AE Rec Loss: 9.925 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.006 
(5.315) - AE Loss: 356494.156 (836624.250) - AE Rec Loss: 2.418 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.005 
(5.315) - AE Loss: 160788.625 (836624.250) - AE Rec Loss: 1.090 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.965) - Batch(s): 3.005 
(5.315) - AE Loss: 195000.938 (836624.250) - AE Rec Loss: 1.322 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.552 
(4.127) - AE Loss: 1486345.250 (813387.312) - AE Rec Loss: 10.080 (5.516) - Disc
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.562 
(4.127) - AE Loss: 171083.922 (813387.312) - AE Rec Loss: 1.160 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.563 
(4.127) - AE Loss: 174283.172 (813387.312) - AE Rec Loss: 1.182 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.561 
(4.127) - AE Loss: 58029.832 (813387.312) - AE Rec Loss: 0.394 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.570 
(4.127) - AE Loss: 610249.312 (813387.312) - AE Rec Loss: 4.139 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.474) - Batch(s): 0.563 
(4.127) - AE Loss: 125305.289 (813387.312) - AE Rec Loss: 0.850 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.552 
(3.414) - AE Loss: 101632.602 (763805.375) - AE Rec Loss: 0.689 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.001 (1.179) - Batch(s): 0.563 
(3.414) - AE Loss: 238314.703 (763805.375) - AE Rec Loss: 1.616 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.569 
(3.414) - AE Loss: 1332191.000 (763805.375) - AE Rec Loss: 9.034 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.563 
(3.414) - AE Loss: 1393356.750 (763805.375) - AE Rec Loss: 9.449 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.563 
(3.414) - AE Loss: 147280.016 (763805.375) - AE Rec Loss: 0.999 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.179) - Batch(s): 0.561 
(3.414) - AE Loss: 1539324.000 (763805.375) - AE Rec Loss: 10.439 (5.180) - Disc
Loss: 0.000 (0.000) - 1.37 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.967 
(3.506) - AE Loss: 201768.609 (726684.875) - AE Rec Loss: 1.368 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 3.336 (1.044) - Batch(s): 3.969 
(3.506) - AE Loss: 161627.812 (726684.875) - AE Rec Loss: 1.096 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.968 
(3.506) - AE Loss: 1708867.000 (726684.875) - AE Rec Loss: 11.589 (4.928) - Disc
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.969 
(3.506) - AE Loss: 79792.117 (726684.875) - AE Rec Loss: 0.541 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.968 
(3.506) - AE Loss: 217195.906 (726684.875) - AE Rec Loss: 1.473 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.044) - Batch(s): 3.968 
(3.506) - AE Loss: 510613.781 (726684.875) - AE Rec Loss: 3.463 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.68 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.563 
(3.086) - AE Loss: 419449.969 (706232.188) - AE Rec Loss: 2.845 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.001 (0.895) - Batch(s): 0.569 
(3.086) - AE Loss: 145393.672 (706232.188) - AE Rec Loss: 0.986 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.563 
(3.086) - AE Loss: 118225.492 (706232.188) - AE Rec Loss: 0.802 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.001 (0.895) - Batch(s): 0.562 
(3.086) - AE Loss: 173493.719 (706232.188) - AE Rec Loss: 1.177 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.001 (0.895) - Batch(s): 0.563 
(3.086) - AE Loss: 155497.625 (706232.188) - AE Rec Loss: 1.055 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.895) - Batch(s): 0.552 
(3.086) - AE Loss: 99383.438 (706232.188) - AE Rec Loss: 0.674 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.73 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.783) - Batch(s): 0.563 
(2.770) - AE Loss: 68375.469 (655757.688) - AE Rec Loss: 0.464 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.552 
(2.770) - AE Loss: 110310.633 (655757.688) - AE Rec Loss: 0.748 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.563 
(2.770) - AE Loss: 233667.703 (655757.688) - AE Rec Loss: 1.585 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.571 
(2.770) - AE Loss: 106065.211 (655757.688) - AE Rec Loss: 0.719 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.783) - Batch(s): 0.565 
(2.770) - AE Loss: 306959.531 (655757.688) - AE Rec Loss: 2.082 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.783) - Batch(s): 0.563 
(2.770) - AE Loss: 191842.797 (655757.688) - AE Rec Loss: 1.301 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.78 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.049 
(4.690) - AE Loss: 174008.312 (626139.688) - AE Rec Loss: 1.180 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.050 
(4.690) - AE Loss: 103381.867 (626139.688) - AE Rec Loss: 0.701 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.001 (1.122) - Batch(s): 20.049 
(4.690) - AE Loss: 56718.184 (626139.688) - AE Rec Loss: 0.385 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.050 
(4.690) - AE Loss: 266677.250 (626139.688) - AE Rec Loss: 1.809 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.050 
(4.690) - AE Loss: 1361076.125 (626139.688) - AE Rec Loss: 9.230 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.32 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (1.122) - Batch(s): 20.051 
(4.690) - AE Loss: 405185.906 (626139.688) - AE Rec Loss: 2.748 (4.246) - Disc 
Loss: 0.000 (0.000) - 3.31 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.669 
(4.377) - AE Loss: 116937.758 (599013.562) - AE Rec Loss: 0.793 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (1.019) - Batch(s): 1.683 
(4.377) - AE Loss: 245293.516 (599013.562) - AE Rec Loss: 1.664 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.678 
(4.377) - AE Loss: 221729.703 (599013.562) - AE Rec Loss: 1.504 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.680 
(4.377) - AE Loss: 154581.172 (599013.562) - AE Rec Loss: 1.048 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.685 
(4.377) - AE Loss: 1658481.500 (599013.562) - AE Rec Loss: 11.247 (4.062) - Disc
Loss: 0.000 (0.000) - 3.45 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (1.019) - Batch(s): 1.681 
(4.377) - AE Loss: 111663.523 (599013.562) - AE Rec Loss: 0.757 (4.062) - Disc 
Loss: 0.000 (0.000) - 3.44 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.324 
(4.641) - AE Loss: 67697.094 (595574.938) - AE Rec Loss: 0.459 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.310 
(4.641) - AE Loss: 76725.320 (595574.938) - AE Rec Loss: 0.520 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.321 
(4.641) - AE Loss: 1796696.000 (595574.938) - AE Rec Loss: 12.185 (4.039) - Disc
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.320 
(4.641) - AE Loss: 175885.547 (595574.938) - AE Rec Loss: 1.193 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.326 
(4.641) - AE Loss: 113707.992 (595574.938) - AE Rec Loss: 0.771 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.980) - Batch(s): 7.322 
(4.641) - AE Loss: 1442905.125 (595574.938) - AE Rec Loss: 9.785 (4.039) - Disc 
Loss: 0.000 (0.000) - 4.00 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:39:54,606[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,775[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,877[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,916[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,937[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:39:54,991[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:39:56,859[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:56,980[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:57,070[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:57,090[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:57,147[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:39:57,216[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,416[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
[[36m2023-11-29 05:39:57,424[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,577[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,649[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:39:57,714[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 05:39:57,729[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:39:57,735[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Running in inference mode: False
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataset) = 54706
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
=> Instantiating valid dataloader 
=> Instantiating valid dataloader 
=> Instantiating the optimizer 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
len(train_dataloader) = 2279
len(valid_dataset) = 4
len(valid_dataset) = 4
batch_size = 2, learning rate = 4.5e-06
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Preparing opt_disc 
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Instantiating the optimizer 
=> Preparing model 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Instantiating the optimizer 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing model 
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 6.118 (5.421) - Batch(s): 10.629 
(10.632) - AE Loss: 589684.812 (558156.438) - AE Rec Loss: 3.999 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.85 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.303 (5.421) - Batch(s): 10.539 
(10.632) - AE Loss: 108519.703 (558156.438) - AE Rec Loss: 0.736 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 7.097 (5.421) - Batch(s): 10.539 
(10.632) - AE Loss: 1388902.125 (558156.438) - AE Rec Loss: 9.419 (3.785) - Disc
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 9.387 (5.421) - Batch(s): 10.864 
(10.632) - AE Loss: 1335940.875 (558156.438) - AE Rec Loss: 9.060 (3.785) - Disc
Loss: 0.000 (0.000) - 0.87 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 2.658 (5.421) - Batch(s): 10.638 
(10.632) - AE Loss: 395910.125 (558156.438) - AE Rec Loss: 2.685 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.85 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 4.071 (5.421) - Batch(s): 10.518 
(10.632) - AE Loss: 175578.250 (558156.438) - AE Rec Loss: 1.191 (3.785) - Disc 
Loss: 0.000 (0.000) - 0.84 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.562 
(5.597) - AE Loss: 287735.250 (762760.312) - AE Rec Loss: 1.951 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.711) - Batch(s): 0.564 
(5.597) - AE Loss: 166180.625 (762760.312) - AE Rec Loss: 1.127 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.90 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.551 
(5.597) - AE Loss: 2796600.000 (762760.312) - AE Rec Loss: 18.966 (5.173) - Disc
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.566 
(5.597) - AE Loss: 182250.797 (762760.312) - AE Rec Loss: 1.236 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.711) - Batch(s): 0.568 
(5.597) - AE Loss: 434238.938 (762760.312) - AE Rec Loss: 2.945 (5.173) - Disc 
Loss: 0.000 (0.000) - 0.89 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.001 (2.711) - Batch(s): 0.561 
(5.597) - AE Loss: 2048390.375 (762760.312) - AE Rec Loss: 13.892 (5.173) - Disc
Loss: 0.000 (0.000) - 0.90 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.896) - Batch(s): 3.879 
(5.024) - AE Loss: 356747.938 (836722.125) - AE Rec Loss: 2.419 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.896) - Batch(s): 3.879 
(5.024) - AE Loss: 1463656.875 (836722.125) - AE Rec Loss: 9.926 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.896) - Batch(s): 3.879 
(5.024) - AE Loss: 1837764.750 (836722.125) - AE Rec Loss: 12.463 (5.674) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.896) - Batch(s): 3.880 
(5.024) - AE Loss: 195119.734 (836722.125) - AE Rec Loss: 1.323 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.20 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 3.205 (1.896) - Batch(s): 3.880 
(5.024) - AE Loss: 1638015.250 (836722.125) - AE Rec Loss: 11.109 (5.674) - Disc
Loss: 0.000 (0.000) - 1.23 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.896) - Batch(s): 3.880 
(5.024) - AE Loss: 160262.047 (836722.125) - AE Rec Loss: 1.087 (5.674) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.562 
(3.909) - AE Loss: 170364.062 (813430.000) - AE Rec Loss: 1.155 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.563 
(3.909) - AE Loss: 125121.383 (813430.000) - AE Rec Loss: 0.849 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.564 
(3.909) - AE Loss: 174148.734 (813430.000) - AE Rec Loss: 1.181 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.550 
(3.909) - AE Loss: 1485961.875 (813430.000) - AE Rec Loss: 10.077 (5.516) - Disc
Loss: 0.000 (0.000) - 1.28 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.561 
(3.909) - AE Loss: 57902.980 (813430.000) - AE Rec Loss: 0.393 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.422) - Batch(s): 0.570 
(3.909) - AE Loss: 610460.625 (813430.000) - AE Rec Loss: 4.140 (5.516) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.563 
(3.240) - AE Loss: 240865.734 (763855.188) - AE Rec Loss: 1.633 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.562 
(3.240) - AE Loss: 1393713.375 (763855.188) - AE Rec Loss: 9.452 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.001 (1.138) - Batch(s): 0.551 
(3.240) - AE Loss: 101259.773 (763855.188) - AE Rec Loss: 0.687 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.34 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.561 
(3.240) - AE Loss: 1539032.375 (763855.188) - AE Rec Loss: 10.437 (5.180) - Disc
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.563 
(3.240) - AE Loss: 147141.406 (763855.188) - AE Rec Loss: 0.998 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.138) - Batch(s): 0.569 
(3.240) - AE Loss: 1331777.000 (763855.188) - AE Rec Loss: 9.032 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.503 
(3.284) - AE Loss: 201125.453 (726732.125) - AE Rec Loss: 1.364 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.504 
(3.284) - AE Loss: 511463.562 (726732.125) - AE Rec Loss: 3.469 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.505 
(3.284) - AE Loss: 1709679.125 (726732.125) - AE Rec Loss: 11.595 (4.928) - Disc
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 2.217 (1.018) - Batch(s): 3.504 
(3.284) - AE Loss: 161636.000 (726732.125) - AE Rec Loss: 1.096 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.506 
(3.284) - AE Loss: 80025.758 (726732.125) - AE Rec Loss: 0.543 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.59 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.018) - Batch(s): 3.506 
(3.284) - AE Loss: 216727.859 (726732.125) - AE Rec Loss: 1.470 (4.928) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.564 
(2.895) - AE Loss: 419430.688 (706248.500) - AE Rec Loss: 2.844 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.553 
(2.895) - AE Loss: 98833.242 (706248.500) - AE Rec Loss: 0.670 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.570 
(2.895) - AE Loss: 144935.891 (706248.500) - AE Rec Loss: 0.983 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.564 
(2.895) - AE Loss: 117537.695 (706248.500) - AE Rec Loss: 0.797 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.64 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.562 
(2.895) - AE Loss: 155587.109 (706248.500) - AE Rec Loss: 1.055 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.873) - Batch(s): 0.562 
(2.895) - AE Loss: 174116.281 (706248.500) - AE Rec Loss: 1.181 (4.790) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.764) - Batch(s): 0.565 
(2.604) - AE Loss: 68344.852 (655752.750) - AE Rec Loss: 0.463 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.764) - Batch(s): 0.565 
(2.604) - AE Loss: 233527.641 (655752.750) - AE Rec Loss: 1.584 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.570 
(2.604) - AE Loss: 106317.305 (655752.750) - AE Rec Loss: 0.721 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.562 
(2.604) - AE Loss: 192112.656 (655752.750) - AE Rec Loss: 1.303 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.764) - Batch(s): 0.554 
(2.604) - AE Loss: 109682.836 (655752.750) - AE Rec Loss: 0.744 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.001 (0.764) - Batch(s): 0.566 
(2.604) - AE Loss: 306468.438 (655752.750) - AE Rec Loss: 2.078 (4.447) - Disc 
Loss: 0.000 (0.000) - 1.69 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.248 (0.711) - Batch(s): 3.844 
(2.742) - AE Loss: 265939.062 (626104.125) - AE Rec Loss: 1.804 (4.246) - Disc 
Loss: 0.000 (0.000) - 2.01 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.844 
(2.742) - AE Loss: 405077.531 (626104.125) - AE Rec Loss: 2.747 (4.246) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 102997.805 (626104.125) - AE Rec Loss: 0.698 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.845 
(2.742) - AE Loss: 1361542.500 (626104.125) - AE Rec Loss: 9.234 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.846 
(2.742) - AE Loss: 173774.641 (626104.125) - AE Rec Loss: 1.178 (4.246) - Disc 
Loss: 0.000 (0.000) - 2.00 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.711) - Batch(s): 3.846 
(2.742) - AE Loss: 56363.250 (626104.125) - AE Rec Loss: 0.382 (4.246) - Disc 
Loss: 0.000 (0.000) - 1.99 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.552 
(2.524) - AE Loss: 116974.234 (598961.438) - AE Rec Loss: 0.793 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.06 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.564 
(2.524) - AE Loss: 111154.055 (598961.438) - AE Rec Loss: 0.754 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.05 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.564 
(2.524) - AE Loss: 245073.016 (598961.438) - AE Rec Loss: 1.662 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.571 
(2.524) - AE Loss: 1658333.500 (598961.438) - AE Rec Loss: 11.246 (4.062) - Disc
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.565 
(2.524) - AE Loss: 154224.516 (598961.438) - AE Rec Loss: 1.046 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.04 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.640) - Batch(s): 0.562 
(2.524) - AE Loss: 222994.203 (598961.438) - AE Rec Loss: 1.512 (4.062) - Disc 
Loss: 0.000 (0.000) - 2.05 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.590) - Batch(s): 1.519 
(2.420) - AE Loss: 175291.844 (595524.625) - AE Rec Loss: 1.189 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.590) - Batch(s): 1.520 
(2.420) - AE Loss: 1796869.250 (595524.625) - AE Rec Loss: 12.186 (4.039) - Disc
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.590) - Batch(s): 1.509 
(2.420) - AE Loss: 75704.016 (595524.625) - AE Rec Loss: 0.513 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.18 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.590) - Batch(s): 1.521 
(2.420) - AE Loss: 67405.953 (595524.625) - AE Rec Loss: 0.457 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.590) - Batch(s): 1.526 
(2.420) - AE Loss: 114110.734 (595524.625) - AE Rec Loss: 0.774 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.16 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.590) - Batch(s): 1.522 
(2.420) - AE Loss: 1442512.125 (595524.625) - AE Rec Loss: 9.783 (4.039) - Disc 
Loss: 0.000 (0.000) - 2.17 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 1.102 (0.558) - Batch(s): 2.060 
(2.390) - AE Loss: 67125.109 (656665.875) - AE Rec Loss: 0.455 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.34 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.059 
(2.390) - AE Loss: 153793.125 (656665.875) - AE Rec Loss: 1.043 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.059 
(2.390) - AE Loss: 1406561.750 (656665.875) - AE Rec Loss: 9.539 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.059 
(2.390) - AE Loss: 1548442.875 (656665.875) - AE Rec Loss: 10.501 (4.453) - Disc
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.001 (0.558) - Batch(s): 2.058 
(2.390) - AE Loss: 176596.109 (656665.875) - AE Rec Loss: 1.198 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.32 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.558) - Batch(s): 2.060 
(2.390) - AE Loss: 1302664.250 (656665.875) - AE Rec Loss: 8.834 (4.453) - Disc 
Loss: 0.000 (0.000) - 2.33 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 4.072 
(2.510) - AE Loss: 1471977.000 (639855.188) - AE Rec Loss: 9.982 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 4.059 
(2.510) - AE Loss: 1446398.500 (639855.188) - AE Rec Loss: 9.809 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.66 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 4.068 
(2.510) - AE Loss: 619888.188 (639855.188) - AE Rec Loss: 4.204 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.537) - Batch(s): 4.076 
(2.510) - AE Loss: 92056.664 (639855.188) - AE Rec Loss: 0.624 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.001 (0.537) - Batch(s): 4.072 
(2.510) - AE Loss: 148060.812 (639855.188) - AE Rec Loss: 1.004 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.001 (0.537) - Batch(s): 4.071 
(2.510) - AE Loss: 194994.219 (639855.188) - AE Rec Loss: 1.322 (4.339) - Disc 
Loss: 0.000 (0.000) - 2.63 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.552 
(2.371) - AE Loss: 101184.031 (651381.812) - AE Rec Loss: 0.686 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.70 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.562 
(2.371) - AE Loss: 422841.312 (651381.812) - AE Rec Loss: 2.868 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.001 (0.499) - Batch(s): 0.565 
(2.371) - AE Loss: 209523.797 (651381.812) - AE Rec Loss: 1.421 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.572 
(2.371) - AE Loss: 136239.500 (651381.812) - AE Rec Loss: 0.924 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.565 
(2.371) - AE Loss: 164973.859 (651381.812) - AE Rec Loss: 1.119 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.68 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.499) - Batch(s): 0.564 
(2.371) - AE Loss: 86094.516 (651381.812) - AE Rec Loss: 0.584 (4.417) - Disc 
Loss: 0.000 (0.000) - 2.69 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.653 
(2.257) - AE Loss: 133379.844 (657828.125) - AE Rec Loss: 0.905 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.466) - Batch(s): 0.653 
(2.257) - AE Loss: 1677381.125 (657828.125) - AE Rec Loss: 11.375 (4.461) - Disc
Loss: 0.000 (0.000) - 2.75 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.466) - Batch(s): 0.653 
(2.257) - AE Loss: 1509771.375 (657828.125) - AE Rec Loss: 10.239 (4.461) - Disc
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.653 
(2.257) - AE Loss: 418820.500 (657828.125) - AE Rec Loss: 2.840 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.74 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.466) - Batch(s): 0.653 
(2.257) - AE Loss: 141483.594 (657828.125) - AE Rec Loss: 0.959 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.466) - Batch(s): 0.654 
(2.257) - AE Loss: 272248.500 (657828.125) - AE Rec Loss: 1.846 (4.461) - Disc 
Loss: 0.000 (0.000) - 2.73 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.315 
(3.440) - AE Loss: 211898.156 (669995.312) - AE Rec Loss: 1.437 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.302 
(3.440) - AE Loss: 49538.918 (669995.312) - AE Rec Loss: 0.336 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.35 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.314 
(3.440) - AE Loss: 537292.500 (669995.312) - AE Rec Loss: 3.644 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.319 
(3.440) - AE Loss: 53644.684 (669995.312) - AE Rec Loss: 0.364 (4.544) - Disc 
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.001 (0.603) - Batch(s): 21.312 
(3.440) - AE Loss: 2915857.000 (669995.312) - AE Rec Loss: 19.774 (4.544) - Disc
Loss: 0.000 (0.000) - 4.33 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.603) - Batch(s): 21.315 
(3.440) - AE Loss: 1714271.875 (669995.312) - AE Rec Loss: 11.626 (4.544) - Disc
Loss: 0.000 (0.000) - 4.32 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.563 
(3.271) - AE Loss: 1501977.625 (672973.312) - AE Rec Loss: 10.186 (4.564) - Disc
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.565 
(3.271) - AE Loss: 57406.969 (672973.312) - AE Rec Loss: 0.389 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.553 
(3.271) - AE Loss: 1631770.500 (672973.312) - AE Rec Loss: 11.066 (4.564) - Disc
Loss: 0.000 (0.000) - 4.39 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.564 
(3.271) - AE Loss: 1654067.500 (672973.312) - AE Rec Loss: 11.217 (4.564) - Disc
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.572 
(3.271) - AE Loss: 1408471.750 (672973.312) - AE Rec Loss: 9.552 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.568) - Batch(s): 0.567 
(3.271) - AE Loss: 86192.680 (672973.312) - AE Rec Loss: 0.585 (4.564) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.536) - Batch(s): 0.659 
(3.126) - AE Loss: 123941.133 (671468.812) - AE Rec Loss: 0.841 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.536) - Batch(s): 0.658 
(3.126) - AE Loss: 368176.250 (671468.812) - AE Rec Loss: 2.497 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.657 
(3.126) - AE Loss: 236085.594 (671468.812) - AE Rec Loss: 1.601 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.536) - Batch(s): 0.658 
(3.126) - AE Loss: 185559.703 (671468.812) - AE Rec Loss: 1.258 (4.554) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.536) - Batch(s): 0.659 
(3.126) - AE Loss: 1582412.500 (671468.812) - AE Rec Loss: 10.731 (4.554) - Disc
Loss: 0.000 (0.000) - 4.43 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.536) - Batch(s): 0.658 
(3.126) - AE Loss: 1503187.750 (671468.812) - AE Rec Loss: 10.194 (4.554) - Disc
Loss: 0.000 (0.000) - 4.42 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.727 
(3.256) - AE Loss: 299940.719 (671042.938) - AE Rec Loss: 2.034 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.713 
(3.256) - AE Loss: 1820045.000 (671042.938) - AE Rec Loss: 12.343 (4.551) - Disc
Loss: 0.000 (0.000) - 4.86 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.730 
(3.256) - AE Loss: 217502.078 (671042.938) - AE Rec Loss: 1.475 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.726 
(3.256) - AE Loss: 119646.805 (671042.938) - AE Rec Loss: 0.811 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.723 
(3.256) - AE Loss: 1349126.625 (671042.938) - AE Rec Loss: 9.149 (4.551) - Disc 
Loss: 0.000 (0.000) - 4.84 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.531) - Batch(s): 5.726 
(3.256) - AE Loss: 1662300.750 (671042.938) - AE Rec Loss: 11.273 (4.551) - Disc
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.553 
(3.122) - AE Loss: 282558.688 (667590.875) - AE Rec Loss: 1.916 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.90 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.565 
(3.122) - AE Loss: 583667.125 (667590.875) - AE Rec Loss: 3.958 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.564 
(3.122) - AE Loss: 211832.125 (667590.875) - AE Rec Loss: 1.437 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.573 
(3.122) - AE Loss: 1473268.500 (667590.875) - AE Rec Loss: 9.991 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.567 
(3.122) - AE Loss: 531263.375 (667590.875) - AE Rec Loss: 3.603 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.87 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.504) - Batch(s): 0.565 
(3.122) - AE Loss: 67636.281 (667590.875) - AE Rec Loss: 0.459 (4.527) - Disc 
Loss: 0.000 (0.000) - 4.88 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
[[36m2023-11-29 05:41:28,659[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,699[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,719[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,730[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,791[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
[[36m2023-11-29 05:41:28,801[0m][[34mroot[0m][[32mINFO[0m] - Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.[0m
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
{'hf_model_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_tokenizer_name': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract', 'hf_proj_type': 'mlp', 'hf_pooler_type': 'cls_last_hidden_state_pooler', 'context_length': 256, 'hf_model_pretrained': False}
[[36m2023-11-29 05:41:30,909[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,914[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,930[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:30,988[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:31,015[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
[[36m2023-11-29 05:41:31,037[0m][[34mroot[0m][[32mINFO[0m] - Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/f42acd8c27f580f7cdedd60945977fb8111cca09/open_clip_pytorch_model.bin).[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:31,511[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 10[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:41:31,608[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 9[0m
[[36m2023-11-29 05:41:31,614[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 8[0m
=> Instantiate accelerator 
=> Instantiate accelerator 
[[36m2023-11-29 05:41:31,692[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 7[0m
=> Instantiate accelerator 
[[36m2023-11-29 05:41:31,693[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 6[0m
[[36m2023-11-29 05:41:31,705[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 11[0m
[[36m2023-11-29 05:41:31,708[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:41:31,708[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
[[36m2023-11-29 05:41:31,708[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Mixed precision: no
=> Mixed precision: no
=> Running in inference mode: False
[[36m2023-11-29 05:41:31,709[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
=> Running in inference mode: False
=> Mixed precision: no
len(train_dataset) = 54706
=> Instantiating train dataloader 
=> Mixed precision: no
=> Running in inference mode: False
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
[[36m2023-11-29 05:41:31,710[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Instantiating train dataloader 
len(valid_dataset) = 4
len(valid_dataloader) = 1
len(train_dataset) = 54706
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
=> Mixed precision: no
len(valid_dataset) = 4
=> Instantiating the optimizer 
len(train_dataloader) = 2279
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Running in inference mode: False
=> Instantiating valid dataloader 
len(valid_dataloader) = 1
=> Instantiating valid dataloader 
=> Instantiating train dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataset) = 4
len(train_dataset) = 54706
=> Preparing model 
len(valid_dataloader) = 1
len(valid_dataloader) = 1
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
len(train_dataloader) = 2279
=> Instantiating the optimizer 
=> Instantiating valid dataloader 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataset) = 4
=> Instantiating the optimizer 
=> Preparing opt_disc 
batch_size = 2, learning rate = 4.5e-06
len(valid_dataloader) = 1
=> Preparing model 
=> Preparing opt_disc 
=> Preparing model 
[[36m2023-11-29 05:41:31,717[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 12 nodes.[0m
=> Preparing opt_disc 
=> Instantiating the optimizer 
=> Mixed precision: no
=> Preparing model 
=> Running in inference mode: False
batch_size = 2, learning rate = 4.5e-06
=> Instantiating train dataloader 
len(train_dataset) = 54706
len(train_dataloader) = 2279
=> Instantiating valid dataloader 
len(valid_dataset) = 4
=> Preparing opt_disc 
len(valid_dataloader) = 1
=> Preparing model 
=> Instantiating the optimizer 
batch_size = 2, learning rate = 4.5e-06
=> Preparing opt_disc 
=> Preparing model 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing opt_ae 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Preparing criterion 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
=> Loading from checkpoint 
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
Loaded checkpoint at epoch 0 and step 401
Loaded checkpoint at epoch 0 and step 401
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
len(train_dataloader) AGAIN = 2280
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
Loaded from checkpoint
=> Starting model training 
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
Loaded from checkpoint
=> Starting model training 
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[Epoch <000/100>: Step <401/2280>] - Data(s): 4.034 (5.543) - Batch(s): 11.677 
(11.648) - AE Loss: 175637.531 (557868.688) - AE Rec Loss: 1.191 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 5.430 (5.543) - Batch(s): 11.662 
(11.648) - AE Loss: 589850.375 (557868.688) - AE Rec Loss: 4.000 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 2.930 (5.543) - Batch(s): 11.549 
(11.648) - AE Loss: 108926.836 (557868.688) - AE Rec Loss: 0.739 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 7.064 (5.543) - Batch(s): 11.680 
(11.648) - AE Loss: 1389440.125 (557868.688) - AE Rec Loss: 9.423 (3.783) - Disc
Loss: 0.000 (0.000) - 0.93 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 10.198 (5.543) - Batch(s): 11.552 
(11.648) - AE Loss: 1336065.125 (557868.688) - AE Rec Loss: 9.061 (3.783) - Disc
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <401/2280>] - Data(s): 3.125 (5.543) - Batch(s): 11.522 
(11.648) - AE Loss: 395217.000 (557868.688) - AE Rec Loss: 2.680 (3.783) - Disc 
Loss: 0.000 (0.000) - 0.92 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.566 
(6.106) - AE Loss: 182635.578 (762433.250) - AE Rec Loss: 1.239 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.97 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.565 
(6.106) - AE Loss: 287702.438 (762433.250) - AE Rec Loss: 1.951 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.97 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.565 
(6.106) - AE Loss: 165772.578 (762433.250) - AE Rec Loss: 1.124 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.98 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.553 
(6.106) - AE Loss: 2796804.500 (762433.250) - AE Rec Loss: 18.967 (5.171) - Disc
Loss: 0.000 (0.000) - 0.98 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.572 
(6.106) - AE Loss: 433684.000 (762433.250) - AE Rec Loss: 2.941 (5.171) - Disc 
Loss: 0.000 (0.000) - 0.98 m remaining

[Epoch <000/100>: Step <402/2280>] - Data(s): 0.000 (2.772) - Batch(s): 0.563 
(6.106) - AE Loss: 2047651.250 (762433.250) - AE Rec Loss: 13.887 (5.171) - Disc
Loss: 0.000 (0.000) - 0.98 m remaining

[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.891 
(5.034) - AE Loss: 355634.562 (836485.750) - AE Rec Loss: 2.412 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.951) - Batch(s): 2.891 
(5.034) - AE Loss: 1463744.750 (836485.750) - AE Rec Loss: 9.927 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.891 
(5.034) - AE Loss: 194663.047 (836485.750) - AE Rec Loss: 1.320 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.22 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 2.241 (1.951) - Batch(s): 2.890 
(5.034) - AE Loss: 1638400.750 (836485.750) - AE Rec Loss: 11.111 (5.673) - Disc
Loss: 0.000 (0.000) - 1.21 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.001 (1.951) - Batch(s): 2.889 
(5.034) - AE Loss: 160591.953 (836485.750) - AE Rec Loss: 1.089 (5.673) - Disc 
Loss: 0.000 (0.000) - 1.22 m remaining

[Epoch <000/100>: Step <403/2280>] - Data(s): 0.000 (1.951) - Batch(s): 2.889 
(5.034) - AE Loss: 1837879.750 (836485.750) - AE Rec Loss: 12.464 (5.673) - Disc
Loss: 0.000 (0.000) - 1.22 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.566 
(3.917) - AE Loss: 124873.148 (813251.188) - AE Rec Loss: 0.847 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.464) - Batch(s): 0.573 
(3.917) - AE Loss: 610614.438 (813251.188) - AE Rec Loss: 4.141 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.554 
(3.917) - AE Loss: 1485997.875 (813251.188) - AE Rec Loss: 10.078 (5.515) - Disc
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.001 (1.464) - Batch(s): 0.563 
(3.917) - AE Loss: 58143.953 (813251.188) - AE Rec Loss: 0.394 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.566 
(3.917) - AE Loss: 173858.328 (813251.188) - AE Rec Loss: 1.179 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.27 m remaining

[Epoch <000/100>: Step <404/2280>] - Data(s): 0.000 (1.464) - Batch(s): 0.565 
(3.917) - AE Loss: 171391.844 (813251.188) - AE Rec Loss: 1.162 (5.515) - Disc 
Loss: 0.000 (0.000) - 1.26 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.001 (1.171) - Batch(s): 0.567 
(3.246) - AE Loss: 243299.297 (763759.312) - AE Rec Loss: 1.650 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.001 (1.171) - Batch(s): 0.553 
(3.246) - AE Loss: 101111.672 (763759.312) - AE Rec Loss: 0.686 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.563 
(3.246) - AE Loss: 1538778.625 (763759.312) - AE Rec Loss: 10.436 (5.180) - Disc
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.572 
(3.246) - AE Loss: 1332342.250 (763759.312) - AE Rec Loss: 9.036 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.564 
(3.246) - AE Loss: 1393755.250 (763759.312) - AE Rec Loss: 9.452 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.31 m remaining

[Epoch <000/100>: Step <405/2280>] - Data(s): 0.000 (1.171) - Batch(s): 0.568 
(3.246) - AE Loss: 146819.125 (763759.312) - AE Rec Loss: 0.996 (5.180) - Disc 
Loss: 0.000 (0.000) - 1.32 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.668 
(3.316) - AE Loss: 80472.344 (726589.438) - AE Rec Loss: 0.546 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.668 
(3.316) - AE Loss: 1708632.500 (726589.438) - AE Rec Loss: 11.587 (4.927) - Disc
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.667 
(3.316) - AE Loss: 511070.594 (726589.438) - AE Rec Loss: 3.466 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 2.436 (1.076) - Batch(s): 3.668 
(3.316) - AE Loss: 161380.875 (726589.438) - AE Rec Loss: 1.094 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.000 (1.076) - Batch(s): 3.667 
(3.316) - AE Loss: 216518.734 (726589.438) - AE Rec Loss: 1.468 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.60 m remaining

[Epoch <000/100>: Step <406/2280>] - Data(s): 0.001 (1.076) - Batch(s): 3.668 
(3.316) - AE Loss: 200669.188 (726589.438) - AE Rec Loss: 1.361 (4.927) - Disc 
Loss: 0.000 (0.000) - 1.61 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.572 
(2.923) - AE Loss: 144587.891 (706129.312) - AE Rec Loss: 0.981 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.553 
(2.923) - AE Loss: 99155.539 (706129.312) - AE Rec Loss: 0.672 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.566 
(2.923) - AE Loss: 117527.836 (706129.312) - AE Rec Loss: 0.797 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.563 
(2.923) - AE Loss: 173573.703 (706129.312) - AE Rec Loss: 1.177 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.566 
(2.923) - AE Loss: 419106.938 (706129.312) - AE Rec Loss: 2.842 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.66 m remaining

[Epoch <000/100>: Step <407/2280>] - Data(s): 0.000 (0.922) - Batch(s): 0.564 
(2.923) - AE Loss: 155312.688 (706129.312) - AE Rec Loss: 1.053 (4.789) - Disc 
Loss: 0.000 (0.000) - 1.65 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.573 
(2.628) - AE Loss: 106076.633 (655652.688) - AE Rec Loss: 0.719 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.554 
(2.628) - AE Loss: 109684.945 (655652.688) - AE Rec Loss: 0.744 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.564 
(2.628) - AE Loss: 233662.484 (655652.688) - AE Rec Loss: 1.585 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.564 
(2.628) - AE Loss: 192119.719 (655652.688) - AE Rec Loss: 1.303 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.566 
(2.628) - AE Loss: 306543.906 (655652.688) - AE Rec Loss: 2.079 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.70 m remaining

[Epoch <000/100>: Step <408/2280>] - Data(s): 0.000 (0.807) - Batch(s): 0.567 
(2.628) - AE Loss: 67860.945 (655652.688) - AE Rec Loss: 0.460 (4.446) - Disc 
Loss: 0.000 (0.000) - 1.71 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.646 
(2.630) - AE Loss: 1361045.750 (626007.500) - AE Rec Loss: 9.230 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 266066.875 (626007.500) - AE Rec Loss: 1.804 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.644 
(2.630) - AE Loss: 404438.125 (626007.500) - AE Rec Loss: 2.743 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.647 
(2.630) - AE Loss: 173930.484 (626007.500) - AE Rec Loss: 1.180 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.645 
(2.630) - AE Loss: 56404.852 (626007.500) - AE Rec Loss: 0.383 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.91 m remaining

[Epoch <000/100>: Step <409/2280>] - Data(s): 0.000 (0.736) - Batch(s): 2.646 
(2.630) - AE Loss: 102800.383 (626007.500) - AE Rec Loss: 0.697 (4.245) - Disc 
Loss: 0.000 (0.000) - 1.92 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (0.662) - Batch(s): 0.564 
(2.424) - AE Loss: 221574.312 (598853.688) - AE Rec Loss: 1.503 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.573 
(2.424) - AE Loss: 1658421.500 (598853.688) - AE Rec Loss: 11.247 (4.061) - Disc
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.554 
(2.424) - AE Loss: 117051.727 (598853.688) - AE Rec Loss: 0.794 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (0.662) - Batch(s): 0.566 
(2.424) - AE Loss: 153664.141 (598853.688) - AE Rec Loss: 1.042 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.97 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.000 (0.662) - Batch(s): 0.565 
(2.424) - AE Loss: 111035.742 (598853.688) - AE Rec Loss: 0.753 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <410/2280>] - Data(s): 0.001 (0.662) - Batch(s): 0.566 
(2.424) - AE Loss: 245176.719 (598853.688) - AE Rec Loss: 1.663 (4.061) - Disc 
Loss: 0.000 (0.000) - 1.96 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.327 
(2.404) - AE Loss: 76055.891 (595402.688) - AE Rec Loss: 0.516 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.340 
(2.404) - AE Loss: 67894.953 (595402.688) - AE Rec Loss: 0.460 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.344 
(2.404) - AE Loss: 113109.789 (595402.688) - AE Rec Loss: 0.767 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.001 (0.616) - Batch(s): 2.339 
(2.404) - AE Loss: 1442235.250 (595402.688) - AE Rec Loss: 9.781 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.14 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.342 
(2.404) - AE Loss: 1796938.875 (595402.688) - AE Rec Loss: 12.186 (4.038) - Disc
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <411/2280>] - Data(s): 0.000 (0.616) - Batch(s): 2.338 
(2.404) - AE Loss: 175332.359 (595402.688) - AE Rec Loss: 1.189 (4.038) - Disc 
Loss: 0.000 (0.000) - 2.15 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.617 
(2.338) - AE Loss: 1548754.625 (656528.812) - AE Rec Loss: 10.503 (4.452) - Disc
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.619 
(2.338) - AE Loss: 153084.047 (656528.812) - AE Rec Loss: 1.038 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.987 (0.571) - Batch(s): 1.620 
(2.338) - AE Loss: 67191.500 (656528.812) - AE Rec Loss: 0.456 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.619 
(2.338) - AE Loss: 1405653.125 (656528.812) - AE Rec Loss: 9.533 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.620 
(2.338) - AE Loss: 175487.484 (656528.812) - AE Rec Loss: 1.190 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.27 m remaining

[Epoch <000/100>: Step <412/2280>] - Data(s): 0.000 (0.571) - Batch(s): 1.618 
(2.338) - AE Loss: 1302064.250 (656528.812) - AE Rec Loss: 8.830 (4.452) - Disc 
Loss: 0.000 (0.000) - 2.28 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.535 
(2.421) - AE Loss: 91025.008 (639690.062) - AE Rec Loss: 0.617 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.532 
(2.421) - AE Loss: 146426.828 (639690.062) - AE Rec Loss: 0.993 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.520 
(2.421) - AE Loss: 1446252.750 (639690.062) - AE Rec Loss: 9.808 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.531 
(2.421) - AE Loss: 1471682.875 (639690.062) - AE Rec Loss: 9.980 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.54 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.529 
(2.421) - AE Loss: 618972.312 (639690.062) - AE Rec Loss: 4.198 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <413/2280>] - Data(s): 0.000 (0.549) - Batch(s): 3.532 
(2.421) - AE Loss: 195345.547 (639690.062) - AE Rec Loss: 1.325 (4.338) - Disc 
Loss: 0.000 (0.000) - 2.55 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.566 
(2.288) - AE Loss: 84598.477 (651182.688) - AE Rec Loss: 0.574 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.001 (0.510) - Batch(s): 0.568 
(2.288) - AE Loss: 164562.375 (651182.688) - AE Rec Loss: 1.116 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.001 (0.510) - Batch(s): 0.555 
(2.288) - AE Loss: 98891.211 (651182.688) - AE Rec Loss: 0.671 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.59 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.566 
(2.288) - AE Loss: 422041.562 (651182.688) - AE Rec Loss: 2.862 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.000 (0.510) - Batch(s): 0.574 
(2.288) - AE Loss: 135959.094 (651182.688) - AE Rec Loss: 0.922 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <414/2280>] - Data(s): 0.001 (0.510) - Batch(s): 0.567 
(2.288) - AE Loss: 209222.797 (651182.688) - AE Rec Loss: 1.419 (4.416) - Disc 
Loss: 0.000 (0.000) - 2.60 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.646 
(2.179) - AE Loss: 1677028.125 (657620.250) - AE Rec Loss: 11.373 (4.460) - Disc
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.645 
(2.179) - AE Loss: 131822.609 (657620.250) - AE Rec Loss: 0.894 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.647 
(2.179) - AE Loss: 141360.375 (657620.250) - AE Rec Loss: 0.959 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.64 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.647 
(2.179) - AE Loss: 418490.375 (657620.250) - AE Rec Loss: 2.838 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.000 (0.476) - Batch(s): 0.647 
(2.179) - AE Loss: 271873.125 (657620.250) - AE Rec Loss: 1.844 (4.460) - Disc 
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <415/2280>] - Data(s): 0.001 (0.476) - Batch(s): 0.646 
(2.179) - AE Loss: 1509877.625 (657620.250) - AE Rec Loss: 10.240 (4.460) - Disc
Loss: 0.000 (0.000) - 2.65 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.815 
(2.211) - AE Loss: 212126.172 (669812.938) - AE Rec Loss: 1.439 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.000 (0.458) - Batch(s): 2.802 
(2.211) - AE Loss: 50072.758 (669812.938) - AE Rec Loss: 0.340 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.001 (0.458) - Batch(s): 2.813 
(2.211) - AE Loss: 536968.375 (669812.938) - AE Rec Loss: 3.642 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.001 (0.458) - Batch(s): 2.818 
(2.211) - AE Loss: 53495.883 (669812.938) - AE Rec Loss: 0.363 (4.542) - Disc 
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.001 (0.458) - Batch(s): 2.811 
(2.211) - AE Loss: 2915868.000 (669812.938) - AE Rec Loss: 19.774 (4.542) - Disc
Loss: 0.000 (0.000) - 2.87 m remaining

[Epoch <000/100>: Step <416/2280>] - Data(s): 0.001 (0.458) - Batch(s): 2.814 
(2.211) - AE Loss: 1715276.750 (669812.938) - AE Rec Loss: 11.632 (4.542) - Disc
Loss: 0.000 (0.000) - 2.86 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.568 
(2.114) - AE Loss: 86469.219 (672827.375) - AE Rec Loss: 0.586 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.568 
(2.114) - AE Loss: 58096.461 (672827.375) - AE Rec Loss: 0.394 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.566 
(2.114) - AE Loss: 1654722.000 (672827.375) - AE Rec Loss: 11.222 (4.563) - Disc
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.555 
(2.114) - AE Loss: 1632023.000 (672827.375) - AE Rec Loss: 11.068 (4.563) - Disc
Loss: 0.000 (0.000) - 2.90 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.574 
(2.114) - AE Loss: 1408554.000 (672827.375) - AE Rec Loss: 9.552 (4.563) - Disc 
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <417/2280>] - Data(s): 0.000 (0.431) - Batch(s): 0.565 
(2.114) - AE Loss: 1502449.250 (672827.375) - AE Rec Loss: 10.189 (4.563) - Disc
Loss: 0.000 (0.000) - 2.91 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 1.044 (0.412) - Batch(s): 1.685 
(2.090) - AE Loss: 1582510.125 (671362.812) - AE Rec Loss: 10.732 (4.553) - Disc
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 237567.516 (671362.812) - AE Rec Loss: 1.611 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.681 
(2.090) - AE Loss: 368582.250 (671362.812) - AE Rec Loss: 2.500 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.001 (0.412) - Batch(s): 1.683 
(2.090) - AE Loss: 185989.016 (671362.812) - AE Rec Loss: 1.261 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.684 
(2.090) - AE Loss: 124757.852 (671362.812) - AE Rec Loss: 0.846 (4.553) - Disc 
Loss: 0.000 (0.000) - 3.03 m remaining

[Epoch <000/100>: Step <418/2280>] - Data(s): 0.000 (0.412) - Batch(s): 1.682 
(2.090) - AE Loss: 1503411.500 (671362.812) - AE Rec Loss: 10.196 (4.553) - Disc
Loss: 0.000 (0.000) - 3.04 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.859 
(2.027) - AE Loss: 301187.656 (670969.938) - AE Rec Loss: 2.043 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 1662431.125 (670969.938) - AE Rec Loss: 11.274 (4.550) - Disc
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.859 
(2.027) - AE Loss: 1349549.750 (670969.938) - AE Rec Loss: 9.152 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.651 (0.393) - Batch(s): 1.224 
(2.027) - AE Loss: 218199.672 (670969.938) - AE Rec Loss: 1.480 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.13 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.859 
(2.027) - AE Loss: 120982.383 (670969.938) - AE Rec Loss: 0.820 (4.550) - Disc 
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <419/2280>] - Data(s): 0.000 (0.393) - Batch(s): 0.860 
(2.027) - AE Loss: 1820384.125 (670969.938) - AE Rec Loss: 12.345 (4.550) - Disc
Loss: 0.000 (0.000) - 3.12 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 1.288 
(1.980) - AE Loss: 583246.438 (667535.562) - AE Rec Loss: 3.955 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.001 (0.377) - Batch(s): 0.930 
(1.980) - AE Loss: 532338.375 (667535.562) - AE Rec Loss: 3.610 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.726 (0.377) - Batch(s): 1.275 
(1.980) - AE Loss: 282254.656 (667535.562) - AE Rec Loss: 1.914 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.001 (0.377) - Batch(s): 1.288 
(1.980) - AE Loss: 67181.711 (667535.562) - AE Rec Loss: 0.456 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.22 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 1.291 
(1.980) - AE Loss: 1472619.875 (667535.562) - AE Rec Loss: 9.987 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <420/2280>] - Data(s): 0.000 (0.377) - Batch(s): 1.286 
(1.980) - AE Loss: 210825.172 (667535.562) - AE Rec Loss: 1.430 (4.527) - Disc 
Loss: 0.000 (0.000) - 3.23 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.001 (0.360) - Batch(s): 15.482 
(2.564) - AE Loss: 420663.219 (656640.125) - AE Rec Loss: 2.853 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.483 
(2.564) - AE Loss: 320851.281 (656640.125) - AE Rec Loss: 2.176 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.001 (0.360) - Batch(s): 15.482 
(2.564) - AE Loss: 129786.992 (656640.125) - AE Rec Loss: 0.880 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.483 
(2.564) - AE Loss: 101383.320 (656640.125) - AE Rec Loss: 0.688 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.001 (0.360) - Batch(s): 15.482 
(2.564) - AE Loss: 1453325.000 (656640.125) - AE Rec Loss: 9.856 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.37 m remaining

[Epoch <000/100>: Step <421/2280>] - Data(s): 0.000 (0.360) - Batch(s): 15.482 
(2.564) - AE Loss: 106611.633 (656640.125) - AE Rec Loss: 0.723 (4.453) - Disc 
Loss: 0.000 (0.000) - 4.36 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.567 
(2.473) - AE Loss: 173475.047 (642935.500) - AE Rec Loss: 1.176 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.565 
(2.473) - AE Loss: 131129.953 (642935.500) - AE Rec Loss: 0.889 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.565 
(2.473) - AE Loss: 210044.797 (642935.500) - AE Rec Loss: 1.424 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.555 
(2.473) - AE Loss: 221047.984 (642935.500) - AE Rec Loss: 1.499 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.40 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.568 
(2.473) - AE Loss: 1445402.750 (642935.500) - AE Rec Loss: 9.802 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <422/2280>] - Data(s): 0.000 (0.343) - Batch(s): 0.574 
(2.473) - AE Loss: 1359240.250 (642935.500) - AE Rec Loss: 9.218 (4.360) - Disc 
Loss: 0.000 (0.000) - 4.41 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.575 
(2.390) - AE Loss: 194245.531 (640218.062) - AE Rec Loss: 1.317 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.555 
(2.390) - AE Loss: 1528632.250 (640218.062) - AE Rec Loss: 10.367 (4.342) - Disc
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.565 
(2.390) - AE Loss: 89339.070 (640218.062) - AE Rec Loss: 0.606 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.565 
(2.390) - AE Loss: 1742322.375 (640218.062) - AE Rec Loss: 11.816 (4.342) - Disc
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.567 
(2.390) - AE Loss: 549231.500 (640218.062) - AE Rec Loss: 3.725 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.45 m remaining

[Epoch <000/100>: Step <423/2280>] - Data(s): 0.000 (0.328) - Batch(s): 0.568 
(2.390) - AE Loss: 1335570.250 (640218.062) - AE Rec Loss: 9.057 (4.342) - Disc 
Loss: 0.000 (0.000) - 4.44 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.644 
(2.317) - AE Loss: 109488.234 (631876.125) - AE Rec Loss: 0.743 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.644 
(2.317) - AE Loss: 55408.430 (631876.125) - AE Rec Loss: 0.376 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.645 
(2.317) - AE Loss: 346120.312 (631876.125) - AE Rec Loss: 2.347 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.49 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.645 
(2.317) - AE Loss: 1592046.625 (631876.125) - AE Rec Loss: 10.797 (4.285) - Disc
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.645 
(2.317) - AE Loss: 377473.500 (631876.125) - AE Rec Loss: 2.560 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <424/2280>] - Data(s): 0.000 (0.315) - Batch(s): 0.645 
(2.317) - AE Loss: 237345.375 (631876.125) - AE Rec Loss: 1.610 (4.285) - Disc 
Loss: 0.000 (0.000) - 4.50 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.575 
(2.247) - AE Loss: 1437406.000 (625146.500) - AE Rec Loss: 9.748 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.555 
(2.247) - AE Loss: 75907.688 (625146.500) - AE Rec Loss: 0.515 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.567 
(2.247) - AE Loss: 305751.469 (625146.500) - AE Rec Loss: 2.074 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.568 
(2.247) - AE Loss: 131216.078 (625146.500) - AE Rec Loss: 0.890 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.567 
(2.247) - AE Loss: 171488.406 (625146.500) - AE Rec Loss: 1.163 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.53 m remaining

[Epoch <000/100>: Step <425/2280>] - Data(s): 0.000 (0.302) - Batch(s): 0.566 
(2.247) - AE Loss: 1301541.500 (625146.500) - AE Rec Loss: 8.827 (4.240) - Disc 
Loss: 0.000 (0.000) - 4.54 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.568 
(2.182) - AE Loss: 246369.734 (628714.688) - AE Rec Loss: 1.671 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.576 
(2.182) - AE Loss: 1648265.625 (628714.688) - AE Rec Loss: 11.178 (4.264) - Disc
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.567 
(2.182) - AE Loss: 537625.000 (628714.688) - AE Rec Loss: 3.646 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.565 
(2.182) - AE Loss: 1502396.750 (628714.688) - AE Rec Loss: 10.189 (4.264) - Disc
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.001 (0.290) - Batch(s): 0.568 
(2.182) - AE Loss: 111732.164 (628714.688) - AE Rec Loss: 0.758 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.58 m remaining

[Epoch <000/100>: Step <426/2280>] - Data(s): 0.000 (0.290) - Batch(s): 0.555 
(2.182) - AE Loss: 57422.938 (628714.688) - AE Rec Loss: 0.389 (4.264) - Disc 
Loss: 0.000 (0.000) - 4.57 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.646 
(2.126) - AE Loss: 152080.422 (626028.000) - AE Rec Loss: 1.031 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.646 
(2.126) - AE Loss: 1503301.750 (626028.000) - AE Rec Loss: 10.195 (4.246) - Disc
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 388027.062 (626028.000) - AE Rec Loss: 2.631 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 107708.680 (626028.000) - AE Rec Loss: 0.730 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.645 
(2.126) - AE Loss: 88009.086 (626028.000) - AE Rec Loss: 0.597 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.62 m remaining

[Epoch <000/100>: Step <427/2280>] - Data(s): 0.000 (0.280) - Batch(s): 0.647 
(2.126) - AE Loss: 112144.391 (626028.000) - AE Rec Loss: 0.761 (4.246) - Disc 
Loss: 0.000 (0.000) - 4.61 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.000 (0.304) - Batch(s): 2.928 
(2.154) - AE Loss: 107303.227 (624615.312) - AE Rec Loss: 0.728 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.000 (0.304) - Batch(s): 2.944 
(2.154) - AE Loss: 452470.156 (624615.312) - AE Rec Loss: 3.069 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.000 (0.304) - Batch(s): 2.940 
(2.154) - AE Loss: 73220.953 (624615.312) - AE Rec Loss: 0.497 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.000 (0.304) - Batch(s): 2.941 
(2.154) - AE Loss: 43573.023 (624615.312) - AE Rec Loss: 0.295 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.82 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.960 (0.304) - Batch(s): 2.937 
(2.154) - AE Loss: 1464165.250 (624615.312) - AE Rec Loss: 9.930 (4.236) - Disc 
Loss: 0.000 (0.000) - 4.83 m remaining

[Epoch <000/100>: Step <428/2280>] - Data(s): 0.000 (0.304) - Batch(s): 2.940 
(2.154) - AE Loss: 1500508.500 (624615.312) - AE Rec Loss: 10.176 (4.236) - Disc
Loss: 0.000 (0.000) - 4.82 m remaining

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
=> Starting 
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 1, 48, 48) = 2304 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth
loaded pretrained LPIPS loss from .cache/vgg.pth

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        

            === Dataset stats for split=train ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/train_images
            Number of samples: 54706
        

            === Dataset stats for split=test ===
            CSV file: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test.csv
            Data directory: /mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/data/mg/test_images
            Number of samples: 4
        
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/mnt/Client/Lachlai6mf74jkmjamzpg5ro3q3jvo3e/laclactagnpqiwtzcuvd76qfflxevkxu/isc-demos/stanford/CompRx/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
